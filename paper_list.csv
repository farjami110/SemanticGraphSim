papers,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Swift Markov Logic for Probabilistic Reasoning on Knowledge Graphs,A Soft Vadalog program induces what we call a Probabilistic Knowledge Graph.,""Luigi Bellomarini, Eleonora Laurenza, Emanuel Sallinger, Evgeny Sherkhonov"",ArXiv,,,10.48550/arXiv.2210.00283,,2022,,https://doi.org/10.48550/arXiv.2210.00283,https://semanticscholar.org/paper/d3d2a24651d9f102084f22754458ddd66025ea90,""We provide a framework for probabilistic reasoning in Vadalog-based Knowledge Graphs (KGs), satisfying the requirements of ontological reasoning: full recursion, powerful existential quanti?cation, expression of inductive de?nitions. Vadalog is a Knowledge Representation and Reasoning (KRR) language based on Warded Datalog+/-, a logical core language of existential rules, with a good balance between computational complexity and expressive power. Handling uncertainty is essential for reasoning with KGs. Yet Vadalog and Warded Datalog+/- are not covered by the existing probabilistic logic programming and statistical relational learning approaches for several reasons, including insuf?cient support for recursion with existential quanti?cation, and the impossibility to express inductive de?nitions. In this work, we introduce Soft Vadalog, a probabilistic extension to Vadalog, satisfying these desiderata. A Soft Vadalog program induces what we call a Probabilistic Knowledge Graph (PKG), which consists of a probability distribution on a network of chase instances, structures obtained by grounding the rules over a database using the chase procedure. We exploit PKGs for probabilistic marginal infere",nce. We discuss,the theory and present MCMC-chase,", a",Monte Carlo,method to use Soft Vadalog in practice.,We apply our framework to solve data management and industria,"l problems, and experimentally evaluate it in the Vadalog system. Under",consid,eration,in,Theory,and,Practice,o,f Logic,Programming,(,"TPLP)."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Towards Loosely-Coupling Knowledge Graph Embeddings and Ontology-based Reasoning,The prediction accuracy of knowledge graph embeddings is enhanced by domain knowledge that may not be included in the input knowledge graph.,""Zoi Kaoudi, Abelardo Carlos Mart??nez Lorenzo, V. Markl"",ArXiv,,,,,2022,2,,https://semanticscholar.org/paper/8ef2e6b11b519b609bfaa7ed056f621cee15d552,""Knowledge graph completion (a.k.a. link prediction), i.e., the task of inferring missing information from knowledge graphs, is a widely used task in many applications, such as product recommendation and question answering. The state-of-the-art approaches of knowledge graph embeddings and/or rule mining and reasoning are data-driven and, thus, solely based on the information the input knowledge graph contains. This leads to unsatisfactory prediction results which make such solutions inapplicable to crucial domains such as healthcare. To further enhance the accuracy of knowledge graph completion we propose to loosely-couple the data-driven power of knowledge graph embeddings with domain-specific reasoning stem-ming from experts or entailment regimes (e.g., OWL2). In this way, we not only enhance the prediction accuracy with domain knowledge that may not be included in the input knowledge graph but also allow users to plugin their own knowledge graph embedding and reasoning method. Our initial results show that we enhance the MRR accuracy of vanilla knowledge graph embeddings by up to 3x and outperform hybrid solutions that combine knowledge graph embeddings with rule mining and reasoning up to 3.5x","MRR."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Knowledge Graph Reasoning with Logics and Embeddings: Survey and Perspective,Logic-based and embedding-based methods are integrated in knowledge graph reasoning.,""Wen Zhang, Jiaoyan Chen, Juan Li, Zezhong Xu, Jeff Z. Pan, Huajun Chen"",ArXiv,,,,,2022,3,,https://semanticscholar.org/paper/4baf6f668b6b10a33a16f12aa51b0edef02b1c35,""Knowledge graph (KG) reasoning is becoming increasingly popular in both academia and industry. Conventional KG reasoning based on symbolic logic is deterministic, with reasoning results being explainable, while modern embedding-based reasoning can deal with uncertainty and predict plausible knowledge, often with high efficiency via vector computation. A promising direction is to integrate both logic-based and embedding-based methods, with the vision to have advantages of both. It has attracted wide research attention with more and more works published in recent years. In this paper, we comprehensively survey these works, focusing on how logics and embeddings are integrated. We first briefly introduce preliminaries, then systematically categorize and discuss works of logic and embedding-aware KG reasoning from different perspectives, and finally conclude and discuss the challenges and further directions."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"An Overview of Knowledge Graph Reasoning: Key Technologies and Applications,Knowledge graph-oriented knowledge reasoning aims to deduce new knowledge or identify wrong knowledge from existing knowledge.,""Yonghong Chen, Hao Li, Han Li, Wenhao Liu, Yirui Wu, Qian Huang, Shaohua Wan"",J. Sens. Actuator Networks,,,10.3390/jsan11040078,https://www.mdpi.com/2224-2708/11/4/78/pdf?version=1669276833,2022,1,https://doi.org/10.3390/jsan11040078,https://semanticscholar.org/paper/f80ee5510c9b8259250013887e141b0556bb5464,""In recent years, with the rapid development of Internet technology and applications, the scale of Internet data has exploded, which contains a significant amount of valuable knowledge. The best methods for the organization, expression, calculation, and deep analysis of this knowledge have attracted a great deal of attention. The knowledge graph has emerged as a rich and intuitive way to express knowledge. Knowledge reasoning based on knowledge graphs is one of the current research hot spots in knowledge graphs and has played an important role in wireless communication networks, intelligent question answering, and other applications. Knowledge graph-oriented knowledge reasoning aims to deduce new knowledge or identify wrong knowledge from existing knowledge. Different from traditional knowledge reasoning, knowledge reasoning methods oriented to knowledge graphs are more diversified due to the concise, intuitive, flexible, and rich knowledge expression forms in knowledge graphs. Based on the basic concepts of knowledge graphs and knowledge graph reasoning, this",paper introduc,es the latest research progress in,kn,owledge grap,h-oriented knowledge reasoning methods i,"n recent years. Specifically, according to different reasoning","methods, knowledge graph reasoning includes rule-based reasoning, dist",ributed,repres,ent,ation-b,ased,reasonin,"g,",neural,network-bas,ed,"reasoning, and mixed reasoning. These methods are summarized in detail, and the future research directions and prospects of knowledge reasoning based on knowledge graphs are discussed and prospected."",,Review",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Analysis of Knowledge Graph Path Reasoning Based on Variational Reasoning,Knowledge graph reasoning improves model accuracy and enhancing model learning and reasoning capabilities.,""Hongmei Tang, Wenzhong Tang, Ruichen Li, Yanyang Wang, Shuai Wang, Lihong Wang"",Applied Sciences,,0.44 (11182),10.3390/app12126168,https://www.mdpi.com/2076-3417/12/12/6168/pdf?version=1655459548,2022,,https://doi.org/10.3390/app12126168,https://semanticscholar.org/paper/8f56e567f1b6df0d3e80e1604520bf2cd5c23209,""Knowledge graph (KG) reasoning improves the perception ability of graph structure features, improving model accuracy and enhancing model learning and reasoning capabilities. This paper proposes a new GraphDIVA model based on the variational reasoning divergent autoencoder (DIVA) model. The network structures and calculation processes of the models are analyzed. The GraphSAGE algorithm is introduced into the path reasoning module to solve the inability of the original model to perceive the features of the graph structure, which leads to a decline in the accuracy rate. Hence, GraphDIVA can achieve a higher accuracy rate with fewer learning iterations. The experiments show the efficiency and effectiveness of our model and proves that our method has a better effect on the accuracy rate and training difficulty than the baseline model on the FB15k-237 and NELL-995 benchmark datasets."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"""Reasoning over Different Types of Knowledge Graphs: Static, Temporal and Multi-Modal"",Knowledge graph reasoning is a fast-growing research direction.,""K. Liang, Lingyuan Meng, Meng Liu, Yue Liu, Wenxuan Tu, Siwei Wang, Sihang Zhou, Xinwang Liu, Fu Sun"",ArXiv,,,10.48550/arXiv.2212.05767,,2022,3,https://doi.org/10.48550/arXiv.2212.05767,https://semanticscholar.org/paper/4b963961f9990dea41133cd09109da1b3fed531f,""—Knowledge graph reasoning (KGR), aiming to deduce new facts from existing facts based on mined logic rules underlying knowledge graphs (KGs), has become a fast-growing research direction. It has been proven to signi?cantly bene?t the usage of KGs in many AI applications, such as question answering and recommendation systems, etc. According to the graph types, the existing KGR models can be roughly divided into three categories, i.e., static models, temporal models, and multi-modal models. The early works in this domain mainly focus on static KGR and tend to directly apply general knowledge graph embedding models to the reasoning task. However, these models are not suitable for more complex but practical tasks, such as inductive static KGR, temporal KGR, and multi-modal KGR. To this end, multiple works have been developed recently, but no survey papers and open-source repositories comprehensively summarize and discuss models in this important direction. To ?ll the gap, we conduct a survey for knowledge graph reasoning tracing from static to temporal and then to multi-modal KGs. Concretely, the preliminaries, summaries of KGR models, and typical datasets are",introduced and,"discussed consequently. Moreover,",we,discuss the,challenges and potential opportunities.,The corresponding open-source repository is shared on GitHub:,"https://github.com/LIANGKE23/Awesome-Knowledge-Graph-Reasoning."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Knowledge graph representation and reasoning,Knowledge graphs can be seen as a means to tackle the problem of explainability in AI.,""Erik  Cambria, Shaoxiong  Ji, Shirui  Pan, Philip S. Yu"",Neurocomputing,,1.66 (1770),10.1016/j.neucom.2021.05.101,,2021,1,https://doi.org/10.1016/j.neucom.2021.05.101,https://semanticscholar.org/paper/75484f4d2f570c2aef353d7e091b5c202dedc7ff,""Recent years have witnessed the release of many open-source and enterprise-driven knowledge graphs with a dramatic increase of applications of knowledge representation and reasoning in fields such as natural language processing, computer vision, and bioinformatics. With those large-scale knowledge graphs, recent research tends to incorporate human knowledge and imitate human’s ability of relational reasoning [1]. Factual knowledge stored in knowledge bases or knowledge graphs can be utilized as a source for logical reasoning and, hence, be integrated to improve real-world applications [2–6]. Emerging embedding-based methods for knowledge graph representation have shown their ability to capture relational facts and model different scenarios with heterogenous information [7]. By combining symbolic reasoning methods or Bayesian models, deep representation learning techniques on knowledge graphs attempt to handle complex reasoning with relational path and symbolic logic and capture the uncertainty with probabilistic inference [8,9]. Furthermore, efficient representation learning and reasoning can be one of the paths towards the emulation of high-level cognition and human-level intelligence. Knowledge graphs can also be seen as a means to tackle the problem of explainability in AI. These trends naturally facilitate relevant downstream applications which inject structural knowledge into wide-applied neural architectures such as attention-based transformers and graph neural networks [10,11]."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Guest Editorial: Knowledge Graph Representation and Reasoning,Knowledge graphs can be seen as a means to tackle the problem of explainability in AI.,""E. Cambria, Shaoxiong Ji, Shirui Pan, Philip S. Yu"",,,,,,2021,1,,https://semanticscholar.org/paper/433ad31f41f41ceecba12582fd7dd45c17172a0c,""Recent years have witnessed the release of many open-source and enterprisedriven knowledge graphs with a dramatic increase of applications of knowledge representation and reasoning in fields such as natural language processing, computer vision, and bioinformatics. With those large-scale knowledge graphs, recent research tends to incorporate human knowledge and imitate human’s ability of relational reasoning [1]. Factual knowledge stored in knowledge bases or knowledge graphs can be utilized as a source for logical reasoning and, hence, be integrated to improve real-world applications [2–6]. Emerging embedding-based methods for knowledge graph representation have shown their ability to capture relational facts and model different scenarios with heterogenous information [7]. By combining symbolic reasoning methods or Bayesian models, deep representation learning techniques on knowledge graphs attempt to handle complex reasoning with relational path and symbolic logic and capture the uncertainty with probabilistic inference [8, 9]. Furthermore, efficient representation learning and reasoning can be one of the paths towards the emulation of high-level cognition and human-level intelligence. Knowledge graphs can also be seen as a means to tackle the problem of explainability in AI. These trends naturally facilitate relevant downstream applications which inject structural knowledge into wide-applied neural architectures such as attention-based transformers and graph neural networks [10,11]."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Knowledge graphs completion via probabilistic reasoning,A model that uses association rules to make inferences outperforms state-of-the-art approaches in knowledge base completion tasks.,""Richong  Zhang, Yongyi  Mao, Weihua  Zhao"",Inf. Sci.,,,10.1016/j.ins.2020.02.016,,2020,10,https://doi.org/10.1016/j.ins.2020.02.016,https://semanticscholar.org/paper/6ee94b8ade6e86c6c820c9ed21ae8ffca874e196,""Abstract Constructing large-scale knowledge base has encountered a bottleneck because of the limitation of natural language processing. Many approaches have been put forward to infer new facts based on existing knowledge. Graph feature models mine rule-like patterns from a knowledge base and use them to predict missing edges. These models take account of the graph structure information and they can explain the existence of a fact reasonably. Existing models only describe local interaction between entities, but how to model co-relationships among facts globally is a tough problem. In this paper, we develop an efficient model which uses association rules to make inferences. First, we use a rule mining model to detect simple association rules and use them to produce large amounts of evidence. Second, based on all the produced evidence and the connections among them, we construct a factor graph which represents the inference space. Then, we develop an EM inference model, wherein the E-step we use Belief Propagation to calculate the marginal distribution of candidate edges and, in the M-step we propose a Generalized Iterative Proportional Fitting algorithm to re-learn the confidence of soft rules. Experiments show that our approach outperforms state-of-the-art approaches in knowledge base completion (KBC) tasks."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"An Overview of Knowledge Graph Reasoning: Key Technologies and Applications,Knowledge graph-oriented knowledge reasoning aims to deduce new knowledge or identify wrong knowledge from existing knowledge.,""Yonghong Chen, Hao Li, Han Li, Wenhao Liu, Yirui Wu, Qian Huang, Shaohua Wan"",J. Sens. Actuator Networks,,,10.3390/jsan11040078,https://www.mdpi.com/2224-2708/11/4/78/pdf?version=1669276833,2022,1,https://doi.org/10.3390/jsan11040078,https://semanticscholar.org/paper/f80ee5510c9b8259250013887e141b0556bb5464,""In recent years, with the rapid development of Internet technology and applications, the scale of Internet data has exploded, which contains a significant amount of valuable knowledge. The best methods for the organization, expression, calculation, and deep analysis of this knowledge have attracted a great deal of attention. The knowledge graph has emerged as a rich and intuitive way to express knowledge. Knowledge reasoning based on knowledge graphs is one of the current research hot spots in knowledge graphs and has played an important role in wireless communication networks, intelligent question answering, and other applications. Knowledge graph-oriented knowledge reasoning aims to deduce new knowledge or identify wrong knowledge from existing knowledge. Different from traditional knowledge reasoning, knowledge reasoning methods oriented to knowledge graphs are more diversified due to the concise, intuitive, flexible, and rich knowledge expression forms in knowledge graphs. Based on the basic concepts of knowledge graphs and knowledge graph reasoning, this paper introduces the latest research progress in knowledge graph-oriented knowledge reasoning methods in recent years. Specifically, according to different reasoning methods, knowledge graph reasoning includes rule-based reasoning, distributed representation-based reasoning, neural network-based reasoni","ng, and mixed reasoning. These methods are",summarized in,"detail,",and the future res,earch,directions and prospects of knowle,dge reasoning,based,on,kno,wledge,gr,aphs,are,d,iscussed,and,pro,"spected.""",",,Review",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Reading and Reasoning with Knowledge Graphs,Knowledge base information can successfully incorporate machine learning models of natural language.,M. Gardner,,,,,,2015,9,,https://semanticscholar.org/paper/1a714200fed1906ba26d311dde8398a49c95fd42,""Much attention has recently been given to the creation of large knowledge bases that contain millions of facts about people, things, and places in the world. These knowledge bases have proven to be incredibly useful for enriching search results, answering factoid questions, and training semantic parsers and relation extractors. The way the knowledge base is actually used in these systems, however, is somewhat shallow—they are treated most often as simple lookup tables, a place to find a factoid answer given a structured query, or to determine whether a sentence should be a positive or negative training example for a relation extraction model. Very little is done in the way of reasoning with these knowledge bases or using them to improve machine reading. This is because typical probabilistic reasoning systems do not scale well to collections of facts as large as modern knowledge bases, and because it is difficult to incorporate information from a knowledge base into typical natural language processing models. In this thesis we present methods for reasoning over very large knowledge bases, and we show how to apply these methods to models of machine reading. The approaches we present view the knowledge base as a graph and extract characteristics of that graph to construct a feature matrix for use in machine learning models. The graph characteristics that we extract correspond to Horn clauses and other logic statements over knowledge base predicates and entities, and thus our methods have strong ties to prior work on logical inference. We show through experiments in knowledge base completion, relation extraction, and question",answering that our methods can successful,ly incorporate,knowled,ge base information,into,machine learning models of natural,"language."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Bayesian Networks and Decision Graphs,The book introduces probabilistic graphical models and decision graphs.,Finn V. Jensen,Statistics for Engineering and Information Science,,,10.1007/978-1-4757-3502-4,https://link.springer.com/content/pdf/bfm:978-1-4757-3502-4/1?pdf=chapter%20toc,2001,4716,https://doi.org/10.1007/978-1-4757-3502-4,https://semanticscholar.org/paper/2aef78ad47756436deecf6b3578d65dc37a61753,""Probabilistic graphical models and decision graphs are powerful modeling tools for reasoning and decision making under uncertainty. As modeling languages they allow a natural specification of problem domains with inherent uncertainty, and from a computational perspective they support efficient algorithms for automatic construction and query answering. This includes belief updating, finding the most probable explanation for the observed evidence, detecting conflicts in the evidence entered into the network, determining optimal strategies, analyzing for relevance, and performing sensitivity analysis. The book introduces probabilistic graphical models and decision graphs, including Bayesian networks and influence diagrams. The reader is introduced to the two types of frameworks through examples and exercises, which also instruct the reader on how to build these models. The book is a new edition of Bayesian Networks and Decision Graphs by Finn V. Jensen. The new edition is structured into two parts. The first part focuses on probabilistic graphical models. Compared with the previous book, the new edition also includes a thorough description of recent extensions to the Bayesian network modeling language, advances in exact and approximate belief updating algorithms, and methods for learning both the structure and the parameters of a Bayesian network. The second part deals with decision graphs, and in addition to the frameworks described in the previous edition, it",also introduces Markov decision processes,and partially,ordered,decision problems.,The,authors also provide a well-founded,practical in,troduc,tio,n to,Bayes,ian,net,work,"s,",object-,orie,nted,Bayesian,"networks, decision trees, influence diagrams (and variants hereof), and Markov decision processes. give practical advice on the construction of Bayesian networks, decision trees, and influence diagrams from domain knowledge. give several examples and exercises exploiting computer systems for dealing with Bayesian networks and decision graphs. present a thorough introduction to state-of-the-art solution and analysis algorithms. The book is intended as a textbook, but it can also be used for self-study and as a reference book."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Analysis of Knowledge Graph Path Reasoning Based on Variational Reasoning,Knowledge graph reasoning improves model accuracy and enhancing model learning and reasoning capabilities.,""Hongmei Tang, Wenzhong Tang, Ruichen Li, Yanyang Wang, Shuai Wang, Lihong Wang"",Applied Sciences,,0.44 (11182),10.3390/app12126168,https://www.mdpi.com/2076-3417/12/12/6168/pdf?version=1655459548,2022,,https://doi.org/10.3390/app12126168,https://semanticscholar.org/paper/8f56e567f1b6df0d3e80e1604520bf2cd5c23209,""Knowledge graph (KG) reasoning improves the perception ability of graph structure features, improving model accuracy and enhancing model learning and reasoning capabilities. This paper proposes a new GraphDIVA model based on the variational reasoning divergent autoencoder (DIVA) model. The network structures and calculation processes of the models are analyzed. The GraphSAGE algorithm is introduced into the path reasoning module to solve the inability of the original model to perceive the features of the graph structure, which leads to a decline in the accuracy rate. Hence, GraphDIVA can achieve a higher accuracy rate with fewer learning iterations. The experiments show the efficiency and effectiveness of our model and proves that our method has a better effect on the accuracy rate and training difficulty than the baseline model on the FB15k-237 and NELL-995 benchmark datasets."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Probabilistic Case-based Reasoning for Open-World Knowledge Graph Completion,""A case-based reasoning system solves a new problem by retrieving """"cases"""" that are similar to the given problem."",""R. Das, Ameya Godbole, Nicholas Monath, M. Zaheer, A. McCallum"",Conference on Empirical Methods in Natural Language Processing,,,10.18653/v1/2020.findings-emnlp.427,https://www.aclweb.org/anthology/2020.findings-emnlp.427.pdf,2020,11,https://doi.org/10.18653/v1/2020.findings-emnlp.427,https://semanticscholar.org/paper/7748bdd5737134bbdf88e06673f7d058d9a7148c,""A case-based reasoning (CBR) system solves a new problem by retrieving `cases' that are similar to the given problem. If such a system can achieve high accuracy, it is appealing owing to its simplicity, interpretability, and scalability. In this paper, we demonstrate that such a system is achievable for reasoning in knowledge-bases (KBs). Our approach predicts attributes for an entity by gathering reasoning paths from similar entities in the KB. Our probabilistic model estimates the likelihood that a path is effective at answering a query about the given entity. The parameters of our model can be efficiently computed using simple path statistics and require no iterative optimization. Our model is non-parametric, growing dynamically as new entities and relations are added to the KB. On several benchmark datasets our approach significantly outperforms other rule learning approaches and performs comparably to state-of-the-art embedding-based approaches. Furthermore, we demonstrate the effectiveness of our model in an """"open-world"""" setting where new entities arrive in an online fashion, significantly outperforming state-of-the-art approaches and nearly matching the best offline method. Code available at this https URL"",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Reasoning in Knowledge Graphs,Knowledge graphs are becoming increasingly popular in the industry and academia.,""Ricardo Guimarães, A. Ozaki"",,,,,,2022,,,https://semanticscholar.org/paper/c32e70cf97faa8d8b5b49e0eacdfe778efc4e337,""Knowledge Graphs (KGs) are becoming increasingly popular in the industry and academia. They can be represented as labelled graphs conveying structured knowledge in a domain of interest, where nodes and edges are enriched with metaknowledge such as time validity, provenance, language, among others. Once the data is structured as a labelled graph one can apply reasoning techniques to extract relevant and insightful information. We provide an overview of deductive and inductive reasoning approaches for reasoning in KGs. 2012 ACM Subject Classification Computing methodologies ? Knowledge representation and reasoning"",,Review",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"""Neural, symbolic and neural-symbolic reasoning on knowledge graphs"",Symbolic reasoning is intolerant of the ambiguous and noisy data.,""Jing  Zhang, Bo  Chen, Lingxi  Zhang, Xirui  Ke, Haipeng  Ding"",,,,10.1016/J.AIOPEN.2021.03.001,http://arxiv.org/pdf/2010.05446,2021,9,https://doi.org/10.1016/J.AIOPEN.2021.03.001,https://semanticscholar.org/paper/91075f524e74bdc618fea689416de22c1cf2a472,""Abstract Knowledge graph reasoning is the fundamental component to support machine learning applications such as information extraction, information retrieval, and recommendation. Since knowledge graphs can be viewed as the discrete symbolic representations of knowledge, reasoning on knowledge graphs can naturally leverage the symbolic techniques. However, symbolic reasoning is intolerant of the ambiguous and noisy data. On the contrary, the recent advances of deep learning have promoted neural reasoning on knowledge graphs, which is robust to the ambiguous and noisy data, but lacks interpretability compared to symbolic reasoning. Considering the advantages and disadvantages of both methodologies, recent efforts have been made on combining the two reasoning methods. In this survey, we take a thorough look at the development of the symbolic, neural and hybrid reasoning on knowledge graphs. We survey two specific reasoning tasks — knowledge graph completion and question answering on knowledge graphs, and explain them in a unified reasoning framework. We also briefly discuss the future directions for knowledge graph reasoning."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"A review: Knowledge reasoning over knowledge graph,Knowledge graph reasoning is a hot research topic.,""Xiaojun  Chen, Shengbin  Jia, Yang  Xiang"",Expert Syst. Appl.,,,10.1016/j.eswa.2019.112948,,2020,111,https://doi.org/10.1016/j.eswa.2019.112948,https://semanticscholar.org/paper/cd343276aec1b22e0c273b1cf5986bb826d3e5a4,""Abstract Mining valuable hidden knowledge from large-scale data relies on the support of reasoning technology. Knowledge graphs, as a new type of knowledge representation, have gained much attention in natural language processing. Knowledge graphs can effectively organize and represent knowledge so that it can be efficiently utilized in advanced applications. Recently, reasoning over knowledge graphs has become a hot research topic, since it can obtain new knowledge and conclusions from existing data. Herein we review the basic concept and definitions of knowledge reasoning and the methods for reasoning over knowledge graphs. Specifically, we dissect the reasoning methods into three categories: rule-based reasoning, distributed representation-based reasoning and neural network-based reasoning. We also review the related applications of knowledge graph reasoning, such as knowledge graph completion, question answering, and recommender systems. Finally, we discuss the remaining challenges and research opportunities for knowledge graph reasoning."",,Review",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Knowledge graph augmented advanced learning models for commonsense reasoning,A textual inference system with external organized common sense graphs for explanatory inferences is proposed.,""Akhilesh Pothuri, Hari Sai Raghuram Veeramallu, Pooja Malik"",,,,10.1088/1757-899X/1022/1/012038,,2021,,https://doi.org/10.1088/1757-899X/1022/1/012038,https://semanticscholar.org/paper/609d2c0c747860afcabf8731f884f22001c3630a,""Machine learning is the key solution to many AI issues, but learning models rely heavily on specific training data. While a Bayesian setup can be used to incorporate some learning patterns with previous knowledge, those patterns can not access any organized world knowledge on requirements. The primary objective is to enable human-capable machines in ordinary everyday circumstances to estimate and make presumptions. In this paper we propose to respond to such common sense issues through a textual inference system with external, organized common sense graphs for explanatory inferences. The framework is based on a schematic map as a pair of questions and answers, a linked subgraph from the semantine to the symbolic space of knowledge-based external information. It displays a schematic map with a new network graphic module for information knowledge and performance with graph representations. LSTMs and graphical networks with a hierarchical attention-based direction are the basis of our model. It is flexible and understandable from the intermediate attention scores, leading to confident results. We also achieved state-of-the-art reliability on CommonsenseQA, a broad database of common sense reasoning utilizing ConceptNet as the only external tool for BERT-based models."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Combining learning and reasoning: new challenges for knowledge graphs,Knowledge graphs have shown promise as a formalism to combine reasoning with learning.,F. V. Harmelen,European Grid Conference,,,,,2019,,,https://semanticscholar.org/paper/d8484a8fe02b74ecfb77b5009c8ad209e0a86497,""The question on how to combine learning with reasoning is widely seen as one of the major challenges for AI. Knowledge Graphs are now well established as a formalism for knowledge representation and reasoning, with large scale adoptions in industry (Google search, Apple’s Siri, Amazon, Uber, Airbnb, BBC, Reuters, and many others). Besides their use for reasoning tasks, knowledge graphs have also shown promise as a formalism to combine reasoning with learning. They have been used as a source of labels for semi-supervised learning, machine learning has been used to generate knowledge graphs, using knowledge graphs can be used to construct post-hoc explanations for machine learning, to name just a few. Central questions in this talk will be : what is the progress that has been made on combining knowledge graphs with machine learning to date, and what are the promises and challenges in both the near and the long term?"",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Cost-Effective Knowledge Graph Reasoning for Complex Factoid Questions,The message passing paradigm is a robust reasoner with better answer quality and significantly improved computational efficiency.,""Xia Yang, Meng-Fen Chiang, Wang-Chien Lee, Yi Chang"",2021 International Joint Conference on Neural Networks (IJCNN),,,10.1109/IJCNN52387.2021.9533753,,2021,,https://doi.org/10.1109/IJCNN52387.2021.9533753,https://semanticscholar.org/paper/b9738d86c83104e52d2ab793f5f383e2836630eb,""The task of reasoning over knowledge graph for factoid questions has received significant interest from the research community of natural language processing. Performing this task inevitably faces the issues of question complexity and reasoning efficiency. In this paper, we investigate modern reasoning approaches over knowledge graph to tackle complex factoid questions of diverse reasoning schemas with attractive speedup in computational efficiency. To this end, we propose two evidence retrieval strategies to generate concise and informative evidence graph of high semantic-relevance and factual coverage to the question. Then, we adopt DELFT, a graph neural networks based framework that takes the linguistic structure representation of a question and the evidence graph as input, to predict the answer by reasoning over the evidence graph. We evaluate the performance across several baselines in terms of effectiveness and efficiency on two real-world datasets, MOOCQA and MetaQA. The results show the superiority of message passing paradigm in delivering a robust reasoner with better answer quality and significantly improved computational efficiency."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"KNOWLEDGE GRAPH CONSTRUCTION FOR SUBSURFACE OBJECTS INCLUDING UNCERTAINTY AND TIME VARIATION,A model to represent parameterized geometries of subsurface objects has been defined as an OWL ontology.,""A. Caselli, G. Falquet, C. Métral"",""The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences"",,,10.5194/isprs-archives-xlvi-4-w4-2021-131-2021,https://www.int-arch-photogramm-remote-sens-spatial-inf-sci.net/XLVI-4-W4-2021/131/2021/isprs-archives-XLVI-4-W4-2021-131-2021.pdf,2021,,https://doi.org/10.5194/isprs-archives-xlvi-4-w4-2021-131-2021,https://semanticscholar.org/paper/862f8360c670e7beb1c1fcd25c8daaec59d7fab6,""Abstract. In the recent years the concept of knowledge graph has emerged as a way to aggregate information from various sources without imposing too strict data modelling constraints. Several graph models have been proposed during the years, ranging from the “standard” RDF to more expressive ones, such as Neo4J and RDF-star. The adoption of knowledge graph has become established in several domains. It is for instance the case of the 3D geoinformation domain, where the adoption of semantic web technologies has led to several works in data integration and publishing. However, yet there is not a well-defined model or technique to represent 3D geoinformation including uncertainty",and time variation in knowledge,graphs. In this paper we propose a model to represent parameterized geometries of,subsurface objects. The vocabulary of the model has been defined as an OWL ontology and it extends existing ontologies by adding classes and properties to represent the uncertainty and the spatio-temporal behavi,"our of a geometry, as well as additional","attributes, such as the d",ata,provenance. The model,has been validated on significant use cases showing different types of,uncertai,nties,on 3D su,bsurface objec,ts.,A possible,imple,mentation i,s also,"presented,",using RDF,#NAME?,data,re,"presentation."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Uncertain Temporal Knowledge Graphs,The facts and rules contained in these graphs tend to be noisy and erroneous due to either the accuracy of the extraction tools or uncertainty in the source data.,""M. Chekol, H. Stuckenschmidt"",URSW@ISWC,,,,,2016,1,,https://semanticscholar.org/paper/fb04ec343a729f6cbbf5e4da758647173430e33a,""Temporal data can be found in various sources from patient histories, purchase histories, employee histories, to web logs. Recent advances in open information extraction have paved the way for automatic construction of knowledge graphs (kgs) from such sources. Often the extraction tools used to construct kgs produce facts and rules along with their confidence scores, leading to the notion of uncertain temporal kgs. The facts and rules contained in these graphs tend to be noisy and erroneous due to either the accuracy of the extraction tools or uncertainty in the source data. In this work, we use a numerical extension of Markov logic networks to provide formal syntax and semantics for uncertain temporal kgs. Moreover, we propose a set of datalog constraints with inequalities, that extend the underlying schema of the kgs and help in resolving conflicting facts. Finally, we characterize the complexity of two important queries, maximum a-posteriori and conditional probability inference, for uncertain tem","poral kgs."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Embedding Uncertain Knowledge Graphs,UKGE shows effectiveness in capturing uncertain knowledge by achieving promising results.,""X. Chen, Muhao Chen, Weijia Shi, Yizhou Sun, C. Zaniolo"",AAAI Conference on Artificial Intelligence,,,10.1609/AAAI.V33I01.33013363,https://ojs.aaai.org/index.php/AAAI/article/download/4210/4088,2018,55,https://doi.org/10.1609/AAAI.V33I01.33013363,https://semanticscholar.org/paper/15c9684321f03744051bb73b4c1141507dc8ddb2,""Embedding models for deterministic Knowledge Graphs (KG) have been extensively studied, with the purpose of capturing latent semantic relations between entities and incorporating the structured knowledge they contain into machine learning. However, there are many KGs that model uncertain knowledge, which typically model the inherent uncertainty of relations facts with a confidence score, and embedding such uncertain knowledge represents an unresolved challenge. The capturing of uncertain knowledge will benefit many knowledge-driven applications such as question answering and semantic search by providing more natural characterization of the knowledge. In this paper, we propose a novel uncertain KG embedding model UKGE, which aims to preserve both structural and uncertainty information of relation facts in the embedding space. Unlike previous models that characterize relation facts",with binary classification tech,"niques, UKGE learns embeddings according to the confidence scores of uncertain rel","ation facts. To further enhance the precision of UKGE, we also introduce probabilistic soft logic to infer confidence scores for unseen relation facts during training. We propose and evaluate two variants of UKGE",based on different confidence score mod,eling strategies. Experime,nts,are conducted on thre,"e real-world uncertain KGs via three tasks, i.e. confidence prediction,",relation,fact,"ranking,",and relation,fact,classific,ation.,UKGE shows,effec,tiveness in,capturing,uncertain kn,owled,ge,by achieving promisi,"ng results, and it consistently outperforms baselines on these tasks."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Towards a representation of uncertain geospatial information in knowledge graphs,The use of real estate advertisements is a good example of uncertain geospatial information in knowledge graphs.,""L. Cadorel, A. Tettamanzi, Fabien L. Gandon"",Proceedings of the 1st ACM SIGSPATIAL International Workshop on Geospatial Knowledge Graphs,,,10.1145/3557990.3567588,https://hal.inria.fr/hal-03913504/file/author-version.pdf,2022,,https://doi.org/10.1145/3557990.3567588,https://semanticscholar.org/paper/7b9dd62da40cd21a16e61dff174f9731849772c5,""This paper highlights the challenges of representing uncertain geospatial information in knowledge graphs. We propose to use Real Estate advertisements since professionals use a lot of vernacular and vague places in order to promote a house to their target audience. Then, we suggest to model local place names using fuzzy set theory. Finally, we discuss how to build a knowledge graph that represents extracted geospatial objects and their uncertainty."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Fast Confidence Prediction of Uncertainty based on Knowledge Graph Embedding,""The method is suitable for the downstream task, confidence prediction of relation facts, whether they are seen in UKG or not."",""Shihan Yang, Weiya Zhang, R. Tang"",International Conference on Advances in Computing and Artificial Intelligence,,,10.1145/3446132.3446186,,2020,2,https://doi.org/10.1145/3446132.3446186,https://semanticscholar.org/paper/0811269f0b3894a67ba5b549e53e754b62d3bf00,""The uncertainty is an inherent feature of Knowledge Graph (KG), which is often modelled as confidence scores of relation facts. Although Knowledge Graph Embedding (KGE) has been a great success recently, it is still a big challenge to predict confidence of unseen facts in KG in the continuous vector space. There are several reasons for this situation. First, the current KGE is often concerned with the deterministic knowledge, in which unseen facts’ confidence are treated as zero, otherwise as one. Second, in the embedding space, uncertainty features are not well preserved. Third, approximate reasoning in embedding spaces is often unexplainable and not intuitive. Furthermore, the time and space cost of obtaining embedding spaces with uncertainty preserved are always very high. To address these issues, considering Uncertain Knowledge Graph (UKG), we propose a fast","and effective embedding method,","UKGsE, in which approximate reasoning and calculation can be quickly performed af",ter generating an Uncertain Knowledge Graph Embedding (UKGE) space in a high speed and reasonable accuracy. The idea is that treating relation facts as short sentences and pre-handling are benefit to the learning,and training confidence scores of them.,The experiment shows that,th,e method is suitable f,"or the downstream task, confidence prediction of relation facts, whethe",r they ar,e see,n in UKG,or not. It ach,ieve,s the best,trade,off between,effic,iency and a,ccuracy of,predicting u,ncert,ain,confidence of knowl,"edge. Further, we found that the model outperforms state-of-the-art uncertain link prediction baselines on CN15k dataset."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Marrying Uncertainty and Time in Knowledge Graphs,A numerical extension of Markov logic networks provides the necessary underpinning to formalize the syntax and semantics of uncertain temporal knowledge graphs.,""M. Chekol, G. Pirrò, J. Schoenfisch, H. Stuckenschmidt"",AAAI Conference on Artificial Intelligence,,,10.1609/aaai.v31i1.10495,https://ojs.aaai.org/index.php/AAAI/article/download/10495/10354,2017,43,https://doi.org/10.1609/aaai.v31i1.10495,https://semanticscholar.org/paper/9badd26e11967f16adf3eaa77cb9e86b90d24741,""The management of uncertainty is crucial when harvesting structured content from unstructured and noisy sources. Knowledge Graphs ( KGs ) are a prominent example. KGs maintain both numerical and non-numerical facts, with the support of an underlying schema. These facts are usually accompanied by a confidence score that witnesses how likely is for them to hold. Despite their popularity, most of existing KGs focus on static data thus impeding the availabilityof timewise knowledge. What is missing is a comprehensive solution for the management of uncertain and temporal data in KGs . The goal of this paper is to fill this gap. We rely on two main ingredients. The first is a numerical extension of Markov Logic Networks (MLNs) that provide the necessary underpinning to formalize the syntax and semantics of unc",ertain temporal KGs . The second,is a set of Datalog constraints with inequalities that extend the underlying sche,"ma of the KGs and help to detect inconsistencies. From a theoretical point of view, we discuss the complexity of two important classes of queries for uncertain temporal KGs: maximuma-posteriori and conditional pr",obability inference. Due to the hardness,of these problems and the,fa,ct that MLN solvers do,"not scale well, we also explore the usage of Probabilistic Soft Logics",(PSL) as,a pr,actical t,ool to support,our,reasoning,tasks,. We report,on an,experiment,al evaluat,ion comparing,the,MLN,and PSL approaches.,""",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Embedding Uncertain Temporal Knowledge Graphs,The CTRIEJ model shows effectiveness in capturing uncertain and temporal knowledge by achieving promising results.,""Tongxin Li, Weiping Wang, Xiaobo Li, Tao Wang, Xin Zhou, Meigen Huang"",Mathematics,,0.538 (9300),10.3390/math11030775,https://www.mdpi.com/2227-7390/11/3/775/pdf?version=1675413830,2023,1,https://doi.org/10.3390/math11030775,https://semanticscholar.org/paper/68fa118d4a8ecef48a69b4862733dd26ff221e18,""Knowledge graph (KG) embedding for predicting missing relation facts in incomplete knowledge graphs (KGs) has been widely explored. In addition to the benchmark triple structural information such as head entities, tail entities, and the relations between them, there is a large amount of uncertain and temporal information, which is difficult to be exploited in KG embeddings, and there are some embedding models specifically for uncertain KGs and temporal KGs. However, these models either only utilize uncertain information or only temporal information, without integrating both kinds of information into the underlying model that utilizes triple structural information. In this paper, we propose an embedding model for uncertain temporal KGs called the confidence score, time, and ranking information embedded jointly model (CTRIEJ), which aims to preserve the uncertainty, tem",poral and structural information,of relation facts in the embedding space. To further enhance the precision of the,"CTRIEJ model, we also introduce a self-adversarial negative sampling technique to generate negative samples. We use the embedding vectors obtained from our model to complete the missing relation facts and predic",t their corresponding confidence scores.,Experiments are conducted,on,an uncertain temporal,"KG extracted from Wikidata via three tasks, i.e., confidence predictio","n, link p",redic,"tion, and",relation fact,cla,ssificatio,n. The,CTRIEJ mod,el sho,ws effectiv,eness in c,apturing unce,rtain,an,d temporal knowledge,"by achieving promising results, and it consistently outperforms baselines on the three downstream experimental tasks."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Uncertain Knowledge Graph Embedding: a Natural and Effective Approach,A simple approach to uncertain knowledge graph embedding achieves results comparing with state-of-the-art approaches on uncertain knowledge graph embedding.,""Shihan Yang, R. Tang, Zhiwei Zhang, Guozhong Li"",,,,10.1088/1742-6596/1824/1/012002,,2021,,https://doi.org/10.1088/1742-6596/1824/1/012002,https://semanticscholar.org/paper/8cb3b040ea5db45f933857b7290397609ebbe107,""Uncertain Knowledge Graph (UKG) models uncertainty of the knowledge, which usually models the inherent uncertainty of relation facts in a knowledge base with a confidence value. Embedding such uncertain knowledge represents is still an unresolved challenge, although deterministic Knowledge Graph embedding has been extensively studied recently, which aims at representing entities and relations as vectors in a continuous vector space and preserving semantic information as much as possible. For capturing both structural and uncertainty information of relation facts in the continuous vector space, we propose a simple but effective two-steps approach to Uncertain Knowledge Graph Embedding (UKGE) based on the skip-gram/CBOW model and learning confidence score by Long Short-Term Memories (LSTM) neural network. We show that the embedding techniques achieve results comparing with state-of-the-art",approaches on uncertain knowled,ge graph embedding. The approach achieves the best tradeoff between efficiency and,"accuracy of UKGE. Because of the simplicity, the method can also handle large size graphs in lower time consumption."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Uncertain Ontology-Aware Knowledge Graph Embeddings,""A novel embedding model UOKGE learns embeddings of entities, classes, and properties on uncertain ontology-aware knowledge graphs according to confidence scores."",""Khaoula  Boutouhami, Jiatao  Zhang, Guilin  Qi, Huan  Gao"",JIST,,,10.1007/978-981-15-3412-6_13,,2019,1,https://doi.org/10.1007/978-981-15-3412-6_13,https://semanticscholar.org/paper/e254dc831ea0cca5b9b388135cafc13b4c0aca10,""Much attention has recently been given to knowledge graphs embedding by exploiting latent and semantic relations among entities and incorporating the structured knowledge they contain into machine learning. Most of the existing graph embedding models can only encode a simple model of the data, while few models are designed for ontology rich knowledge graphs. Furthermore, many automated knowledge construction tools produce modern knowledge graphs with rich semantics and uncertainty. However, there is no graph embedding model which includes uncertain ontological information into graph embedding models. In this paper, we propose a novel embedding model UOKGE (Uncertain Ontology-aware Knowledge Graph Embeddings), which learns embeddings of entities, classes, and properties on uncertain ontology-aware knowledge graphs according to confidence scores. The proposed method preserves both structures",and uncertainty of knowledge in,"the embedding space. Specifically, UOKGE encodes each entity in a knowledge graph","as a point of n-dimensional vector, each class as a n-sphere and each property as 2n-sphere in the same semantic space. This representation allows for the natural expression of uncertain ontological triples. The",preliminary experimental results show t,hat UOKGE can robustly lea,rn,representations of unc,ertain ontology-aware knowledge graphs when evaluated on a benchmark da,"taset."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Knowledge graph embedding for experimental uncertainty estimation,Knowledge graph embedding can be used to predict the missing uncertainty of the experiments when there is a hidden relationship between the experiment metadata and the uncertainty values.,""Edoardo Ramalli, B. Pernici"",Information Discovery and Delivery,,0.427 (11479),10.1108/idd-06-2022-0060,https://www.emerald.com/insight/content/doi/10.1108/IDD-06-2022-0060/full/pdf?title=knowledge-graph-embedding-for-experimental-uncertainty-estimation,2023,,https://doi.org/10.1108/idd-06-2022-0060,https://semanticscholar.org/paper/f3c686eeab819a7d40f6e8f776932919086b0e71,""Purpose",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Experiments are the backbone of the development process of data-driven predictive models for scientific applications. The quality of the experiments directly impacts the model performance. Uncertainty inherently affects experiment measurements and is often missing in the available data sets due to its estimation cost. For similar reasons, experiments are very few compared to other data sources. Discarding experiments based on the missing uncertainty values would preclude the development of predictive models. Data profiling techniques are fundamental to assess data quality, but some data quality dimensions are challenging to evaluate without knowing the uncertainty. In this context, this paper aims to predict the missing uncertainty of the experiments.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"The employment of knowledge graph embedding to predict the missing experimental uncertainty is a novel alternative to the current and more costly techniques in the literature. Such contribution permits a better data quality profiling of scientific repositories and improves the development process of data-driven models based on scientific experiments."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Modeling the evolution of temporal knowledge graphs with uncertainty,The evolution of temporal knowledge graphs with uncertainty can be modelled.,""Soeren Nolting, Zhen Han, Volker Tresp"",ArXiv,,,10.48550/arXiv.2301.04977,,2023,,https://doi.org/10.48550/arXiv.2301.04977,https://semanticscholar.org/paper/74d2c6b5f3cd9839330cb4d32ca130951c64dc2b,"","",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Subgraph pattern matching over uncertain graphs with identity linkage uncertainty,A probabilistic entity graph is a formal model that defines a distribution over possible graphs at the entity level.,""W. E. Moustafa, Angelika Kimmig, A. Deshpande, L. Getoor"",IEEE International Conference on Data Engineering,,,10.1109/ICDE.2014.6816710,https://lirias.kuleuven.be/bitstream/123456789/426995/1/moustafa-icde14.pdf,2013,35,https://doi.org/10.1109/ICDE.2014.6816710,https://semanticscholar.org/paper/f160078377f0a2cdfb58e81ed8ca2ab37bd4e66d,""There is a growing need for methods that can represent and query uncertain graphs. These uncertain graphs are often the result of an information extraction and integration system that attempts to extract an entity graph or a knowledge graph from multiple unstructured sources [25], [7]. Such an integration typically leads to identity uncertainty, as different data sources may use different references to the same underlying real-world entities. Integration usually also introduces additional uncertainty on node attributes and edge existence. In this paper, we propose the notion of a probabilistic entity graph (PEG), a formal model that uniformly and systematically addresses these three types of uncertainty. A PEG is a probabilistic graph model that defines a distribution over possible graphs at th",e entity level. We introduce a g,eneral framework for constructing a PEG given uncertain data at the reference leve,"l and develop efficient algorithms to answer subgraph pattern matching queries in this setting. Our algorithms are based on two novel ideas: context-aware path indexing and reduction by join-candidates, which dra",stically reduce the query search space.,A comprehensive experiment,al,evaluation shows that,our approach outperforms baseline implementations by orders of magnitud,"e."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Supply Chain Link Prediction on Uncertain Knowledge Graph,The first graph neural network approach to model uncertainty in supply chain knowledge graph reasoning is shown.,""Nils Brockmann, E. Kosasih, A. Brintrup"",SIGKDD Explorations,,,10.1145/3575637.3575655,,2022,2,https://doi.org/10.1145/3575637.3575655,https://semanticscholar.org/paper/b249198cf6e3c63a1d25bce5ba7661f6d5ac78e8,""With manufacturing companies outsourcing to each other, multi-echelon supply chain networks emerge in which risks can propagate over multiple entities. Considerable structural and organizational barriers hamper obtaining the supply chain visibility that would be required for a company to monitor and mitigate these risks. Our work proposes to combine the automated extraction of supply chain relations from web data using NLP with augmenting the results using link prediction. For this, the first graph neural network based approach to model uncertainty in supply chain knowledge graph reasoning is shown. We illustrate our approach on a novel dataset and manage to improve the state-of-the-art performance by 60% in uncertainty link prediction. Generated confidence scores support real-world decision-making."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Visualizing node attribute uncertainty in graphs,Visualizations can potentially misrepresent information if they ignore or hide the uncertainty that are usually present in the data.,""N. Cesario, A. Pang, L. Singh"",Electronic imaging,,,10.1117/12.872677,https://repository.library.georgetown.edu/bitstream/10822/761517/6/Singh_VisualizingNodeAttribute.pdf,2011,14,https://doi.org/10.1117/12.872677,https://semanticscholar.org/paper/d51c1ce99c8c4335c3b99ae3c529eb923a4d199f,""Visualizations can potentially misrepresent information if they ignore or hide the uncertainty that are usually present in the data. While various techniques and tools exist for visualizing uncertainty in scientific visualizations, there are very few tools that primarily focus on visualizing uncertainty in graphs or network data. With the popularity of social networks and other data sets that are best represented by graphs, there is a pressing need for visualization systems to show uncertainty that are present in the data. This paper focuses on visualizing a particular type of uncertainty in graphs - we assume that nodes in a graph can have one or more attributes, and each of these attributes may have an uncertainty associated with it. Unlike previous efforts in visualizing node or edge uncertainty in graphs by changing the appearance of the nodes or edges,","e.g. by blurring, the approach i",n this paper is to use the spatial layout of the graph to represent the uncertaint,"y information. We describe a prototype tool that incorporates several uncertainty-to-spatial-layout mappings and describe a scenario showing how it might be used for a visual analysis task."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Uncertainty models for knowledge-based systems,The underlying processes of reasoning lead to decision analyses in various contexts of knowledge-based system theory.,""I. Goodman, H. Nguyen"",,,,,,1985,252,,https://semanticscholar.org/paper/29163740c9aa2b67e4949abbd30dfd4d4daa329d,""Abstract : This Research Monograph is a first attempt to present a general framework for the manipulation and explanation of uncertainty in the design of knowledge-based expert systems. It provides mathematical foundations and gives extension and applications of various theories of uncertainty, including Bayes' Statistics, Zadeh's Possibility Theory and Belief Functions. Also, this monograph addresses topics such as knowledge representation, inference rules, and combination of evidence. The general framework is based upon the theory of formal languages and semantic evaluations from different systems of mathematical logic. The underlying processes of reasoning lead to decision analyses in various contexts of knowledge-based system theory. A general discussion is presented on topics such as generalized set theory from a viewpoint of multi- valued logic and its connection with Category Theory. This monograph also gives a survey of the state-of-the-art of research in the areas of fuzzy sets and Zadeh's Possibility Theory."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Structured uncertainty and the graph topology,A new metric on the space of linear time-invariant continuous-time systems is defined.,G. Vinnicombe,[1991] Proceedings of the 30th IEEE Conference on Decision and Control,,,10.1109/CDC.1991.261364,,1991,15,https://doi.org/10.1109/CDC.1991.261364,https://semanticscholar.org/paper/cc906c61dd1b4749109582ebaaf1424ec5001e6f,""A new metric on the space of linear time-invariant continuous-time systems is defined. This metric is no greater than the gap metric and is in fact the smallest metric for which a certain robust stabilization result holds. Unlike all other known metrices which induce the graph topology, it has an obvious frequency response interpretation. This allows questions regarding stability robustness in the face of parametric uncertainty to be considered terms of this metric. <<ETX>>"",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Uncertainty in Graph-Based Map Learning,A robot can learn the spatial layout of its environment for navigation purposes.,""Thomas  Dean, Kenneth  Basye, Leslie Pack Kaelbling"",,,,10.1007/978-1-4615-3184-5_7,,1993,20,https://doi.org/10.1007/978-1-4615-3184-5_7,https://semanticscholar.org/paper/b0d79f4c3acf81405b503bdf54fcb6251728eb9f,""For certain applications it is useful for a robot to predict the consequences of its actions. As a particular example, consider programming a robot to learn the spatial layout of its environment for navigation purposes. For this problem it is useful to represent the interaction of the robot with its environment as a deterministic finite automaton. In map learning the states correspond tolocally distinctive placesthe inputs to robot actions (navigation procedures), and the outputs to the information available through observation at a given place. In general, it is not possible to infer the exact structure of the underlying automaton(e.g.the robot’s sensors may not allow it to discriminate among distinct structures). However, even learning just thediscernible structure of its environment is not an easy problem when various types of uncertainty are considered. In this chapter we will examine the effects of only having probablistic information about transitions between states and only probablistic",knowledge of the identity of th,e current state. Using this theoretical framework we can then determine whether it,"is at all possible for a given robot to learn some specific environment and, if so, how long this can be expected to take."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Knowledge Graphs and Network Text Analysis,Concepts might be too broad or complex to be used properly.,R. Popping,,,,10.1177/0539018403042001798,https://pure.rug.nl/ws/files/10288912/PoppingR-Knowledge-RUG-2003.pdf,2003,116,https://doi.org/10.1177/0539018403042001798,https://semanticscholar.org/paper/241fc01b327856476e0194265ddd36bd50e7d3f5,""A knowledge graph is a kind of semantic network representing some scientific theory. The article describes the present state of this field and addresses a number of problems that have not yet been solved. These problems are implicit relations, strength of (causal) relations, and exclusiveness. Concepts might be too broad or complex to be used properly, so directions for solving these problems are explored. The solutions are applied to a knowledge graph in the field of labour markets."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Measuring uncertainty in graph cut solutions,The min-marginal energies obtained by our proposed algorithm are exact.,""Pushmeet  Kohli, Philip H. S. Torr"",Comput. Vis. Image Underst.,,,10.1016/j.cviu.2008.07.002,https://radar.brookes.ac.uk/radar/file/99ce2936-544b-b4a3-9438-8451ab4045ff/1/torr2008measuring.pdf,2008,95,https://doi.org/10.1016/j.cviu.2008.07.002,https://semanticscholar.org/paper/face222ba09d66daa6e226cddd3e3bd579095f6a,""In recent years graph cuts have become a popular tool for performing inference in Markov and conditional random fields. In this context the question arises as to whether it might be possible to compute a measure of uncertainty associated with the graph cut solutions. In this paper we answer this particular question by showing how the min-marginals associated with the label assignments of a random field can be efficiently computed using a new algorithm based on dynamic graph cuts. The min-marginal energies obtained by our proposed algorithm are exact, as opposed to the ones obtained from other inference algorithms like loopy belief propagation and generalized belief propagation. The paper also shows how min-marginals can be used for parameter learning in conditional random fields."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Knowledge acquisition under uncertainty — a rough set approach,""Uncertainty implies inconsistencies, which are taken into account with the help of rough set theory."",Jerzy W. Grzymala-Busse,J. Intell. Robotic Syst.,,,10.1007/BF00437317,,1988,274,https://doi.org/10.1007/BF00437317,https://semanticscholar.org/paper/562783ce4aec301238c336fa451c85492d3519ba,""The paper describes knowledge acquisition under uncertainty using rough set theory, a concept introduced by Z. Pawlak in 1981. A collection of rules is acquired, on the basis of information stored in a data base-like system, called an information system. Uncertainty implies inconsistencies, which are taken into account, so that the produced rules are categorized into certain and possible with the help of rough set theory. The approach presented belongs to the class of methods of learning from examples. The taxonomy of all possible expert classifications, based on rough set theory, is also established. It is shown that some classifications are theoretically (and, therefore, in practice) forbidden."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"A framework for building knowledge-bases under uncertainty,The computational efficiency of reasoning over Bayesian knowledge-bases is computationally tractable.,""E. Santos, E. Santos"",Journal of experimental and theoretical artificial intelligence (Print),,,10.1080/095281399146571,,1999,71,https://doi.org/10.1080/095281399146571,https://semanticscholar.org/paper/484cee9de16e6eafeef5466208383f5b43c58fe0,""Managing uncertainty during the knowledge engineering process from elicitation to validation and verification requires a flexible, intuitive, and semantically sound knowledge representation. This is especially important since this process is typically highly interactive with the human user to add, update, and maintain knowledge. In this paper, we present a model of knowledge representation called Bayesian Knowledge-Bases (BKBs). It unifies a ‘if-then’ style rules with probability theory. We also consider the computational efficiency of reasoning over BKBs. We can show that through careful construction of the knowledge-base, reasoning is computationally tractable and can in fact be polynomial-time. BKBs are currently fielded in the PESKI intelligent system development environment."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Uncertain Knowledge Graph Embedding Using Probabilistic Logic Neural Networks,Existing embedding methods are mostly designed for deterministic knowledge graphs.,""Zijie Huang, Roshni G. Iyer, Zhiping Xiao"",,,,,,2020,,,https://semanticscholar.org/paper/16934881fb06e63b9f9665a1624ed28e7cb9e7e1,""Knowledge graph (KG) embedding embeds components of a KG into low-dimensional continuous vector spaces, while preserving the inherent structure of the KG. Existing embedding methods (e.g. TransE, DistMult) have two main drawbacks: (1) They fail to leverage the underlying domain knowledge, which can be captured by the symbolic rule-based approach with first-order logic; and (2) they are mostly designed for deterministic KGs and thereby fail to model the inherent uncertainty present in real-world KGs. In this paper, we propose the uncertain probabilistic logic neural network (PKGE) which captures domain knowledge and uncertainty information, preserves entity-relation semantic information, preserves graph structure, and can be trained effectively. To achieve this, PKGE employs the Markov Logic Network (MLN) to learn firstorder logic and encodes uncertainty by leaning confidence scores using the novel Uncertain KG Embedding (UKGE) model. We conduct optimization using the variational EM algorithm."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Uncertainty and vagueness in knowledge based systems: numerical methods,Vagueness and uncertainty can be handled adequately by using measure theoretic methods in the field of artificial intelligence.,""R. Kruse, E. Schwecke, J. Heinsohn"",Artificial Intelligence,,1.673 (1740),,,1991,165,,https://semanticscholar.org/paper/6b2b0842e5357cc8b92073b2fe58bc976114b194,""The primary aim of this monograph is to provide a formal framework for the representation and management of uncertainty and vagueness in the field of artificial intelligence. Particular emphasis is put on a thorough analysis of these phenomena and on the development of sound mathematical modelling approaches. The scope of the book also includes implementational aspects and a valuation of existing models and systems. The fundamental claim of the book is that vagueness and uncertainty can be handled adequately by using measure theoretic methods. The presentation of applicable knowledge representation formalisms and reasoning algorithms shows that efficiency requirements do not necessarily require renunciation of an uncompromising mathematical modelling approach. The results are used to evaluate systems based on probabilistic methods as well as on non-standard concepts such as certainty factors, fuzzy sets or belief functions. The book is self-contained and addresses r",esearchers and practitioners in,the field of knowledge based systems and decision support systems. This monograph,"on computer science, artificial intelligence, knowledge based systems, applied mathematics, probability theory, statistics and operations research is intended for researchers, practitioners, and advanced students","."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Visualizing Summary Statistics and Uncertainty,A hybrid summary plot incorporates a collection of descriptive statistics to highlight salient features of the data.,""Kristin C. Potter, J. Kniss, R. Riesenfeld, Chris R. Johnson"",Computer graphics forum (Print),,,10.1111/j.1467-8659.2009.01677.x,,2010,145,https://doi.org/10.1111/j.1467-8659.2009.01677.x,https://semanticscholar.org/paper/c4b1ef4c1c04ba5240cfdfe189a90436bd81dca0,""The graphical depiction of uncertainty information is emerging as a problem of great importance. Scientific data sets are not considered complete without indications of error, accuracy, or levels of confidence. The visual portrayal of this information is a challenging task. This work takes inspiration from graphical data analysis to create visual representations that show not only the data value, but also important characteristics of the data including uncertainty. The canonical box plot is reexamined and a new hybrid summary plot is presented that incorporates a collection of descriptive statistics to highlight salient features of the data. Additionally, we present an extension of the summary plot to two dimensional distributions. Finally, a use?case of these new plots is presented, demonstrating their ability to present high?level overviews as well as detailed insight into the salient features of th","e underlying data distribution.""",",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Editorial: Special Issue on Quality Assessment of Knowledge Graphs Dedicated to the Memory of Amrapali Zaveri,Knowledge graphs are essentially repositories of graph-based data.,""A. Rula, A. Zaveri, E. Simperl, Elena Demidova"",ACM Journal of Data and Information Quality,,,10.1145/3388748,https://dl.acm.org/doi/pdf/10.1145/3388748,2020,,https://doi.org/10.1145/3388748,https://semanticscholar.org/paper/41a6893a06257e46efddab4c7edba9d6d262c562,""We have recently witnessed a rise in the number and scale of knowledge graphs, including YAGO [7], DBpedia [6], Wikidata [3], EventKG [5], and the Google Knowledge Vault [1]. Knowledge graphs are essentially repositories of graph-based data [4]. They store millions of statements about entities of interest in a domain, for instance, people, places, organizations, and events. They are extensively used in various Artificial Intelligence (AI) contexts, from search and natural language processing to data integration, as a means to add context and depth to machine learning and generate human-readable explanations. Building and using knowledge graphs come with several challenges: they draw content from multiple sources (variety), in large quantities (volume), and at speed (velocity). For these reasons, they may include outdated or inconsistent information (veracity), which affects the applica",tions developed on top of them [,"4, 5, 9]. The quality of knowledge graphs is, hence, an ongoing concern, which so","far has not received enough attention from the research community [4, 8]. By comparison,"",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Node classification in uncertain graphs,The uncertainty in the classification process as a first-class citizen is beneficial.,""Michele Dallachiesa, C. Aggarwal, Themis Palpanas"",International Conference on Statistical and Scientific Database Management,,,10.1145/2618243.2618277,http://disi.unitn.it/%7Ethemis/publications/ssdbm14.pdf,2014,13,https://doi.org/10.1145/2618243.2618277,https://semanticscholar.org/paper/620bfadd90c6173b60af036a6c5aca6cb94c7eb4,""In many real applications that use and analyze networked data, the links in the network graph may be erroneous, or derived from probabilistic techniques. In such cases, the node classification problem can be challenging, since the unreliability of the links may affect the final results of the classification process. In this paper, we focus on situations that require the analysis of the uncertainty that is present in the graph structure. We study the novel problem of node classification in uncertain graphs, by treating uncertainty as a first-class citizen. We propose two techniques based on a Bayes model, and show the benefits of incorporating uncertainty in the classification process as a first-class citizen. The experimental results demonstrate the effectiveness of our approaches."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Knowledge structures in a tolerance knowledge base and their uncertainty measures,Knowledge structures in a tolerance knowledge base are depicted by means of set vectors.,""Bin  Qin, Fan-ping  Zeng, Ke-song  Yan"",Knowl. Based Syst.,,,10.1016/j.knosys.2018.03.032,,2018,7,https://doi.org/10.1016/j.knosys.2018.03.032,https://semanticscholar.org/paper/61e7b7d0a30a0718dd4ea4b5bc8ce4727274bd2f,""Abstract Rough set theory is a useful tool for dealing with imprecise knowledge. Its important notion is a knowledge base. In a knowledge base, one can approximately describe the target notion in terms of existing knowledge structures. A tolerance knowledge base is the generalization of knowledge bases. This paper investigates knowledge structures in a tolerance knowledge base and their uncertainty measures. Knowledge structures in a tolerance knowledge base are first depicted by means of set vectors. Then, dependence and independence between knowledge structures are described by using inclusion degree. Next, mapping and lattice characterizations of knowledge structures are given. Finally, measuring uncertainty of knowledge structures in a tolerance knowledge base is studied, two numerical experiments on the congressional voting records data set that comes from UCI Repository of machine learning databases are conducted, and based on these","numerical experiments, effectiv",eness analysis from the angle of statistics is given to evaluate the performance o,"f the proposed measures. These results will be helpful for establishing a framework of granular computing in knowledge bases."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Depth of knowledge and the effect of higher order uncertainty,The depth of knowledge can be used to bind the effect of higher order uncertainty in certain problems.,""Stephen  Morris, Andrew  Postlewaite, Hyun Song Shin"",,,,10.1007/BF01211787,,1995,54,https://doi.org/10.1007/BF01211787,https://semanticscholar.org/paper/e84ecafa512cfc68ab74dce2fbb6e044c2636482,SummaryA number of recent papers have highlighted the importance of uncertainty about others' information in models of asymmetric information. We introduce a notion that reflects the depth of knowledge in an information system. We show how the depth of knowledge can be used to bound the effect of higher order uncertainty in certain problems. We further provide bounds on the size of bubbles in finite horizon rational expectations models where the bounds depend on the depth of knowledge.,,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Graphes et incertitude Graphs and Uncertainty,Querying the graph changes when edges become uncertain.,S. Maniu,,,,,,2022,,,https://semanticscholar.org/paper/8207d324f321bc066dbbf80b1acd42fe8c4248be,""In many domains, graphs are one of the most intuitive ways of representing data, and many important tasks can be translated into graph queries and combinatorial problems on graphs. In most real-world scenarios, graph data or models have some uncertainty attached. In this manuscript, we discuss two aspects of challenges that occur when graph data or models are uncertain. First, we discuss how querying the graph changes when edges become uncertain; for this, we introduce the concept of tree decompositions for query processing on uncertain graphs. Moreover, we make the link between query efficiency and the concept of treewidth. In the second part of the manuscript, we discuss how to solve a well-known graph problem – social influence maximization – in the case where little is known about the underlying graph over which influence is performed. We discuss how approaches such as multiarmed-bandits can be applied."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"SUKE: Embedding Model for Prediction in Uncertain Knowledge Graph,The proposed embedding model can help advance the research on the embedding of uncertain knowledge graphs.,""Jingbin Wang, Kuan-Yu Nie, Xinyuan Chen, Jingpei Lei"",IEEE Access,,0.927 (4581),10.1109/ACCESS.2020.3047086,https://ieeexplore.ieee.org/ielx7/6287639/9312710/09306835.pdf,2021,1,https://doi.org/10.1109/ACCESS.2020.3047086,https://semanticscholar.org/paper/aaf5042a60ff366b3a1f46b85da695617ab07e26,""Graph embedding models are widely used in knowledge graph completion (KGC) task. However, most models are based on the assumption that knowledge is completely certain, and this is inconsistent with real-world situations. Although there are multiple studies on uncertain knowledge embedding tasks, they often use knowledge confidence to learn embedding and cannot make full use the structural and uncertain information of knowledge. This paper presents a new embedding model named Structural and Uncertain Knowledge Embedding (SUKE), which comprises two components: an evaluator and a confidence generator. For unknown triples, the evaluator learns the structural and uncertain information to evaluate its rationality and obtain a candidate set. The confidence generator then determines the confidence of the candidate set to achieve KGC. To verify the effectiveness of th","e proposed model, confidence pre","diction, triple evaluation, and fact classification tasks are performed on three d","ata sets. Experimental results show that SUKE performs better than mainstream embedding methods. The model proposed in this paper can help advance the research on the embedding of uncertain knowledge graphs."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"""Knowing What You Tell, Telling What You Know: Uncertainty and Asymmetries of Meaning in Interpreting Graphical Data"",Knowledgeability with respect to graphs and natural phenomena are continuously shifting as interview participants draw on a variety of resources as means for managing the task at hand.,""wolff-michael  roth, david  middleton"",,,,10.1007/S11422-005-9000-Y,,2006,55,https://doi.org/10.1007/S11422-005-9000-Y,https://semanticscholar.org/paper/6c9b845055d0c68674ff3b2ef12b92892a1b0397,""Research on knowing and learning in science commonly presupposes that knowledge, expertise, power, identity, and so on are stable features determining the outcome of interactions between individuals. In addition such individuals are conceptualized as differing in terms of the amount or types of the things in these categories. However, in a variety of disciplines including social psychology, sociology, and anthropology, the starting point for theoretical and empirical work is different: What really matters to social interaction is not the content of mind but how participants in social interaction deploy a variety of resources to constitute such things as memory, knowledge, expertise, and so on. This study was designed to investigate the local organization of interaction between research assistants, who had been hired to conduct a ser",ies of interviews (using a think,"-aloud protocol) about graphs, and scientists (N = 37) to better understand the pe","rson-situation interface in studies of scientific and mathematical knowing. Drawing on analytic methods from discursive psychology and conversation analysis, our analyses show how knowledgeability with respect to","graphs and natural phenomena, assessmen","t, giving and receiving of",in,"struction, accountabil","ity, insight, and uncertainty are continuously shifting as interview pa",rticipant,s dra,w on a va,riety of resou,rces,as means,for ma,naging the,task a,t hand. In,the proces,"s, uncertaint",y its,elf,is managed by drawi,"ng on uncertainty."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Measures of uncertainty for knowledge bases,The proposed measures are based on the knowledge structure of a given knowledge base.,""Zhaowen  Li, Gangqiang  Zhang, Wei-Zhi  Wu, Ningxin  Xie"",Knowledge and Information Systems,,0.988 (4186),10.1007/s10115-019-01363-0,,2019,6,https://doi.org/10.1007/s10115-019-01363-0,https://semanticscholar.org/paper/ddc8b5a505ad8687fef638e1d7f6015bd31ce230,""This paper investigates measures of uncertainty for knowledge bases by using their knowledge structures. Knowledge structures of knowledge bases are first introduced. Then, dependence and independence between knowledge structures of knowledge bases are proposed, which are characterized by inclusion degree. Next, measures of uncertainty for a given knowledge base are studied, and it is proved that the proposed measures are based on the knowledge structure of this knowledge base. Finally, a numerical experiment is conducted to show performance of the proposed measures and effectiveness analysis is done from two aspects of dispersion and correlation in statistics. These results will be significant for understanding the essence of uncertainty for knowledge bases."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Proving the Correctness of Knowledge Graph Update: A Scenario From Surveillance of Adverse Childhood Experiences,Knowledge graphs are a modern way to store information.,""J. H. Brenas, Arash Shaban-Nejad"",Frontiers in Big Data,,0.735 (6426),10.3389/fdata.2021.660101,https://www.frontiersin.org/articles/10.3389/fdata.2021.660101/pdf,2021,1,https://doi.org/10.3389/fdata.2021.660101,https://semanticscholar.org/paper/e7088b8a79be039a19b7cbbb6d27674456777c11,""Knowledge graphs are a modern way to store information. However, the knowledge they contain is not static. Instances of various classes may be added or deleted and the semantic relationship between elements might evolve as well. When such changes take place, a knowledge graph might become inconsistent and the knowledge it conveys meaningless. In order to ensure the consistency and coherency of dynamic knowledge graphs, we propose a method to model the transformations that a knowledge graph goes through and to prove that the new transformations do not yield inconsistencies. To do so, we express the knowledge graphs as logically decorated graphs, then we describe the transformations as algorithmic graph transformations and we use a Hoare-like verification process to prove correctness. To demonstrate the proposed method in action, we use examples from Adverse Childhood Experi","ences (ACEs), which is a public","health crisis."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"A Methodology for Uncertainty in Knowledge-Based Systems,Interval estimation of probabilities in diagnostic systems is demonstrated.,""Kurt  Weichselberger, Sigrid  Pöhlmann"",Lecture Notes in Computer Science,,0.407 (11926),10.1007/BFb0037513,https://link.springer.com/content/pdf/bfm:978-3-540-46964-3/1?pdf=chapter%20toc,1990,91,https://doi.org/10.1007/BFb0037513,https://semanticscholar.org/paper/eea944f69a15a01daf122c1dbe9af890392a5806,The aims of this study. - Interval estimation of probabilities. - Related theories. - The simplest case of a diagnostic system. - Generalizations. - Interval estimation of probabilities in diagnostic systems. - A demonstration of the use of interval estimation.,,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Representing uncertain knowledge - an artificial intelligence approach,Knowledge graphs and uncertainty are an artificial intelligence approach.,""P. Krause, D. Clark"",,,,,,1993,126,,https://semanticscholar.org/paper/1d0454981eccff3b9be48c556cace19dbbf06c5d,Preface. 1. The Nature of Uncertainty. 2. Bayesian Probability. 3. The Certainty Factor Model. 4. Epistemic Probability: the Dempster-Shafer Theory of Evidence. 5. Reasoning with Imprecise and Vague Data. 6. Non-Monotonic Logic. 7. Argumentation. 8. Overview. References. Subject Index. Author Index.,,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Introducing Subjective Knowledge Graphs,Different users may have distinct opinions about the same fact.,""Francisco J. Navarrete, Antonio Vallecillo"",IEEE International Enterprise Distributed Object Computing Conference,,,10.1109/EDOC52215.2021.00017,,2021,1,https://doi.org/10.1109/EDOC52215.2021.00017,https://semanticscholar.org/paper/18fca9db2baec53f249e0747e98583c7717c0a8d,""Knowledge-based applications that deal with uncertainty usually represent it by means of a confidence score that expresses the probability that a given fact is true. However, different users may have distinct opinions about the same fact, something that is not considered in existing proposals. This is critical in a number of areas where individual opinions need to be taken into account when making informed decisions, particularly when these are to be made by consensus. This paper introduces Subjective Knowledge Graphs (SKG), an extension to Probabilistic Knowledge Graphs that considers the individual opinions of separate users about the same facts, and allows reasoning about them. We show how SKGs can be implemented using standard graph databases and how the results of the queries can be enriched with the associated degrees of uncertainty."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Computing and Maintaining Provenance of Query Result Probabilities in Uncertain Knowledge Graphs,HAPPI is more efficient than knowledge compilation for answering commonly occurring queries with lower range of probability derivation complexity.,""Garima Gaur, Abhishek Dang, Arnab Bhattacharya, Srikanta J. Bedathur"",International Conference on Information and Knowledge Management,,,10.1145/3459637.3482330,https://dl.acm.org/doi/pdf/10.1145/3459637.3482330,2021,,https://doi.org/10.1145/3459637.3482330,https://semanticscholar.org/paper/aba282d331b70f044f5da93f4df36de0bd4a4a52,""Knowledge graphs (KG) model relationships between entities as labeled edges (or facts). They are mostly constructed using a suite of automated extractors, thereby inherently leading to uncertainty in the extracted facts. Modeling the uncertainty as probabilistic confidence scores results in a probabilistic knowledge graph. Graph queries over such probabilistic KGs require answer computation along with the computation of result probabilities, i.e., probabilistic inference. We propose a system, HAPPI (How Provenance of Probabilistic Inference), to handle such query processing and inference. Complying with the standard provenance semiring model, we propose a novel commutative semiring to symbolically compute the probability of the result of a query. These p",rovenance-polynomial-like symbol,ic expressions encode fine-grained information about the probability computation p,"rocess. We leverage this encoding to efficiently compute as well as maintain probabilities of results even as the underlying KG changes. Focusing on conjunctive basic graph pattern queries, we observe that HAPPI",is more efficient than knowledge compila,tion for answering commonl,y o,ccurring queries with,lower range of probability derivation complexity. We propose an adaptiv,e system,that,leverages,the strengths,of,both HAPPI,and c,ompilation,based,"techniques,",for not o,nly to perfor,m eff,ici,ent probabilistic in,"ference and compute their provenance, but also to incrementally maintain them."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Integrated Uncertainty in Knowledge Modelling and Decision Making,""Uncertainty formalisms include Bayesian probability, Dempster-Shafer theory, random sets, rough sets, fuzzy sets, and interval-based models."",""Van-Nam  Huynh, Masahiro  Inuiguchi, Bac  Le, Bao Nguyen Le, Thierry  Denoeux"",Lecture Notes in Computer Science,,0.407 (11926),10.1007/978-3-319-25135-6,,2015,15,https://doi.org/10.1007/978-3-319-25135-6,https://semanticscholar.org/paper/de754668f0950222a7f448ac1f4ccb9be62a7753,""• Uncertainty formalisms: Bayesian probability, Dempster-Shafer theory, imprecise probability, random sets, rough sets, fuzzy sets & interval-based models. • Modelling uncertainty & inconsistency in big data • Learning and reasoning with uncertainty • Information fusion & knowledge integration in uncertain environments • Decision making under various types of uncertainty • Aggregation operators • Copulas for dependence modelling • Granular and soft computing • Computational intelligence Application"",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"On Statistical Characteristics of Real-Life Knowledge Graphs,The management of knowledge graphs is required.,""Wenliang  Cheng, Chengyu  Wang, Bing  Xiao, Weining  Qian, Aoying  Zhou"",BPOE,,,10.1007/978-3-319-29006-5_4,,2015,1,https://doi.org/10.1007/978-3-319-29006-5_4,https://semanticscholar.org/paper/ef6eefb5726c6f52caedefeeb6510097f55fc160,""The success of open-access knowledge graphs, such as YAGO, and commercial products, such as Google Knowledge Graph, has attracted much attention from both academic and industrial communities in building common-sense and domain-specific knowledge graphs. A natural question arises that how to effectively and efficiently manage a large-scale knowledge graph. Though systems and technologies that use relational storage engines or native graph database management systems are proposed, there exists no widely accepted solution. Therefore, a benchmark for management of knowledge graphs is required."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Dynamic Educational Knowledge Graph Model via Information Entropy for Knowledge Building,The proposed IE-DEKG method outperforms the state-of-the-art methods.,""Zengcan Xue, Hai Liu, Zhaoli Zhang, Shuoqiu Yang"",""International Conference on Teaching, Assessment, and Learning for Engineering"",,,10.1109/TALE52509.2021.9678627,,2021,,https://doi.org/10.1109/TALE52509.2021.9678627,https://semanticscholar.org/paper/6b122fbf129de9bebc6d0d558edc0534de6c6af5,""Knowledge building is the production and continual improvement of ideas of value to a community, which attaches importance to conceptual engagement and contribution. However, knowledge building community will accumulate large and complex semi-structured educational data over time. It is not conducive to the continuation of in-depth knowledge building activities. To overcome these issues, we propose a dynamic educational knowledge graph with information entropy (IE-DEKG) model for knowledge building community. The model can construct dynamic knowledge graphs that contain instructional concepts and educational relations for learners. Specifically, it adopts the mutual information and adjacent information entropy to detect new terminologies on pedagogical data, and then the topic modeling algorithm is utilized to extract instructional concepts. Moreover, the model employs association rule mining to identify the prerequisite relations and uses pattern matching to obtain the inclusion relations. For the sake of satisfying the needs of educational applications and services, we design and implement the dynamic educational knowledge graph system. Experimental results demonstrate that the proposed IE-DEKG method outperforms the state-of-the-art methods."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Dynamic Educational Knowledge Graph Model via Information Entropy for Knowledge Building,The proposed IE-DEKG method outperforms the state-of-the-art methods.,""Zengcan Xue, Hai Liu, Zhaoli Zhang, Shuoqiu Yang"",""2021 IEEE International Conference on Engineering, Technology & Education (TALE)"",,,10.1109/TALE52509.2021.9678627,,2021,,https://doi.org/10.1109/TALE52509.2021.9678627,https://semanticscholar.org/paper/e3778803deb0fd3ad361289087848a9682516469,""Knowledge building is the production and continual improvement of ideas of value to a community, which attaches importance to conceptual engagement and contribution. However, knowledge building community will accumulate large and complex semi-structured educational data over time. It is not conducive to the continuation of in-depth knowledge building activities. To overcome these issues, we propose a dynamic educational knowledge graph with information entropy (IE-DEKG) model for knowledge building community. The model can construct dynamic knowledge graphs that contain instructional concepts and educational relations for learners. Specifically, it adopts the mutual information and adjacent information entropy to detect new terminologies on pedagogical data, and then the topic modeling algorithm is utilized to extract instructional concepts. Moreover, the model employs association rule mining to identify the prerequisite relations and uses pattern matching to obtain the inclusion relations. For the sake of satisfying the needs of educational applications and services, we design and implement the dynamic educational knowledge graph system. Experimental results demonstrate that the proposed IE-DEKG method outperforms the state-of-the-art methods."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Relation and Entropy Weight-Aware Knowledge Graph Embedding for Cloud Manufacturing,A novel relation and entropy weight-aware embedding model is proposed.,""Feng Zhao, Langjunqing Jin, L. Yang, Hai Jin"",IEEE Transactions on Industrial Informatics,,4.333 (350),10.1109/TII.2022.3178414,,2022,1,https://doi.org/10.1109/TII.2022.3178414,https://semanticscholar.org/paper/4eadfb1b5cbf7ad1f8b2920100c700a9a0a71d75,""Cloud manufacturing has emerged as a service-oriented paradigm, in which knowledge graphs (KGs) play a crucial role in enabling modularization and on-demand servitization by converting unstructured resources into a structured graph representation and factual knowledge for manufacturing tasks. KG embedding converts entities and relations into a low-dimensional space while expressing rich semantics of high-dimensional KGs. Existing works just focus on translating relations surrounding the nodes of graphs, while ignoring the applicability for modeling and inferring multiple relation patterns in the manufacturing context. Furthermore, the relative importance of complex manufacturing relations among different dimensions in embedded procedures has been ignored, leading to unclear representation learning of complex relations and entities in KGs. To overcome this issue, in this article, a novel relation and entropy weight-aware embedding model is proposed, named TransCE. TransCE performs coordinated transformations in vector space by normalizing the distance to integrate coordination. An entropy-based weighting method is also proposed to represent complex relations and entities surrounding the edges of graph embedding and assign the weighted value of relations to support the score function. Extended experiments are performed on several datasets,",and a manufacturing indicates that,Tr,ansCE,shows,remarkable,im,provement,relativ,e t,o ba,selin,e m,odels,".""",",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"A Graph Data Augmentation Strategy with Entropy Preserving,Graph entropy is a quantitative index to evaluate feature information diffusion among a graph.,""Xue-bo Liu, Dan Sun, Wei Wei"",ArXiv,,,,,2021,1,,https://semanticscholar.org/paper/09a7334a76ffbe97a0e2928ec69853365e98b5e6,""The Graph Convolutional Networks (GCNs) proposed by Kipf and Welling are effective models for semi-supervised learning, but facing the obstacle of over-smoothing, which will weaken the representation ability of GCNs. Recently some works are proposed to tackle with above limitation by randomly perturbing graph topology or feature matrix to generate data augmentations as input for training. However, these operations have to pay the price of information structure integrity breaking, and inevitably sacrifice information stochastically from original graph. In this paper, we introduce a novel graph entropy definition as an quantitative index to evaluate feature information diffusion among a graph. Under considerations of preserving graph entropy, we propose an effective strategy to generate perturbed training data using a stochastic mechanism but guaranteeing graph topology integrity and with only a small amount of graph entropy decaying. Extensive experiments have been conducted on real-world datasets and the results verify the effectiveness of our proposed method in improving semi-supervised node classification accuracy compared with a surge of baselines. Beyond that, our proposed approach significantly enhances the robustness and generalization ability of GCNs during the training process."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Knowledge graphs,The interweaving of data and knowledge is a historical event.,""Aidan  Hogan, Eva  Blomqvist, Michael  Cochez, Claudia  d'Amato, Gerard de Melo, Claudio  Gutierrez, Jos'e Emilio Labra Gayo, Sabrina  Kirrane, Sebastian  Neumaier, Axel  Polleres, Roberto  Navigli, Axel-Cyrille Ngonga Ngomo, Sabbir M. Rashid, Anisa  Rula, Lukas  Schmelzeisen, Juan  Sequeda, Steffen  Staab, Antoine  Zimmermann"",Commun. ACM,,,10.1145/3418294,https://dl.acm.org/action/downloadSupplement?doi=10.1145%2F3418294&file=p96-gutierrez-supp.pdf,2021,186,https://doi.org/10.1145/3418294,https://semanticscholar.org/paper/dcae74560222bce436c0b4c2ad078c66b2968ecc,Tracking the historical events that lead to the interweaving of data and knowledge.,,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Guest Editorial: Knowledge Graph Representation and Reasoning,Knowledge graphs can be seen as a means to tackle the problem of explainability in AI.,""E. Cambria, Shaoxiong Ji, Shirui Pan, Philip S. Yu"",,,,,,2021,1,,https://semanticscholar.org/paper/433ad31f41f41ceecba12582fd7dd45c17172a0c,""Recent years have witnessed the release of many open-source and enterprisedriven knowledge graphs with a dramatic increase of applications of knowledge representation and reasoning in fields such as natural language processing, computer vision, and bioinformatics. With those large-scale knowledge graphs, recent research tends to incorporate human knowledge and imitate human’s ability of relational reasoning [1]. Factual knowledge stored in knowledge bases or knowledge graphs can be utilized as a source for logical reasoning and, hence, be integrated to improve real-world applications [2–6]. Emerging embedding-based methods for knowledge graph representation have shown their ability to capture relational facts and model different scenarios with heterogenous information [7]. By combining symbolic reasoning methods or Bayesian models, deep representation learning techniques on knowledge graphs attempt to handle complex reasoning with relational path and symbolic logic and capture the uncertainty with probabilistic inference [8, 9]. Furthermore, efficient representation learning and reasoning can be one of the paths towards the emulation of high-level cognition and human-level intelligence. Knowledge graphs can also be seen as a means to tackle the problem of explainability in AI. These trends naturally facilitate relevant downstream applications which inject structural knowledge into wide-applied neural architectures such as attention-based transformers an","d graph neural networks [10,11]."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"""A Survey on Knowledge Graphs: Representation, Acquisition, and Applications"",""Knowledge graph embedding is organized from four aspects of representation space, scoring function, encoding models, and auxiliary information."",""Shaoxiong  Ji, Shirui  Pan, Erik  Cambria, Pekka  Marttinen, Philip S. Yu"",IEEE Transactions on Neural Networks and Learning Systems,,4.222 (355),10.1109/TNNLS.2021.3070843,https://research-repository.griffith.edu.au/bitstream/10072/416709/2/Pan2923674-Accepted.pdf,2022,340,https://doi.org/10.1109/TNNLS.2021.3070843,https://semanticscholar.org/paper/c9ec8cf5ce461647d0d1cf67093feeadea5d9957,""Human knowledge provides a formal understanding of the world. Knowledge graphs that represent structural relations between entities have become an increasingly popular research direction toward cognition and human-level intelligence. In this survey, we provide a comprehensive review of the knowledge graph covering overall research topics about: 1) knowledge graph representation learning; 2) knowledge acquisition and completion; 3) temporal knowledge graph; and 4) knowledge-aware applications and summarize recent breakthroughs and perspective directions to facilitate future research. We propose a full-view categorization and new taxonomies on these topics. Knowledge graph embedding is organized from four aspects of representation space, scoring function, encoding models, and auxiliary information. For knowledge acquisition, especially knowledge graph completion, embedding methods, path inference, and logical rule reasoning are reviewed. We further explore several emerging topics, including metarelational learning, commonsense reasoning, and temporal knowledge graphs. To facilitate future research on knowledge graphs, we also provide",a curated collection of data sets,and,open,#NAME?,e libraries,on,differen,t tasks.,In,the,"end,",we,have,a,"thorough outlook on several promising research directions."",,Review",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"What is Learned in Knowledge Graph Embeddings?,Knowledge graph models can learn motifs.,""Michael R. Douglas, Michael  Simkin, Omri  Ben-Eliezer, Tianqi  Wu, Peter  Chin, Trung V. Dang, Andrew  Wood"",Complex Networks & Their Applications X,,,10.1007/978-3-030-93413-2_49,http://arxiv.org/pdf/2110.09978,2022,,https://doi.org/10.1007/978-3-030-93413-2_49,https://semanticscholar.org/paper/f1ca30edae390927ffa7ce5767369ad5165c62af,""A knowledge graph (KG) is a data structure which represents entities and relations as the vertices and edges of a directed graph with edge types. KGs are an important primitive in modern machine learning and artificial intelligence. Embedding-based models, such as the seminal TransE [Bordes et al., 2013] and the recent PairRE [Chao et al., 2020] are among the most popular and successful approaches for representing KGs and inferring missing edges (link completion). Their relative success is often credited in the literature to their ability to learn logical rules between the relations. In this work, we investigate whether learning rules between relations is indeed what drives the performance of embedding-based methods. We define motif learning and two alternative mechanisms, network learning (based only on the connectivity of the KG, ignoring the relation types), and unstructured statistical learning (ignoring the connectivity of the graph). Using experiments on synthetic KGs, we show that KG models can learn motifs and how this ability is degraded by non-motif (noise) edges. We propose tests to distinguish the contributions of the three mechanisms to performance, and apply them to popular KG benchmarks. We also discuss an issue with the standard performance testing protocol and suggest an improvement. 7"",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Knowledge Graphs,Knowledge can be represented and extracted using a combination of deductive and inductive techniques.,""Aidan  Hogan, Eva  Blomqvist, Michael  Cochez, Claudia  D’amato, Gerard De Melo, Claudio  Gutierrez, Sabrina  Kirrane, José Emilio Labra Gayo, Roberto  Navigli, Sebastian  Neumaier, Axel-Cyrille Ngonga Ngomo, Axel  Polleres, Sabbir M. Rashid, Anisa  Rula, Lukas  Schmelzeisen, Juan  Sequeda, Steffen  Staab, Antoine  Zimmermann"",ACM Comput. Surv.,,,10.1145/3447772,https://dl.acm.org/doi/pdf/10.1145/3447772,2021,28,https://doi.org/10.1145/3447772,https://semanticscholar.org/paper/4f00435f66a3dee7d5965fe8696c56f67021f1cc,""In this article, we provide a comprehensive introduction to knowledge graphs, which have recently garnered significant attention from both industry and academia in scenarios that require exploiting diverse, dynamic, large-scale collections of data. After some opening remarks, we motivate and contrast various graph-based data models, as well as languages used to query and validate knowledge graphs. We explain how knowledge can be represented and extracted using a combination of deductive and inductive techniques. We conclude with high-level future research directions for knowledge graphs."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"A Survey on State-of-the-art Techniques for Knowledge Graphs Construction and Challenges ahead,Automated schemes can reduce the cost of building knowledge graphs up to 15-250 times.,""Ali Hur, N. Janjua, Mohiuddin Ahmed"",International Conference on Artificial Intelligence and Knowledge Engineering,,,10.1109/AIKE52691.2021.00021,http://arxiv.org/pdf/2110.08012,2021,7,https://doi.org/10.1109/AIKE52691.2021.00021,https://semanticscholar.org/paper/60724aa3b8f903d4ecdd1aa2173504e9adf07234,""Global datasphere is increasing fast, and it is expected to reach 175 Zettabytes by 20251. However, most of the content is unstructured and is not understandable by machines. Structuring this data into a knowledge graph enables intelligent applications such as deep question answering, recommendation systems, semantic search, etc. The knowledge graph is an emerging technology that allows logical reasoning and uncovers new insights using content and context. Thereby, it provides necessary syntax and reasoning semantics that enable machines to solve complex healthcare, security, financial institutions, economics, and business problems. As an outcome, enterprises are putting their effort into constructing and maintaining knowledge graphs to support various downstream applications. Manual approaches are too expensive. Automated schemes can reduce the cost of building knowledge graphs up to 15–250 times. This paper critiques state-of-the-art automated techniques to produce knowledge graphs of near-human quality autonomously. Additionally, it highlights different research issues that need to be addressed to deliver high-quality knowledge graphs."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Knowledge Graph Representation with Embeddings,Knowledge graph embeddings are a popular technique for representation learning.,,,,,,,2021,,,https://semanticscholar.org/paper/7f9aa14cf22af1259411d8cfa377a5f4b4723dcd,""Knowledge graphs (KGs) serve as structured repositories of real-world facts in the form of triples comprising of entities and relations. KGs such as Yago and Wikidata (Vrande?i? and Krötzsch 2014) have been applied to a number of applications including question answering, rule mining and web search. Knowledge graph embeddings have recently emerged as a popular technique for representation learning, where entities and relations are represented by lowdimensional dense vectors that can capture the interactions within the knowledge graph and then used for predicting missing links. Several popular KG embedding models have been successfully used for the task of link prediction (Wang et al. 2017). Such models have gained considerable attention and are being exploited for various other semantic tasks."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Sharing Parameter by Conjugation for Knowledge Graph Embeddings in Complex Space,A parameter-sharing method for complex numbers employed in KGE models improves memory efficiency by 2x in relation embedding.,""Xincan Feng, Zhi Qu, Yuchang Cheng, Taro Watanabe, N. Yugami"",Workshop on Graph-based Methods for Natural Language Processing,,,,,2022,,,https://semanticscholar.org/paper/33cc24c32e8ae4361e439237e0711806d8dad00e,""A Knowledge Graph (KG) is the directed graphical representation of entities and relations in the real world. KG can be applied in diverse Natural Language Processing (NLP) tasks where knowledge is required. The need to scale up and complete KG automatically yields Knowledge Graph Embedding (KGE), a shallow machine learning model that is suffering from memory and training time consumption issues. To mitigate the computational load, we propose a parameter-sharing method, i.e., using conjugate parameters for complex numbers employed in KGE models. Our method improves memory efficiency by 2x in relation embedding while achieving comparable performance to the state-of-the-art non-conjugate models, with faster, or at least comparable, training time. We demonstrated the generalizability of our method on two best-performing KGE models 5^{\bigstar}\mathrm{E} (CITATION) and \mathrm{ComplEx} (CITATION) on five benchmark datasets."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"International Workshop on Knowledge Graph: Heterogenous Graph Deep Learning and Applications,Knowledge graphs are the backbone to enable cognitive artificial intelligence.,""Ying Ding, Bogdan Arsintescu, Ching-Hua Chen, Haoyun Feng, F. Scharffe, O. Seneviratne, Juan Sequeda"",Knowledge Discovery and Data Mining,,,10.1145/3447548.3469473,,2021,1,https://doi.org/10.1145/3447548.3469473,https://semanticscholar.org/paper/b0342facee1e63e794a7535290893911b4ee297b,""Knowledge graph (KG) is the backbone to enable cognitive Artificial Intelligence (AI), which relies on cognitive computing and semantic reasoning. Knowledge graph is the connected data with the semantically enriched context. It is the necessary step for the next move of AI. Our daily activities have closely intermingled with various applications powered by knowledge graphs. It has even entered our healthcare system to facilitate clinical decision making and improve hospital efficiency. This workshop aims to bring researchers and practitioners to promote research and applications related to knowledge graph."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Knowledge Graph Completion by Jointly Learning Structural Features and Soft Logical Rules,A novel knowledge graph embedding model can learn more expressive embedding of entities and relations.,""Weidong Li, Rong Peng, Zhi Li"",IEEE Transactions on Knowledge and Data Engineering,,2.431 (883),10.1109/TKDE.2021.3108224,,2023,3,https://doi.org/10.1109/TKDE.2021.3108224,https://semanticscholar.org/paper/2acfa599b8f6d6a25d650fc3030f87004c9f7d99,""With the rapid development and widespread application of Knowledge graphs (KGs) in many artificial intelligence tasks, a large number of efforts have been made to refine them and increase their quality. Knowedge graph embedding (KGE) has become one of the main refinement tasks, which aims to predict missing facts based on existing ones in KGs. However, there are still mainly two difficult unresolved challenges: (i) how to leverage the local structural features of entities and the potential soft logical rules to learn more expressive embedding of entites and relations; and (ii) how to combine these two learning processes into one unified model. To conquer these problems, we propose a novel KGE model named JSSKGE, which can Jointly learn the local Structural features of entities and Soft logical rules. First, we employ graph attention networks which are specially designed for graph-structured data to aggregate the local structural information of nodes. Then, we utilize soft logical rules implicated in KGs as an expert to further rectify the embeddings of entities and relations. By jointly learning, we can obtain more informative embeddings to predict new facts. With experiments on four commonly used datasets, the JSSKGE obtains better performance than state-of-the-art approaches."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"An improved Knowledge Graph Model Based on Fuzzy Theory and TransR,The knowledge graph training process and time required for the training process are reduced.,""Yingkai Cai, Chu Wang, Zhongfeng Wang, Chunhe Song, Yunfeng Zou"",IEEE Joint International Information Technology and Artificial Intelligence Conference,,,10.1109/ITAIC49862.2020.9338752,,2020,1,https://doi.org/10.1109/ITAIC49862.2020.9338752,https://semanticscholar.org/paper/a456eaef382869cafae25104637f6c1a9284e2f2,""Thispaper relates to the field of knowledge management and information retrieval technology, and specifically provides a method for constructing a knowledge graph. The method for constructing the knowledge graph includes: acquiring triple data, converting the triple data into a normalized triple vector, using the triple vector to construct a knowledge graph based on fuzzy relations, and The minimization objective optimization function of the triple vector is acquired, and the knowledge graph is optimized. This paper reduces the complexity of the knowledge map training process and the time required for the training process."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Querying Fuzzy RDF Knowledge Graphs Data,The concept of SPARQL graph pattern makes it possible to query an element-level fuzzy RDF knowledge graphs with high degree of truth.,""Guanfeng Li, Weijun Li, Hairong Wang"",IEEE International Conference on Fuzzy Systems,,,10.1109/FUZZ48607.2020.9177616,,2020,1,https://doi.org/10.1109/FUZZ48607.2020.9177616,https://semanticscholar.org/paper/93dacfa3d8f6cf6bb78ca365a32ad012b4999087,""Knowledge graphs have become increasingly popular over the past years. The most popular data model for representing knowledge graphs is the Resource Description Framework (RDF). In an open Web environment, it is common case that the RDF knowledge graphs data from different sources may often contain inconsistent or imprecise information. Efficient querying of fuzzy RDF knowledge graphs is therefore of increasing importance. In this paper, we firstly introduce practical extensions of the RDF model to represent vagueness based on fuzzy graph. Then we extend the concept of SPARQL graph pattern making it possible to query an element-level fuzzy RDF knowledge graphs with high degree of truth. Finally, we present a backtracking algorithm for calculating the set of homomorphisms from fuzzy SPARQL graph into a fuzzy RDF graph to demonstrate our proposed methods."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Knowledge representation using fuzzy deduction graphs,A fuzzy reasoning path gives a relationship between the antecedent proposition and consequent proposition.,""M. Chandwani, N. Chaudhari"",IEEE Trans. Syst. Man Cybern. Part B,,,10.1109/3477.544298,,1996,13,https://doi.org/10.1109/3477.544298,https://semanticscholar.org/paper/45245782b8119a62cbb1c9c37f3edb88e5ecf4d7,""A new knowledge representation model, known as fuzzy deduction graph (FDG), is introduced in this paper. An FDG can represent a knowledge base containing the fuzzy propositions and fuzzy rules. In an FDG, a systematic method of finding the fuzzy reasoning path (FRP) is given which is based on Dijkstra's shortest path framework. The FRP gives a relationship between the antecedent (source) proposition and consequent (goal) proposition, such that the consequent proposition is reached with the greatest fuzzy value. The process of finding the FRP is illustrated with examples."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"A Fuzzy Query Method Oriented to Knowledge Graph,The fuzzy query method for RDF models proposed in this paper has more vital fuzzy query ability and more flexible universality.,Yunxing Liu,Journal of Physics: Conference Series,,,10.1088/1742-6596/2221/1/012051,https://iopscience.iop.org/article/10.1088/1742-6596/2221/1/012051/pdf,2022,,https://doi.org/10.1088/1742-6596/2221/1/012051,https://semanticscholar.org/paper/0fcfafab8d0efea34de7eb8f30f92ef8aea772eb,""With the widespread application of Knowledge Graphs, Knowledge Graph query technology has received widespread attention. The daily use of natural language usually contains fuzzy terms. The use of fuzzy terms in queries is more in line with natural language habits. Therefore, fuzzy questions have been widely discussed and applied in relational data models, and their use in NoSQL data models has also begun to be affected in recent years. RDF (Resource Description Framework) is a representative model of the knowledge graph, and SPARQL is the standard query language of RDF. To realize the fuzzy query of the knowledge graph, this paper introduces the unclear expansion syntax of aggregate function based on summarizing and analyzing the existing SPARQL fuzzy expansion. Supplements the qualitative preference analysis method then proposes and SPARQL1. 1 Corresponding fuzzy SPARQL1.1 (f-SPARQL1.1) simultaneously provides strategies and techniques for rewriting ambiguous queries into classic SPARQL","queries. In addition, this article also provides a v",isual interface for defining the membership functions of fuzzy terms and,provides three interactive methods,for setting,fuzzy,m,"embership functions. Compared with the previous fuzzy query methods for RDF models, the method proposed in this paper has more vital fuzzy query ability and more flexible universality. The experimental results show the usability of the method proposed in this paper."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"ProjFE: Prediction of fuzzy entity and relation for knowledge graph completion,A proposed method to predict the missing parts of triplets for knowledge graph completion is proposed.,""Huajing  Liu, Luyi  Bai, Xiangnan  Ma, Wenting  Yu, Changming  Xu"",Appl. Soft Comput.,,,10.1016/J.ASOC.2019.105525,,2019,5,https://doi.org/10.1016/J.ASOC.2019.105525,https://semanticscholar.org/paper/b95226acd0f70c98f230c2b06756d294c19ec52f,""Abstract A growing number of tasks about knowledge graph completion have been studied and improved recently, but most of them use translation matrices or reflect known entity to other space, always focusing on improving the method of translating known entities and relations. Differing from current works, our paper employs a combination operator instead of the translation matrix to avoid massive calculations, and takes fuzzy membership degree into consideration in the predicting process to enhance accuracy of projection. Hence, we propose a method called ProjFE to predict the missing parts of triplets for knowledge graph completion. This model uses fuzzy combination operators to combine the fuzzy known entities and relations. Score function is employed to access to a descending order of the correct candidates after combination, where the target entity is the top one. What is more, we use sigmoid and ReLU activation functions for evaluations, which could alleviate some undesirable gradient problems in the training process. It",is worth noting that our method ProjFE tends to have,"a relatively smaller parameter size than some existing models. Besides,",our model is proved to perform bet,ter in terms,of Me,an,"Rank."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Knowledge processing with Fuzzy Cognitive Maps,A knowledge-based expert system lacks the intrinsic structure for modeling these effects.,Rod  Taber,,,,10.1016/0957-4174(91)90136-3,,1991,304,https://doi.org/10.1016/0957-4174%2891%2990136-3,https://semanticscholar.org/paper/a0cfd4c9701921f40dd8e16b50ab3c14563979d7,""Abstract Complex social systems are difficult to represent. Relationships between social forces demand feedback. For example, the causal connection between commodity price and consumer demand is a feedback system. Price increase tends to decrease demand for some commodities. On the other hand, an increased demand tends to elevate price. A stable system settles into equilibrium. A dynamic system is needed to model shifts in equilibrium brought about by changes in the causal environment. The knowledge-based expert system lacks the intrinsic structure for modeling these effects. Internally, all expert systems depend on these representations. Some attempt to simulate unrestricted graphs with virtual registers and loop counters. The result is a semantic gap between the internal representation of the social system and the social system itself. This article presents the Fuzzy Cognitive Map (FCM) alternative to the expert system. We first describe the FCM. We then diagram several social systems. Finally, we show a method for combining credibility-weighted FCMs to achieve a single global knowledge base."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Dynamic representation of fuzzy knowledge based on fuzzy petri net and genetic-particle swarm optimization,A knowledge representation scheme is proposed.,""Wei-ming  Wang, Xun  Peng, Guo-Niu  Zhu, Jie  Hu, Ying-hong  Peng"",Expert Syst. Appl.,,,10.1016/j.eswa.2013.08.034,,2014,33,https://doi.org/10.1016/j.eswa.2013.08.034,https://semanticscholar.org/paper/c8d6be45cc659578e2b2a6c4a180513a5376a833,""Information in some fields like complex product design is usually imprecise, vague and fuzzy. Therefore, it would be very useful to design knowledge representation model capable to be adjusted according to information dynamics. Aiming at this objective, a knowledge representation scheme is proposed, which is called DRFK (Dynamic Representation of Fuzzy Knowledge). This model has both the features of a fuzzy Petri net and the learning ability of evolutionary algorithms. An efficient Genetic Particle Swarm Optimization (GPSO) learning algorithm is developed to solving fuzzy knowledge representation parameters. Being trained, a DRFK model can be used for dynamic knowledge representation and inference. Finally, an example is included as an illustration."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"FUZZY PETRI NETS AND KNOWLEDGE REPRESENTATION,A new method for fuzzy production rules of a rule-based system allows clear representation and easy analysis of concurrency and asynchronous reasoning.,Z. Cai,,,,,,1994,5,,https://semanticscholar.org/paper/bd65c89cf247bc7773cc3524bbd2398cea44a124,""With models of Fuzzy Petri nets and general Fuzzy Petri nets, this paper presents a new method for fuzzy production rules of a rule-based system which allows clear representation and easy analysis of concurrency and asynchronous reasoning. Algorithms for reasoning are also proposed, and the description of the model and fuzzy reasoning algorithms are described in detail."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Representing fuzzy knowledge using extended fuzzy Petri nets,The fuzzy reasoning process presented by S. M. Chen (1992) can be modeled by the extended fuzzy Petri nets.,Shyi-Ming Chen,1993 (2nd) International Symposium on Uncertainty Modeling and Analysis,,,10.1109/ISUMA.1993.366746,,1993,6,https://doi.org/10.1109/ISUMA.1993.366746,https://semanticscholar.org/paper/f672cd5e2f4488b0421252fa687eafd0f9588a13,The authors presents a knowledge representation technique for representing fuzzy knowledge using extended fuzzy Petri nets. Here the uncertainty factors of the fuzzy production rules in a rule-based system and the truth values in a rule-based system and the truth values of the propositions appearing in the rules are represented by fuzzy numbers. The fuzzy reasoning process presented by S. M. Chen (1992) also can be modeled by the extended fuzzy Petri nets. An example is used to illustrate the fuzzy reasoning process using extended fuzzy Petri nets. <<ETX>>,,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Document retrieval using knowledge-based fuzzy information retrieval techniques,The implicit relevant values between concepts are inferred by the transitive closure of the concept matrix based on fuzzy logic.,""Shyi-Ming Chen, Jeng-Yih Wang"",""IEEE Transactions on Systems, Man and Cybernetics"",,,10.1109/21.376492,,1995,81,https://doi.org/10.1109/21.376492,https://semanticscholar.org/paper/14a28da0a1d5095325c5f2b97e6d17a152316d62,""A knowledge-based approach for fuzzy information retrieval is proposed, where interval queries and weighted-interval queries are allowed for document retrieval. In this paper, knowledge is represented by a concept matrix, where the elements in a concept matrix represent relevant values between concepts. The implicit relevant values between concepts are inferred by the transitive closure of the concept matrix based on fuzzy logic. The proposed method is more flexible than previous methods due to the fact that it has the capability to deal with interval queries and weighted-interval queries. >"",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Knowledge Representation using Fuzzy Ontologies – A Review,Fuzzy ontologies are able to deal with imprecise and vague knowledge using fuzzy sets and its relations.,""Nilavu Devadoss, Sivakumar Ramakrishnan"",,,,,,2015,8,,https://semanticscholar.org/paper/2215115f76da6a72fcc44bfce50cc0794dca8aea,""-Fuzzy ontologies are able to deal with imprecise and vague knowledge using fuzzy sets and its relations. Ontologies are currently emerging as a powerful knowledge representation technique on the semantic web. However, it doesn’t have an ability to represent the fuzzy information as well as the uncertainty. This survey aims at giving a brief and comprehensible overview of the research directions practiced under the domain of ontology deal with the fuzzy knowledge, reconciling various definitions given in scientific literature and identifying some of the future research challenges in this domain. We hope this review will provide a useful resource for the fuzzy ontology learners’ community. Keywords--Ontology, Fuzzy, Semantic web."",,Review",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Knowledge-based representation of fuzzy sets,Knowledge plays important roles in determining a fuzzy set.,""R. Intan, M. Mukaidono, Masashi Emoto"",2002 IEEE World Congress on Computational Intelligence. 2002 IEEE International Conference on Fuzzy Systems. FUZZ-IEEE'02. Proceedings (Cat. No.02CH37291),,,10.1109/FUZZ.2002.1005058,,2002,10,https://doi.org/10.1109/FUZZ.2002.1005058,https://semanticscholar.org/paper/9bec0e43d090560a05f2b436815385897b9e194c,""A fuzzy set is considered to represent deterministic uncertainty called fuzziness. In deterministic uncertainty of fuzzy sets, one may subjectively determine the membership function of a given element by his knowledge. Different persons with different knowledge may provide different membership functions for elements in a universe with respect to a given fuzzy set. Here, knowledge plays important roles in determining or defining a fuzzy set. By adding the component of knowledge, we generalize the definition of fuzzy set based on probability theory. Some basic operations are re-defined. In addition, by using a fuzzy conditional probability relation, granularity of knowledge is given in two frameworks, crisp granularity and fuzzy granularity. Also, two asymmetric similarity classes or subsets are considered. When fuzzy sets represent problems or situations, a granule of knowledge might describe a class (group) of knowledge (persons) who has similar point of view in dealing the problems. Objectivit",y and individuality measures are proposed in order to,"calculate degree of objectivity and individuality, respectively of a gi","ven element of knowledge."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Fuzzy knowledge representation and reasoning using Petri nets,Petri nets can represent fuzzy production rules of a rule-based system.,""D. S. Yeung, E.C.C.  Tsang"",,,,10.1016/0957-4174(94)90044-2,,1994,53,https://doi.org/10.1016/0957-4174%2894%2990044-2,https://semanticscholar.org/paper/d6d654c9914e91d518d4ae78c2debcd0e96d6264,""Abstract The expert knowledge captured and stored in an expert system makes it possible for nonexperts to solve a particular problem. This expert knowledge is usually expressed in precise form. Many knowledge representation methods have been developed for exact knowledge type. Fuzzy knowledge, on the other hand, is not as easily represented as nonfuzzy (exact) knowledge because it consists of some linguistic (fuzzy) variables. Petri nets, owing to their representing power, have been used to represent exact knowledge. However, many existing Expert Systems use Mycin-like methods to represent uncertain knowledge that assigns a certainty factor value to each uncertain fact. It is possible to use Petri nets to represent fuzzy production rules of a rule-based system. In this article, we propose a modified fuzzy reasoning algorithm based on Chen, Ke, and Chang (1990), which enhances the reasoning capability of the original algorithm. We also propose two additional algorithms for building reachability sets and adjacent places , tables that are required when applying the fuzzy reasoning algorithm. Furthermore, these algorithms",are implemented on the Knowledge Craft 1 frame-based,expert system to build a fuzzy expert system that aims to help students,choose their colleges and academic,departments,"."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Use of fuzzy ontologies in generalization of knowledge tree results,Fuzzy ontologies can generalize the results produced by the knowledge tree process from an information base.,""F. Perry, R. Yager"",Annual Conference on the North American Fuzzy Information Processing Society,,,10.1109/NAFIPS.2008.4531344,,2008,,https://doi.org/10.1109/NAFIPS.2008.4531344,https://semanticscholar.org/paper/69234a27700b55c7bc2e2f52e468ad215ed52c8b,In this paper we examine issues involving data generalization using a fuzzy ontology. In particular we consider generalizing the results produced by the knowledge tree process from an information base.,,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Paper title,Abstract summary,Authors,Journal,Influential citations,Scimago Journal Rank,DOI,PDF,Year,Citations,DOI URL,Semantic Scholar URL,Abstract,Takeaway suggests yes/no,Study type",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Explainable Recommendation Using Knowledge Graphs and Random Walks,The proposed method can generate explanation for all recommendations that have no path in the graph.,""Kaname Muto, S. Oyama, I. Noda"",2022 IEEE International Conference on Big Data (Big Data),,,10.1109/BigData55660.2022.10021120,https://eprints.lib.hokudai.ac.jp/dspace/bitstream/2115/88665/1/muto-hmdata2022.pdf,2022,,https://doi.org/10.1109/BigData55660.2022.10021120,https://semanticscholar.org/paper/9f23d36981bd6691dc26160d015ecb11d74122c9,""A knowledge graph (KG) contains rich information about users and items. The relationship among users and items can help to generate intuitive explanations for recommended items. Many variations of KG-based recommendation algorithms use the shortest path from the user to the item in order to generate an explan",ation of the recommendation.,"However, the s",imple,shortest path,may not be useful,in the,case when the path is,"long,",be,cause,the interpretation,of the long path,is,diffi,"cult. Also, there may be",no,path,between,t,he user and the recommended item. In order to,"overcome these difficulties, we",proposed an,extension of,the existing framework ba,sed on,random w,"alk with KG embedding. In the proposed framework, we",use the most probable,path in a,random,walk as an,explanation.,"Thereby,",our framework,can,even,explain i,tems,that,have no connect,ion in the,KG due,to,the,latent connection resul,ting from,r,andom wal,k teleportation. Comp,arison experiment,demonstrated,that the framework can provide more,suitable,recomme,ndations than t,he existing method. In a,dditi,"on, the",experiment show the ability of,the,proposed method,to generate explanation,for all recommendations that have no path in,the,"graph."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Auto-encoding a Knowledge Graph Using a Deep Belief Network: A Random Fields Perspective,The structure of the hierarchy can be internally captured by the neural network.,R. Murphy,ArXiv,,,,,2019,1,,https://semanticscholar.org/paper/83b625018f50bd1e760a10ee10f2047b1003accf,""We started with a knowledge graph of connected entities and descriptive properties of those entities, from which, a hierarchical representation of the knowledge graph is derived. Using a graphical, energy-based neural network, we are able to show that the structure of the hierarchy can be internally captured by the neural network, which allows for efficient output of the underlying equilibrium distribution from which the data are drawn."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Auto-encoding a Knowledge Graph Using a Deep Belief Network: A Random Fields Perspective,The structure of the hierarchy can be internally captured by the neural network.,Robert A. Murphy,ArXiv,,,,,2019,1,,https://semanticscholar.org/paper/f8a47fbc6c48143f458745f54c0cd9b344944913,""We started with a knowledge graph of connected entities and descriptive properties of those entities, from which, a hierarchical representation of the knowledge graph is derived. Using a graphical, energy-based neural network, we are able to show that the structure of the hierarchy can be internally captured by the neural network, which allows for efficient output of the underlying equilibrium distribution from which the data are drawn."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"A hierarchy of randomness for graphs,The four levels form a hierarchy.,""Miklós  Simonovits, Vera T. Sós"",Discret. Math.,,,10.1016/j.disc.2004.12.024,http://real.mtak.hu/110694/1/1-s2.0-S0012365X05004255-main.pdf,2005,,https://doi.org/10.1016/j.disc.2004.12.024,https://semanticscholar.org/paper/b1d79a75e981f0beb1d35107c10e25585a379c88,""In this paper we formulate four families of problems with which we aim at distinguishing different levels of randomness. The first one is completely non-random, being the ordinary Ramsey-Turan problem and in the subsequent three problems we formulate some randomized variations of it. As we will show, these four levels form a hierarchy. In a continuation of this paper we shall prove some further theorems and discuss some further, related problems."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Hierarchical Random Walk Inference in Knowledge Graphs,A hierarchical random-walk inference algorithm for relational learning in large scale graph-structured knowledge bases provides better inference accuracy than related works.,""Qiao Liu, Liuyi Jiang, Minghao Han, Yao Liu, Z. Qin"",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,,,10.1145/2911451.2911509,,2016,21,https://doi.org/10.1145/2911451.2911509,https://semanticscholar.org/paper/6a86696974d5d49b4b9be6bd10ffcf92f996f4db,""Relational inference is a crucial technique for knowledge base population. The central problem in the study of relational inference is to infer unknown relations between entities from the facts given in the knowledge bases. Two popular models have been put forth recently to solve this problem,",which are the latent factor,models and the,rand,"om-walk models,",respectively. Ho,"wever,",each of them has their,pros,and,"cons,",depending on their,computational e,ffi,ciency,and inference accuracy.,In,this,"paper,",we,propose a hierarchical random-walk inference,algorithm for relational learni,ng in large,scale graph-s,"tructured knowledge bases,",which,not only,maintains the computational simplicity of the rando,"m-walk models, but also",provides,better,inference,accuracy than,related,works. The imp,rove,ments,come from,two,basic,assumptions we,proposed,in this,pa,per.,"Firstly, we assume that",although,a,relation,between two entities,is syntactically,"directional,",the information conveyed by this re,lation is,equally,shared between,"the connected entities,",thus,all of,the relations are semantically,bid,irectional. Seco,"ndly, we assume that the",topology structures of the relation-specific,sub,graphs in knowled,ge,bases,can,be,exploi,ted,to,"improve the performance of the random-walk based relational inference algorithms. The proposed algorithm and ideas are validated with numerical results on experimental data sampled from practical knowledge bases, and the results are compared to state-of-the-art approaches."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Quantifying randomness in real networks,""Many important local and global structural properties of these networks are reproduced by dk-random graphs whose degree distributions, degree correlations and clustering are as in the corresponding real network."",""Chiara  Orsini, Marija M Dankulov, Pol  Colomer-de-Simón, Almerima  Jamakovic, Priya  Mahadevan, Amin  Vahdat, Kevin E Bassler, Zoltán  Toroczkai, Marián  Boguñá, Guido  Caldarelli, Santo  Fortunato, Dmitri  Krioukov"",Nature communications,,4.846 (280),10.1038/ncomms9627,https://www.nature.com/articles/ncomms9627.pdf,2015,95,https://doi.org/10.1038/ncomms9627,https://semanticscholar.org/paper/a60c5035a9dae585271ddb59e8301f0f47e691ec,""Represented as graphs, real networks are intricate combinations of order and disorder. Fixing some of the structural properties of",network models to their val,ues observed in,real,"networks, many",other properties,appear,as statistical conseq,uences,of,these,"fixed observables,",plus randomness,in,other,respects. Here we emplo,y t,he dk,"-series,",a,complete set of basic characteristics of the,"network structure, to study the",statistical,dependencies,between different network,prope,rties. We,"consider six real networks—the Internet, US airport","network, human protein",interact,"ions, t",echnosocial,web of trust,", English","word network,",and,an f,MRI map of,the,human,brain—and find,that many,import,ant,loc,al and global structural,properti,es,of these,networks are closely,reproduced by dk,#NAME?,"s whose degree distributions, degree",correlat,ions and,clustering are,as in the corresponding,real,networ,k. We discuss important concept,"ual,","methodological,",and practical implicati,"ons of this evaluation of network randomness,",and,release software,t,o gene,rate,dk,#NAME?,gr,aph,"s."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Knowledge Graphs and Network Text Analysis,Concepts might be too broad or complex to be used properly.,R. Popping,,,,10.1177/0539018403042001798,https://pure.rug.nl/ws/files/10288912/PoppingR-Knowledge-RUG-2003.pdf,2003,116,https://doi.org/10.1177/0539018403042001798,https://semanticscholar.org/paper/241fc01b327856476e0194265ddd36bd50e7d3f5,""A knowledge graph is a kind of semantic network representing some scientific theory. The article describes the present state of this field and addresses a number of problems that have not yet been solved. These problems are implicit relations, strength of (causal) relations, and exclusiveness. Concepts might be too broad or complex to be used properly, so directions for solving these problems are explored. The solutions are applied to a knowledge graph in the field of labour","markets."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Causal Relationship over Knowledge Graphs,Causal relations can be represented and measured with some semantics which are uncovered by state-of-the-art approaches.,Hao Huang,International Conference on Information and Knowledge Management,,,10.1145/3511808.3557818,https://dl.acm.org/doi/pdf/10.1145/3511808.3557818,2022,,https://doi.org/10.1145/3511808.3557818,https://semanticscholar.org/paper/02d2b77db2fbaf9e85b6c64ec10b77b635d9850f,""Causality has been discussed for centuries, and the theory of causal inference over tabular data has been broadly studied and utilized in multiple disciplines. However, only a few works attempt to infer the causality while exploiting the meaning of the data represented in a data structure like knowledge graph. These works offer a glance at the possibilities of causal inference over knowledge graphs, but do not yet consider the metadata, e.g., cardinalities, class subsumption and overlap, and integrity constraints. We propose CareKG, a new formalism to express causal relationships among concepts, i.e., classes and relations, and enable causal queries over knowledge graphs using semantics of metadata. We empirically evaluate the expressiveness of CareKG in a synthetic knowledge graph concerning cardinalities, class subsumption and overlap, integrity constraints. Our initial results indicate that CareKG can represent and measure causal relations with some semantics which are uncovered by state-of-the-art approaches."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Towards Causal Knowledge Graphs - Position Paper,""Causal relations from text can be represented in the form of knowledge graphs to empower downstream ML applications, or AI systems in general, with the ability to distinguish correlation from causation and reason with causality in an explicit manner."",""E. Blomqvist, Marjan Alirezaie, M. Santini"",KDH@ECAI,,,,,2020,,,https://semanticscholar.org/paper/64e87e9f2d44aa10746d7783e989cc4bef665c45,""In this position paper, we highlight that being able to analyse the cause-effect relationships for determining the causal status among a set of events is an essential requirement in many contexts and argue that cannot be overlooked when building systems targeting real-world use cases. This is especially true for medical contexts where the understanding of the cause(s) of a symptom, or observation, is of vital importance. However, most approaches purely based on Machine Learning (ML) do not explicitly represent and reason with causal relations, and may therefore mistake correlation for causation. In the paper, we therefore argue for an approach to extract causal relations from text, and represent them in the form of Knowledge Graphs (KG), to empower downstream ML applications, or AI systems in general, with the ability to distinguish correlation from causation and reason with causality in an explicit manner. So far, the bottlenecks in KG creation have been scalability and accuracy of automated methods, hence, we argue that two novel features are required from methods for addressing these challenges, i.e. (i) the use of Knowledge Patterns to guide the KG generation process towards a certain","resulting knowledge structure, and (ii)",the use of a semantic referee to automatica,lly,curate t,he,extra,cted,kno,wled,ge.,W,e claim,that,"this will be an important step forward for supporting interpretable AI systems, and integrating ML and knowledge representation approaches, such as KGs, which should also generalise well to other types of relations, apart from causality."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Explanation knowledge graph construction through causality extraction from texts,The accuracy result of the explanation knowledge graph construction is 90% based on expert judgments.,""Chaveevan  Pechsiri, Rapepun  Piriyakul"",,,,10.1007/S11390-010-1083-6,,2010,6,https://doi.org/10.1007/S11390-010-1083-6,https://semanticscholar.org/paper/ba012043e7f176eeda6ad8429f111a65bf9e3595,""Explanation knowledge expressed by a graph, especially in the graphical model, is essential to comprehend clearly all paths of effect events in causality for basic diagnosis. This research focuses on determining the effect boundary using a statistical based approach and patterns of effect events in the graph whether they are consequence or concurrence without temporal markers. All necessary causality events from texts for the graph construction are extracted on multiple clauses/EDUs (Elementary Discourse Units) which assist in determining effect-event patterns from written event sequences in documents. To extract the causality events from documents, it has to face the effect-boundary determination problems after applying verb pair rules (a causative verb and an effect verb) to identify the causality. Therefore, we propose Bayesian Network and Maximum entropy to determine the boundary of the effect EDUs. We also propose learning the effect-verb order pairs from the adjacent effect EDUs to solve the effect-event patterns for representing the extracted causality by the graph construction. The accuracy result of the explanation knowledge graph construction is 90% based on expert judgments whereas the average accuracy results from the effect boundary dete",rmination by Bayesian Network and Maximum,"entropy are 90% and 93%, respectively."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Explanation Knowledge Graph Construction Through Causality Extraction from Texts,The accuracy result of the explanation knowledge graph construction is 90% based on expert judgments.,""Chaveevan  Pechsiri, Rapepun  Piriyakul"",Journal of Computer Science and Technology,,0.587 (8459),10.1007/s11390-010-9387-0,,2010,26,https://doi.org/10.1007/s11390-010-9387-0,https://semanticscholar.org/paper/fee060896476b6c9bb80e2904ab633d4d58cfb40,""Explanation knowledge expressed by a graph, especially in the graphical model, is essential to comprehend clearly all paths of effect events in causality for basic diagnosis. This research focuses on determining the effect boundary using a statistical based approach and patterns of effect events in the graph whether they are consequence or concurrence without temporal markers. All necessary causality events from texts for the graph construction are extracted on multiple clauses/EDUs (Elementary Discourse Units) which assist in determining effect-event patterns from written event sequences in documents. To extract the causality events from documents, it has to face the effect-boundary determination problems after applying verb pair rules (a causative verb and an effect verb) to identify the causality. Therefore, we propose Bayesian Network and Maximum entropy to determine the boundary of the effect EDUs. We also propose learning the effect-verb order pairs from the adjacent effect EDUs to solve the effect-event patterns for representing the extracted causality by the graph construction. The accuracy result of the explanation knowledge graph construction is 90% based on expert judgments whereas the",average accuracy results from the effect,boundary determination by Bayesian Network,an,d Maximum,e,ntropy,are,90%,and,93,"%,",respec,tivel,"y."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Causal Discovery in Knowledge Graphs by Exploiting Asymmetric Properties of Non-Gaussian Distributions,Causal modeling has been used widely to improve generalization and to provide interpretability in machine learning models.,""Rohan Giriraj, S. S. Thomas"",ArXiv,,,,,2021,,,https://semanticscholar.org/paper/d56f8a2aab4c623715c8249d69131cf2259611e6,""In recent years, causal modelling has been used widely to improve generalization and to provide interpretability in machine learning models. To determine causeeffect relationships in the absence of a randomized trial, we can model causal systems with counterfactuals and interventions given enough domain knowledge. However, there are several cases where domain knowledge is almost absent and the only recourse is using a statistical method to estimate causal relationships. While there have been several works done in estimating causal relationships in unstructured data, we are yet to find a well-defined framework for estimating causal relationships in Knowledge Graphs (KG). It is commonly used to provide a semantic framework for data with complex inter-domain relationships. In this work, we define a hybrid approach that allows us to discover cause-effect relationships in KG. The proposed approach is based around the finding of the instantaneous causal structure of a non-experimental matrix using a non-Gaussian model, i.e; finding the causal ordering of the variables in a non-Gaussian setting. The non-experimental matrix is a low-dimensional tensor projection obtained by decomposing the adjacency tensor of a KG. We use two different pre-existing algorithms, one for the causal discovery",and the other for decomposing the KG and,combining them to get the causal structure,in,"a KG."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Differential Causal Rules Mining in Knowledge Graphs,A semantic matching approach can help gain insights into various domains.,""Lucas Simonne, N. Pernelle, Fatiha Saïs, R. Thomopoulos"",International Conference on Knowledge Capture,,,10.1145/3460210.3493584,,2021,1,https://doi.org/10.1145/3460210.3493584,https://semanticscholar.org/paper/58270735a9fa7a6a4f0e6e449eef0e13d77c455a,""In recent years, keen interest towards Knowledge Graphs has increased in both academia and the industry which has led to the creation of various datasets and the development of different research topics. In this paper, we present an approach that discovers differential causal rules in Knowledge Graphs. Such rules express that for two different class instances, a different treatment leads to different outcomes. Discovering causal rules is often the key of experiments, independently of their domain. The proposed approach is based on semantic matching relying on community detection and strata that can be defined as complex sub-classes. An experimental evaluation on two datasets shows that such mined rules can help gain insights into various domains."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Knowledge Graphs and Network Text Analysis,Concepts might be too broad or complex to be used properly.,R. Popping,,,,10.1177/0539018403042001798,https://pure.rug.nl/ws/files/10288912/PoppingR-Knowledge-RUG-2003.pdf,2003,116,https://doi.org/10.1177/0539018403042001798,https://semanticscholar.org/paper/241fc01b327856476e0194265ddd36bd50e7d3f5,""A knowledge graph is a kind of semantic network representing some scientific theory. The article describes the present state of this field and addresses a number of problems that have not yet been solved. These problems are implicit relations, strength of (causal) relations, and exclusiveness. Concepts might be too broad or complex to be used properly, so directions for solving these problems are explored. The solutions are applied to a knowledge graph in the field of labour markets."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Differential Causal Rules Mining in Knowledge Graphs,""Differential causal rules are often the key of experiments, independent of their domain."",""Lucas  Simonne, Nathalie  Pernelle, Fatiha  Saïs, Rallou  Thomopoulos"",K-CAP,,,10.1145/3460210.3493584,,2021,,https://doi.org/10.1145/3460210.3493584,https://semanticscholar.org/paper/8552d9c9baad767e852011f334627a8867829bb2,""In recent years, keen interest towards Knowledge Graphs has increased in both academia and the industry which has led to the creation of various datasets and the development of different research topics. In this paper, we present an approach that discovers differential causal rules in Knowledge Graphs. Such rules express that for two different class instances, a different treatment leads to different outcomes. Discovering causal rules is often the key of experiments, independently of their domain. The proposed approach is based on semantic matching relying on community detection and strata that can be defined as complex sub-classes. An experimental evaluation on two datasets shows that such mined rules can help gain insights into various domains."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Interactive Causal Discovery in Knowledge Graphs,A relational schema can be used to learn a probabilistic relational model.,""M. Munch, Juliette Dibie-Barthélemy, Pierre-Henri Wuillemin, C. Manfredotti"",PROFILES/SEMEX@ISWC,,,,,2019,4,,https://semanticscholar.org/paper/4e1c9fbf81553952583317043868a1ca88589a7e,""Being able to provide explanations about a domain is a hard task that requires from a probabilistic reasoning's viewpoint a causal knowledge about the domain variables, allowing one to predict how they can influence each others. However, causal discovery from data alone remains a challenging question. In this article, we introduce a way to tackle this question by presenting an interactive method to build a probabilistic relational model from any given relevant domain represented by a knowledge graph. Combining both ontological and expert knowledge, we define a set of constraints translated into a so-called relational schema. Such a relational schema can then be used to learn a probabilistic relational model, which allows causal discovery."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"iLab at FinCausal 2022: Enhancing Causality Detection with an External Cause-Effect Knowledge Graph,The proposed graph builder method outperforms the other methods w/o external knowledge.,""Ziwei Xu, R. Nararatwong, N. Kertkeidkachorn, R. Ichise"",FNP,,,,,2022,,,https://semanticscholar.org/paper/3ccef67dbaa605887e6193dc3d25bad2099fa2f6,""The application of span detection grows fast along with the increasing need of understanding the causes and effects of events, especially in the finance domain. However, once the syntactic clues are absent in the text, the model tends to reverse the cause and effect spans. To solve this problem, we introduce graph construction techniques to inject cause-effect graph knowledge for graph embedding. The graph features combining with BERT embedding, then are used to predict the cause effect spans. The results show our proposed graph builder method outperforms the other methods w/wo external knowledge."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Distilling Causal Metaknowledge from Massive Knowledge Graphs,The quality and interpretability of causal rules outperform correlation-based rules in knowledge graphs.,,,,,,,2021,,,https://semanticscholar.org/paper/22b78bdcfafe60bfed299341e6212a41db8a2467,""In recent years, the growing information over- 001 load facilitates the access to billions of rela- 002 tional facts in the world, which are usually in- 003 tegrated in all manner of knowledge graphs. 004 The metaknowledge, defined as the knowledge 005 about knowledge, reveals the inner principle 006 of arising these factual knowledge, and hence 007 is of vital importance to be discovered for the 008 understanding, exploiting and completion of 009 knowledge. In this paper, we focus on captur- 010 ing the causal component of metaknowledge, 011 that is a metarule with causal semantic. For 012 the propose, we devise an efficient causal rule 013 discovery algorithm called CaRules that distills 014 the causal rules between two knowledge graph 015 schemata abstracted from instances from mas- 016 sive knowledge graphs. Extensive experiments 017 demonstrate that the quality and interpretabil- 018 ity of the causation-based rules outperform the 019 correlation-based rules, especially in the out- 020 of-distribution tasks. 021"",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Incorporating prior knowledge from counterfactuals into knowledge graph reasoning,Prior knowledge extracted from counterfactuals is effective in improving the multi-hop reasoning model.,""Zikang  Wang, Linjing  Li, Daniel Dajun Zeng, Xiaofei  Wu"",Knowl. Based Syst.,,,10.1016/j.knosys.2021.107035,,2021,3,https://doi.org/10.1016/j.knosys.2021.107035,https://semanticscholar.org/paper/32e960e791f20aa3dac59873daf3cb7cb541a362,""Abstract Knowledge graph reasoning aims to find the missing links in knowledge graphs and is an important fundamental task. Existing methods mostly reason end-to-end and ignore the prior knowledge in the knowledge graph. In this paper, we attempt to mine prior knowledge from the knowledge graph based on counterfactuals and to use the prior knowledge to enhance the model. Specifically, we begin by constructing counterfactuals to assign a weight for",each relation as,prior knowledge and then perform reasoning based on both prior,knowledge and reinforcement learning. This approach combines the advantages of prior knowledge and neural networks. Experiments on three large datasets show that the prio,r knowledge extracted from counterfactual,s is,effective,in imp,roving,the,multi-hop reasoning model.,Prior knowledge also has the,advantage,of,"being path-length independent,",wh,ich mitigates the performance degradation in multi-hop reason,ing when t,he reason,ing path,"is excessively long."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"A Variational Quantum Circuit Model for Knowledge Graph Embeddings,Quantum representations can be trained efficiently meanwhile preserving the quantum advantages.,Yunpu  Ma,,,,,,2020,,,https://semanticscholar.org/paper/4d21668cb366f8df5919dc45477aeb9b13d2535f,""Can quantum computing resources facilitate representation learning? In this work, we propose the first quantum Ansatz for statistical relational learning on knowledge graphs using parametric quantum circuits. We propose a variational quantum circuit for modeling knowledge graphs by introducing quantum representations of entities. In particular, latent representations of entities are encoded as coefficients of quantum states, while predicates are characterized by parametric gates acting on the quantum states. We show that quantum representations can be trained efficiently meanwhile preserving the quantum advantages. Simulations on classical machines with different datasets show that our proposed quantum circuit Ansatz and quantum representations can achieve comparable results to the state-of-the-art classical models, e.g., RESCAL, DISTMULT. Furthermore, after optimizing the models, the complexity of inductive inference on the knowledge graphs can be reduced with respect to the number of entities."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Quantum Machine Learning Algorithm for Knowledge Graphs,A sampling-based quantum algorithm achieves speedup with a polylogarithmic runtime in the dimension of knowledge graph tensor.,""Yunpu Ma, Yuyi Wang, Volker Tresp"",ACM Transactions on Quantum Computing,,,10.1145/3467982,http://arxiv.org/pdf/2001.01077,2020,7,https://doi.org/10.1145/3467982,https://semanticscholar.org/paper/3c183e10dc822ae615d5eb2b6f180958ab12a224,""Semantic knowledge graphs are large-scale triple-oriented databases for knowledge representation and reasoning. Implicit knowledge can be inferred by modeling the tensor representations generated from knowledge graphs. However, as the sizes of knowledge graphs continue to grow, classical modeling becomes increasingly computationally resource intensive. This article investigates how to capitalize on quantum resources to accelerate the modeling of knowledge graphs. In particular, we propose the first quantum machine learning algorithm for inference on tensorized data, i.e., on knowledge graphs. Since most tensor problems are NP-hard [18], it is challenging to devise quantum algorithms to support the inference task. We simplify the modeling task by making the plausible assumption that the tensor representation of a knowledge graph can be approximated by its low-rank tensor singular value decomposition, which is verified by our experiments. The proposed sampling-based quantum algorithm achieves speedup with a polylogarithmic runtime in the dimension of knowledge graph tensor."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Quantum Machine Learning Algorithm for Knowledge Graphs,A sampling-based quantum algorithm achieves speedup with a polylogarithmic runtime in the dimension of knowledge graph tensor.,""Yunpu  Ma, Yuyi  Wang, Volker  Tresp"",ACM Transactions on Quantum Computing,,,10.1145/3467982,http://arxiv.org/pdf/2001.01077,2021,6,https://doi.org/10.1145/3467982,https://semanticscholar.org/paper/83ec55bfc5ffe00be79a00ac10dad3f4d44957ff,""Semantic knowledge graphs are large-scale triple-oriented databases for knowledge representation and reasoning. Implicit knowledge can be inferred by modeling the tensor representations generated from knowledge graphs. However, as the sizes of knowledge graphs continue to grow, classical modeling becomes increasingly computationally resource intensive. This article investigates how to capitalize on quantum resources to accelerate the modeling of knowledge graphs. In particular, we propose the first quantum machine learning algorithm for inference on tensorized data, i.e., on knowledge graphs. Since most tensor problems are NP-hard [18], it is challenging to devise quantum algorithms to support the inference task. We simplify the modeling task by making the plausible assumption that the tensor representation of a knowledge graph can be approximated by its low-rank tensor singular value decomposition, which is verified by our experiments. The proposed sampling-based quantum algorithm achieves speedup with a polylogarithmic runtime in the dimension of knowledge graph tensor."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Quantum Machine Learning Algorithm for Knowledge Graphs,A sampling-based quantum algorithm achieves exponential speedup with a runtime that is polylogarithmic in the dimension of knowledge graph tensor.,Ludwig Maximilian,,,,,,2020,1,,https://semanticscholar.org/paper/d4e27ce8ed14abb8e0465d2379348041794dddc5,""Semantic knowledge graphs are large-scale triple-oriented databases for knowledge representation and reasoning. Implicit knowledge can be inferred by modeling and reconstructing the tensor representations generated from knowledge graphs. However, as the sizes of knowledge graphs continue to grow, classical modeling becomes increasingly computational resource intensive. This paper investigates how quantum resources can be capitalized to accelerate the modeling of knowledge graphs. In particular, we propose the first quantum machine learning algorithm for making inference on tensorized data, e.g., on knowledge graphs. Since most tensor problems are NP-hard Hillar and Lim [16], it is challenging to devise quantum algorithms to support that task. We simplify the problem by making a plausible assumption that the tensor representation of a knowledge graph can be approximated by its low-rank tensor singular value decomposition, which is verified by our experiments. The proposed sampling-based quantum algorithm achieves exponential speedup with a runtime that is polylogarithmic in the dimension of knowledge graph tensor."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Variational Quantum Circuit Model for Knowledge Graph Embedding,The quantum embeddings can be trained efficiently meanwhile preserving the quantum advantages.,""Yunpu Ma, Volker Tresp, Liming Zhao, Yuyi Wang"",Advanced Quantum Technologies,,1.858 (1414),10.1002/qute.201800078,,2019,9,https://doi.org/10.1002/qute.201800078,https://semanticscholar.org/paper/23830bb104b25103162ec9f9f463624d9a434194,""In this work, the first quantum Ansätze for the statistical relational learning on knowledge graphs using parametric quantum circuits are proposed. Two types of variational quantum circuits for knowledge graph embedding are introduced. Inspired by the classical representation learning, latent features for entities are first considered as coefficients of quantum states, while predicates are characterized by parametric gates acting on the quantum states. For the first model, the quantum advantages disappear when it comes to the optimization of this model. Therefore, a second quantum circuit model is introduced where embeddings of entities are generated from parameterized quantum gates acting on the pure quantum state. The benefit of the second method is that the quantum embeddings can be trained efficiently meanwhile preserving the quantum advantages. It is shown that the proposed methods can achieve comparable results to the state?of?the?art classical models, for example, RESCAL, DistMult. Furthermore, after optimizing the models, the complexity of inductive inference on the knowledge graphs might be reduced with",respect,to the n,umber,"of entities."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Quantum graphs: I. Some basic structures,A quantum graph is a graph equipped with a self-adjoint differential or pseudo-differential Hamiltonian.,P. Kuchment,,,,10.1088/0959-7174/14/1/014,,2004,586,https://doi.org/10.1088/0959-7174/14/1/014,https://semanticscholar.org/paper/edd7d691cf10d967d8b8fd83bbb11089f4587541,""A quantum graph is a graph equipped with a self-adjoint differential or pseudo-differential Hamiltonian. Such graphs have been studied recently in relation to some problems of mathematics, physics and chemistry. The paper has a survey nature and is devoted to the description of some basic notions concerning quantum graphs, including the boundary conditions, self-adjointness, quadratic forms, and relations between quantum and combinatorial graph models."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"""Quantum experiments and graphs II: Quantum interference, computation, and state generation"",Complex weights in graphs naturally lead to quantum interference.,""Xuemei Gu, Manuel Erhard, A. Zeilinger, M. Krenn"",Proceedings of the National Academy of Sciences,,,10.1073/pnas.1815884116,https://www.pnas.org/content/pnas/116/10/4147.full.pdf,2018,35,https://doi.org/10.1073/pnas.1815884116,https://semanticscholar.org/paper/04394eb915c78f369c0873d87fc3c03f9cb571ac,""Significance Graph theory can be used to model and explain different phenomena from physics. In this paper, we show that one can interpret quantum experiments composed of linear optics and probabilistic sources with graph theory. The important understanding is that complex weights in the graph naturally describe the quantum interference. That point of view leads to several results: We uncover a yet unexplored type of multiphoton quantum interference. It can be used to solve questions that are intractable on a classical computer. Also, the connection points toward a general restriction on creating certain classes of quantum states. In general, it gives another perspective on a mature photonic technology and will be significant for future designs of such experiments. We present an approach to describe state-of-the-art photonic quantum experiments using graph theory. There, the quantum states are given by the coherent superpositions of perfect matchings. The crucial observation is that introducing complex weights in graphs naturally leads to quantum i",nterfere,nce. This,view,point immediately,leads,to,many,i,nte,resti,ng,res,ults,", so",me,of,whic,h we,present,here.,First,", w",e i,den,tify,an,ex,perimen,tal,unexpl,ore,d multip,hoto,n i,nterferen,ce,ph,enomenon.,"Second,",we,fin,d tha,t c,omputin,g t,he,resul,ts,of,s,uch,ex,periments,is,#P-,"hard,",w,hic,h mean,s it,is,a,c,lass,ically,i,ntractable,p,roblem,deali,ng,with,the,c,omputation,of,a,m,atr,ix,f,uncti,on,Permanent,and,it,s ge,neraliz,atio,n Ha,fnian.,"Third,",we,explai,n how,a r,ecent,no-go,res,ult,applies,ge,nerally,to,li,near,optical,qua,ntum,ex,per,imen,"ts,",t,hus,revealing,"important insights into quantum state generation with current photonic technology. Fourth, we show how to describe quantum protocols such as entanglement swapping in a graphical way. The uncovered bridge between quantum experiments and graph theory offers another perspective on a widely used technology and immediately raises many follow-up questions."",,",,,,
"Encoding graphs into quantum states: An axiomatic approach,A rich structure includes and generalizes several classes of multipartite entangled state.,""R. Ionicioiu, T. Spiller"",,,,10.1103/PhysRevA.85.062313,http://arxiv.org/pdf/1110.5681,2011,12,https://doi.org/10.1103/PhysRevA.85.062313,https://semanticscholar.org/paper/b1ea7f96ad897d0c1c73bab965796f09231bd2f8,""A fundamental problem in quantum information is to describe efficiently multipartite quantum states. An efficient representation in terms of graphs exists for several families of quantum states (graph, cluster, stabilizer states), motivating us to extend this construction to other classes. We introduce an axiomatic framework for mapping graphs to quantum states of a suitable physical system. Starting from three general axioms we derived a rich structure which includes and generalizes several classes of multipartite entangled state, like graph/stabilizer states, Gaussian cluster states, quantum random networks and projected entangled pair states (PEPS). Due to its flexibility we can extend the present formalism to include directed and weighted graphs."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"From Quantum Graph Computing to Quantum Graph Learning: A Survey,Advanced quantum algorithms have been proposed for characterizing the graph structures.,""Yehui Tang, Junchi Yan, Hancock Edwin"",ArXiv,,,,,2022,1,,https://semanticscholar.org/paper/ed57f4dde9b0a173bd7a39b2ad4777c27d7afa47,""Quantum computing (QC) is a new computational paradigm whose foundations relate to quantum physics. Notable progress has been made, driving the birth of a series of quantum-based algorithms that take advantage of quantum computational power. In this paper, we provide a targeted survey of the development of QC for graphrelated tasks. We first elaborate the correlations between quantum mechanics and graph theory to show that quantum computers are able to generate useful solutions that can not be produced by classical systems efficiently for some problems related to graphs. For its practicability and wide-applicability, we give a brief review of typical graph learning techniques designed for various tasks. Inspired by these powerful methods, we note that advanced quantum algorithms have been proposed for characterizing the graph structures. We give a snapshot of quantum graph learning where expectations serve as a catalyst for subsequent research. We further discuss the challenges of using quantum algorithms in graph learning, and future directions towards more flexible and versatile quantum graph learning solvers."",,Review",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Quantum graphs: II. Some spectral properties of quantum and combinatorial graphs,A periodic combinatorial or quantum graph has a point spectrum.,P. Kuchment,,,,10.1088/0305-4470/38/22/013,http://arxiv.org/pdf/math-ph/0411003,2004,239,https://doi.org/10.1088/0305-4470/38/22/013,https://semanticscholar.org/paper/ba5ea21afd5d7d3f35ff2dac3274eb8ce27a5d66,""The paper deals with some spectral properties of (mostly infinite) quantum and combinatorial graphs. Quantum graphs have been intensively studied lately due to their numerous applications to mesoscopic physics, nanotechnology, optics and other areas. A Schnol-type theorem is proven that allows one to detect that a point ? belongs to the spectrum when a generalized eigenfunction with an sub-exponential growth integral estimate is available. A theorem on spectral gap opening for 'decorated' quantum graphs is established (its analogue is known for the combinatorial case). It is also shown that if a periodic combinatorial or quantum graph has a point spectrum, it is generated by compactly supported eigenfunctions ('scars')."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Which Graph States are Useful for Quantum Information Processing?,Graph states are an elegant and powerful quantum resource for measurement-based quantum computation.,""Mehdi  Mhalla, Mio  Murao, Simon  Perdrix, Masato  Someya, Peter S. Turner"",TQC,,,10.1007/978-3-642-54429-3_12,http://arxiv.org/pdf/1006.2616,2011,23,https://doi.org/10.1007/978-3-642-54429-3_12,https://semanticscholar.org/paper/f0d85213a6f66aaeae00724cc8c2d133b282484e,""Graph statesa[ 5 ] are an elegant and powerful quantum resource for measurement based quantum computation (MBQC). They are also used for many quantum protocols (error correction, secret sharing, etc.). The main focus of this paper is to provide a structural characterisation of the graph states that can be used for quantum information processing. The existence of a gflow (generalized flow) [ 8 ] is known to be a requirement for open graphs (graph, input set and output set) to perform uniformly and strongly deterministic computations. We weaken the gflow conditions to define two new more general kinds of MBQC: uniform equiprobability and constant probability. These classes can be useful from a cryptographic and information point of view because even though we cannot do a deterministic computation in general we can preserve the information and transfer it perfectly from the inputs to the outputs. We derive simple graph characterisations for these classes and prove that the deterministic and uniform equiprobability classes collapse when the cardinalities of inputs and outputs",are the,same. We,also,prove the revers,ibilit,y o,f gfl,ow,in,that,c,ase.,The,new,g,rap,hical,cha,racteris,ations,allow,us,to,go,fro,m o,pen,graphs,to,graphs,in,general,and,to,consider,t,his,question,: given,a g,raph,with,no,inputs,or,o,utputs,f,ixe,"d,",wh,ich,vertices,ca,n be,chos,en,as,input,and,ou,tp,ut,for,quant,um,informati,on,proce,ssing?,W,e pre,sent,a,character,isa,ti,on,of,t,he,sets,o,f possible,inp,uts,and,ouputs,for,the,equip,robabil,ity,"class,",which,is,also,valid,for,de,terminis,tic,comput,ati,ons,wit,h inputs,and,oup,uts,of,the,sa,me,ca,rdinality.,""",,",,,,
"Connectivity for quantum graphs,A definition of connectedness for quantum graphs generalizes the classical definition.,""JAVIER ALEJANDRO CHÁVEZ-DOMÍNGUEZ, ANDREW T. SWIFT"",,,,10.1016/j.laa.2020.08.020,http://manuscript.elsevier.com/S0024379520303931/pdf/S0024379520303931.pdf,2019,4,https://doi.org/10.1016/j.laa.2020.08.020,https://semanticscholar.org/paper/7f2d654b0d3368e53a0d8fce68e16bfe10c1938c,""In quantum information theory there is a construction for quantum channels, appropriately called a quantum graph, that generalizes the confusability graph construction for classical channels in classical information theory. In this paper, we provide a definition of connectedness for quantum graphs that generalizes the classical definition. This is used to prove a quantum version of a particular case of the classical tree-packing theorem from graph theory. Generalizations for the related notions of $k$-connectedness and of orthogonal representation are also proposed for quantum graphs, and it is shown that orthogonal representations have the same implications for connectedness as they do in the classical case."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"""Healthcare Knowledge Graph Construction: State-of-the-art, open issues, and opportunities"",Knowledge graphs are rooted in a number of healthcare applications to furnish better data representation and knowledge inference.,""Bilal Abu-Salih, Muhammad Al-Qurishi, Mohammed Alweshah, M. Al-Smadi, Reem Alfayez, Heba Saadeh"",ArXiv,,,10.48550/arXiv.2207.03771,,2022,1,https://doi.org/10.48550/arXiv.2207.03771,https://semanticscholar.org/paper/84cd55fbdaf8481e90f4d36a9bb245b6e5b0abf7,""The incorporation of data analytics in the healthcare industry has made significant progress, driven by the demand for efficient and effective big data analytics solutions. Knowledge graphs (KGs) have proven utility in this arena and are rooted in a number of healthcare applications to furnish better data representation and knowledge inference. However, in conjunction with a lack of a representative KG construction taxonomy, several existing approaches in this designated domain are inadequate and inferior. This paper is the first to provide a comprehensive taxonomy and a bird's eye view of healthcare KG construction. Additionally, a thorough examination of the current state-of-the-art techniques drawn from academic works relevant to various healthcare contexts is carried out. These techniques are critically evaluated in terms of methods used for knowledge extraction, types of the knowledge base and sources, and the incorporated evaluation protocols. Finally, several research","findings and existing issues in the literature are reported and discussed, opening horizons for future research in this vibrant area."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Efficient and Robust Knowledge Graph Construction,Knowledge graph construction has appealed to the NLP community researchers.,""Ningyu Zhang, Tao Gui, Guoshun Nan"",AACL,,,,,2022,,,https://semanticscholar.org/paper/f14ea74a40c40cad10c32fccf5a410144735d683,""Knowledge graph construction which aims to extract knowledge from the text corpus, has appealed to the NLP community researchers. Previous decades have witnessed the remarkable progress of knowledge graph construction on the basis of neural models; however, those models often cost massive computation or labeled data resources and suffer from unstable inference accounting for biased or adversarial samples. Recently, numerous approaches have been explored to mitigate the efficiency and robustness issues for knowledge graph construction, such as prompt learning and adversarial training. In this tutorial, we aim to bring interested NLP researchers up to speed on the recent and ongoing techniques for efficient and robust knowledge graph construction. Additionally, our goal is to provide a systematic and up-to-date overview of these methods and reveal new research opportunities to the audience."",,Review",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"KGGen: A Generative Approach for Incipient Knowledge Graph Population,A generative model KGGen can generate triplets regardless of entity pair co-occurrence in the text corpus.,""Hao Chen, Chenwei Zhang, Jun Li, Philip S. Yu, N. Jing"",IEEE Transactions on Knowledge and Data Engineering,,2.431 (883),10.1109/tkde.2020.3014166,,2022,3,https://doi.org/10.1109/tkde.2020.3014166,https://semanticscholar.org/paper/addaceff526337211d202e41fb6dd326d831decf,""Knowledge graph is becoming an indispensable resource that offers structured information for numerous AI applications. However, the knowledge graph often suffers from its incompleteness. Building a complete, high-quality knowledge graph is time-consuming and requires significant human annotation efforts. In this paper, we study the Knowledge Graph Population task, which aims at extending the scale of structured knowledge, with a special focus on reducing data preparation and annotation efforts. Previous works mainly based on discriminative methods build classifiers and verify candidate triplets that are extracted from texts, which heavily rely on the quality of data collection and co-occurrance of entities in the text. However, such methods fail to generalize on entity pairs that are not highly co-occurred, and fail to discover entity pairs that are not co-occurred at all in the given text corpus. We introduce a generative perspective to approach this task and define each relationship by learning the da","ta distribution that embodies the core common properties for relational reasoning. A generative model KGGen is proposed, which samples from the learned data distribution for each relation",and can,generate triplets regardless of entity pair co-occurrence,in the text corpus. To further improve the,generation q,uality while alleviate human annot,ation effor,"ts, a",dversarial,lear,ning is,adopted to,not,only,enc,ourage,ge,ne,rating,hi,gh,qua,lity,tri,plets,", b",ut,a,lso,give,model,the,abili,ty,to,aut,oma,ti,ca,lly,as,sess,the,ge,ne,ration,q,uality,. Q,uantita,tive,and,qual,it,ative,exp,eri,men,tal,r,esul,ts,cond,ucte,d on,t,wo,real-w,"orld generic knowledge graphs show that the proposed model KGGen generates novel and meaningful triplets with improved efficiency and less human annotation comparing with the state-of-the-art approaches."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"A Comprehensive Survey on Automatic Knowledge Graph Construction,Automatic knowledge graph construction aims to manufacture structured human knowledge.,""Lingfeng Zhong, Jia Wu, Qian Li, Hao Peng, Xindong Wu"",ArXiv,,,10.48550/arXiv.2302.05019,,2023,,https://doi.org/10.48550/arXiv.2302.05019,https://semanticscholar.org/paper/9ea5874d261359e287eabb735de38a8edba1e091,""Automatic knowledge graph construction aims to manufacture structured human knowledge. To this end, much effort has historically been spent extracting informative fact patterns from different data sources. However, more recently, research interest has shifted to acquiring conceptualized structured knowledge beyond informative data. In addition, researchers have also been exploring new ways of handling sophisticated construction tasks in diversified scenarios. Thus, there is a demand for a systematic review of paradigms to organize knowledge structures beyond data-level mentions. To meet this demand, we comprehensively survey more than 300 methods to summarize the latest developments in knowledge graph construction. A knowledge graph is built in three steps: knowledge acquisition, knowledge refinement, and knowledge evolution. The processes of knowledge acquisition are reviewed in detail, including obtaining entities with fine-grained types and their conceptual linkages to knowledge graphs; resolving coreferences; and extracting entity relationships in complex scenarios. The survey cove","rs models for knowledge refinement, including knowledge graph completion, and knowledge fusion. Methods to handle knowledge evolution are also systematically presented, including conditio",n knowle,"dge acquisition, condition knowledge graph completion, and",knowledge dynamic. We present the paradigm,s to compare,the distinction among these method,s along the,axis,of the da,ta en,vironme,"nt, motivat","ion,",and,arch,itectu,re.,A,dditio,nal,ly,", we",als,o pr,ovide,br,ie,fs,on,acce,ssible,res,ources,t,hat,can,he,lp,r,ead,ers,to,deve,lop,p,ractic,al,knowl,edg,e graph,sys,tems,. The,s,urvey,con,clu,des,wi,th,dis,cu,ssion,s on,the,c,ha,llenges,"and possible directions for future exploration."",,Systematic Review",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Knowledge graph construction and Internet of Things optimisation for power grid data knowledge extraction,The knowledge graph construction and Internet of Things optimization framework of power grid data knowledge extraction are proposed in this article.,""Xiang-yang Sun, Ting Hao, Xing Li"",Applied Mathematics and Nonlinear Sciences,,0.84 (5327),10.2478/amns.2021.2.00283,https://sciendo.com/pdf/10.2478/amns.2021.2.00283,2022,,https://doi.org/10.2478/amns.2021.2.00283,https://semanticscholar.org/paper/50b68e2e11bc8f907b8ed288090fefd4bcc331b7,""Abstract Problems exist in power grid data management that have unclear relationships, weak security and low accuracy. By analysing the knowledge graph construction characteristics of smart grid data information and knowledge extraction, the grid data management platform is reshaped architecturally, and the knowledge graph construction technology is embedded in the grid data management framework. For the aforementioned problems, the knowledge graph construction and Internet of Things optimisation framework of power grid data knowledge extraction are proposed in this article. Firstly, the semantic search (KGSS) algorithm based on the knowledge graph is used. The KGSS algorithm extracts knowledge from structured, semi-structured and unstructured grid data through the massively parallel processing acquisition model and Hadoop database, and constructs knowledge entities, attributes and inter-entity relationships.","Then, it optimises and predicts through the knowledge graph construction and Internet of Things optimisation framework extracted from power grid data knowledge. Finally, the experimental",results,show that the accuracy rate of the KGSS algorithm is 92%.,The experimental results also show that it,provides new,ideas and research directions for,power grid,data,under big,data,in the,"future."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Complex Question Answering over Incomplete Knowledge Graph as N-ary Link Prediction,The embedding-based retrieval strategy beats the state-of-the-art models on incomplete and complex KGQA tasks by a significant margin.,""Daoguang Zan, Sirui Wang, Hongzhi Zhang, Kun Zhou, Wei Wu, Wayne Xin Zhao, Bingchao Wu, Bei Guan, Yongji Wang"",IEEE International Joint Conference on Neural Network,,,10.1109/IJCNN55064.2022.9892700,,2022,,https://doi.org/10.1109/IJCNN55064.2022.9892700,https://semanticscholar.org/paper/b2159e6ad8efb3e057e7d8f1d9e9ea1f5a3b5697,""The Question Answering over Knowledge Graph (KGQA) task seeks entities (answers) from the Knowledge Graph (KG) in order to answer natural language questions. In practice, KG is often incomplete, with numerous missing links and nodes. With such an incomplete KG, it is tricky to use the semantics inside the KG to get the golden answers, particularly for complex questions. Some current efforts concentrate on using external corpora to overcome KG sparsity; however, identifying and obtaining the corpora is challenging. Other types of work aim to leverage the pre-trained embeddings to resolve the issue but perform slightly worse on complex questions involving numerous triple facts in KG. To address the aforementioned problems, we present a framework CAPKGQA, which transforms Complex KGQA into an n-Ary link Prediction task capable of explicitly modeling complex questions. Furthermore, previous methods also suffer","from incomplete KG throughout the candidate answer generation phase. Therefore, we devise an embedding-based retrieval strategy to extract more reliable candidate answers from incomplete",KG. Ext,ensive experiments reveal that our approach beats the stat,e-of-the-art models on incomplete and compl,ex KGQA tasks,"by a significant margin."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Knowledge Graph Completion Based on GCN of Multi-Information Fusion and High-Dimensional Structure Analysis Weight,A knowledge graph completion model encodes and decodes the feature information is proposed.,""Niu Haoran, He Haitao, Feng Jianzhou, Nie Junlan, Zhang Yangsen, Ren Jiadong"",,,,10.1049/CJE.2021.00.080,https://onlinelibrary.wiley.com/doi/pdfdirect/10.1049/cje.2021.00.080,2022,2,https://doi.org/10.1049/CJE.2021.00.080,https://semanticscholar.org/paper/e0ba1a1513a9417e623dcbc51cc749e64bdf977d,""Knowledge graph completion (KGC) can solve the problem of data sparsity in the knowledge graph. A large number of models for the KGC task have been proposed in recent years. However, the underutilisation of the structure information around nodes is one of the main problems of the previous KGC model, which leads to relatively single encoding information. To this end, a new KGC model that encodes and decodes the feature information is proposed. First, we adopt the subgraph sampling method to extract node structure. Moreover, the Graph convolutional network (GCN) introduced the channel attention convolution encode node structure features and represent them in matrix form to fully mine the node feature information. Eventually, the high-dimensional structure analysis weight decodes the encoded matrix embeddings and then constructs the scoring function. The experimental results show that the model performs well on the datasets used."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Construction and Applications of Open Business Knowledge Graph,OpenBG is ongoing.,""Shumin Deng, Hui Chen, Zhoubo Li, Feiyu Xiong, Qiang Chen, Mosha Chen, Xiangwen Liu, Jiaoyan Chen, Jeff Z. Pan, Huajun Chen, Ningyu Zhang"",,,,,,2022,1,,https://semanticscholar.org/paper/ec3c1ba06113635cf56e7b6fbeab7546b398f4ab,""Business Knowledge Graph is important to many enterprises today, providing the factual knowledge and structured data that steer many products and make them more intelligent. De-spite the welcome outcome, building business KG brings prohibitive issues of de?cient structure, multiple modalities and unmanageable quality. In this paper, we advance the practical challenges related to building KG in non-trivial real-world systems. We introduce the process of building an open business knowledge graph (OpenBG) derived from a well-known enterprise. Speci?cally, we de?ne a core ontology to cover various abstract products and consumption demands, with ?ne-grained taxonomy and multi-modal facts in deployed applications. OpenBG is ongoing, and the current version contains more than 2.6 bil-lion triples with more than 88 million entities and 2,681 types of relations. We release all the open resources (OpenBG benchmark) derived from it for the community. We also report benchmark results with best learned lessons 1 ."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Generative Knowledge Graph Construction: A Review,Generative knowledge graph construction methods are flexible and can be adapted to widespread tasks.,""Hongbin Ye, Ningyu Zhang, Hui Chen, Huajun Chen"",Conference on Empirical Methods in Natural Language Processing,,,10.48550/arXiv.2210.12714,,2022,1,https://doi.org/10.48550/arXiv.2210.12714,https://semanticscholar.org/paper/816593b1abbc9b09763fcb2894ca3778db341769,""Generative Knowledge Graph Construction (KGC) refers to those methods that leverage the sequence-to-sequence framework for building knowledge graphs, which is flexible and can be adapted to widespread tasks. In this study, we summarize the recent compelling progress in generative knowledge graph construction. We present the advantages and weaknesses of each paradigm in terms of different generation targets and provide theoretical insight and empirical analysis. Based on the review, we suggest promising research directions for the future. Our contributions are threefold: (1) We present a detailed, complete taxonomy for the generative KGC methods; (2) We provide a theoretical and empirical analysis of the generative KGC methods; (3) We propose several research directions that can be developed in the future."",,Review",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Multi-Modal Knowledge Graph Construction and Application: A Survey,Multi-modal knowledge graphs are an inevitable key step towards the realization of human-level machine intelligence.,""Xiangru Zhu, Zhixu Li, Xiaodan Wang, Xueyao Jiang, Penglei Sun, Xuwu Wang, Yanghua Xiao, N. Yuan"",ArXiv,,,,,2022,4,,https://semanticscholar.org/paper/c885288bf6dbd4448ffb0317af63cee63ce6eb62,""Recent years have witnessed the resurgence of knowledge engineering which is featured by the fast growth of knowledge graphs. However, most of existing knowledge graphs are represented with pure symbols, which hurts the machine’s capability to understand the real world. The multi-modalization of knowledge graphs is an inevitable key step towards the realization of human-level machine intelligence. The results of this endeavor are Multi-modal Knowledge Graphs (MMKGs). In this survey on MMKGs constructed by texts and images, we first give definitions of MMKGs, followed with the preliminaries on multi-modal tasks and techniques. We then systematically review the challenges, progresses and opportunities on the construction and application of MMKGs respectively, with detailed analyses of the strength and weakness of different solutions. We finalize this survey with open research problems relevant to"",,Review",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"A Review of Knowledge Graph Completion,Knowledge graph representation learning is divided into conventional and graph neural network representation learning.,""Mohamad Zamini, H. Reza, M. Rabiei"",Inf.,,,10.3390/info13080396,https://www.mdpi.com/2078-2489/13/8/396/pdf?version=1661395650,2022,6,https://doi.org/10.3390/info13080396,https://semanticscholar.org/paper/15bcddf2d3ac05f54879e7153c434a532ec13c64,""Information extraction methods proved to be effective at triple extraction from structured or unstructured data. The organization of such triples in the form of (head entity, relation, tail entity) is called the construction of Knowledge Graphs (KGs). Most of the current knowledge graphs are incomplete. In order to use KGs in downstream tasks, it is desirable to predict missing links in KGs. Different approaches have been recently proposed for representation learning of KGs by embedding both entities and relations into a low-dimensional vector space aiming to predict unknown triples based on previously visited triples. According to how the triples will be treated independently or dependently, we divided the task of knowledge graph completion into conventional and graph neural network representation learning and we discuss them in more detail. In conventional approaches, each triple will be processed independently and in GNN-based approaches, triples also consider their local neighborhood."",,Review",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"A Human-in-the-Loop Approach for Personal Knowledge Graph Construction from File Names,File systems are promising sources for constructing personal knowledge graphs.,""Markus Schröder, Christian Jilek, A. Dengel"",KGCW@ESWC,,,,,2022,1,,https://semanticscholar.org/paper/c9f56d69c76cb5e7a9d803ffcdbf28ee8a463405,""Users’ personal and work related concepts (e.g. persons, projects, topics) are usually not sufficiently covered by knowledge graphs. Yet, already handmade classification schemes, prominently folder structures, naturally mention several of their concepts in file names. Thus, such data could be a promising source for constructing personal knowledge graphs. However, this idea poses several challenges: file names are usually noisy non-grammatical text snippets, while folder structures do not clearly define how concepts relate to each other. To cope with this semantic gap, we include knowledge workers as humans-in-the-loop to guide the building process with their feedback. Our semi-automatic personal knowledge graph construction approach consists of four major stages: domain term extraction, ontology population, taxonomic and non-taxonomic relation learning. We conduct a case study with four expert interviews from different domains in an industrial scenario. Results indicate that file systems are promising sources and, combined with our approach, already yield useful personal knowledge graphs with moderate effort spent."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Multi-Modal Knowledge Graph Construction and Application: A Survey,Multi-modal knowledge graphs are an inevitable key step towards the realization of human-level machine intelligence.,""Xiangru Zhu, Zhixu Li, Xiaodan Wang, Xueyao Jiang, Penglei Sun, Xuwu Wang, Yanghua Xiao, N. Yuan"",IEEE Transactions on Knowledge and Data Engineering,,2.431 (883),10.1109/TKDE.2022.3224228,http://arxiv.org/pdf/2202.05786,2022,14,https://doi.org/10.1109/TKDE.2022.3224228,https://semanticscholar.org/paper/fa350b1089db1f8ab97bb72287b37ed4748c89cf,""—Recent years have witnessed the resurgence of knowledge engineering which is featured by the fast growth of knowledge graphs. However, most of existing knowledge graphs are represented with pure symbols, which hurts the machine’s capability to understand the real world. The multi-modalization of knowledge graphs is an inevitable key step towards the realization of human-level machine intelligence. The results of this endeavor are Multi-modal Knowledge Graphs (MMKGs). In this survey on MMKGs constructed by texts and images, we ?rst give de?nitions of MMKGs, followed with the preliminaries on multi-modal tasks and techniques. We then systematically review the challenges, progresses and opportunities on the construction and application of MMKGs respectively, with detailed analyses of the strengths and weaknesses of different solutions. We ?nalize this survey with open research problems relevant to MMKGs."",,Review",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Knowledge Graph Construction for Electric Substation Based on Multiple-source Data,Knowledge graphs are constructed for grid substations based on multi-source data.,""Zheng Jiang, Huang Long"",2022 IEEE 5th International Electrical and Energy Conference (CIEEC),,,10.1109/CIEEC54735.2022.9845990,,2022,,https://doi.org/10.1109/CIEEC54735.2022.9845990,https://semanticscholar.org/paper/2748b0d01fd89ad5dd59aefa5de2944db5d3f7b8,""Knowledge graph (KG) is a database that stores the information and relationship between entities in the form of graph. This paper presents a knowledge graph construction method for grid substation knowledge graph based on multi-source data. The device connection, alarm information and ledgers are contained in KG, which benefits the substation operation and maintenance. First, entities and relationships are selected according to the actual composition of substation. Then, triples are extracted through domain dictionaries and conditional random field. Entity disambiguation is carried out before establishing the knowledge graph based on corresponding data sources. Finally, knowledge fusion is used to remove the redundancy in the database to complete the construction of the KG. Compared to traditional relational database, graph database can more intuitively show the connection relationship between devices. By adding more links to knowledge graph, it takes less time for monitoring personnel to locate accidents when dealing with alarm","information."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Temporal Knowledge Graph Completion: A Survey,Knowledge graph completion can predict missing links and is crucial for real-world knowledge graphs which widely suffer from incompleteness.,""Borui Cai, Yong Xiang, Longxiang Gao, Heng Zhang, Yunfeng Li, Jianxin Li"",ArXiv,,,,,2022,8,,https://semanticscholar.org/paper/ec61bc70c26436eeac63637b75ce4ab0127561aa,""Knowledge graph completion (KGC) can predict missing links and is crucial for real-world knowledge graphs, which widely suffer from incompleteness. KGC methods assume a knowledge graph is static, but that may lead to inaccurate prediction results because many facts in the knowledge graphs change over time. Recently, emerging methods have shown improved predictive results by further incorporating the timestamps of facts; namely, temporal knowledge graph completion (TKGC). With this temporal information, TKGC methods can learn the dynamic evolution of the knowledge graph that KGC methods fail to capture. In this paper, for the first time, we summarize the recent advances in TKGC research. First, we detail the background of TKGC, including the problem definition, benchmark datasets, and evaluation metrics. Then, we summarize existing TKGC methods based on how timestamps of facts are used to capture the temporal dynamics. Finally, we conclude the paper and present future research directions of TKGC."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"""FAIR Knowledge Graph Construction from Text, an Approach Applied to Fictional Novels"",Large and openly available knowledge graphs are universal cross-domain knowledge bases.,""Diego Rincon-Yanez, S. Senatore"",TEXT2KG/MK@ESWC,,,,,2022,,,https://semanticscholar.org/paper/53610396debf12b8e89e5f595160832438342c0c,""A Knowledge Graph (KG) is a form of structured human knowledge depicting relations between entities, destined to reflect cognition and human-level intelligence. Large and openly available knowledge graphs (KGs) like DBpedia, YAGO, WikiData are universal cross-domain knowledge bases and are also accessible within the Linked Open Data (LOD) cloud, according to the FAIR principles that make data findable, accessible, interoperable and reusable. This work aims at proposing a methodological approach to construct domain-oriented knowledge graphs by parsing natural language content to extract simple triple-based sentences that summarize the analyzed text. The triples coded in RDF are in the form of subject, predicate, and object. The goal is to generate a KG that, through the main identified concepts, can be navigable and linked to the existing KGs to be automatically found and usable on the Web LOD cloud."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"MEduKG: A Deep-Learning-Based Approach for Multi-Modal Educational Knowledge Graph Construction,The proposed approach can manage and present various modes of educational resources.,""Nan Li, Qiang Shen, Rui Song, Yang Chi, Hao Xu"",Inf.,,,10.3390/info13020091,https://www.mdpi.com/2078-2489/13/2/91/pdf?version=1644898821,2022,4,https://doi.org/10.3390/info13020091,https://semanticscholar.org/paper/cf7eb1e29a3d6eed2ec739e9cd5c8c96f8027f1b,""The popularity of information technology has given rise to a growing interest in smart education and has provided the possibility of combining online and offline education. Knowledge graphs, an effective technology for knowledge representation and management, have been successfully utilized to manage massive educational resources. However, the existing research on constructing educational knowledge graphs ignores multiple modalities and their relationships, such as teacher speeches and their relationship with knowledge. To tackle this problem, we propose an automatic approach to construct multi-modal educational knowledge graphs that integrate speech as a modal resource to facilitate the reuse of educational resources. Specifically, we first propose a fine-tuned Bidirectional Encoder Representation from Transformers (BERT) model based on education lexicon, called EduBERT, which can adaptively capture effective information in the education field. We also add a Bidirectional Long Short-Term Memory-Conditional Random","Field (BiLSTM-CRF) to effectively identify educational entities. Then, the locational information of the entity is incorporated into BERT to extract the educational relationship. In addi","tion, to",cover the shortage of traditional text-based knowledge gr,"aphs, we focus on collecting teacher speech",to construct,a multi-modal knowledge graph. We,propose a,speec,h-fusion m,ethod,that l,inks these,data,into,the,graph,as,a,class,of,e,ntit,ies.,The,nume,ric,r,es,ult,s sho,w that,our,propo,se,d a,ppro,ach,c,an,ma,nag,e an,d pr,ese,nt,vario,us,modes,of,educat,iona,l re,sourc,es,and,that,it,ca,n p,ro,vide,b,etter,edu,cati,on,s,ervices,"."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Knowledge Graph Quality Evaluation under Incomplete Information,Knowledge graph quality evaluation under incomplete information.,""Xiaodong Li, Chenxin Zou, Yimeng Cai, Yuelong Zhu"",ArXiv,,,10.48550/arXiv.2212.00994,,2022,,https://doi.org/10.48550/arXiv.2212.00994,https://semanticscholar.org/paper/62e74be3dba081f0d9cf50a554f592f38c532f45,evaluators under incomplete information.,,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"From Discrimination to Generation: Knowledge Graph Completion with Generative Transformer,Knowledge graph completion aims to address the problem of extending a KG with missing triples.,""Xin Xie, Ningyu Zhang, Zhoubo Li, Shumin Deng, Hui Chen, Feiyu Xiong, Mosha Chen, Huajun Chen"",WWW,,,10.1145/3487553.3524238,https://dl.acm.org/doi/pdf/10.1145/3487553.3524238,2022,4,https://doi.org/10.1145/3487553.3524238,https://semanticscholar.org/paper/a146bc7758cf9233971e5d695550a366ad5022ae,""Knowledge graph completion aims to address the problem of extending a KG with missing triples. In this paper, we provide an approach GenKGC, which converts knowledge graph completion to sequence-to-sequence generation task with the pre-trained language model. We further introduce relation-guided demonstration and entity-aware hierarchical decoding for better representation learning and fast inference. Experimental results on three datasets show that our approach can obtain better or comparable performance than baselines and achieve faster inference speed compared with previous methods with pre-trained language models. We also release a new large-scale Chinese knowledge graph dataset OpenBG500 for research purpose1."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Toward Crowdsourced Knowledge Graph Construction: Interleaving Collection and Verification of Triples,The proposed approach can collect and verify distributed knowledge among casual workers.,""Helun Bu, K. Kuwabara"",International Conference on Agents and Artificial Intelligence,,,10.5220/0010902700003116,,2022,,https://doi.org/10.5220/0010902700003116,https://semanticscholar.org/paper/ef89c758e9e46332f03ee4ed8a5466351a1c8438,This paper presents a method for building a knowledge graph using crowdsourcing. The collection and verification of pieces of knowledge are essential components of building a high-quality knowledge graph. We introduce fill-in-the-blank-type of quizzes to collect knowledge as triples and true-or-false-type quizzes to verify the collected triples. We also present score functions to evaluate and select a quiz for efficient knowledge graph construction based on the workers’ past inputs. The collection and verification processes are dynamically interleaved using weights in the score function. Simulation results show that the proposed approach can collect and verify distributed knowledge among casual workers.,,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Research on the Knowledge Graph Construction Technology and its Power Grid Applications,""Knowledge graph can effectively manage massive information and realize intelligent knowledge extraction, reasoning, storage and retrieval."",""Yuan Gu, Lucheng Hong, Zehua Chen, Yuchen Zhang, Minghe Wu, Ziheng Yan"",2022 IEEE 5th International Electrical and Energy Conference (CIEEC),,,10.1109/cieec54735.2022.9846702,,2022,,https://doi.org/10.1109/cieec54735.2022.9846702,https://semanticscholar.org/paper/280e5d89106874a1130fbad0a381d20d1bfec1a4,""With the booming development of Internet, cloud computing and big data, the demand for processing massive data has greatly increased. As a key technology of knowledge engineering in artificial intelligence, knowledge graph can effectively manage massive information and realize intelligent knowledge extraction, reasoning, storage and retrieval. Its characteristics and application scenarios fit well with power grid systems. This paper introduces the development history of knowledge graph technology and analyzes the construction process of knowledge graph in detail. A review of its existing applications in the power grid from different perspective is presented. And the future challenges of knowledge graph construction have been put forward in the paper."",,Review",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"An Overview of Entity Relation Extraction Techniques,The need to invent approaches capable of handling higher order relations efficiently is important aspect of entity relation.,A. Zadgaonkar,,,,,,2015,3,,https://semanticscholar.org/paper/d8968951cb72d6bf9d9bd0c3c1306bc6606162b1,""Natural language processing requires deep understanding of semantic relationships between entities. This paper presents comprehensive review of various aspects of the Entity Relation Extraction task. Here, an attempt is made to cover in detail some of the important supervised and Semi-supervised classification approaches to the relation extraction task along with critical analyses. One of the most important aspects of Entity relation is higher-order relations. So there is a need of inventing approaches capable of handling higher order relations efficiently. Finally, in this paper some relation extraction applications like Question answering and Bio-text mining are also discuss."",,Review",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Joint Entity and Relation Extraction from Scientific Documents: Role of Linguistic Information and Entity Types,A sequence of enriched token representations forms a span.,""Santosh T.Y.S.S, Prantika Chakraborty, S. Dutta, Debarshi Kumar Sanyal, P. Das"",EEKE@JCDL,,,,,2021,7,,https://semanticscholar.org/paper/3e25847f045c42710dc30e9c8e3967c21d258fc7,""Scientific articles contain various types of domain-specific entities and relations between them. The entities and their relations succinctly capture important information about the topic of the document and hence, they are crucial to the understanding and automatic analysis of the documents. In this paper, we aim to automatically extract entities and relations from a scientific abstract using a deep neural model. Given an input sentence, we use a pretrained transformer to produce contextual embeddings of the tokens which are then enriched with embeddings of their part-ofspeech (POS) tags. A sequence of enriched token representations forms a span, and entities and relations are jointly learned over spans. Entity logits predicted by the entity classifier are used as features in the relation classifier. Our proposed model improves upon competitive baselines in the literature for entity and relation extraction on SciERC and ADE datasets."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"A Frustratingly Easy Approach for Entity and Relation Extraction,A simple pipelined approach for entity and relation extraction is the state-of-the-art on standard benchmarks.,""Zexuan Zhong, Danqi Chen"",North American Chapter of the Association for Computational Linguistics,,,10.18653/V1/2021.NAACL-MAIN.5,https://aclanthology.org/2021.naacl-main.5.pdf,2020,145,https://doi.org/10.18653/V1/2021.NAACL-MAIN.5,https://semanticscholar.org/paper/c4b22cf9ca9ffecc8f62baadbacd5f77f80141d9,""End-to-end relation extraction aims to identify named entities and extract relations between them. Most recent work models these two subtasks jointly, either by casting them in one structured prediction framework, or performing multi-task learning through shared representations. In this work, we present a simple pipelined approach for entity and relation extraction, and establish the new state-of-the-art on standard benchmarks (ACE04, ACE05 and SciERC), obtaining a 1.7%-2.8% absolute improvement in relation F1 over previous joint models with the same pre-trained encoders. Our approach essentially builds on two independent encoders and merely uses the entity model to construct the input for the relation model. Through a series of careful examinations, we validate the importance of learning distinct contextual representations for entities and relations, fusing entity information early in the","relation model, and",incorporating,global,context.,"Finally, we also",present an,efficient a,pproximation,to our approach,which,requires only one pass of,both entity,and relation encoders at,"inference time,",achieving an,8-16×,speedup,with a,sli,ght reduction in,"accuracy."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Enriching Relation representation vectors using Entity types and Dependency parse For Entity and Relation Extraction Model,SpERT.ET uses entity types of two spans and update gate to enrich relation representation vector.,""Bui Le Ngoc Min, Q. T. Tho"",""Conference on Research, Innovation and Vision for the Future in Computing & Communication Technologies"",,,10.1109/RIVF55975.2022.10013885,,2022,,https://doi.org/10.1109/RIVF55975.2022.10013885,https://semanticscholar.org/paper/eb7a07a2c9949ff87033d4a2b99245e39a222865,""Joint entity and relation extraction is a branch of information extraction, from the input sentence, the model identifies named entities and the relation between them. In this paper, we propose two models for joint entity and relation extraction, including (1) SpERT.ET: uses entity types of two spans and update gate to enrich relation representation vector, (2) SpERT.PDP: integrates Dependency parse information of the words to enrich relation representation vector. Our models outperform baseline models for joint entity and relation extraction on SciERC dataset."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"The Overview of Entity Relation Extraction Methods,The correct relationship between various entities is a key technology of information extraction system.,""Xian-Yi  Cheng, Xiao-hong  Chen, Jin  Hua"",ICIC 2011,,,10.1007/978-3-642-18129-0_113,,2011,4,https://doi.org/10.1007/978-3-642-18129-0_113,https://semanticscholar.org/paper/02f05aad1cdabe1e1126abab6d99710cb50a989d,""The Information extraction can be defined as the task of extracting information of specified events or facts, and then stored in a database for the users’ querying. Only with the correct relationship between the various entities, the database can be correctly store in. Entity relation extraction becomes a key technology of information Extraction system. In this paper, we analyze the status of entity relation extraction method; propose several problems for this field to be solved."",,Review",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"A Novel Feature-based Approach to Chinese Entity Relation Extraction,A feature-based Chinese relation extraction approach is effective when evaluated on the ACE 2005 Chinese data set.,""Wenjie Li, Peng Zhang, Furu Wei, Yuexian Hou, Q. Lu"",Annual Meeting of the Association for Computational Linguistics,,,10.3115/1557690.1557714,https://dl.acm.org/doi/pdf/10.5555/1557690.1557714,2008,40,https://doi.org/10.3115/1557690.1557714,https://semanticscholar.org/paper/7beac20d7f5f953cc2269d9433d7bbaa1367a6f4,""Relation extraction is the task of finding semantic relations between two entities from text. In this paper, we propose a novel feature-based Chinese relation extraction approach that explicitly defines and explores nine positional structures between two entities. We also suggest some correction and inference mechanisms based on relation hierarchy and co-reference information etc. The approach is effective when evaluated on the ACE 2005 Chinese data set."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Joint Extraction of Entities and Relations for Opinion Recognition,""Global, constraint-based inference can significantly boost the performance of both relation extraction and the extraction of opinion-related entities."",""Yejin Choi, Eric Breck, Claire Cardie"",Conference on Empirical Methods in Natural Language Processing,,,10.3115/1610075.1610136,https://dl.acm.org/doi/pdf/10.5555/1610075.1610136,2006,226,https://doi.org/10.3115/1610075.1610136,https://semanticscholar.org/paper/337d81402dedbb664e3ba0baddb761084588cbbb,""We present an approach for the joint extraction of entities and relations in the context of opinion recognition and analysis. We identify two types of opinion-related entities --- expressions of opinions and sources of opinions --- along with the linking relation that exists between them. Inspired by Roth and Yih (2004), we employ an integer linear programming approach to solve the joint opinion recognition task, and show that global, constraint-based inference can significantly boost the performance of both relation extraction and the extraction of opinion-related entities. Performance further improves when a semantic role labeling system is incorporated. The resulting system achieves F-measures of 79 and 69 for entity and relation extraction, respectively, improving substantially over prior results in the area."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Techniques for Jointly Extracting Entities and Relations: A Survey,Joint extraction is beneficial for both tasks.,""Sachin Pawar, P. Bhattacharyya, Girish Keshav Palshikar"",ArXiv,,,,,2021,4,,https://semanticscholar.org/paper/6e24cb022e89a8d6adc91cec15a9428eb8f10309,""Relation Extraction is an important task in Information Extraction which deals with identifying semantic relations between entity mentions. Traditionally, relation extraction is carried out after entity extraction in a """"pipeline"""" fashion, so that relation extraction only focuses on determining whether any semantic relation exists between a pair of extracted entity mentions. This leads to propagation of errors from entity extraction stage to relation extraction stage. Also, entity extraction is carried out without any knowledge about the relations. Hence, it was observed that jointly performing entity and relation extraction is beneficial for both the tasks. In this paper, we survey various techniques for jointly extracting entities and relations. We categorize techniques based on the approach they adopt for joint extraction, i.e. whether they employ joint inference or joint modelling or both. We further describe some representative techniques for joint inference and joint modelling. We also describe two standard datasets, evaluation techniques and performance of the joint extraction approaches on these",datasets. We presen,t a brief anal,ysis of,applicat,ion of a general,domain join,t extraction,approach to,a Biomedical da,taset.,This survey is useful for,researchers,as well as practitioners,in the field of,Information,Extrac,"tion, by",coveri,ng a,broad landscape,of joint extrac,tion,te,chni,"ques."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Using Entity Information from a Knowledge Base to Improve Relation Extraction,The notable type information improves relation extraction more than NER labels alone across a wide range of entity types and relations.,""Lan Du, Anish Kumar, Mark Johnson, Massimiliano Ciaramita"",Australasian Language Technology Association Workshop,,,,,2015,12,,https://semanticscholar.org/paper/26c39342628e5b62778956c2bde20d9b965a46b0,""Relation extraction is the task of extracting predicate-argument relationships between entities from natural language text. This paper investigates whether background information about entities available in knowledge bases such as FreeBase can be used to improve the accuracy of a state-of-the-art relation extraction system. We describe a simple and effective way of incorporating FreeBase’s notable types into a state-of-the-art relation extraction system (Riedel et al., 2013). Experimental results show that our notable typebased system achieves an average 7.5% weighted MAP score improvement. To understand where the notable type information contributes the most, we perform a series of ablation experiments. Results show that the notable type information improves relation extraction more than NER labels alone across a wide range of entity types and relations."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"A Entity Relation Extraction Method Based on Wikipedia and Pattern Clustering,The method achieves a good performance with high-quality seeds and patterns.,Han Xianpei,,,,,,2012,8,,https://semanticscholar.org/paper/18575e71e64b53a22e348dddf4cb816698752e1a,""This paper proposes a method to extract Chinese entity relations of high accuracy from open text based on Wikipedia and pattern clustering.We get relation instances by a mapping from HowNet to Wikipedia and via the structural characteristics of Wikipedia.Based on these,the method solves the entity recognition and generates significant sentence instances.Furthermore,significance assumption and keyword assumption are proposed to support classification and hierarchy clustering algorithm for pattern reliability.The results show that the method achieves a good performance with high-quality seeds and patterns."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Entity Relation Extraction Based on Entity Indicators,The neural network is effective for encoding syntactic and semantic information about a relation instance.,""Yongbin Qin, Weizhe Yang, Kai Wang, Ruizhang Huang, Feng Tian, Shaolin Ao, Yanping Chen"",Symmetry,,0.54 (9271),10.3390/SYM13040539,https://www.mdpi.com/2073-8994/13/4/539/pdf?version=1616744980,2021,11,https://doi.org/10.3390/SYM13040539,https://semanticscholar.org/paper/d09c2b925bead20b07ad0b22c5a93646064759e5,""Relation extraction aims to extract semantic relationships between two specified named entities in a sentence. Because a sentence often contains several named entity pairs, a neural network is easily bewildered when learning a relation representation without position and semantic information about the considered entity pair. In this paper, instead of learning an abstract representation from raw inputs, task-related entity indicators are designed to enable a deep neural network to concentrate on the task-relevant information. By implanting entity indicators into a relation instance, the neural network is effective for encoding syntactic and semantic information about a relation instance. Organized, structured and unified entity indicators can make the similarity between sentences that possess the same or similar entity pair and the internal symmetry of one sentence more obviously. In the experiment,",a systemic analysis,was conducted,to eva,luate the,impact of entity,indicators,on relation,extraction.,This method has,achie,ved state-of-the-art perfo,"rmance, exce",eding the compared method,s by more than 3,".7%, 5.0% and",11.20%,in F1 s,core on,the,ACE Chinese cor,"pus, ACE English",cor,pus,and,"Chinese literature text corpus, respectively."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Modeling Joint Entity and Relation Extraction with Table Representation,A joint learning approach significantly outperforms a pipeline approach by incorporating global features and by selecting appropriate learning methods and search orders.,""Makoto Miwa, Yutaka Sasaki"",Conference on Empirical Methods in Natural Language Processing,,,10.3115/v1/D14-1200,https://aclanthology.org/D14-1200.pdf,2014,229,https://doi.org/10.3115/v1/D14-1200,https://semanticscholar.org/paper/1845a57621ba2ce9ff3c2d1dcaa1f7f4b04b2186,""This paper proposes a history-based structured learning approach that jointly extracts entities and relations in a sentence. We introduce a novel simple and flexible table representation of entities and relations. We investigate several feature settings, search orders, and learning methods with inexact search on the table. The experimental results demonstrate that a joint learning approach significantly outperforms a pipeline approach by incorporating global features and by selecting appropriate learning methods and search orders."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"A Review on Entity Relation Extraction,The research status of relation extraction is analyzed.,""Qianqian Zhang, Mengdong Chen, Lianzhong Liu"",""2017 Second International Conference on Mechanical, Control and Computer Engineering (ICMCCE)"",,,10.1109/ICMCCE.2017.14,,2017,16,https://doi.org/10.1109/ICMCCE.2017.14,https://semanticscholar.org/paper/f422764e6c7d746ba26b70b5a92b4584f80b4e14,""Because of large amounts of unstructured data generated on the Internet, entity relation extraction is believed to have high commercial value. Entity relation extraction is a case of information extraction and it is based on entity recognition. This paper firstly gives a brief overview of relation extraction. On the basis of reviewing the history of relation extraction, the research status of relation extraction is analyzed. Then the paper divides theses research into three categories: supervised machine learning methods, semi-supervised machine learning methods and unsupervised machine learning method, and toward to the deep learning direction."",,Review",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"A Frustratingly Easy Approach for Joint Entity and Relation Extraction,A simple approach for joint entity and relation extraction is a new state-of-the-art on standard benchmarks.,""Zexuan Zhong, Danqi Chen"",ArXiv,,,,,2020,29,,https://semanticscholar.org/paper/f8d7b263e8d663583cd22d5988c8ea4a49ed2840,""End-to-end relation extraction aims to identify named entities and extract relations between them simultaneously. Most recent work models these two subtasks jointly, either by unifying them in one structured prediction framework, or multi-task learning through shared representations. In this work, we describe a very simple approach for joint entity and relation extraction, and establish the new state-of-the-art on standard benchmarks (ACE04, ACE05, and SciERC). Our approach essentially builds on two independent pre-trained encoders and merely uses the entity model to provide input features for the relation model. Through a series of careful examinations, we validate the importance of learning distinct contextual representations for entities and relations, fusing entity information at the input layer of the relation model, and incorporating global context. Finally, we also present an efficient approximation to our approach which requires only one pass of both encoders at inference time, obtaining a 8-16$\times$ speedup with a small accuracy drop."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Trustworthy Knowledge Graph Completion Based on Multi-sourced Noisy Data,Open knowledge graph completion methods leverage the Web to find missing facts.,""Jiacheng Huang, Yao Zhao, Wei Hu, Zhen-Hu Ning, Qijin Chen, Xiaoxia Qiu, Chengfu Huo, Weijun Ren"",The Web Conference,,,10.1145/3485447.3511938,http://arxiv.org/pdf/2201.08580,2022,2,https://doi.org/10.1145/3485447.3511938,https://semanticscholar.org/paper/37a2010deebb7cca1550c93b0bc5b3b7c1e7bc62,""Knowledge graphs (KGs) have become a valuable asset for many AI applications. Although some KGs contain plenty of facts, they are widely acknowledged as incomplete. To address this issue, many KG completion methods are proposed. Among them, open KG completion methods leverage the Web to find missing facts. However, noisy data collected from diverse sources may damage the completion accuracy. In this paper, we propose a new trustworthy method that exploits facts for a KG based on multi-sourced noisy data and existing facts in the KG. Specifically, we introduce a graph neural network with a holistic scoring function to judge the plausibility of facts with various value types. We design value alignment networks to resolve the heterogeneity between values and map them to entities even outside the KG. Furthermore, we present a truth inference model that incorporates data source qualities into the fact scoring function, and design a semi-supervised learning way to infer the truths from heterogeneous values. We conduct extensive experiments to compare our method with the state-of-the-arts. The results show that our method achieves superior accuracy not only in completing missing facts but also in discovering new facts."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"KGGen: A Generative Approach for Incipient Knowledge Graph Population,A generative model KGGen can generate triplets regardless of entity pair co-occurrence in the text corpus.,""Hao Chen, Chenwei Zhang, Jun Li, Philip S. Yu, N. Jing"",IEEE Transactions on Knowledge and Data Engineering,,2.431 (883),10.1109/tkde.2020.3014166,,2022,3,https://doi.org/10.1109/tkde.2020.3014166,https://semanticscholar.org/paper/addaceff526337211d202e41fb6dd326d831decf,""Knowledge graph is becoming an indispensable resource that offers structured information for numerous AI applications. However, the knowledge graph often suffers from its incompleteness. Building a complete, high-quality knowledge graph is time-consuming and requires significant human annotation efforts. In this paper, we study the Knowledge Graph Population task, which aims at extending the scale of structured knowledge, with a special focus on reducing data preparation and annotation efforts. Previous works mainly based on discriminative methods build classifiers and verify candidate triplets that are extracted from texts, which heavily rely on the quality of data collection and co-occurrance of entities in the text. However, such methods fail to generalize on entity pairs that are not highly co-occurred, and fail to discover entity pairs that are not co-occurred at all in the given text corpus. We introduce a generative perspective to approach this task and define each relationship by learning the data distribution that embodies the core common properties for relational reasoning. A generative model KGGen is proposed, which samples from the learned data distribution for each relation and can generate triplets regardless of entity pair co-occurrence in the text corpus. To further improve the generation quality while alleviate human annotation efforts, adversarial learning is adopted to",not,only encourage ge,nerating high,qu,ality tri,"plets,",b,ut,a,lso,give,model,the,a,bili,ty,to,auto,matic,al,ly,assess,th,e g,enera,tion,qua,lity,. Qua,ntita,tive,and,qu,alita,tive,e,xperim,ent,al,res,ults,cond,ucted,on,t,wo,re,al-worl,d generic,kn,owled,ge,gr,ap,hs,show,th,at,t,he,pro,pos,ed,mod,el,K,GGen,genera,tes,novel,and,mean,ingf,ul,tri,plet,s with,improve,d efficien,cy,a,nd,les,s h,uman,"annotation comparing with the state-of-the-art approaches."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Inductive Logical Query Answering in Knowledge Graphs,Inductive models are able to perform logical reasoning at inference time over unseen nodes generalizing to graphs up to 500% larger than training ones.,""Mikhail Galkin, Zhaocheng Zhu, Hongyu Ren, Jian Tang"",ArXiv,,,10.48550/arXiv.2210.08008,,2022,3,https://doi.org/10.48550/arXiv.2210.08008,https://semanticscholar.org/paper/d2c177f6386e7b88b406e2f741ed5387e4ced3b0,""Formulating and answering logical queries is a standard communication interface for knowledge graphs (KGs). Alleviating the notorious incompleteness of real-world KGs, neural methods achieved impressive results in link prediction and complex query answering tasks by learning representations of entities, relations, and queries. Still, most existing query answering methods rely on transductive entity embeddings and cannot generalize to KGs containing new entities without retraining the entity embeddings. In this work, we study the inductive query answering task where inference is performed on a graph containing new entities with queries over both seen and unseen entities. To this end, we devise two mechanisms lever-aging inductive node and relational structure representations powered by graph neural networks (GNNs). Experimentally, we show that inductive models are able to perform logical reasoning at inference time over unseen nodes generalizing to graphs up to 500% larger than training ones. Exploring the ef?ciency–effectiveness trade-off, we ?nd the inductive relational structure representation method generally achieves higher performance, while the inductive node representation method is able to answer complex queries in the inference-only regime without any training on queries and scales to graphs of millions of nodes. Code is available at https://github.com/DeepGraphLearning/InductiveQE ."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Utilizing Language Model Probes for Knowledge Graph Repair,A novel method to repair incorrect statements in knowledge graphs by replacing incorrect subject-predicate-object triples with likely correct ones.,""Hiba Arnaout, Bosch"",,,,,,2022,2,,https://semanticscholar.org/paper/a1c7793b102f065e5469f30f387266defbec04c7,""Structured knowledge is an important backend in the Wikimedia ecosystem, and knowledge graphs (KGs) like Wikidata are an as-set also in many other applications like web search and question answering. At web scale, it is unavoidable that KGs contain erroneous statements. While error detection and subsequent removal of incorrect facts have received attention in prior works, a better approach is to repair errors without losing information. This paper presents a novel method to repair incorrect statements in KGs by replacing incorrect subject-predicate-object (SPO) triples with likely correct ones, thus avoiding information loss. To this end, our method explores the power of LM probes for KG repair, and shows that context retrieval from the KG can significantly boost the probing. Specifically, we use the KG to augment LM probes so as to generate high-confidence values for the replacements of incorrect SPO triples. Experiments with Wikidata and DBpedia show that our method is viable and outperforms a prior baseline."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"A Review of Knowledge Graph Completion,Knowledge graph representation learning is divided into conventional and graph neural network representation learning.,""Mohamad Zamini, H. Reza, M. Rabiei"",Inf.,,,10.3390/info13080396,https://www.mdpi.com/2078-2489/13/8/396/pdf?version=1661395650,2022,6,https://doi.org/10.3390/info13080396,https://semanticscholar.org/paper/15bcddf2d3ac05f54879e7153c434a532ec13c64,""Information extraction methods proved to be effective at triple extraction from structured or unstructured data. The organization of such triples in the form of (head entity, relation, tail entity) is called the construction of Knowledge Graphs (KGs). Most of the current knowledge graphs are incomplete. In order to use KGs in downstream tasks, it is desirable to predict missing links in KGs. Different approaches have been recently proposed for representation learning of KGs by embedding both entities and relations into a low-dimensional vector space aiming to predict unknown triples based on previously visited triples. According to how the triples will be treated independently or dependently, we divided the task of knowledge graph completion into conventional and graph neural network representation learning and we discuss them in more detail. In conventional approaches, each triple will be processed independently and in GNN-based approaches, triples also consider their local neighborhood."",,Review",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Temporal Knowledge Graph Completion: A Survey,Knowledge graph completion can predict missing links and is crucial for real-world knowledge graphs.,""Borui Cai, Yong Xiang, Longxiang Gao, Heng Zhang, Yunfeng Li, Jianxin Li"",ArXiv,,,,,2022,8,,https://semanticscholar.org/paper/ec61bc70c26436eeac63637b75ce4ab0127561aa,""Knowledge graph completion (KGC) can predict missing links and is crucial for real-world knowledge graphs, which widely suffer from incompleteness. KGC methods assume a knowledge graph is static, but that may lead to inaccurate prediction results because many facts in the knowledge graphs change over time. Recently, emerging methods have shown improved predictive results by further incorporating the timestamps of facts; namely, temporal knowledge graph completion (TKGC). With this temporal information, TKGC methods can learn the dynamic evolution of the knowledge graph that KGC methods fail to capture. In this paper, for the first time, we summarize the recent advances in TKGC research. First, we detail the background of TKGC, including the problem definition, benchmark datasets, and evaluation metrics. Then, we summarize existing TKGC methods based on how timestamps of facts are used to capture the temporal dynamics. Finally, we conclude the paper and present future research directions of TKGC."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"From Discrimination to Generation: Knowledge Graph Completion with Generative Transformer,Knowledge graph completion aims to address the problem of extending a KG with missing triples.,""Xin Xie, Ningyu Zhang, Zhoubo Li, Shumin Deng, Hui Chen, Feiyu Xiong, Mosha Chen, Huajun Chen"",WWW,,,10.1145/3487553.3524238,https://dl.acm.org/doi/pdf/10.1145/3487553.3524238,2022,4,https://doi.org/10.1145/3487553.3524238,https://semanticscholar.org/paper/a146bc7758cf9233971e5d695550a366ad5022ae,""Knowledge graph completion aims to address the problem of extending a KG with missing triples. In this paper, we provide an approach GenKGC, which converts knowledge graph completion to sequence-to-sequence generation task with the pre-trained language model. We further introduce relation-guided demonstration and entity-aware hierarchical decoding for better representation learning and fast inference. Experimental results on three datasets show that our approach can obtain better or comparable performance than baselines and achieve faster inference speed compared with previous methods with pre-trained language models. We also release a new large-scale Chinese knowledge graph dataset OpenBG500 for research purpose1."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Neural Methods for Logical Reasoning over Knowledge Graphs,Neural network models achieve a 10% relative increase over the best performing state of the art.,""Alfonso Amayuelas, Shuai Zhang, Susie Xi Rao, Ce Zhang"",International Conference on Learning Representations,,,10.48550/arXiv.2209.14464,,2022,4,https://doi.org/10.48550/arXiv.2209.14464,https://semanticscholar.org/paper/2d80d0b053179988f2155ea9eaf57b60a7742c16,""Reasoning is a fundamental problem for computers and deeply studied in Arti?cial Intelligence. In this paper, we speci?cally focus on answering multi-hop logical queries on Knowledge Graphs (KGs). This is a complicated task because, in real-world scenarios, the graphs tend to be large and incomplete. Most previous works have been unable to create models that accept full First-Order Logical (FOL) queries, which include negative queries, and have only been able to process a limited set of query structures. Additionally, most methods present logic operators that can only perform the logical operation they are made for. We introduce a set of models that use Neural Networks to create one-point vector embeddings to answer the queries. The versatility of neural networks allows the framework to handle FOL queries with Conjunction ( ? ), Disjunction ( ? ) and Negation ( ¬ ) operators. We demonstrate experimentally the performance of our model through extensive experimentation on well-known benchmarking datasets. Besides having more versatile operators, the models achieve a 10% relative increase over the best performing state of the art and more than 30% over the original method based on single-point vector embeddings."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"From Discrimination to Generation: Knowledge Graph Completion with Generative Transformer,Knowledge graph completion aims to address the problem of extending a KG with missing triples.,""Xin  Xie, Ningyu  Zhang, Zhoubo  Li, Shumin  Deng, Hui  Chen, Feiyu  Xiong, Mosha  Chen, Huajun  Chen"",ArXiv,,,10.1145/3487553.3524238,https://dl.acm.org/doi/pdf/10.1145/3487553.3524238,2022,1,https://doi.org/10.1145/3487553.3524238,https://semanticscholar.org/paper/e2b6b918a0a0150c593eaf13c7be1919271ffdbf,""Knowledge graph completion aims to address the problem of ex-tending a KG with missing triples. In this paper, we provide an approach GenKGC , which converts knowledge graph completion to sequence-to-sequence generation task with the pre-trained language model. We further introduce relation-guided demonstration and entity-aware hierarchical decoding for better representation learning and fast inference. Experimental results on three datasets show that our approach can obtain better or comparable performance than baselines and achieve faster inference speed com-pared with previous methods with pre-trained language models. We also release a new large-scale Chinese knowledge graph dataset OpenBG500 for research purpose 1 ."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Multilingual Knowledge Graph Completion with Self-Supervised Adaptive Graph Alignment,A new pair generator dynamically captures potential alignment pairs in a self-supervised paradigm.,""Zijie Huang, Zheng Li, Haoming Jiang, Tianyu Cao, Hanqing Lu, Bing Yin, Karthik Subbian, Yizhou Sun, Wei Wang"",Annual Meeting of the Association for Computational Linguistics,,,10.48550/arXiv.2203.14987,,2022,6,https://doi.org/10.48550/arXiv.2203.14987,https://semanticscholar.org/paper/cca3f7725a64a3b269711ba43e69f3d80c319c5c,""Predicting missing facts in a knowledge graph (KG) is crucial as modern KGs are far from complete. Due to labor-intensive human labeling, this phenomenon deteriorates when handling knowledge represented in various languages. In this paper, we explore multilingual KG completion, which leverages limited seed alignment as a bridge, to embrace the collective knowledge from multiple languages. However, language alignment used in prior works is still not fully exploited: (1) alignment pairs are treated equally to maximally push parallel entities to be close, which ignores KG capacity inconsistency; (2) seed alignment is scarce and new alignment identification is usually in a noisily unsupervised manner. To tackle these issues, we propose a novel self-supervised adaptive graph alignment (SS-AGA) method. Specifically, SS-AGA fuses all KGs as a whole graph by regarding alignment as a new edge type. As such, information propagation and noise influence across KGs can be adaptively controlled via relation-aware attention weights. Meanwhile, SS-AGA features a new pair generator that dynamically captures potential alignment pairs in a self-supervised paradigm. Extensive experiments on both the public multilingual DBPedia KG and newly-created industrial multilingual E-commerce KG empirically demonstrate the effectiveness of SS-AGA"",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"GreenKGC: A Lightweight Knowledge Graph Completion Method,A lightweight modularized knowledge graph completion solution is proposed to address this issue.,""Yun Cheng Wang, Xiou Ge, Bin Wang, C.-C. Jay Kuo"",ArXiv,,,10.48550/arXiv.2208.09137,,2022,1,https://doi.org/10.48550/arXiv.2208.09137,https://semanticscholar.org/paper/eb49e1012423a4c571286d1e3128bc0e2d02a75a,""Knowledge graph completion (KGC) aims to discover missing relationships between entities in knowledge graphs (KGs). Most prior KGC work focuses on learning representations for entities and relations. Yet, a higher-dimensional embedding space is usually required for a better reasoning capability, which leads to a larger model size and hinders applicability to real-world problems (e.g., large-scale KGs or mobile/edge computing). A lightweight modularized KGC solution, called GreenKGC, is proposed in this work to address this issue. GreenKGC consists of three modules: 1) representation learning, 2) feature pruning, and 3) decision learning. In Module 1, we leverage existing KG embedding models to learn high-dimensional representations for entities and relations. In Module 2, the KG is partitioned into several relation groups followed by a feature pruning process to find the most discriminant features for each relation group. Finally, a classifier is assigned to each relation group to cope with low-dimensional triple features for KGC tasks in Module 3. We evaluate the performance of GreenKGC on four widely used link prediction datasets and observe that GreenKGC can achieve comparable or even better performance against original high-dimensional embeddings with a much smaller model size. Furthermore, we experiment on two triple classification datasets to demonstrate that the same methodology can generalize to more tasks."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Knowledge Graph Contrastive Learning for Recommendation,Knowledge graph-enhanced recommender systems are often noisy and contain topic-irrelevant connections between items and entities.,""Yuhao Yang, Chao Huang, Lianghao Xia, Chenliang Li"",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,,,10.1145/3477495.3532009,,2022,12,https://doi.org/10.1145/3477495.3532009,https://semanticscholar.org/paper/895396389a9fee1b607bf5141a6cc7925bb1e069,""Knowledge Graphs (KGs) have been utilized as useful side information to improve recommendation quality. In those recommender systems, knowledge graph information often contains fruitful facts and inherent semantic relatedness among items. However, the success of such methods relies on the high quality knowledge graphs, and may not learn quality representations with two challenges: i) The long-tail distribution of entities results in sparse supervision signals for KG-enhanced item representation; ii) Real-world knowledge graphs are often noisy and contain topic-irrelevant connections between items and entities. Such KG sparsity and noise make the item-entity dependent relations deviate from reflecting their true characteristics, which significantly amplifies the noise effect and hinders the accurate representation of user's preference. To fill this research gap, we design a general Knowledge Graph Contrastive Learning framework (KGCL) that alleviates the information noise for knowledge graph-enhanced recommender systems. Specifically, we propose a knowledge graph augmentation schema to suppress KG noise in information aggregation, and derive more robust knowledge-aware representations for items. In addition, we exploit additional supervision signals from the KG augmentation process to guide a cross-view contrastive learning paradigm, giving a greater role",to,unbiased user-item,interactions,in,gradient,desce,nt,a,nd,fu,rther,suppr,essi,ng,the,n,oise,. Ex,tensi,ve,e,xperime,nts,on,thre,e pu,blic,dat,asets,demo,nstr,ate,the,cons,iste,nt,super,ior,it,y of,our,KGCL,over,st,at,e-,of-,the-art,techniqu,es.,KGCL,a,lso,a,ch,ieves,st,ro,ng,p,erfo,rma,nc,e in,r,ec,omme,ndation,sc,enario,s wit,h sp,arse,u,ser-,item,inter,"actions,",long-tail,a,nd,n,oisy,KG,ent,"ities. Our implementation codes are available at https://github.com/yuh-yang/KGCL-SIGIR22."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Knowledge Graph Contrastive Learning for Recommendation,Knowledge graph-enhanced recommender systems are often noisy and contain topic-irrelevant connections between items and entities.,""Yuhao Yang, Chao Huang, Lianghao Xia, Chenliang Li"",SIGIR,,,10.1145/3477495.3532009,,2022,4,https://doi.org/10.1145/3477495.3532009,https://semanticscholar.org/paper/ed2226e222c68311d5c22c2eb6e5f35244232153,""Knowledge Graphs (KGs) have been utilized as useful side information to improve recommendation quality. In those recommender systems, knowledge graph information often contains fruitful facts and inherent semantic relatedness among items. However, the success of such methods relies on the high quality knowledge graphs, and may not learn quality representations with two challenges: i) The long-tail distribution of entities results in sparse supervision signals for KG-enhanced item representation; ii) Real-world knowledge graphs are often noisy and contain topic-irrelevant connections between items and entities. Such KG sparsity and noise make the item-entity dependent relations deviate from reflecting their true characteristics, which significantly amplifies the noise effect and hinders the accurate representation of user's preference. To fill this research gap, we design a general Knowledge Graph Contrastive Learning framework (KGCL) that alleviates the information noise for knowledge graph-enhanced recommender systems. Specifically, we propose a knowledge graph augmentation schema to suppress KG noise in information aggregation, and derive more robust knowledge-aware representations for items. In addition, we exploit additional supervision signals from the KG augmentation process to guide a cross-view contrastive learning paradigm, giving a greater role to unbiased user-item interactions in gradient descent and further suppressing the noise.",Ext,ensive experiments,on three pub,lic,datasets,demon,st,ra,te,th,e con,sisten,t su,pe,rior,it,y of,our,KGCL,o,ve,r state,#NAME?,#NAME?,e-art,tec,hniq,ues.,KGCL,also,ach,ieve,s s,trong,per,fo,rmance,in,r,ecom,mend,ation,scen,ari,os,w,ith,sparse,user-ite,m i,ntera,ct,ion,"s,",l,ong-t,ail,a,nd,n,oisy,KG,e,ntit,ie,s.,Our,implem,ent,ation,codes,are,ava,il,able,at,https:,//github,.com/yuh-y,an,g/,KG,CL-S,IGI,R22.,""",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Knowledge Graph Completion by Jointly Learning Structural Features and Soft Logical Rules,A novel knowledge graph embedding model can jointly learn the local structural features of entities and soft logical rules.,""Weidong Li, Rong Peng, Zhi Li"",IEEE Transactions on Knowledge and Data Engineering,,2.431 (883),10.1109/TKDE.2021.3108224,,2023,3,https://doi.org/10.1109/TKDE.2021.3108224,https://semanticscholar.org/paper/2acfa599b8f6d6a25d650fc3030f87004c9f7d99,""With the rapid development and widespread application of Knowledge graphs (KGs) in many artificial intelligence tasks, a large number of efforts have been made to refine them and increase their quality. Knowedge graph embedding (KGE) has become one of the main refinement tasks, which aims to predict missing facts based on existing ones in KGs. However, there are still mainly two difficult unresolved challenges: (i) how to leverage the local structural features of entities and the potential soft logical rules to learn more expressive embedding of entites and relations; and (ii) how to combine these two learning processes into one unified model. To conquer these problems, we propose a novel KGE model named JSSKGE, which can Jointly learn the local Structural features of entities and Soft logical rules. First, we employ graph attention networks which are specially designed for graph-structured data to aggregate the local structural information of nodes. Then, we utilize soft logical rules implicated in KGs as an expert to further rectify the embeddings of entities and relations. By jointly learning, we can obtain more informative embeddings to predict new facts. With experiments on four commonly used datasets, the JSSKGE obtains better performance than state-of-the-art approaches."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"CAKE: A Scalable Commonsense-Aware Framework For Multi-View Knowledge Graph Completion,The proposed commonsense-aware negative sampling module is superior to other NS techniques.,""Guanglin Niu, Bo Li, Yongfei Zhang, Shi Pu"",Annual Meeting of the Association for Computational Linguistics,,,10.18653/v1/2022.acl-long.205,https://aclanthology.org/2022.acl-long.205.pdf,2022,8,https://doi.org/10.18653/v1/2022.acl-long.205,https://semanticscholar.org/paper/009263dec4026507d5809b14881f833c80b74cbc,""Knowledge graphs store a large number of factual triples while they are still incomplete, inevitably. The previous knowledge graph completion (KGC) models predict missing links between entities merely relying on fact-view data, ignoring the valuable commonsense knowledge. The previous knowledge graph embedding (KGE) techniques suffer from invalid negative sampling and the uncertainty of fact-view link prediction, limiting KGC’s performance. To address the above challenges, we propose a novel and scalable Commonsense-Aware Knowledge Embedding (CAKE) framework to automatically extract commonsense from factual triples with entity concepts. The generated commonsense augments effective self-supervision to facilitate both high-quality negative sampling (NS) and joint commonsense and fact-view link prediction. Experimental results on the KGC task demonstrate that assembling our framework could enhance the performance of the original KGE models, and the proposed commonsense-aware NS module is superior to other NS techniques. Besides, our proposed framework could be easily adaptive to various KGE models and explain the predicted results."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Knowledge Graph Quality Evaluation under Incomplete Information,Knowledge graph quality evaluation under incomplete information.,""Xiaodong Li, Chenxin Zou, Yimeng Cai, Yuelong Zhu"",ArXiv,,,10.48550/arXiv.2212.00994,,2022,,https://doi.org/10.48550/arXiv.2212.00994,https://semanticscholar.org/paper/62e74be3dba081f0d9cf50a554f592f38c532f45,evaluators under incomplete information.,,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Relational Message Passing for Fully Inductive Knowledge Graph Completion,A novel relational message passing network for fully inductive knowledge graph completion is proposed.,""Yuxia Geng, Jiaoyan Chen, Wen Zhang, Jeff Z. Pan, Mingyang Chen, Hua-zeng Chen, Song Jiang"",ArXiv,,,10.48550/arXiv.2210.03994,,2022,2,https://doi.org/10.48550/arXiv.2210.03994,https://semanticscholar.org/paper/fb2497fff440fcc3c3685b5bf5b2b68493cdcac2,""—In knowledge graph completion (KGC), predicting triples involving emerging entities and/or relations, which are unseen when the KG embeddings are learned, has become a critical challenge. Subgraph reasoning with message passing is a promising and popular solution. Some recent methods have achieved good performance, but they (i) usually can only predict triples involving unseen entities alone, failing to address more realistic fully inductive situations with both unseen entities and unseen relations, and (ii) often conduct message passing over the entities with the relation patterns not fully utilized. In this study, we propose a new method named RMPI which uses a novel R elational M essage P assing network for fully I nductive KGC. It passes messages directly between relations to make full use of the relation patterns for subgraph reasoning with new techniques on graph transformation, graph pruning, relation- aware neighborhood attention, addressing empty subgraphs, etc., and can utilize the relation semantics de?ned in the KG’s ontological schema. Extensive evaluation on multiple benchmarks has shown the effectiveness of RMPI’s techniques and its better performance compared with the existing methods that support fully inductive KGC. RMPI is also comparable to the state-of-the- art partially inductive KGC methods with very promising results achieved. Our codes, data and some supplementary experiment results",are,available at http,s://github.co,m/z,jukg/RMPI,"."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Declarative Description of Knowledge Graphs Construction Automation: Status & Challenges,Automation of knowledge graph construction is a promising direction.,""David Chaves-Fraga, Anastasia Dimou"",KGCW@ESWC,,,,,2022,3,,https://semanticscholar.org/paper/1df5a9fcdcef9461abfdd5da2521331627edb6eb,""Nowadays, Knowledge Graphs (KG) are among the most powerful mechanisms to represent knowledge and integrate data from multiple domains. However, most of the available data sources are still described in heterogeneous data structures, schemes, and formats. The conversion of these sources into the desirable KG requires manual and time-consuming tasks, such as programming translation scripts, defining declarative mapping rules, etc. In this vision paper, we analyze the trends regarding the automation of KG construction but also the use of mapping languages for the same process, and align the two by analyzing their tasks and a few exemplary tools. Our aim is not to have a complete study but to investigate if there is potential in this direction and, if so, to discuss what challenges we need to address to guarantee the maintainability, explainability, and reproducibility of the KG construction."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"A Comprehensive Survey of Graph Neural Networks for Knowledge Graphs,Graph neural network-based technologies for solving four different knowledge graph tasks are hot research topics in recent years.,""Zi Ye, Y. J. Kumar, G. O. Sing, Fengyan Song, Junsong Wang"",IEEE Access,,0.927 (4581),10.1109/access.2022.3191784,https://ieeexplore.ieee.org/ielx7/6287639/6514899/09831453.pdf,2022,2,https://doi.org/10.1109/access.2022.3191784,https://semanticscholar.org/paper/60a6b17f28e88f17e58f60923d98674358dbd0e4,""The Knowledge graph, a multi-relational graph that represents rich factual information among entities of diverse classifications, has gradually become one of the critical tools for knowledge management. However, the existing knowledge graph still has some problems which form hot research topics in recent years. Numerous methods have been proposed based on various representation techniques. Graph Neural Network, a framework that uses deep learning to process graph-structured data directly, has significantly advanced the state-of-the-art in the past few years. This study firstly is aimed at providing a broad, complete as well as comprehensive overview of GNN-based technologies for solving four different KG tasks, including link prediction, knowledge graph alignment, knowledge graph reasoning, and node classification. Further, we also investigated the related artificial intelligence applications of knowledge graphs based on advanced GNN methods, such as recommender systems, question answering, and drug-drug interaction. This review will provide new insights for further study of KG and GNN."",,Review",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Identifying relevant common sense information in knowledge graphs,A triple selection method based on a ranking model improves question answering accuracy over existing methods.,""Guy Aglionby, Simone Tuefel"",CSRR,,,10.18653/v1/2022.csrr-1.1,https://aclanthology.org/2022.csrr-1.1.pdf,2022,1,https://doi.org/10.18653/v1/2022.csrr-1.1,https://semanticscholar.org/paper/40657ecca836d46f5f5025b240d5649fd581947a,""Knowledge graphs are often used to store common sense information that is useful for various tasks. However, the extraction of contextually-relevant knowledge is an unsolved problem, and current approaches are relatively simple. Here we introduce a triple selection method based on a ranking model and find that it improves question answering accuracy over existing methods. We additionally investigate methods to ensure that extracted triples form a connected graph. Graph connectivity is important for model interpretability, as paths are frequently used as explanations for the reasoning that connects question and answer."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Joint Language Semantic and Structure Embedding for Knowledge Graph Completion,The semantics in the natural language description of the knowledge triplets with their structure information play an important role in knowledge graph completion.,""Jianhao Shen, Chenguang Wang, Linyuan Gong, Dawn Song"",International Conference on Computational Linguistics,,,10.48550/arXiv.2209.08721,,2022,4,https://doi.org/10.48550/arXiv.2209.08721,https://semanticscholar.org/paper/933cb8bf1cd50d6d5833a627683327b15db28836,""The task of completing knowledge triplets has broad downstream applications. Both structural and semantic information plays an important role in knowledge graph completion. Unlike previous approaches that rely on either the structures or semantics of the knowledge graphs, we propose to jointly embed the semantics in the natural language description of the knowledge triplets with their structure information. Our method embeds knowledge graphs for the completion task via fine-tuning pre-trained language models with respect to a probabilistic structured loss, where the forward pass of the language models captures semantics and the loss reconstructs structures. Our extensive experiments on a variety of knowledge graph benchmarks have demonstrated the state-of-the-art performance of our method. We also show that our method can significantly improve the performance in a low-resource regime, thanks to the better use of semantics. The code and datasets are available at https://github.com/pkusjh/LASS."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"SKILL: Structured Knowledge Infusion for Large Language Models,Large language models pre-trained on knowledge graphs outperform the T5 baselines on FreebaseQA and WikiHop.,""Fedor Moiseev, Zhe Dong, Enrique Alfonseca, Martin Jaggi"",North American Chapter of the Association for Computational Linguistics,,,10.18653/v1/2022.naacl-main.113,https://aclanthology.org/2022.naacl-main.113.pdf,2022,3,https://doi.org/10.18653/v1/2022.naacl-main.113,https://semanticscholar.org/paper/eea2129457fcd78c4071a9020355a2fe1da4d2fd,""Large language models (LLMs) have demonstrated human-level performance on a vast spectrum of natural language tasks. However, it is largely unexplored whether they can better internalize knowledge from a structured data, such as a knowledge graph, or from text. In this work, we propose a method to infuse structured knowledge into LLMs, by directly training T5 models on factual triples of knowledge graphs (KGs). We show that models pre-trained on Wikidata KG with our method outperform the T5 baselines on FreebaseQA and WikiHop, as well as the Wikidata-answerable subset of TriviaQA and NaturalQuestions. The models pre-trained on factual triples compare competitively with the ones on natural language sentences that contain the same knowledge. Trained on a smaller size KG, WikiMovies, we saw 3x improvement of exact match score on MetaQA task. The proposed method has an advantage that no alignment between the knowledge graph and text corpus is required in curating training data. This makes our method particularly useful when working with industry-scale knowledge graphs."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"CAKE: A Scalable Commonsense-Aware Framework For Multi-View Knowledge Graph Completion,The proposed commonsense-aware negative sampling module is superior to other NS techniques.,""Guanglin Niu, Bo Li, Yongfei Zhang, Shi Pu"",Annual Meeting of the Association for Computational Linguistics,,,10.18653/v1/2022.acl-long.205,https://aclanthology.org/2022.acl-long.205.pdf,2022,8,https://doi.org/10.18653/v1/2022.acl-long.205,https://semanticscholar.org/paper/009263dec4026507d5809b14881f833c80b74cbc,""Knowledge graphs store a large number of factual triples while they are still incomplete, inevitably. The previous knowledge graph completion (KGC) models predict missing links between entities merely relying on fact-view data, ignoring the valuable commonsense knowledge. The previous knowledge graph embedding (KGE) techniques suffer from invalid negative sampling and the uncertainty of fact-view link prediction, limiting KGC’s performance. To address the above challenges, we propose a novel and scalable Commonsense-Aware Knowledge Embedding (CAKE) framework to automatically extract commonsense from factual triples with entity concepts. The generated commonsense augments effective self-supervision to facilitate both high-quality negative sampling (NS) and joint commonsense and fact-view link prediction. Experimental results on the KGC task demonstrate that assembling our framework could enhance the performance of the original KGE models, and the proposed commonsense-aware NS module is superior to other NS techniques. Besides, our proposed framework could be easily adaptive to various KGE models and explain the predicted results."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"KNN-Diffusion: Image Generation via Large-Scale Retrieval,Large-scale retrieval methods can be used to train a model to adapt to new samples.,""Oron Ashual, Shelly Sheynin, A. Polyak, Uriel Singer, Oran Gafni, Eliya Nachmani, Yaniv Taigman"",ArXiv,,,10.48550/arXiv.2204.02849,,2022,28,https://doi.org/10.48550/arXiv.2204.02849,https://semanticscholar.org/paper/a225d5d846ba5110232ed5bb32d54ea742b1c2d4,""While the availability of massive Text-Image datasets is shown to be extremely useful in training large-scale generative models (e.g. DDPMs, Transformers), their output typ-ically depends on the quality of both the input text, as well as the training dataset. In this work, we show how large-scale retrieval methods, in particular ef?cient K-Nearest-Neighbors (KNN) search, can be used in order to train a model to adapt to new samples. Learning to adapt enables several new capabilities. Sifting through billions of records at inference time is extremely ef?cient and can alleviate the need to train or memorize an adequately large generative model. Additionally, ?ne-tuning trained models to new samples can be achieved by simply adding them to the table. Rare concepts, even without any presence in the training set, can be then leveraged during test time without any modi?cation to the generative model. Our diffusion-based model trains on images only, by leveraging a joint Text-Image multi-modal metric. Compared to baseline methods, our generations achieve state of the art results both in human evaluations as well as with perceptual scores when tested on a public multimodal dataset of natural images, as well as on a collected dataset of 400 million Stickers."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Scalable Batch Acquisition for Deep Bayesian Active Learning,Existing solutions to this problem in the Bayesian setup have significant limitations in selecting a large number of examples.,""A. Rubashevskii, Daria A. Kotova, Maxim Panov"",ArXiv,,,10.48550/arXiv.2301.05490,,2023,1,https://doi.org/10.48550/arXiv.2301.05490,https://semanticscholar.org/paper/1e250ee9f97a4438f720adc40d73298776b76f43,""In deep active learning, it is especially important to choose multiple examples to markup at each step to work e?ciently, especially on large datasets. At the same time, existing solutions to this problem in the Bayesian setup, such as BatchBALD, have signi?cant limitations in selecting a large number of examples, associated with the exponential complexity of computing mutual information for joint random variables. We, therefore, present the Large BatchBALD algorithm, which gives a well-grounded approximation to the BatchBALD method that aims to achieve comparable quality while being more computationally e?cient. We provide a complexity analysis of the algorithm, showing a reduction in computation time, especially for large batches. Furthermore, we present an extensive set of experimental results on image and text data, both on toy datasets and larger ones such as CIFAR-100."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Scalable Batch Acquisition for Deep Bayesian Active Learning,Existing solutions to this problem in the Bayesian setup have significant limitations in selecting a large number of examples.,""A. Rubashevskii, Daria A. Kotova, Maxim Panov"",ArXiv,,,10.48550/arXiv.2301.05490,,2023,1,https://doi.org/10.48550/arXiv.2301.05490,https://semanticscholar.org/paper/107ec9f06b9a53e20a91fcf9b31a6e40518ac3de,""In deep active learning, it is especially important to choose multiple examples to markup at each step to work efficiently, especially on large datasets. At the same time, existing solutions to this problem in the Bayesian setup, such as BatchBALD, have significant limitations in selecting a large number of examples, associated with the exponential complexity of computing mutual information for joint random variables. We, therefore, present the Large BatchBALD algorithm, which gives a well-grounded approximation to the BatchBALD method that aims to achieve comparable quality while being more computationally efficient. We provide a complexity analysis of the algorithm, showing a reduction in computation time, especially for large batches. Furthermore, we present an extensive set of experimental results on image and text data, both on toy datasets and larger ones such as CIFAR-100."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Simplifying Access to Large-scale Structured Datasets by Meta-Profiling with Scalable Training Set Enrichment,""A standardized interface to a topic of interest in large-scale structured datasets using deep-learning and our new unsupervised, scalable training set enrichment algorithm helps data scientists and end users get access to all relevant topical tables, even in ultra large-scale datasets such as WDC."",""Sophie Pavia, Rituparna Khan, A. Pyayt, M. Gubanov"",SIGMOD Conference,,,10.1145/3514221.3520156,,2022,1,https://doi.org/10.1145/3514221.3520156,https://semanticscholar.org/paper/9f018a6fc0e6668de4aeae9a185de07e6b305562,""Accessing large-scale structured datasets such as WDC [21], having millions of tables coming from hundreds of thousands of sources is very challenging [11, 13, 14, 30, 31]. Even if one topic (e.g. Job postings) is of interest, Jobs tables in different sources have hundreds of different schemas, which significantly complicates both finding and querying them. Here we demonstrate our scalable Meta-data profiler, capable of constructing a standardized interface to a topic of interest in large-scale structured datasets using Deep-Learning and our new unsupervised, scalable training set enrichment algorithm. This interface, called Meta-profile represents a meta-data summary per each topic, representative of the entire dataset. It helps data scientists and end users get access to all relevant topical tables, even in ultra large-scale datasets such as WDC, which would be very difficult or impossible otherwise [22, 31]."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Spark Rough Hypercuboid Approach for Scalable Feature Selection,The proposed algorithms are perfectly capable of exploiting the distributed-memory clusters to accomplish the computation task that fails on a single node due to the memory constraints.,""Chuan Luo, Sizhao Wang, Tianrui Li, Hongmei Chen, J. Lv, Zhang Yi"",IEEE Transactions on Knowledge and Data Engineering,,2.431 (883),10.1109/TKDE.2021.3112520,,2023,4,https://doi.org/10.1109/TKDE.2021.3112520,https://semanticscholar.org/paper/fc86ddfef53deec4bae27c89d42ca0aad62ebeec,""Feature selection refers to choose an optimal non-redundant feature subset with minimal degradation of learning performance and maximal avoidance of data overfitting. The appearance of large data explosion leads to the sequential execution of algorithms are extremely time-consuming, which necessitates the scalable parallelization of algorithms by efficiently exploiting the distributed computational capabilities. In this paper, we present parallel feature selection algorithms underpinned by a rough hypercuboid approach in order to scale for the growing data volumes. Metrics in terms of rough hypercuboid are highly suitable to parallel distributed processing, and fits well with the Apache Spark cluster computing paradigm. Two data parallelism strategies, namely, vertical partitioning and horizontal partitioning, are implemented respectively to decompose the data into concurrent iterative computing streams. Experimental results on representative datasets show that our algorithms significantly faster than its original sequential counterpart while guaranteeing the quality of the results. Furthermore, the proposed algorithms are perfectly capable of exploiting the distributed-memory clusters to accomplish the computation task that fails on a single node due to the memory constraints. Parallel scalability and extensibility analysis have confirmed that our parallelization extends well to process massive amount of data and can scales well with the increase of computational nodes."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Scaling Knowledge Graph Embedding Models,A scaling solution for GNN-based knowledge graph embedding models achieves a 16x speed up on benchmark datasets.,""Nasrullah Sheikh, Xiao Qin, B. Reinwald, Chuan Lei"",,,,,,2022,1,,https://semanticscholar.org/paper/b3cbbc1f34a20c22853f3dd347fd635b2e414fd5,""Developing scalable solutions for training Graph Neural Networks (GNNs) for link prediction tasks is challenging due to the high data dependencies which entail high computational cost and huge memory footprint. We propose a new method for scaling training of knowledge graph embedding models for link prediction to address these challenges. Towards this end, we propose the following algorithmic strategies: self-sufficient partitions, constraint-based negative sampling, and edge mini-batch training. Both, partitioning strategy and constraint-based negative sampling, avoid cross partition data transfer during training. In our experimental evaluation, we show that our scaling solution for GNN-based knowledge graph embedding models achieves a 16x speed up on benchmark datasets while maintaining a comparable model performance as non-distributed methods on standard metrics."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"BertNet: Harvesting Knowledge Graphs from Pretrained Language Models,""The knowledge harvested with our approach shows competitive quality, diversity, and novelty."",""Shibo Hao, Bowen Tan, Kaiwen Tang, Hengzhe Zhang, E. Xing, Zhiting Hu"",ArXiv,,,10.48550/arXiv.2206.14268,,2022,9,https://doi.org/10.48550/arXiv.2206.14268,https://semanticscholar.org/paper/a11fa157d6d80b57016f548dbdf5ca94a3cd5a36,""Symbolic knowledge graphs (KGs) have been constructed either by expensive human crowdsourcing or with complex text mining pipelines. The emerging large pretrained language models (LMs), such as B ERT , have shown to implicitly encode massive knowledge which can be queried with properly designed prompts. However, compared to the explicit KGs, the implict knowledge in the black-box LMs is often dif?cult to access or edit and lacks explainability. In this work, we aim at harvesting symbolic KGs from the LMs, and propose a new framework for automatic KG construction empowered by the neural LMs’ ?exibility and scalability. Compared to prior works that often rely on large human annotated data or existing massive KGs, our approach requires only the minimal de?nition of relations as inputs, and hence is suitable for extracting knowledge of rich new relations that are instantly assigned and not available before. The framework automatically generates diverse prompts, and performs ef?cient knowledge search within a given LM for consistent outputs. The knowledge harvested with our approach shows competitive quality, diversity, and novelty. As a result, we derive from diverse LMs a family of new KGs (e.g., B ERT N ET and R O BERT A N ET ) that contain a richer set of relations, including some complex ones (e.g., """"A is capable of but not good at B"""" ) that cannot be extracted with previous methods. Besides, the resulting KGs also serve as a vehicle to interpret the respective source LMs, leading to new insights into the varying knowledge capability of different LMs."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Progressively Optimized Bi-Granular Document Representation for Scalable Embedding Based Retrieval,The sparse embeddings are learned ahead for high-quality search of candidates.,""Shitao Xiao, Zheng Liu, Weihao Han, Jianjin Zhang, Chaozhuo Li, Yingxia Shao, Defu Lian, Xing Xie, Hao Sun, Denvy Deng, Liangjie Zhang, Qi Zhang"",The Web Conference,,,10.1145/3485447.3511957,http://arxiv.org/pdf/2201.05409,2022,2,https://doi.org/10.1145/3485447.3511957,https://semanticscholar.org/paper/ac2453dae214effcfd40c0b14103cc3bc94c1b75,""Ad-hoc search calls for the selection of appropriate answers from a massive-scale corpus. Nowadays, the embedding-based retrieval (EBR) becomes a promising solution, where deep learning based document representation and ANN search techniques are allied to handle this task. However, a major challenge is that the ANN index can be too large to fit into memory, given the considerable size of answer corpus. In this work, we tackle this problem with Bi-Granular Document Representation, where the lightweight sparse embeddings are indexed and standby in memory for coarse-grained candidate search, and the heavyweight dense embeddings are hosted in disk for fine-grained post verification. For the best of retrieval accuracy, a Progressive Optimization framework is designed. The sparse embeddings are learned ahead for high-quality search of candidates. Conditioned on the candidate distribution induced by the sparse embeddings, the dense embeddings are continuously learned to optimize the discrimination of ground-truth from the shortlisted candidates. Besides, two techniques: the contrastive quantization and the locality-centric sampling are introduced for the learning of sparse and dense embeddings, which substantially contribute to their performances. Thanks to the above features, our method effectively handles massive-scale EBR with strong advantages in accuracy: with up to recall gain on million-scale corpus, and up to recall gain on billion-scale corpus. Besides, Our method is applied to a major sponsored search platform with substantial gains on revenue (), Recall () and CTR (). Our code",is available,at,http,s://gi,thu,b.co,m/m,ic,roso,ft/,BiD,R.,""",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Subgraph Retrieval Enhanced Model for Multi-hop Knowledge Base Question Answering,A trainable subgraph retriever enables a plug-and-play framework to enhance any subgraph-oriented knowledge base question answering model.,""Jing Zhang, Xiaokang Zhang, Jifan Yu, Jian Tang, Jie Tang, Cuiping Li, Hong Chen"",Annual Meeting of the Association for Computational Linguistics,,,10.18653/v1/2022.acl-long.396,https://aclanthology.org/2022.acl-long.396.pdf,2022,11,https://doi.org/10.18653/v1/2022.acl-long.396,https://semanticscholar.org/paper/767ceaade8a2cfb186f20091e50c7d03641e0caa,""Recent works on knowledge base question answering (KBQA) retrieve subgraphs for easier reasoning. The desired subgraph is crucial as a small one may exclude the answer but a large one might introduce more noises. However, the existing retrieval is either heuristic or interwoven with the reasoning, causing reasoning on the partial subgraphs, which increases the reasoning bias when the intermediate supervision is missing. This paper proposes a trainable subgraph retriever (SR) decoupled from the subsequent reasoning process, which enables a plug-and-play framework to enhance any subgraph-oriented KBQA model. Extensive experiments demonstrate SR achieves significantly better retrieval and QA performance than existing retrieval methods. Via weakly supervised pre-training as well as the end-to-end fine-tuning, SR achieves new state-of-the-art performance when combined with NSM (He et al., 2021), a subgraph-oriented reasoner, for embedding-based KBQA methods. Codes and datasets are available online (https://github.com/RUCKBReasoning/SubgraphRetrievalKBQA)"",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Aggregate Queries on Knowledge Graphs: Fast Approximation with Semantic-aware Sampling,A sampling-estimation model to answer aggregate queries over knowledge graphs is the first work to provide an approximate aggregate result with an effective accuracy guarantee.,""Yuxiang Wang, Arijit Khan, Xiaoliang Xu, Ji Jin, Qifan Hong, Tao Fu"",IEEE International Conference on Data Engineering,,,10.48550/arXiv.2203.03792,,2022,4,https://doi.org/10.48550/arXiv.2203.03792,https://semanticscholar.org/paper/96520415e0581af864aabfd8eafe0b0588407232,""A knowledge graph (KG) manages large-scale and real-world facts as a big graph in a schema-flexible manner. Aggregate query is a fundamental query over KGs, e.g., “what is the average price of cars produced in Germany?”. Despite its importance, answering aggregate queries on KGs has received little attention in the literature. Aggregate queries can be supported based on factoid queries, e.g., “find all cars produced in Germany”, by applying an additional aggregate operation on factoid queries' answers. However, this straightforward method is challenging because both the accuracy and efficiency of factoid query processing will seriously impact the performance of aggregate queries. In this paper, we propose a “sampling-estimation” model to answer aggregate queries over KGs, which is the first work to provide an approximate aggregate result with an effective accuracy guarantee, and without relying on factoid queries. Specifically, we first present a semantic-aware sampling to collect a high-quality random sample through a random walk based on knowledge graph embedding. Then, we propose unbiased estimators for COUNT, SUM, and a consistent estimator for AVG to compute the approximate aggregate results based on the random sample, with an accuracy guarantee in the form of confidence interval. We extend our approach to support iterative improvement of accuracy, and more complex queries with filter, GROUP-BY, and different graph shapes, e.g., chain, cycle, star, flower. Extensive experiments over real-world KGs demonstrate the effectiveness and efficiency of our approach."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Scalable Bigraphical Lasso: Two-way Sparse Network Inference for Count Data,The multi-way network inference approach can be used for discrete data.,""Sijia Li, Mart'in L'opez-Garc'ia, Neil D. Lawrence, L. Cutillo"",International Conference on Artificial Intelligence and Statistics,,,10.48550/arXiv.2203.07912,,2022,2,https://doi.org/10.48550/arXiv.2203.07912,https://semanticscholar.org/paper/8cdf206c07347108e03f8764d734b2057e5c5939,""Classically, statistical datasets have a larger number of data points than features ( n > p ). The standard model of classical statistics caters for the case where data points are considered conditionally independent given the parameters. However, for n ? p or p > n such models are poorly determined. Kalaitzis et al. (2013) introduced the Bigraphical Lasso, an estimator for sparse precision matrices based on the Cartesian product of graphs. Unfor-tunately, the original Bigraphical Lasso algorithm is not applicable in case of large p and n due to memory requirements. We exploit eigenvalue decomposition of the Cartesian product graph to present a more efficient version of the algorithm which reduces memory requirements from O ( n 2 p 2 ) to O ( n 2 + p 2 ). Many datasets in different application fields, such as biology, medicine and social science, come with count data, for which Gaussian based models are not applicable. Our multi-way network inference approach can be used for discrete data. Our methodology accounts for the dependencies across both instances and features, reduces the computational complexity for high dimensional data and enables to deal with both discrete and continuous data. Numerical studies on both synthetic and real datasets are presented to showcase the performance of our method."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Scalable Analytics on Large Sequence Collections,Fast similarity search for supporting machine learning applications is needed.,""Karima Echihabi, Themis Palpanas"",International Conference on Mobile Data Management,,,10.1109/MDM55031.2022.00022,,2022,,https://doi.org/10.1109/MDM55031.2022.00022,https://semanticscholar.org/paper/1add007a5e7938524605f15fef60c073e259dea4,""Data series are a prevalent data type that has attracted lots of interest in recent years. Specifically, there has been an explosive interest towards the analysis of large volumes of data series in many different domains, and in particular, in the Internet of Things (IoT). In this tutorial, we focus on applications that produce massive collections of data series, and we provide the necessary background on data series management and analytics. Moreover, we discuss the need for fast similarity search for supporting machine learning applications, and describe efficient similarity search techniques, indexes and query processing algorithms. Finally, we discuss the role that deep learning techniques can play in this context. We conclude with the challenges and open research problems in this domain."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Simplifying Text Mining Activities: Scalable and Self-Tuning Methodology for Topic Detection and Characterization,A new automated data analysis engine called ESCAPE has been designed and developed.,""Evelina Di Corso, Stefano Proto, Bartolomeo Vacchetti, P. Bethaz, T. Cerquitelli"",Applied Sciences,,0.44 (11182),10.3390/app12105125,https://www.mdpi.com/2076-3417/12/10/5125/pdf?version=1653020798,2022,1,https://doi.org/10.3390/app12105125,https://semanticscholar.org/paper/2b5808c2c7c6699ce20f9a08d136f650fc717146,""In recent years, the number and heterogeneity of large scientific datasets have been growing steadily. Moreover, the analysis of these data collections is not a trivial task. There are many algorithms capable of analyzing large datasets, but parameters need to be set for each of them. Moreover, larger datasets also mean greater complexity. All this leads to the need to develop innovative, scalable, and parameter-free solutions. The goal of this research activity is to design and develop an automated data analysis engine that effectively and efficiently analyzes large collections of text data with minimal user intervention. Both parameter-free algorithms and self-assessment strategies have been proposed to suggest algorithms and specific parameter values for each step that characterizes the analysis pipeline. The proposed solutions have been tailored to text corpora characterized by variable term distributions and different document lengths. In particular, a new engine called ESCAPE (enhanced self-tuning characterization of document collections after parameter evaluation) has been designed and developed. ESCAPE integrates two different solutions for document clustering and topic modeling: the joint approach and the probabilistic approach. Both methods include ad hoc self-optimization strategies to configure the specific algorithm parameters. Moreover, novel visualization techniques and quality metrics have been integrated to analyze the performances of both approaches and to help domain experts interpret the discovered knowledge. Both approaches are able to correctly identify meaningful par",titions of a,give,n do,cument,co,rpus,by,g,roup,ing,th,em,"according to topics."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Subgraph Retrieval Enhanced Model for Multi-hop Knowledge Base Question Answering,A trainable subgraph retriever enables a plug-and-play framework to enhance any subgraph-oriented knowledge base question answering model.,""Jing Zhang, Xiaokang Zhang, Jifan Yu, Jian Tang, Jie Tang, Cuiping Li, Hong-yan Chen"",ACL,,,10.18653/v1/2022.acl-long.396,https://aclanthology.org/2022.acl-long.396.pdf,2022,1,https://doi.org/10.18653/v1/2022.acl-long.396,https://semanticscholar.org/paper/f68b988e85f35bbe4affdc9127241a37fd31b213,""Recent works on knowledge base question answering (KBQA) retrieve subgraphs for easier reasoning. The desired subgraph is crucial as a small one may exclude the answer but a large one might introduce more noises. However, the existing retrieval is either heuristic or interwoven with the reasoning, causing reasoning on the partial subgraphs, which increases the reasoning bias when the intermediate supervision is missing. This paper proposes a trainable subgraph retriever (SR) decoupled from the subsequent reasoning process, which enables a plug-and-play framework to enhance any subgraph-oriented KBQA model. Extensive experiments demonstrate SR achieves significantly better retrieval and QA performance than existing retrieval methods. Via weakly supervised pre-training as well as the end-to-end fine-tuning, SR achieves new state-of-the-art performance when combined with NSM (He et al., 2021), a subgraph-oriented reasoner, for embedding-based KBQA methods. Codes and datasets are available online (https://github.com/RUCKBReasoning/SubgraphRetrievalKBQA)"",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"A Fast Clustering Algorithm for Modularization of Large-Scale Software Systems,The proposed clustering algorithm achieves higher quality modularization compared with hierarchical algorithms.,""Navid Teymourian, H. Izadkhah, A. Isazadeh"",IEEE Transactions on Software Engineering,,2.027 (1214),10.1109/tse.2020.3022212,,2022,9,https://doi.org/10.1109/tse.2020.3022212,https://semanticscholar.org/paper/12dc616fab097ae45dc608129ddc3c5e58c9cb6a,""A software system evolves over time in order to meet the needs of users. Understanding a program is the most important step to apply new requirements. Clustering techniques through dividing a program into small and meaningful parts make it possible to understand the program. In general, clustering algorithms are classified into two categories: hierarchical and non-hierarchical algorithms (such as search-based approaches). While clustering problems generally tend to be NP-hard, search-based algorithms produce acceptable clustering and have time and space constraints and hence they are inefficient in large-scale software systems. Most algorithms which currently used in software clustering fields do not scale well when applied to large and very large applications. In this paper, we present a new and fast clustering algorithm, FCA, that can overcome space and time constraints of existing algorithms by performing operations on the dependency matrix and extracting other matrices based on a set of features. The experimental results on ten small-sized applications, ten folders with different functionalities from Mozilla Firefox, a large-sized application (namely ITK), and a very large-sized application (namely Chromium) demonstrate that the proposed algorithm achieves higher quality modularization compared with hierarchical algorithms. It can also compete with search-based algorithms and a clustering algorithm based on subsystem patterns. But the running time of the proposed algorithm is much shorter than that of the hierarchical and non-hierarchical algorithms. The source code of the proposed algorithm can be accessed at https://github.com/SoftwareMaintenanceLab."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"DeepKE: A Deep Learning Based Knowledge Extraction Toolkit for Knowledge Base Population,DeepKE allows developers and researchers to customize datasets and models to extract information from unstructured texts according to their requirements.,""Ningyu Zhang, Xin Xu, Li Tao, Haiyang Yu, Hongbin Ye, Xin Xie, Xiang Chen, Zhoubo Li, Lei Li, Xiaozhuan Liang, Yunzhi Yao, Shumin Deng, Zhenru Zhang, Chuanqi Tan, Fei Huang, Guozhou Zheng, Huajun Chen"",ArXiv,,,,,2022,2,,https://semanticscholar.org/paper/aa4684d91cb6ce692daffde731610dfb9368a5cb,""We present the first open-source and extensible knowledge extraction toolkit DeepKE, supporting low-resource few-shot and documentlevel scenarios in knowledge base population. DeepKE implements various information extraction tasks, including named entity recognition, relation extraction and attribute extraction. With a unified framework, DeepKE allows developers and researchers to customize datasets and models to extract information from unstructured texts according to their requirements. Specifically, DeepKE not only provides various functional modules and model implementation for different tasks and scenarios but also organizes all components by consistent frameworks to maintain sufficient modularity and extensibility. Besides, we present an online platform1 for realtime extraction of various tasks. DeepKE has been equipped with Google Colab tutorials and comprehensive documents2 for beginners. We release the source code at GitHub3, with a demo video4."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"DeepKE: A Deep Learning Based Knowledge Extraction Toolkit for Knowledge Base Population,DeepKE allows developers and researchers to customize datasets and models to extract information from unstructured data according to their requirements.,""Ningyu Zhang, Xin Xu, Li Tao, Haiyang Yu, Hongbin Ye, Xin Xie, Xiang Chen, Zhoubo Li, Lei Li, Xiaozhuan Liang, Yunzhi Yao, Shumin Deng, Zhenru Zhang, Chuanqi Tan, Fei Huang, Guozhou Zheng, Huajun Chen"",ArXiv,,,,,2022,11,,https://semanticscholar.org/paper/6339ababdcda13b19979b314d5afeb53a83a6a4a,""We present an open-source and extensible knowledge extraction toolkit DeepKE, supporting complicated low-resource, document-level and multimodal scenarios in the knowledge base population. DeepKE implements various information extraction tasks, including named entity recognition, relation extraction and attribute extraction. With a unified framework, DeepKE allows developers and researchers to customize datasets and models to extract information from unstructured data according to their requirements. Specifically, DeepKE not only provides various functional modules and model implementation for different tasks and scenarios but also organizes all components by consistent frameworks to maintain sufficient modularity and extensibility. We release the source code at GitHub in https://github.com/zjunlp/DeepKE with Google Colab tutorials and comprehensive documents for beginners. Besides, we present an online system in http://deepke.openkg.cn/EN/re_doc_show.html for real-time extraction of various tasks, and a demo video."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"A Unified Knowledge Extraction Method Based on BERT and Handshaking Tagging Scheme,Traditional knowledge extraction models cannot be directly transferred to new domains directly.,""Ning Yang, S. Pun, M. Vai, Yifan Yang, Qingliang Miao"",Applied Sciences,,0.44 (11182),10.3390/app12136543,https://www.mdpi.com/2076-3417/12/13/6543/pdf?version=1656413488,2022,1,https://doi.org/10.3390/app12136543,https://semanticscholar.org/paper/55b2a3a40051aed8fcfca689e45b43334e05e8fa,""In the actual knowledge extraction system, different applications have different entity classes and relationship schema, so the generalization and migration ability of knowledge extraction are very important. By training a knowledge extraction model in the source domain and applying the model to an arbitrary target domain directly, open domain knowledge extraction technology becomes crucial to mitigate the generalization and migration ability issues. Traditional knowledge extraction models cannot be directly transferred to new domains and also cannot extract undefined relation types. In order to deal with the above issues, in this paper, we proposed an end-to-end Chinese open-domain knowledge extraction model, TPORE (Extract Open-domain Relations through Token Pair linking), which combined BERT with a handshaking tagging scheme. TPORE can alleviate the nested entities and nested relations issues. Additionally, a new loss function that conducts a pairwise comparison of target category score and non-target category score to automatically balance the weight was adopted, and the experiment results indicate that the loss function can bring speed and performance improvements. The extensive experiments demonstrate that the proposed method can significantly surpass strong baselines. Specifically, our approach can achieve new state-of-the-art Chinese open Relation Extraction (ORE) benchmarks (COER and SAOKE). In the COER dataset, F1 increased from 66.36% to 79.63%, and in the SpanSAOKE dataset, F1 increased from 46.0% to 54.91%. In the medical domain, our method can obtain close performance compared with the SOTA method in the CMeIE and CMeEE","datasets."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Kubric: A scalable dataset generator,Synthetic data is a powerful tool with the potential to address these shortcomings.,""Klaus Greff, Francois Belletti, L. Beyer, Carl Doersch, Yilun Du, Daniel Duckworth, David J. Fleet, Dan Gnanapragasam, Florian Golemo, Charles Herrmann, Thomas Kipf, Abhijit Kundu, Dmitry Lagun, I. Laradji, Hsueh-Ti Liu, H. Meyer, Yishu Miao, Derek Nowrouzezahrai, Cengiz Oztireli, Etienne Pot, Noha Radwan, Daniel Rebain, S. Sabour, Mehdi S. M. Sajjadi, Matan Sela, V. Sitzmann, Austin Stone, Deqing Sun, Suhani Vora, Ziyu Wang, Tianhao Wu, K. M. Yi, Fangcheng Zhong, A. Tagliasacchi"",Computer Vision and Pattern Recognition,,,10.1109/CVPR52688.2022.00373,http://arxiv.org/pdf/2203.03570,2022,35,https://doi.org/10.1109/CVPR52688.2022.00373,https://semanticscholar.org/paper/7613b1df07b909a91e608d75babc834df40cf85a,""Data is the driving force of machine learning, with the amount and quality of training data often being more important for the performance of a system than architecture and training details. But collecting, processing and annotating real data at scale is difficult, expensive, and frequently raises additional privacy, fairness and legal concerns. Synthetic data is a powerful tool with the potential to address these shortcomings: 1) it is cheap 2) supports rich ground-truth annotations 3) offers full control over data and 4) can circumvent or mitigate problems regarding bias, privacy and licensing. Unfortunately, software tools for effective data generation are less mature than those for architecture design and training, which leads to fragmented generation efforts. To address these problems we introduce Kubric, an open-source Python framework that interfaces with PyBullet and Blender to generate photo-realistic scenes, with rich annotations, and seamlessly scales to large jobs distributed over thousands of machines, and generating TBs of data. We demonstrate the effectiveness of Kubric by presenting a series of 13 different generated datasets for tasks ranging from studying 3D NeRF models to optical flow estimation. We release Kubric, the used assets, all of the generation","code, as wel",l as,the,rende,red,dat,ase,ts,for,re,use,a,"nd modification."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"An automatic method for constructing machining process knowledge base from knowledge graph,The knowledge representation method based on fuzzy comprehensive evaluation is established.,""Liang  Guo, Fu  Yan, Tian  Li, Tao  Yang, Yuqian  Lu"",Robotics Comput. Integr. Manuf.,,,10.1016/J.RCIM.2021.102222,,2022,5,https://doi.org/10.1016/J.RCIM.2021.102222,https://semanticscholar.org/paper/ec77a43c75a428ac34e03dec8b56774c6fa72d06,""Abstract The process knowledge base is the key module in intelligent process design, it determines the intelligence degree of the design system and affects the quality of product design. However, traditional process knowledge base construction is non-automated, time consuming and requires much manual work, which is not sufficient to meet the demands of the modern manufacturing mode. Moreover, the knowledge base often adopts a single knowledge representation, and this may lead to ambiguity in the meaning of some knowledge, which will affect the quality of the process knowledge base. To overcome the above problems, an automatic construction framework for the process knowledge base in the field of machining based on knowledge graph (KG) is introduced. First, the knowledge is classified and annotated based on the function-behavior-states (FBS) design method. Second, a knowledge extraction framework based on BERT-BiLSTM-CRF is established to perform the automatic knowledge extraction of process text. Third, a knowledge representation method based on fuzzy comprehensive evaluation is established, forming three types of knowledge representation with the KG as the main, production rules and two-dimensional data linked list as a supplement. In addition, to overcome the redundancy in the knowledge fusion stage, a hybrid algorithm based on an improved edit distan",ce and attribute weighting is built.,Finall,"y, a prototype system is developed, and quality analysis is carried out. Compared with the F values",of BiLSTM-CRF and,"CNN-BiLSTM-CRF, that",of the proposed extraction method in,the,machining domain is,increa,"sed by 7.35% and 3.87%,","respectively."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Cache-enabled Knowledge Base Construction Strategy in Semantic Communications,The recovery accuracy of semantic information and the system delay of the proposed schemes are better than other schemes.,""Yue Che, Huachao Xiong, Shujun Han, Xiaodong Xu"",2022 IEEE Globecom Workshops (GC Wkshps),,,10.1109/GCWkshps56602.2022.10008494,,2022,,https://doi.org/10.1109/GCWkshps56602.2022.10008494,https://semanticscholar.org/paper/dfa1856f9d0f8ecb5285f85b9c167aadd99fe9ba,""With the increasing demand for intelligence in wireless networks, semantic communication is considered as a enabling technology to achieve goal-oriented communication. Deploying semantic knowledge base is seen as a critical technology for support semantic communication in resource-constrained systems. However, the current network architecture does not consider the way of deploying and constructing knowledge bases. To fill this gap, we propose a knowledge base deployment mechanism based on edge caching to support the application of semantic communication. Further, for the semantic understanding-oriented requests of intelligent devices, the knowledge base is considered to be deployed in the edge cache in the form of a knowledge graph. Considering the reusability of triples in requested subgraphs, we define a subgraph value function to measure the translatability and effectiveness of subgraphs, and establish a cached semantic knowledge base value maximization model. Besides, we propose two semantic knowledge base caching strategies, including a subgraph-based dynamic programming caching strategy and a triple-based greedy caching strategy. Compared with other schemes, the recovery accuracy of semantic information and the system delay of the proposed schemes both achieve better performances."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Knowledge Base Construction from Pre-trained Language Models by Prompt learning,Pre-trained language models have advanced the state-of-the-art for many semantic tasks.,""Xiaomin Ning, R. Çelebi"",,,,,,2022,,,https://semanticscholar.org/paper/6f0e7f51f0ceb317061a803ae5d5eb79ef668b4c,""Pre-trained language models (LMs) have advanced the state-of-the-art for many semantic tasks and have also been proven effective for extracting knowledge from the models itself. Although several works have explored the capability of the LMs for constructing knowledge bases, including prompt learning, this potential has not yet been fully explored. In this work, we propose a method of extracting factual knowledge from LMs for given subject-relation pairs and explore the most effective strategy to generate blank object entities for each relation of triples. We design prompt templates for each relation using personal knowledge and the descriptive information available on the web such as WikiData. The probing approach of our proposed LMs is tested on the dataset provided by the International Semantic Web Conference (ISWC 2022) LM-KBC Challenge. To cope with the problem of varying performance for each relation, we designed a parameter selection strategy for each relation. Using the test dataset, we obtain an F1-score of 0.4935%, which is higher than the baseline of 31.08%."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"LM-KBC: Knowledge Base Construction from Pre-trained Language Models,Pre-training BERT specific to a relation performed better than pre-training for all relations.,""Sneha Singhania, Tuan-Phong Nguyen, Simon Razniewski"",,,,,,2022,,,https://semanticscholar.org/paper/c575b88a049a5fbbeeac446c5443fc3bd490f519,""Pre-trained Language Models (LMs) have advanced a range of semantic tasks, and have also shown promise for factual knowledge extraction encoded in them. Although several works have explored this ability in the LM probing setting, viability of knowledge base construction from LMs has not yet been explored. In light of this, we hosted the LM-KBC challenge at the 21 st International Semantic Web Conference (ISWC 2022). Participants were asked to build actual knowledge bases from LMs, for a given set of subjects and relations. In crucial difference to existing probing benchmarks like LAMA [1], we made no simplifying assumptions on relation cardinalities, i.e., a subject-entity could stand in relation with zero, one, or many object-entities. Furthermore, submitted systems were required to go beyond just ranking the predictions and materialize the outputs, which we evaluated using the established KB metrics of precision, recall, and ?? 1 -score. The challenge had two tracks: (1) a BERT-type LM track with low computational requirements and (2) an open track, where participants could use any LM of their choice. In this first edition of the challenge, we received a total of five submissions, four for track 1 and one for track 2. We present the contributions and insights of our peer-reviewed submissions and lay out the possible paths for future work. The challenge website is https://lm-kbc.github.io. The authors present a system that performed task-specific pre-training of BERT,",employed prompt decomposition for p,rogress,"ive generation of candidate objects, and use adaptive thresholds for final candidate object selecti",on. They collected,additional knowledge,triples from Wikidata KB and further,pre,#NAME?,masked,token prediction objec,tive. They formula,ted,the,"input as a cloze-style prompt and masked the object-entity, ensuring that the model knows what to recover during prediction. In this modified pre-training step, they also experimented with additionally masking tokens (window size of 1 or 2) appearing in vicinity of the object-entity; however, this did not lead to a gain in the overall performance. They also showed that task-specific pre-training of BERT specific to a relation performed better than pre-training for all relations."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"The Core of Smart Cities: Knowledge Representation and Descriptive Framework Construction in Knowledge-Based Visual Question Answering,Knowledge is important for answering questions correctly.,""Ruiping Wang, Shihong Wu, Xiaoping Wang"",Sustainability,,0.664 (7320),10.3390/su142013236,https://www.mdpi.com/2071-1050/14/20/13236/pdf?version=1666606790,2022,1,https://doi.org/10.3390/su142013236,https://semanticscholar.org/paper/c302556986d527713f501ad9d46f3468d665b4ec,""Visual question answering (VQA), which is an important presentation form of AI-complete task and visual Turing tests, coupled with its potential application value, attracted widespread attention from both researchers in computer vision and natural language processing. However, there are no relevant research regarding the expression and participation methods of knowledge in VQA. Considering the importance of knowledge for answering questions correctly, this paper analyzes and researches the stratification, expression and participation process of knowledge in VQA and proposes a knowledge description framework (KDF) to guide the research of knowledge-based VQA (Kb-VQA). The KDF consists of a basic theory, implementation methods and specific applications. This paper focuses on describing mathematical models at basic theoretical levels, as well as the knowledge hierarchy theories and key implementation behaviors established on this basis. In our experiment, using the statistics of VQA’s accuracy in the relevant literature, we propose a good corroboration of the research results from knowledge stratification, participation methods and expression forms in this paper."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"MEduKG: A Deep-Learning-Based Approach for Multi-Modal Educational Knowledge Graph Construction,The proposed approach can manage and present various modes of educational resources.,""Nan Li, Qiang Shen, Rui Song, Yang Chi, Hao Xu"",Inf.,,,10.3390/info13020091,https://www.mdpi.com/2078-2489/13/2/91/pdf?version=1644898821,2022,4,https://doi.org/10.3390/info13020091,https://semanticscholar.org/paper/cf7eb1e29a3d6eed2ec739e9cd5c8c96f8027f1b,""The popularity of information technology has given rise to a growing interest in smart education and has provided the possibility of combining online and offline education. Knowledge graphs, an effective technology for knowledge representation and management, have been successfully utilized to manage massive educational resources. However, the existing research on constructing educational knowledge graphs ignores multiple modalities and their relationships, such as teacher speeches and their relationship with knowledge. To tackle this problem, we propose an automatic approach to construct multi-modal educational knowledge graphs that integrate speech as a modal resource to facilitate the reuse of educational resources. Specifically, we first propose a fine-tuned Bidirectional Encoder Representation from Transformers (BERT) model based on education lexicon, called EduBERT, which can adaptively capture effective information in the education field. We also add a Bidirectional Long Short-Term Memory-Conditional Random Field (BiLSTM-CRF) to effectively identify educational entities. Then, the locational information of the entity is incorporated into BERT to extract the educational relationship. In addition, to cover the shortage of traditional text-based knowledge graphs, we focus on collecting teacher speech to construct a multi-modal knowled",ge graph. We propose a speech-fusion,method,that links these data into the graph as a class of entities. The numeric results show that our pro,posed approach can,manage and present v,arious modes of educational resources,and,that it can provide,better,"education services."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Design and Implementation of Knowledge Base for Runtime Management of Software Defined Hardware,A dynamic and extensible knowledge base supports compilation of high-level languages to leverage arbitrary reconfigurable platforms.,""Hongkuan Zhou, Ajitesh Srivastava, R. Kannan, V. Prasanna"",ArXiv,,,10.1109/HPEC.2017.8091048,http://arxiv.org/pdf/2203.15534,2022,2,https://doi.org/10.1109/HPEC.2017.8091048,https://semanticscholar.org/paper/7a65bb57dad061da000e8169450611a0be741a2c,""—Runtime-recon?gurable software coupled with re- con?gurable hardware is highly desirable as a means to-wards maximizing runtime ef?ciency without compromising pro- grammability. Compilers for such software systems are extremely dif?cult to design as they must leverage different types of hardware at runtime. To address the need for static and dynamic compiler optimization of work?ows matched to dynamically recon?gurable hardware, we propose a novel design of the central component of a dynamic software compiler for software de?ned hardware. Our comprehensive design focuses not just on static knowledge but also on semi-supervised extraction of knowledge from program executions and developing their performance models. Speci?cally, our novel dynamic and extensible knowledge base 1) continuously gathers knowledge during execution of work?ows 2) identi?es optimal implementations of work?ows on optimal (available) hardware con?gurations. It plays a hub role in storing information from, and providing information to other components of the compiler, as well as the human analyst. Through a rich tripartite graph representation, the knowledge base captures and learns extensive information on decomposition and mapping of code steps to kernels and mapping of kernels to available hardware con?gurations. The knowle",dge base is implemented using the C+,#NAME?,Library and is capable of quickly processing of?ine and online queries and updates. We show that o,ur knowledge base,can answer queries in,1 ms regardless of the number of wor,k?ow,s it stores. To the,best of,"our knowledge, this is",the ?rst design o,f a,dyn,"amic and extensible knowledge base to support compilation of high-level languages to leverage arbitrary recon?gurable platforms."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Representing Knowledge by Spans: A Knowledge-Enhanced Model for Information Extraction,Knowledge-enhanced pre-trained models for language representation have been shown to be more effective in knowledge base construction tasks than language models such as BERT.,""Jiacheng Li, Yannis Katsis, Tyler Baldwin, Ho-Cheol Kim, Andrew Bartko, Julian McAuley, Chun-Nan Hsu"",ArXiv,,,10.48550/arXiv.2208.09625,,2022,,https://doi.org/10.48550/arXiv.2208.09625,https://semanticscholar.org/paper/2ee39a9a7d7186a351f2170ce7ebd61f8264a860,""Knowledge-enhanced pre-trained models for language representation have been shown to be more effective in knowledge base construction tasks (i.e., relation extraction) than language models such as BERT. These knowledge-enhanced language models incorporate knowledge into pre-training to generate representations of entities or relationships. However, existing methods typically represent each entity with a separate embedding. As a result, these methods struggle to represent out-of-vocabulary entities and a large amount of parameters, on top of their underlying token models (i.e., the transformer), must be used and the number of entities that can be handled is limited in practice due to memory constraints. Moreover, existing models still struggle to represent entities and relationships simultaneously. To address these problems, we propose a new pre-trained model that learns representations of both entities and relationships from token spans and span pairs in the text respectively. By encoding spans efficiently with span modules, our model can represent both entities and their relationships but requires fewer parameters than existing models. We pre-trained our model with the knowledge graph extracted from Wikipedia and test it on a broad range of supervised and",unsupervised information extraction,tasks.,Results show that our model learns better representations for both entities and relationships than,"baselines, while",in supervised setting,"s, fine-tuning our model outperforms",RoBE,RTa consistently and,achiev,es competitive results,on information ext,rac,tion,"tasks."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Building structured Knowledge Base for trustable NLP application systems by Resource by Collaborative Construction scheme,The team's goal is to build a structured Wikipedia.,S. Sekine,Impact,,,10.21820/23987073.2022.1.9,,2022,,https://doi.org/10.21820/23987073.2022.1.9,https://semanticscholar.org/paper/c828a6351a27190e2799f22efcbbd2006ba6a3d2,""Wikipedia is an exhaustive resource that contains too much information for any one human to completely absorb. Computers, on the other hand, are able to trawl through information at a rapid pace. However, as Wikipedia is written in such a way that it is clear for people to read, it",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"ImPaKT: A Dataset for Open-Schema Knowledge Base Construction,The ImPaKT dataset for open-schema information extraction consists of around 2500 text snippets from the C4 corpus in the shopping domain.,""L. Vilnis, Zachary Kenneth Fisher, Bhargav Kanagal, Patrick C. Murray, Sumit K. Sanghai"",ArXiv,,,10.48550/arXiv.2212.10770,,2022,,https://doi.org/10.48550/arXiv.2212.10770,https://semanticscholar.org/paper/18e1dd6604f98ebcdf3f281803a5c92763e3ffef,""Large language models have ushered in a golden age of semantic parsing. The seq2seq paradigm allows for open-schema and abstractive attribute and relation extraction given only small amounts of ?netuning data. Language model pretraining has simultaneously enabled great strides in natural language inference, reasoning about entailment and implication in free text. These advances motivate us to construct ImPaKT, a dataset for open-schema information extraction, consisting of around 2500 text snippets from the C4 corpus, in the shopping domain (product buying guides), pro-fessionally annotated with extracted attributes, types, attribute summaries (attribute schema discovery from idiosyncratic text), many-to-one relations between compound and atomic attributes, and implication relations. We release this data in hope that it will be useful in ?ne tuning semantic parsers for information extraction and knowledge base construction across a variety of domains. We evaluate the power of this approach by ?ne-tuning the open source UL2 language model on a subset of the dataset, extracting a set of implication relations from a corpus of product buying guides, and conducting human evaluations of the resulting predictions."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Research on the Development Process and Construction of Domain-specific Knowledge Graph,""The construction of domain-specific knowledge graph has great application value in intelligent search, intelligent question and answer, intelligent recommendation and other information services."",""Yuanyuan Yang, Kailei Li, Yun Yan, Jiali Zhu"",""2022 IEEE Asia-Pacific Conference on Image Processing, Electronics and Computers (IPEC)"",,,10.1109/ipec54454.2022.9777576,,2022,,https://doi.org/10.1109/ipec54454.2022.9777576,https://semanticscholar.org/paper/a8907c638fc75d29304dcfb7de724e5ad58d2ba9,""Knowledge graph is the core content of artificial intelligence research in the new era. With the rapid development of artificial intelligence in science and various fields of technology and society, it has attracted the attention of academia and industry. Various fields are actively constructing the Domain-specific Knowledge Graph (DKG). The construction of Domain-specific Knowledge Graph has great application value in intelligent search, intelligent question and answer, intelligent recommendation and other information services. This paper taking the artificial intelligence system development as background, systematically elaborated the origin and composition of Domain-specific Knowledge Graph, finding out that the Domain-specific Knowledge Graph has characteristics of extending the depth and detailing granularity of the knowledge representation of Domain-specific Knowledge Graph. And the development process of Domain-specific Knowledge Graph technology: developing from the symbol and the reasoning model to knowledge engineering, then to an important approach to knowledge representation of big data. The key steps and methods of Domain-specific Knowledge Graph construction are described, including",entity recognition and attribute in,formati,"on recognition, and extraction of relationships between entities. The entity recognition technology",and relation extr,action technology are,systematically described to provide,some,useful references f,or the,construction of Domain-,specific Knowledge,Gr,aph.,""",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Research on knowledge base question and answer methods based on the joint subgraph structure of interrogative features,The entity representation is pre-trained based on the background knowledge base and fused with the corresponding structural representation.,""Yuan Yu, Xianling Lu"",2022 International Conference on Machine Learning and Knowledge Engineering (MLKE),,,10.1109/MLKE55170.2022.00052,,2022,,https://doi.org/10.1109/MLKE55170.2022.00052,https://semanticscholar.org/paper/0f3c0739f13ece0010d43d50e5ea385e7f880c11,""Existing knowledge base question and answer methods rarely consider the influence of question sentences and candidate subgraph structure information when performing entity representation. This paper proposes a knowledge base question and answer method based on subgraph structure fusion question perception to address these issues. Firstly, the question is transformed into a semantic quantity by the pre-training model RoBERTa; secondly, the subgraphs of the candidate answer sets are extracted from the knowledge base based on the subject entities in the question, and the structural representation of the candidate subgraphs is enhanced by the attention calculation based on the query information to achieve question perception; secondly, the entity representation is pre-trained based on the background knowledge base and fused with the corresponding structural representation. Finally, the candidate answers are scored based on the fused vectors, and the entity with the highest score is taken as the answer. Comparative tests were conducted on the WebQuestionsSP dataset, and the experimental results showed that the proposed model outperformed other benchmark models."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Knowledge Base Completion using Web-Based Question Answering and Multimodal Fusion,A web-based question answering system can achieve good performance with very few questions.,""Yang Peng, D. Wang"",ArXiv,,,10.48550/arXiv.2211.07098,,2022,2,https://doi.org/10.48550/arXiv.2211.07098,https://semanticscholar.org/paper/c94f549124efce89cac112ece4839bc4d0b0cb4a,""Over the past few years, large knowledge bases have been con-structed to store massive amounts of knowledge. However, these knowledge bases are highly incomplete. To solve this problem, we propose a web-based question answering system system with multimodal fusion of unstructured and structured information, to fill in missing information for knowledge bases. To utilize unstructured information from the Web for knowledge base completion, we design a web-based question answering system using multimodal features and question templates to extract missing facts, which can achieve good performance with very few questions. To help improve extraction quality, the question answering system employs structured information from knowledge bases, such as entity types and entity-to-entity relatedness."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"AKB-48: A Real-World Articulated Object Knowledge Base,AKB-48 is a large-scale articulated object knowledge base.,""L. Liu, Wenqiang Xu, Haoyuan Fu, Sucheng Qian, Yong-Jin Han, Cewu Lu"",Computer Vision and Pattern Recognition,,,10.1109/CVPR52688.2022.01439,http://arxiv.org/pdf/2202.08432,2022,10,https://doi.org/10.1109/CVPR52688.2022.01439,https://semanticscholar.org/paper/2472119fb37004ae338ee3252e3171014d1c5e31,""Human life is populated with articulated objects. A comprehensive understanding of articulated objects, namely appearance, structure, physical property, and semantics, will benefit many research communities. As current articulated object understanding solutions are usually based on synthetic object dataset with CAD models without physics properties, which prevent satisfied generalization from simulation to real-world applications in visual and robotics tasks. To bridge the gap, we present AKB-48: a large-scale Articulated object Knowledge Base which consists of 2,037 real-world 3D articulated object models of 48 categories. Each object is described by a knowledge graph ArtiKG. To build the AKB-48, we present a fast articulation knowledge modeling (FArM) pipeline, which can fulfill the ArtiKG for an articulated object within 10–15 minutes, and largely reduce the cost for object modeling in the real world. Using our dataset, we propose AKBNet, an integral pipeline for Category-level Visual Articulation Manipulation (C-VAM) task, in which we benchmark three sub-tasks, namely pose estimation, object reconstruction and manipulation. Dataset, codes, and models are publicly available at https://liuliu66.github.io/AKB-48."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"NeuralKG: An Open Source Library for Diverse Representation Learning of Knowledge Graphs,NeuralKG is highly configurable and extensible.,""Wen Zhang, Xian-gan Chen, Zhen Yao, Mingyang Chen, Yushan Zhu, Hongtao Yu, Yufen Huang, Zezhong Xu, Yajing Xu, Ningyu Zhang, Zonggang Yuan, Feiyu Xiong, Huajun Chen"",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,,,10.1145/3477495.3531669,http://arxiv.org/pdf/2202.12571,2022,5,https://doi.org/10.1145/3477495.3531669,https://semanticscholar.org/paper/220ee63042d1c6301264dcb4d9b4687913683356,""NeuralKG is an open-source Python-based library for diverse representation learning of knowledge graphs. It implements three kinds of Knowledge Graph Embedding (KGE) methods, including conventional KGEs, GNN-based KGEs, and Rule-based KGEs. With a unified framework, NeuralKG successfully reproduces link prediction results of these methods on benchmarks, freeing users from the laborious task of reimplementing them, especially for some methods originally written in non-python programming languages. Besides, NeuralKG is highly configurable and extensible. It provides various decoupled modules that can be mixed and adapted to each other. Thus with NeuralKG, developers and researchers can quickly implement their own designed models and obtain the optimal training methods to achieve the best performance efficiently. We built a website http://neuralkg.zjukg.org to organize an open and shared KG representation learning community. The library, experimental methodologies, and model reimplement results of NeuralKG are all publicly released at https://github.com/zjukg/NeuralKG."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Towards Fair Representation Learning in Knowledge Graph with Stable Adversarial Debiasing,A weights normalization technique can mitigate the pitfalls of instability in adversarial debasing towards fair-and-stable machine learning.,""Yihe Wang, Mohammad Mahdi Khalili, X. Zhang"",2022 IEEE International Conference on Data Mining Workshops (ICDMW),,,10.1109/ICDMW58026.2022.00119,,2022,,https://doi.org/10.1109/ICDMW58026.2022.00119,https://semanticscholar.org/paper/4e7fe6abcf023d7ab0ddc1551b293afb38c57ab4,""With graph-structured tremendous information, Knowledge Graphs (KG) aroused increasing interest in aca-demic research and industrial applications. Recent studies have shown demographic bias, in terms of sensitive attributes (e.g., gender and race), exist in the learned representations of KG entities. Such bias negatively affects specific popu-lations, especially minorities and underrepresented groups, and exacerbates machine learning-based human inequality. Adversariallearning is regarded as an effective way to alleviate bias in the representation learning model by simultaneously training a task-specific predictor and a sensitive attribute-specific discriminator. However, due to the unique challenge caused by topological structure and the comprehensive re-lationship between knowledge entities, adversarial learning-based debiasing is rarely studied in representation learning in knowledge graphs. In this paper, we propose a framework to learn unbiased representations for nodes and edges in knowledge graph mining. Specifically, we integrate a simple-but-effective normalization technique with Graph Neural Networks (GNNs) to constrain the weights updating process. Moreover, as a work-in-progress paper, we also find that the introduced weights normalization technique can mitigate the pitfalls of instability in adversarial debasing towards fair-and-stable machine learning. We evaluate the proposed fra",mework,on,a,benchmarking,graph wi,th m,ultiple edge,types and,node,t,ypes.,The,experimen,tal,resu,lts,s,how,that,"our model achieves comparable or better gender fairness over three competitive baselines on Equality of Odds. Importantly, our superiority in the fair model does not scarify the performance in the knowledge graph task (i.e., multi-class edge classification)."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"A Representation Learning Method of Knowledge Graph Integrating Ordered Relation Path and Entity Description Information,The model has higher accuracy than existing baselines.,""Haoxiang Ma, Xuesong Jiang, Huihui Chai, Xiumei Wei"",""IEEE International Conference on Systems, Man and Cybernetics"",,,10.1109/SMC53654.2022.9945592,,2022,1,https://doi.org/10.1109/SMC53654.2022.9945592,https://semanticscholar.org/paper/6139af5179527be9c7fab7293f0317b08eb584ce,""Knowledge graph representation learning aims to obtain its vector representation by mapping entities and relations in knowledge graphs to a continuous low-dimensional vector space by learning methods. Most of the existing knowledge graph representation learning methods only consider the single-step relation between entities from the perspective of triples and fail to effectively utilize important information such as ordered multi-step relation paths and entity descriptions, thus affecting the ability of knowledge representation learning. We propose a knowledge graph representation learning model that integrates ordered relation paths and entity descriptions in response to the above problems. The model can integrate the triple representation in the knowledge graph, the semantic representation of entity description, and the representation of ordered relation paths for training. On the FB15K, WN18, FB15K-237, and WN18RR datasets, the proposed model and baselines are run on the link prediction task. Experimental results show that the model has higher accuracy than existing baselines, demonstrating the effectiveness and superiority of the method."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Representation Learning of Knowledge Graph Integrating Entity Description and Language Morphological Structure Information,The Hit@10s of head entity prediction for N-1 relations and tail entity prediction for 1-N relations improved on FB15K database.,""Xiaojuan Du, Yizheng Tao, Gongliang Li"",2022 IEEE 2nd International Conference on Information Communication and Software Engineering (ICICSE),,,10.1109/icicse55337.2022.9828957,,2022,,https://doi.org/10.1109/icicse55337.2022.9828957,https://semanticscholar.org/paper/6bfb4f3c053b3824a0b8c90a4d831032bc1118e3,""Knowledge graph embedding, which projects the symbolic relations and entities onto low-dimension continuous spaces, is the key to knowledge graph completion. The representation learning methods based on translation, such as TransE, TransH and TransR, only consider the triple information of knowledge graph, and fail to make effective use of other information of entity. To solve these problems, in this paper, we propose a knowledge graph representation learning method which integrates entity description and language morphological structure information to deal with complex relations (i.e. 1-N, N-1 and N-N relations). Firstly, the fastText model which considers affix of words is used to get the embedding of all entity description information. Then, the triple embedding, entity description embedding are spliced to obtain the representation of the final entity embedding. In addition, we propose a new score function-distcos–man, which considers the similarity of entity vector not only from the value of each dimension, but also from the direction of vectors. Experiments show that our method achieves substantial improvements against state-of-the-art baselines, especially the Hit@10s of head entity prediction for N-1 relations and tail entity prediction for 1-N relations improved by about 11.6% and 17.9% on FB15K database respectively."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Meta-Learning Based Knowledge Extrapolation for Knowledge Graphs in the Federated Setting,A model trained on an existing knowledge graph needs to embed an emerging knowledge graph with unseen entities and relations.,""Mingyang Chen, Wen Zhang, Zhen Yao, Xian-gan Chen, Mengxiao Ding, Fei Huang, Huajun Chen"",International Joint Conference on Artificial Intelligence,,,10.48550/arXiv.2205.04692,,2022,5,https://doi.org/10.48550/arXiv.2205.04692,https://semanticscholar.org/paper/c943efc1e766a08f67b1364c13292092b17592b1,""We study the knowledge extrapolation problem to embed new components (i.e., entities and relations) that come with emerging knowledge graphs (KGs) in the federated setting. In this problem, a model trained on an existing KG needs to embed an emerging KG with unseen entities and relations. To solve this problem, we introduce the meta-learning setting, where a set of tasks are sampled on the existing KG to mimic the link prediction task on the emerging KG. Based on sampled tasks, we meta-train a graph neural network framework that can construct features for unseen components based on structural information and output embeddings for them. Experimental results show that our proposed method can effectively embed unseen components and outperforms models that consider inductive settings for KGs and baselines that directly use conventional KG embedding methods."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Representation Learning Method with Semantic Propagation on Text-Augmented Knowledge Graphs,SP-TAG achieves competitive performance on text-augmented knowledge graphs.,""Ling Wang, Jicang Lu, Gang Zhou, Hangyu Pan, Taojie Zhu, Ningbo Huang, Peng He"",Computational Intelligence and Neuroscience,,0.863 (5106),10.1155/2022/1438047,https://downloads.hindawi.com/journals/cin/2022/1438047.pdf,2022,,https://doi.org/10.1155/2022/1438047,https://semanticscholar.org/paper/49a6378b7945e91b5bbef46bb15a69067090ad5d,""Knowledge graph representation learning aims to provide accurate entity and relation representations for tasks such as intelligent question answering and recommendation systems. Existing representation learning methods, which only consider triples, are not sufficiently accurate, so some methods use external auxiliary information such as text, type, and time to improve performance. However, they often encode this information independently, which makes it challenging to fully integrate this information with the knowledge graph at a semantic level. In this study, we propose a method called SP-TAG, which realizes the semantic propagation on text-augmented knowledge graphs. Specifically, SP-TAG constructs a text-augmented knowledge graph by extracting named entities from text descriptions and connecting them with the corresponding entities. Then, SP-TAG uses a graph convolutional network to propagate semantic information between the entities and new named entities so that the text and triple structure are fully integrated. The results of experiments on multiple benchmark datasets show that SP-TAG attains competitive performance. When the number of training samples is limited, SP-TAG maintains its high performance, verifying the importance of text augmentation and semantic propagation."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Representation Learning: Recommendation With Knowledge Graph via Triple-Autoencoder,The semi-autoencoder is designed to learn more abstract and higher-level feature representations for personalized recommendation.,""Yishuai Geng, Xiao Xiao, Xiaobing Sun, Yi Zhu"",Frontiers in Genetics,,1.096 (3556),10.3389/fgene.2022.891265,https://www.frontiersin.org/articles/10.3389/fgene.2022.891265/pdf,2022,1,https://doi.org/10.3389/fgene.2022.891265,https://semanticscholar.org/paper/8da5faeaed49cdca243a7ddfa7bfe9dcd7550cde,""The last decades have witnessed a vast amount of interest and research in feature representation learning from multiple disciplines, such as biology and bioinformatics. Among all the real-world application scenarios, feature extraction from knowledge graph (KG) for personalized recommendation has achieved substantial performance for addressing the problem of information overload. However, the rating matrix of recommendations is usually sparse, which may result in significant performance degradation. The crucial problem is how to extract and extend features from additional side information. To address these issues, we propose a novel feature representation learning method for the recommendation in this paper that extends item features with knowledge graph via triple-autoencoder. More specifically, the comment information between users and items is first encoded as sentiment classification. These features are then applied as the input to the autoencoder for generating the auxiliary information of items. Second, the item-based rating, the side information, and the generated comment representations are incorporated into the semi-autoencoder for reconstructed output. The low-dimensional representations of this extended information are learned with the semi-autoencoder. Finally, the reconstructed output generated by the semi-autoencoder is input into a third autoencoder. A serial connection",betwe,en,th,e semi-autoen,coder and,the,autoencoder,is design,ed he,re,to l,earn,more abst,rac,t and,hi,gh,er-,level,"feature representations for personalized recommendation. Extensive experiments conducted on several real-world datasets validate the effectiveness of the proposed method compared to several state-of-the-art models."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Representation Learning of Knowledge Graph for Wireless Communication Networks,The proposed model realizes automatic nodes classification and network anomaly cause tracing.,""Shiwen He, Yeyu Ou, Liang Wang, Hang Zhan, Peng Ren, Yongming Huang"",Global Communications Conference,,,10.1109/GLOBECOM48099.2022.10001185,http://arxiv.org/pdf/2208.10496,2022,,https://doi.org/10.1109/GLOBECOM48099.2022.10001185,https://semanticscholar.org/paper/df9f0d80cbcde4b87526664260614a8cd04d665b,""With the application of the fifth-generation wireless communication technologies, more smart terminals are being used and generating huge amounts of data, which has prompted extensive research on how to handle and utilize these wireless data. Researchers currently focus on the research on the upper-layer application data or studying the intelligent transmission methods concerning a specific problem based on a large amount of data generated by the Monte Carlo simulations. This article aims to understand the endogenous relationship of wireless data by constructing a knowledge graph according to the wireless communication protocols, and domain expert knowledge and further investigating the wireless endogenous intelligence. We firstly construct a knowledge graph of the endogenous factors of wireless core network data collected via a 5G/B5G testing network. Then, a novel model based on graph convolutional neural networks is designed to learn the representation of the graph, which is used to classify graph nodes and simulate the relation prediction. The proposed model realizes the automatic nodes classification and network anomaly cause tracing. It is also applied to the public datasets in an unsupervised manner. Finally, the results show that the classification accuracy of the proposed model is better than the existing unsupervised graph neural network models, such as VGAE and ARVGE."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"A Comprehensive Survey of Graph Neural Networks for Knowledge Graphs,Graph neural network-based technologies for solving four different knowledge graph tasks are reviewed.,""Zi Ye, Y. J. Kumar, G. O. Sing, Fengyan Song, Junsong Wang"",IEEE Access,,0.927 (4581),10.1109/access.2022.3191784,https://ieeexplore.ieee.org/ielx7/6287639/6514899/09831453.pdf,2022,2,https://doi.org/10.1109/access.2022.3191784,https://semanticscholar.org/paper/60a6b17f28e88f17e58f60923d98674358dbd0e4,""The Knowledge graph, a multi-relational graph that represents rich factual information among entities of diverse classifications, has gradually become one of the critical tools for knowledge management. However, the existing knowledge graph still has some problems which form hot research topics in recent years. Numerous methods have been proposed based on various representation techniques. Graph Neural Network, a framework that uses deep learning to process graph-structured data directly, has significantly advanced the state-of-the-art in the past few years. This study firstly is aimed at providing a broad, complete as well as comprehensive overview of GNN-based technologies for solving four different KG tasks, including link prediction, knowledge graph alignment, knowledge graph reasoning, and node classification. Further, we also investigated the related artificial intelligence applications of knowledge graphs based on advanced GNN methods, such as recommender systems, question answering, and drug-drug interaction. This review will provide new insights for further study of KG and GNN."",,Review",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Eureka: Neural Insight Learning for Knowledge Graph Reasoning,A neural insight learning framework named Eureka bridges the seen-to-unseen gap.,""Alex Zhang, Xun Liang, Bo Wu, Xiangping Zheng, Sensen Zhang, Yuhui Guo, Jun Wang, Xin-Yang Liu"",International Conference on Computational Linguistics,,,,,2022,,,https://semanticscholar.org/paper/35ca0a9d530cd848e89ff9c206fcb1ae541cff1c,""The human recognition system has presented the remarkable ability to effortlessly learn novel knowledge from only a few trigger events based on prior knowledge, which is called insight learning. Mimicking such behavior on Knowledge Graph Reasoning (KGR) is an interesting and challenging research problem with many practical applications. Simultaneously, existing works, such as knowledge embedding and few-shot learning models, have been limited to conducting KGR in either “seen-to-seen” or “unseen-to-unseen” scenarios. To this end, we propose a neural insight learning framework named Eureka to bridge the “seen” to “unseen” gap. Eureka is empowered to learn the seen relations with sufficient training triples while providing the flexibility of learning unseen relations given only one trigger without sacrificing its performance on seen relations. Eureka meets our expectation of the model to acquire seen and unseen relations at no extra cost, and eliminate the need to retrain when encountering emerging unseen relations. Experimental results on two real-world datasets demonstrate that the proposed framework also outperforms various state-of-the-art baselines on datasets of both seen and unseen relations."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Towards Unsupervised Machine Learning Approaches for Knowledge Graphs,The proposed approach can defeat current state-of-the-art unsupervised methods.,""Filippo Minutella, F. Falchi, P. Manghi, M. Bonis, Nicola Messina"",Italian Research Conference on Digital Library Management Systems,,,,,2022,,,https://semanticscholar.org/paper/9ad697897f63312f1747d042c8cd7381aab07b57,""Nowadays, a lot of data is in the form of Knowledge Graphs aiming at representing information as a set of nodes and relationships between them. This paper proposes an efficient framework to create informative embeddings for node classification on large knowledge graphs. Such embeddings capture how a particular node of the graph interacts with his neighborhood and indicate if it is either isolated or part of a bigger clique. Since a homogeneous graph is necessary to perform this kind of analysis, the framework exploits the metapath approach to split the heterogeneous graph into multiple homogeneous graphs. The proposed pipeline includes an unsupervised attentive neural network to merge different metapaths and produce node embeddings suitable for classification. Preliminary experiments on the IMDb dataset demonstrate the validity of the proposed approach, which can defeat current state-of-the-art unsupervised methods."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Visual Relationship Detection using Knowledge Graphs for Neural-Symbolic AI,Combining Semantic Web domain knowledge and reasoning with deep learning can deliver superior performance.,D. Herron,,,,,,2022,,,https://semanticscholar.org/paper/bd96f64b59de0b812e04c83e94e6bedee6d1cc83,""Momentum is surging behind the consensus that neural-symbolic AI is the right road for AI to take today. We propose to travel this road using Semantic Web technologies to represent the symbolic AI tradition. Our objective is to investigate and compare the efficacy of a variety of strategies for combining the capabilities of deep neural networks for statistical learning from data with those of OWL ontologies and knowledge graphs for symbolic knowledge representation and reasoning. Our application area is visual relationship detection within images. Deep learning is data hungry and struggles to generalise to examples outside the training distribution. We seek to show that combining Semantic Web domain knowledge and reasoning with deep learning can deliver superior performance, can substitute for plentiful training data, and can deliver robust generalisation in few-shot/zero-shot learning scenarios."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Neural Methods for Logical Reasoning over Knowledge Graphs,Neural network models achieve a 10% relative increase over the best performing state of the art.,""Alfonso Amayuelas, Shuai Zhang, Susie Xi Rao, Ce Zhang"",International Conference on Learning Representations,,,10.48550/arXiv.2209.14464,,2022,4,https://doi.org/10.48550/arXiv.2209.14464,https://semanticscholar.org/paper/2d80d0b053179988f2155ea9eaf57b60a7742c16,""Reasoning is a fundamental problem for computers and deeply studied in Arti?cial Intelligence. In this paper, we speci?cally focus on answering multi-hop logical queries on Knowledge Graphs (KGs). This is a complicated task because, in real-world scenarios, the graphs tend to be large and incomplete. Most previous works have been unable to create models that accept full First-Order Logical (FOL) queries, which include negative queries, and have only been able to process a limited set of query structures. Additionally, most methods present logic operators that can only perform the logical operation they are made for. We introduce a set of models that use Neural Networks to create one-point vector embeddings to answer the queries. The versatility of neural networks allows the framework to handle FOL queries with Conjunction ( ? ), Disjunction ( ? ) and Negation ( ¬ ) operators. We demonstrate experimentally the performance of our model through extensive experimentation on well-known benchmarking datasets. Besides having more versatile operators, the models achieve a 10% relative increase over the best performing state of the art and more than 30% over the original method based on single-point vector embeddings."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"An Open Challenge for Inductive Link Prediction on Knowledge Graphs,The ILPC 2022 challenge on knowledge graph inductive link prediction is a novel open challenge on knowledge graphs.,""Mikhail Galkin, M. Berrendorf, Charles Tapley Hoyt"",ArXiv,,,10.48550/arXiv.2203.01520,,2022,4,https://doi.org/10.48550/arXiv.2203.01520,https://semanticscholar.org/paper/afbb1e7a2583c2d009845cbc112f4028f7ec92a3,""An emerging trend in representation learning over knowledge graphs (KGs) moves beyond transductive link prediction tasks over a fixed set of known entities in favor of inductive tasks that imply training on one graph and performing inference over a new graph with unseen entities. In inductive setups, node features are often not available and training shallow entity embedding matrices is meaningless as they cannot be used at inference time with unseen entities. Despite the growing interest, there are not enough benchmarks for evaluating inductive representation learning methods. In this work, we introduce ILPC 2022 , a novel open challenge on KG inductive link prediction. To this end, we constructed two new datasets based on Wikidata with various sizes of training and inference graphs that are much larger than existing inductive benchmarks. We also provide two strong baselines leveraging recently proposed inductive methods. We hope this challenge helps to streamline community efforts in the inductive graph representation learning area. ILPC 2022 follows best practices on evaluation fairness and reproducibility, and is available at https://github.com/pykeen/ilpc2022."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Entity-Agnostic Representation Learning for Parameter-Efficient Knowledge Graph Embedding,The number of embedding parameters increases linearly as the growth of knowledge graphs.,""Mingyang Chen, Wen Zhang, Zhen Yao, Yushan Zhu, Yang Gao, Jeff Z. Pan, Hua-zeng Chen"",ArXiv,,,10.48550/arXiv.2302.01849,,2023,,https://doi.org/10.48550/arXiv.2302.01849,https://semanticscholar.org/paper/10d949dee482aeea1cab8b42c326d0dbf0505de3,""We propose an entity-agnostic representation learning method for handling the problem of inefficient parameter storage costs brought by embedding knowledge graphs. Conventional knowledge graph embedding methods map elements in a knowledge graph, including entities and relations, into continuous vector spaces by assigning them one or multiple specific embeddings (i.e., vector representations). Thus the number of embedding parameters increases linearly as the growth of knowledge graphs. In our proposed model, Entity-Agnostic Representation Learning (EARL), we only learn the embeddings for a small set of entities and refer to them as reserved entities. To obtain the embeddings for the full set of entities, we encode their distinguishable information from their connected relations, k-nearest reserved entities, and multi-hop neighbors. We learn universal and entity-agnostic encoders for transforming distinguishable information into entity embeddings. This approach allows our proposed EARL to have a static, efficient, and lower parameter count than conventional knowledge graph embedding methods. Experimental results show that EARL uses fewer parameters and performs better on link prediction tasks than baselines, reflecting its parameter efficiency."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Attention-Based Relational Graph Convolutional Network for Knowledge Graph Reasoning,The attention-based relational graph convolutional network outperforms the R-GCN in entity classification and link prediction tasks.,""Junhua Duan, Yucheng Huang, Zhu Yi-an, Dong Zhong"",International Symposium on Communications and Information Technologies,,,10.1109/ISCIT55906.2022.9931190,,2022,,https://doi.org/10.1109/ISCIT55906.2022.9931190,https://semanticscholar.org/paper/0dc146a3044991231c9f48b22170811fcb4c412c,""In recent years, with the rapid growth of knowledge graphs, knowledge reasoning technology is in great demand for research. The knowledge graph is a heterogeneous network with a graph structure. Graph Convolutional Network (GCN) is an extension of traditional Convolutional Neural Network (CNN) in non-Euclidean space, very suitable for processing complex graph data. In this paper, a attention-based relational graph convolutional network (AR-GCN) is proposed. When aggregating neighbor information, the weight of neighbor nodes is adaptively assigned through the attention mechanism, so that nodes can focus on different neighbor information and enhance the accuracy of feature representation. According to the topological characteristics of different knowledge graphs, two attention mechanisms are proposed. The experimental results show that AR-GCN outperforms R-GCN in entity classification and link prediction tasks, further showing that it has stronger characterization ability."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"A Novel Representation Learning for Dynamic Graphs Based on Graph Convolutional Networks.,Existing GCN-based methods for graph representation learning mainly focus on static graphs.,""Chao Gao, Junyou Zhu, Fan Zhang, Zhen Wang, Xuelong Li"",IEEE Transactions on Cybernetics,,4.506 (325),10.1109/TCYB.2022.3159661,,2022,10,https://doi.org/10.1109/TCYB.2022.3159661,https://semanticscholar.org/paper/fc9e25150df546bf7a6745e3a8b547ad96b3ded1,""Graph representation learning has re-emerged as a fascinating research topic due to the successful application of graph convolutional networks (GCNs) for graphs and inspires various downstream tasks, such as node classification and link prediction. Nevertheless, existing GCN-based methods for graph representation learning mainly focus on static graphs. Although some methods consider the dynamic characteristics of networks, the global structure information, which helps a node to gain worthy features from distant but valuable nodes, has not received enough attention. Moreover, these methods generally update the features of the nodes by averaging the features of neighboring nodes, which may not effectively consider the importance of different neighboring nodes during the aggregation. In this article, we propose a novel representation learning for dynamic graphs based on the GCNs, called DGCN. More specifically, the long short-term memory (LSTM) is utilized to update the weight parameters of GCN for capturing the global structure information across all time steps of dynamic graphs. Besides, a new Dice similarity is proposed to overcome the problem that the influence of directed neighbors is unnoticeable, which is further used to guide the aggregation. We evaluate the performance of the proposed method in the field of node clustering and link prediction, and the experimental results show a generally better performance of our proposed DGCN than baseline methods."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Node Representation Learning in Graph via Node-to-Neighbourhood Mutual Information Maximization,A topology-aware positive sampling strategy samples positives from the neighborhood by considering the structural dependencies between nodes.,""Wei Dong, Junsheng Wu, Yi Luo, ZongYuan Ge, Peifeng Wang"",Computer Vision and Pattern Recognition,,,10.1109/CVPR52688.2022.01612,http://arxiv.org/pdf/2203.12265,2022,4,https://doi.org/10.1109/CVPR52688.2022.01612,https://semanticscholar.org/paper/5fb340fdd01508d9bbdbf0873114b5d5403ecd7f,""The key towards learning informative node representations in graphs lies in how to gain contextual information from the neighbourhood. In this work, we present a simple-yet-effective self-supervised node representation learning strategy via directly maximizing the mutual information between the hidden representations of nodes and their neighbourhood, which can be theoretically justified by its link to graph smoothing. Following InfoNCE, our framework is optimized via a surrogate contrastive loss, where the positive selection underpins the quality and efficiency of rep-resentation learning. To this end, we propose a topology-aware positive sampling strategy, which samples positives from the neighbourhood by considering the structural dependencies between nodes and thus enables positive selection upfront. In the extreme case when only one positive is sampled, we fully avoid expensive neighbourhood aggregation. Our methods achieve promising performance on various node classification datasets. It is also worth mentioning by applying our loss function to MLP based node encoders, our methods can be orders of faster than existing solutions. Our codes and supplementary materials are available at https://github.com/dongwei156/n2n."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"""The Largest Knowledge Graph in Materials Science Entities, Relations, and Link Prediction through Graph Representation Learning"",MatKG allows the rapid dissemination and assimilation of data when used as a knowledge base.,""John Dagdelen, Alex Dunn, O. Kononova, Mary Brady, C. Campbell, Arthur P Ramirez, Lars PE Yunker"",,,,,,2022,,,https://semanticscholar.org/paper/4538fd99ea0fce7bc255985046a9890312d6d1ed,""This paper introduces MatKG, a novel graph database of key concepts in material 1 science spanning the traditional material-structure-property-processing paradigm. 2 MatKG is autonomously generated through transformer-based, large language 3 models and generates pseudo ontological schema through statistical co-occurrence 4 mapping. At present, MatKG contains over 2 million unique relationship triples 5 derived from 80,000 entities. This allows the curated analysis, querying, and 6 visualization of materials knowledge at unique resolution and scale. Further, 7 Knowledge Graph Embedding models are used to learn embedding representations 8 of nodes in the graph which are used for downstream tasks such as link prediction 9 and entity disambiguation. MatKG allows the rapid dissemination and assimilation 10 of data when used as a knowledge base, while enabling the discovery of new 11 relations when trained as an embedding model."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Convolutional Neural Network Knowledge Graph Link Prediction Model Based on Relational Memory,A knowledge graph embedding model based on a relational memory network and convolutional neural network outperforms existing models and methods on several metrics.,""Ming Shi, Jing Zhao, Donglin Wu"",Computational Intelligence and Neuroscience,,0.863 (5106),10.1155/2023/3909697,https://downloads.hindawi.com/journals/cin/2023/3909697.pdf,2023,,https://doi.org/10.1155/2023/3909697,https://semanticscholar.org/paper/0fd42d5142da516fc1efc4772cfefaeaeffe7b80,""A knowledge graph is a collection of fact triples, a semantic network composed of nodes and edges. Link prediction from knowledge graphs is used to reason about missing parts of triples. Common knowledge graph link prediction models include translation models, semantics matching models, and neural network models. However, the translation models and semantic matching models have relatively simple structures and poor expressiveness. The neural network model can easily ignore the overall structural characteristics of triples and cannot capture the links between entities and relations in low-dimensional space. In response to the above problems, we propose a knowledge graph embedding model based on a relational memory network and convolutional neural network (RMCNN). We encode triple embedding vectors using a relational memory network and decode using a convolutional neural network. First, we will obtain entity and relation vectors by encoding the latent dependencies between entities and relations and some critical information and keeping the translation properties of triples. Then, we compose a matrix of head entity encoding embedding vector, relation encoding embedding vector, and tail entity embedding encoding vector as the input of the convolutional neural network. Finally, we use a convolutional neural network as the decoder and a dimension conversion",strat,egy,t,o improve the,informat,ion,interaction,capability,of e,nt,ities,and,relations,in,more,di,me,nsi,ons.,"Experiments show that our model achieves significant progress and outperforms existing models and methods on several metrics."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Adaptive Attentional Network for Few-Shot Relational Learning of Knowledge Graphs,A model for few-shot relational learning of knowledge graphs produces large performance improvements on the NELL-One dataset.,""Ruixin Ma, Zeyang Li, Yunlong Ma, Hao Wu, Mengfei Yu, Liang Zhao"",Applied Sciences,,0.44 (11182),10.3390/app12094284,https://www.mdpi.com/2076-3417/12/9/4284/pdf?version=1650960573,2022,,https://doi.org/10.3390/app12094284,https://semanticscholar.org/paper/a19fa61773657c4b2247beb578286527a2925859,""Few-shot knowledge graph reasoning is a research focus in the field of knowledge graph reasoning. At present, in order to expand the application scope of knowledge graphs, a large number of researchers are devoted to the study of the multi-shot knowledge graph model. However, as far as we know, the knowledge graph contains a large number of missing relations and entities, and there are not many reference examples at the time of training. In this paper, our goal is to be able to infer the correct entity given a few training instances, or even only one training instance is available. Therefore, we propose an adaptive attentional network for few-shot relational learning of knowledge graphs, extracting knowledge based on traditional embedding methods, using the Transformer mechanism and hierarchical attention mechanism to obtain hidden attributes of entities, and then using a noise checker to filter out unreasonable candidate entities. Our model produces large performance improvements on the NELL-One dataset."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Learning Representations for Hyper-Relational Knowledge Graphs,,""Harry Shomer, Wei Jin, Juanhui Li, Yao Ma, Jiliang Tang"",ArXiv,,,10.48550/arXiv.2208.14322,,2022,,https://doi.org/10.48550/arXiv.2208.14322,https://semanticscholar.org/paper/91e9ef35323b059feaed63ac30b6bef553773e05,""Knowledge graphs (KGs) have gained promi-nence for their ability to learn representations for uni-relational facts. Recently, research has focused on modeling hyper-relational facts, which move beyond the restriction of uni-relational facts and allow us to represent more complex and real-world information. How-ever, existing approaches for learning representations on hyper-relational KGs majorly fo-cus on enhancing the communication from quali?ers to base triples while overlooking the ?ow of information from base triple to quali?ers. This can lead to suboptimal quali?er representations, especially when a large amount of quali?ers are presented. It motivates us to design a framework that utilizes multiple aggregators to learn representations for hyper-relational facts: one from the perspective of the base triple and the other one from the perspective of the quali?ers. Experiments demonstrate the effectiveness of our framework for hyper-relational knowledge graph completion across multiple datasets. Furthermore, we conduct an ablation study that validates the importance of the various components in our framework. The code to reproduce our results can be found at https://github.com/ HarryShomer/QUAD ."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Learning Relation-Specific Representations for Few-shot Knowledge Graph Completion,,""Yuling Li, Kui Yu, Yuhong Zhang, Xindong Wu"",ArXiv,,,10.48550/arXiv.2203.11639,,2022,1,https://doi.org/10.48550/arXiv.2203.11639,https://semanticscholar.org/paper/cffe596ef04dc60604b9977ddfe0a791d057c0e4,""Recent years have witnessed increasing interest in few-shot knowledge graph completion (FKGC), which aims to infer unseen query triples for a few-shot relation using a handful of reference triples of the relation. The primary focus of existing FKGC methods lies in learning the relation representations that can reflect the common information shared by the query and reference triples. To this end, these methods learn the embeddings of entities with their direct neighbors, and use the concatenation of the entity embeddings as the relation representations. However, the entity embeddings learned only from direct neighborhoods may have low expressiveness when the entity has sparse neighbors or shares a common local neighborhood with other entities. Moreover, the embeddings of two entities are insufficient to represent the semantic information of their relationship, especially when they have multiple relations. To address these issues, we propose a Relation-Specific Context Learning (RSCL) framework, which exploits graph contexts of triples to capture the semantic information of relations and entities simultaneously. Specifically, we first extract graph contexts for each triple, which can provide long-term entity-relation dependencies. To model the graph contexts, we then develop a hierarchical relation-specific learner to learn global and local relation-specific representations for relations by capturing contextualized information of triples and incorporating local information of entities. Finally, we utilize the learned representations to predict the likelihood of the query triples. Experimental results on two",public,da,ta,sets demonstr,ate that,RSCL,outperforms,state-of-,the-a,rt,FKGC,met,"hods."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Learning Relation-Specific Representations for Few-shot Knowledge Graph Completion,,""Yuling Li, Kui Yu, Yuhong Zhang, Xindong Wu"",ArXiv,,,10.48550/arXiv.2203.11639,,2022,1,https://doi.org/10.48550/arXiv.2203.11639,https://semanticscholar.org/paper/88a81681f061b22d4420d6af47a9b593b3a0889a,""—Recent years have witnessed increasing interest in few-shot knowledge graph completion (FKGC), which aims to infer unseen query triples for a few-shot relation using a few reference triples about the relation. The primary focus of existing FKGC methods lies in learning relation representations that can re?ect the common information shared by the query and reference triples. To this end, these methods learn entity-pair representations from the direct neighbors of head and tail entities, and then aggregate the representations of reference entity pairs. However, the entity-pair representations learned only from direct neighbors may have low expressiveness when the involved entities have sparse direct neighbors or share a common local neighborhood with other entities. Moreover, merely modeling the semantic information of head and tail entities is insuf?cient to accurately infer their relational information especially when they have multiple relations. To address these issues, we propose a Relation-Speci?c Context Learning (RSCL) framework, which exploits graph contexts of triples to learn global and local relation-speci?c representations for few-shot relations. Speci?- cally, we ?rst extract graph contexts for each triple, which can provide long-term entity-relation dependencies. To encode the extracted graph contexts, we then present a hierarchical attention network to capture contextualized information of triples and highlight valuable local neighborhood information of entities. Finally, we design a hybrid attention aggregator to evaluate the likelihood of the query triples at the global and local levels. E",xperim,ent,al,results on t,wo public,dat,asets demons,trate that,RSCL,o,utper,form,s state-of,#NAME?,e-art,FK,GC,me,thods,"."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"StarGraph: A Coarse-to-Fine Representation Method for Large-Scale Knowledge Graph,,""Hongzhu Li, Xiang Gao, Yafeng Deng"",ArXiv,,,10.48550/arXiv.2205.14209,,2022,2,https://doi.org/10.48550/arXiv.2205.14209,https://semanticscholar.org/paper/e8dc16227100503c5684c05dfab07b9c60d97817,""Conventional representation learning algorithms for knowledge graphs (KG) map each entity to a unique embedding vector, ignoring the rich information contained in neighbor entities. We propose a method named StarGraph, which gives a novel way to utilize the neighborhood information for large-scale knowledge graphs to get better entity representations. The core idea is to divide the neighborhood information into different levels for sampling and processing, where the generalized coarse-grained information and unique ?ne-grained information are combined to generate an ef?cient subgraph for each node. In addition, a self-attention network is proposed to process the subgraphs and get the entity representations, which are used to replace the entity embeddings in conventional methods. The proposed method achieves the best results on the ogbl-wikikg2 dataset, which validates the effectiveness of it. The code is now available at https://github.com/hzli-ucas/StarGraph ."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Towards Unified Representations of Knowledge Graph and Expert Rules for Machine Learning and Reasoning,,""Zhepei Wei, Yue Wang, Jinnan Li, Zhining Liu, Erxin Yu, Yuan Tian, Xin Wang, Yi Chang"",AACL,,,,,2022,,,https://semanticscholar.org/paper/e467a035a0136d4e3fd2ae9e84acd925dd5aa400,""With a knowledge graph and a set of if-then rules, can we reason about the conclusions given a set of observations? In this work, we formalize this question as the cognitive inference problem, and introduce the Cognitive Knowledge Graph (CogKG) that unifies two representations of heterogeneous symbolic knowledge: expert rules and relational facts. We propose a general framework in which the unified knowledge representations can perform both learning and reasoning. Specifically, we implement the above framework in two settings, depending on the availability of labeled data. When no labeled data are available for training, the framework can directly utilize symbolic knowledge as the decision basis and perform reasoning. When labeled data become available, the framework casts symbolic knowledge as a trainable neural architecture and optimizes the connection weights among neurons through gradient descent. Empirical study on two clinical diagnosis benchmarks demonstrates the superiority of the proposed method over time-tested knowledge-driven and data-driven methods, showing the great potential of the proposed method in unifying heterogeneous symbolic knowledge, i.e., expert rules and relational facts, as the substrate of machine learning and reasoning models."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Task-specific Pre-training and Prompt Decomposition for Knowledge Graph Population with Language Models,,""Tianyi Li, Wenyu Huang, Nikos Papasarantopoulos, P. Vougiouklis, Jeff Z. Pan"",ArXiv,,,10.48550/arXiv.2208.12539,,2022,1,https://doi.org/10.48550/arXiv.2208.12539,https://semanticscholar.org/paper/4b56830dfe097d460482599eedee9521de450c6c,""We present a system for knowledge graph population with Language Models, evaluated on the Knowledge Base Construction from Pre-trained Language Models (LM-KBC) challenge at ISWC 2022. Our system involves task-specific pre-training to improve LM representation of the masked object tokens, prompt decomposition for progressive generation of candidate objects, among other methods for higher-quality retrieval. Our system is the winner of track 1 of the LM-KBC challenge , based on BERT LM; it achieves 55.0% F-1 score on the hidden test set of the challenge. 1"",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Knowledge Graph Completion by Jointly Learning Structural Features and Soft Logical Rules,,""Weidong Li, Rong Peng, Zhi Li"",IEEE Transactions on Knowledge and Data Engineering,,2.431 (883),10.1109/TKDE.2021.3108224,,2023,3,https://doi.org/10.1109/TKDE.2021.3108224,https://semanticscholar.org/paper/2acfa599b8f6d6a25d650fc3030f87004c9f7d99,""With the rapid development and widespread application of Knowledge graphs (KGs) in many artificial intelligence tasks, a large number of efforts have been made to refine them and increase their quality. Knowedge graph embedding (KGE) has become one of the main refinement tasks, which aims to predict missing facts based on existing ones in KGs. However, there are still mainly two difficult unresolved challenges: (i) how to leverage the local structural features of entities and the potential soft logical rules to learn more expressive embedding of entites and relations; and (ii) how to combine these two learning processes into one unified model. To conquer these problems, we propose a novel KGE model named JSSKGE, which can Jointly learn the local Structural features of entities and Soft logical rules. First, we employ graph attention networks which are specially designed for graph-structured data to aggregate the local structural information of nodes. Then, we utilize soft logical rules implicated in KGs as an expert to further rectify the embeddings of entities and relations. By jointly learning, we can obtain more informative embeddings to predict new facts. With experiments on four commonly used datasets, the JSSKGE obtains better performance than state-of-the-art approaches."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Exploring Transformer Backbones for Heterogeneous Treatment Effect Estimation,Transformers as treatment effect estimators are proposed.,""Yi-Fan Zhang, Hanlin Zhang, Zachary Chase Lipton, Li Erran Li, Eric Xing"",,,,,,2022,8,,https://semanticscholar.org/paper/0109c662c101723aea99e561937e3aca58563537,""Previous works on Treatment Effect Estimation (TEE) are not in widespread use because they are predomi-nantly theoretical, where strong parametric assumptions are made but untractable for practical application. Recent work uses multilayer perceptron (MLP) for modeling casual relationships, however, MLPs lag far behind recent advances in ML methodology, which limits their applicability and generalizability. To extend beyond the single domain formulation and towards more realistic learning scenarios, we explore model design spaces beyond MLPs, i.e., transformer backbones, which provide ?exibility where attention layers govern interactions among treatments and covariates to exploit structural similarities of potential outcomes for confounding control. Through careful model design, Trans formers as T reatment E ffect E stimators (TransTEE) is proposed. We show empirically that TransTEE can: (1) serve as a general purpose treatment effect estimator that signi?cantly outperforms competitive baselines in a variety of challenging TEE problems (e.g., discrete, continuous, structured, or dosage-associated treatments) and is applicable to both when covariates are tabular and when they consist of structural data (e.g., texts, graphs); (2) yield multiple advantages: compatibility with propensity score modeling, parameter ef?ciency, robustness to continuous treatment value distribution shifts, explainable in covariate adjustment, and real-world utility in auditing pre-trained language models. 1"",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Improved model for knowledge representation: TransMR,The TransMR model uses the Marxian distance to calculate the distance between vectors.,""Xuyang Wang, Yiyuan Zhang"",""2022 3rd Asia-Pacific Conference on Image Processing, Electronics and Computers"",,,10.1145/3544109.3544394,,2022,,https://doi.org/10.1145/3544109.3544394,https://semanticscholar.org/paper/85b8d0ade3941110534c52b11148491df9cc465e,""Knowledge graphs have developed rapidly in recent years, and knowledge representation learning is a fundamental task of knowledge graphs, so knowledge representation learning has likewise received widespread attention. Therefore, a series of knowledge representation models based on TransE methods have been proposed by scholars one after another, among which, the translation model TransE has low model complexity, high computational efficiency, and strong semantic representation ability for knowledge representation of triples. However, the TransE method cannot handle dealing with complex relations. In view of this, this paper proposes an improved knowledge representation model TransMR based on the TransE method, which uses the Marxian distance instead of Euclidean distance to calculate the distance between vectors, and builds entity and relationship models in entity space and relationship space respectively, in which the back propagation and nonlinear operation of single layer neural network are used to enhance the semantic connection between them. Meanwhile, during the model training process, experiments are conducted to improve the fault tolerance of negative example triples by using substitution for the most similar entities."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"SpaceE: Knowledge Graph Embedding by Relational Linear Transformation in the Entity Space,The proposed SpaceE models non-injective relations with singular linear transformations in knowledge graphs as matrices.,""Jinxing Yu, Yunfeng Cai, Mingming Sun, P. Li"",ACM Conference on Hypertext & Social Media,,,10.1145/3511095.3531284,http://arxiv.org/pdf/2204.10245,2022,1,https://doi.org/10.1145/3511095.3531284,https://semanticscholar.org/paper/68f166ec1aaa01c6a62d15f2ae600bb0eaa149ba,""Translation distance based knowledge graph embedding (KGE) methods, such as TransE and RotatE, model the relation in knowledge graphs as translation or rotation in the vector space. Both translation and rotation are injective; that is, the translation or rotation of different vectors results in different results. In knowledge graphs, different entities may have a relation with the same entity; for example, many actors starred in one movie. Such a non-injective relation pattern cannot be well modeled by the translation or rotation operations in existing translation distance based KGE methods. To tackle the challenge, we propose a translation distance-based KGE method called SpaceE to model relations as linear transformations. The proposed SpaceE embeds both entities and relations in knowledge graphs as matrices and SpaceE naturally models non-injective relations with singular linear transformations. We theoretically demonstrate that SpaceE is a fully expressive model with the ability to infer multiple desired relation patterns, including symmetry, skew-symmetry, inversion, Abelian composition, and non-Abelian composition. Experimental results on link prediction datasets illustrate that SpaceE substantially outperforms many previous translation distance based knowledge graph embedding methods, especially on datasets with many non-injective relations. The code is available based on the PaddlePaddle",deep learning,"platform https://www.paddlepaddle.org.cn/."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Open Research Online Trans4E: Link Prediction on Scholarly Knowledge Graphs,Trans4E outperforms the other models when using low embedding dimensions.,""M. Nayyeri, Gokce Muge, S. Vahdati, Francesco Osborne, Mahfuzur Rahman, Simone Angioni, Angelo Salatino, D. Recupero, Nadezhda Vassilyeva, E. Motta, Jens Lehmann"",,,,,,2022,,,https://semanticscholar.org/paper/464b1322ee1e91752f2c6c280058bbc0406f614a,""typesetting and review before in its but providing this to give early visibility of the article. Please note that, during the production process, errors may be discovered which could affect the content, and all legal disclaimers that apply to the pertain. The incompleteness of Knowledge Graphs (KGs) is a crucial issue a?ecting the quality of AI-based services. Inthescholarlydomain, KGsdescribingresearchpublicationstypicallylackimportantinfor-mation, hindering our ability to analyse and predict research dynamics. In recent years, link prediction approaches based on Knowledge Graph Embedding models became the ?rst aid for this issue. In this work, we present Trans4E, a novel embedding model that is particularly ?t for KGs which include N to M relations with N ? M. This is typical for KGs that categorize a large number of entities (e.g., research articles, patents, persons) according to a relatively small set of categories. Trans4E was applied on two large-scale knowledge graphs, the Academia/Industry DynAmics (AIDA) and Microsoft Academic Graph (MAG), for completing the information about Fields of Study (e.g., ’neural networks’, ’machine learning’, ’arti?cial intelligence’), and a?liation types (e.g., ’education’, ’company’, ’gov-ernment’), improving the scope and accuracy of the resulting data. We evaluated our approach against alternative solutions on AIDA, MAG, and four other benchmarks (FB15k, FB15k-237, WN18, and WN18RR). Trans4E outperforms the other models when using l",ow embedding d,imensions and ob- tains competitive results in,hig,"h dimensions."",,Review",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"HTransE: Hybrid Translation-based Embedding for Knowledge Graphs,The hybrid TransE model converges much quicker in comparison to TransE.,""A. Shah, Bonaventure Molokwu, Ziad Kobti"",2022 IEEE International Conference on Knowledge Graph (ICKG),,,10.1109/ICKG55886.2022.00037,,2022,,https://doi.org/10.1109/ICKG55886.2022.00037,https://semanticscholar.org/paper/bc1c5c0cd480fdb573b9e21fb699f45e8e72b62a,""Basically, a Knowledge Graph (KG) is a graph variant that represents data via triplets comprising a head, a tail, and a relation. Realistically, most KGs are compiled either manually or semi-automatically, and this usually results in a significant loss of vital information with respect to the KG. Thus, this problem of incompleteness is common to virtually all KGs; and it is formally defined as Knowledge Graph Completion (KGC) problem. In this paper, we have explored learning the representations of a KGs with regard to its entities and relations for the purpose of any predicting missing link(s). In that regard, this paper proposes a hybrid variant, composed of TransE and SimplE models, for solving KGC problems. On one hand, the TransE model depicts a relation as the translation from the source entity (head) to the target entity (tail) within an embedding space. In TransE, the head and tail entities are derived from the same embedding-generation class, which results in a low prediction score. Also, the TransE model is not able to capture symmetric relationships as well as one-to-many relationships. On the other hand, the SimplE model is based on Canonical Polyadic (CP) decomposition. SimplE enhances CP via the addition of the inverse relation, while the head entity and tail entity are derived from different embedding-generation classes which are interdependent. Hence, we employed the principle of inverse-relation embedding (from the SimplE model) onto the native TransE model so",as to yield a,"new hybrid resultant: HTransE. Therefore, HTr",ansE,boasts of efficiency as we,ll as,impro,ved,prediction s,cor,es.,Effic,"iently,",HTransE,converges,m,uch quick,er,in comparison,to TransE.,In ot,her wo,"rds,",H,Trans,E c,onv,erges,at,appro,ximatel,y $,n/2,$ it,erat,ions,where,$n,$ den,ote,s the,it,erati,on,s r,equ,ired,to,fu,lly,train,Tr,ans,E.,O,ur,r,esu,"lts outperform the native TransE approach with a significant difference. Also, HTransE outperforms several state-of-the-art models on different datasets."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"TranS: Transition-based Knowledge Graph Embedding with Synthetic Relation Representation,The single relation vector in traditional scoring patterns is replaced with synthetic relation representation.,""Xuanyu Zhang, Qing Yang, Dongliang Xu"",Conference on Empirical Methods in Natural Language Processing,,,10.48550/arXiv.2204.08401,,2022,4,https://doi.org/10.48550/arXiv.2204.08401,https://semanticscholar.org/paper/9e5600974e7b2bb5116bb888d62ae6e94a304b92,""Knowledge graph embedding (KGE) aims to learn continuous vectors of relations and entities in knowledge graph. Recently, transition-based KGE methods have achieved promising performance, where the single relation vector learns to translate head entity to tail entity. However, this scoring pattern is not suitable for complex scenarios where the same entity pair has different relations. Previous models usually focus on the improvement of entity representation for 1-to-N, N-to-1 and N-to-N relations, but ignore the single relation vector. In this paper, we propose a novel transition-based method, TranS, for knowledge graph embedding. The single relation vector in traditional scoring patterns is replaced with synthetic relation representation, which can solve these issues effectively and efficiently. Experiments on a large knowledge graph dataset, ogbl-wikikg2, show that our model achieves state-of-the-art results."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"TranS: Transition-based Knowledge Graph Embedding with Synthetic Relation Representation,The single relation vector in traditional scoring patterns is replaced with synthetic relation representation.,""Xuanyu  Zhang, Qing  Yang, Dongliang  Xu"",ArXiv,,,10.48550/arXiv.2204.08401,,2022,,https://doi.org/10.48550/arXiv.2204.08401,https://semanticscholar.org/paper/77dd01e525e653ab9fa10b2736a51ea1df44668b,""Knowledge graph embedding (KGE) aims to learn continuous vectors of relations and entities in knowledge graph. Recently, transition-based KGE methods have achieved promising performance, where the single relation vector learns to translate head entity to tail entity. However, this scoring pattern is not suitable for complex scenarios where the same entity pair has different relations. Previous models usually focus on the improvement of entity representation for 1-to-N, N-to-1 and N-to-N relations, but ignore the single relation vector. In this paper, we propose a novel transition-based method, TranS, for knowledge graph embedding. The single relation vector in traditional scoring patterns is replaced with synthetic relation representation, which can solve these issues effectively and ef?ciently. Experiments on a large knowledge graph dataset, ogbl-wikikg2, show that our model achieves state-of-the-art results."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"TransER: Homogeneous Transfer Learning for Entity Resolution,Transfer learning can overcome this expensive labelling task by utilising existing training data from a semantically related source domain to classify instances in a target domain where no training data are available.,""Nishadi Kirielle, P. Christen, T. Ranbaduge"",International Conference on Extending Database Technology,,,10.48786/edbt.2022.03,,2022,2,https://doi.org/10.48786/edbt.2022.03,https://semanticscholar.org/paper/51dcd4d256d1a22f06b0e822233409bc13fc2a25,""Entity resolution (ER) is the process of linking records that refer to the same entity across one or more databases. While recent advances in supervised learning can provide high quality results for ER, these often come with large efforts to obtain labelled training data. Transfer learning (TL) can overcome this expensive labelling task by utilising existing training data from a semantically related source domain to classify instances in a target domain where no training data are available. However, most existing TL solutions for ER involve deep learning models that have shown to be mostly useful for long textual and unstructured attributes. These models are less successful for short structured attributes such as personal data that are known to contain variations and typographical errors. In this paper, we propose a novel TL framework for resolving entities in structured data. We assume homogeneous domains that have the same feature space (same attribute types and similarity functions) for transferring. As records are sourced from different domains, there however can be three key challenges. The marginal probability distributions of the data in the two domains can be different, there can be feature vectors that have contradicting labels in the two domains resulting in different class conditional probability distributions, and the class imbalance and",bi-modal data,distributions common in ER make it challengin,g to,apply existing TL methods.,We a,ddress,th,ese challenge,s w,ith,three,contri,butions:,an instan,ce,selector,to,choose sourc,e instances,with,a high,con,fi,dence,an,d a,simi,lar,local,struct,ure,to,the,tar,get,domain,", a",labe,l g,enera,tor,that,c,rea,tes,pse,udo,la,bels,for,tar,get,i,ns,ta,nc,"es,","and a final classifier that labels target instances using only high confidence pseudo labels. On seven data sets we show that our framework outperforms the best of several state-of-the-art methods by up to 13% in precision and 50% in recall, while also being substantially faster."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"TransUNetCD: A Hybrid Transformer Network for Change Detection in Optical Remote-Sensing Images,The TransUNetCD model can further reduce false alarms and missed alarms.,""Qingyang Li, Ruofei Zhong, Xin Du, Yuying Du"",IEEE Transactions on Geoscience and Remote Sensing,,2.404 (905),10.1109/TGRS.2022.3169479,,2022,9,https://doi.org/10.1109/TGRS.2022.3169479,https://semanticscholar.org/paper/1802354241d28002e1f82ee823b41166d3805e84,""In the change detection (CD) task, the UNet architecture has achieved superior results. However, due to the inherent limitation of convolution operations, UNet is inadequate in learning global context and long-range spatial relations. Transformers can capture long-range feature dependencies, but the lack of low-level details may result in limited localization capabilities. Therefore, this article proposes an end-to-end encoding–decoding hybrid transformer model for CD, TransUNetCD, which has the advantages of both transformers and UNet. The model encodes the tokenized image patches from the convolutional neural network (CNN) feature map to extract rich global context information. The decoder upsamples the encoded features, connects them with higher-resolution multiscale features through skip connections to learn local–global semantic features, and restores the full spatial resolution of the feature map to achieve precise localization. The model proposed in this article not only solves the problem that redundant information is generated when extracting low-level features under the UNet framework, but also solves the problem that the relationship between each feature layer cannot be fully modeled and the optimal feature difference representation cannot be obtained. On this basis, we introduce a difference enhancement module to generate a difference feature map containing rich change information. By weighting each pixel and selectively aggregating","features, the",effectiveness of the network and the accuracy,of,extracting changing feature,s are,impro,ved,. The results,on,mu,ltiple,datase,ts demon,strate tha,"t,",compared,to,state-of-the,#NAME?,"s, the",Trans,UNet,CD,can,fur,the,r red,uce,FALSE,alarms,an,d m,isse,d al,arms,", and",the,edge,of,the,cha,nging,a,rea,is,mor,e a,ccu,rate,. The,mo,del,h,as,t,he,hi,"ghest score in each metric than other baseline models and has a robust generalization ability."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"TripleRE: Knowledge Graph Embeddings via Tripled Relation Vectors,The approach achieved state-of-the-art performance on the large-scale knowledge graph dataset ogbl-wikikg2.,""Long Yu, Zhi-Ping Luo, Huan Liu, Deng Lin, Hongzhu Li, Yafeng Deng"",ArXiv,,,10.48550/arXiv.2209.08271,,2022,8,https://doi.org/10.48550/arXiv.2209.08271,https://semanticscholar.org/paper/76274fd1dac6e70fece009f2f53cd223277f8f34,""Translation-based knowledge graph embedding has been one of the most important branches for knowledge representation learning since TransE came out. Although many translation-based approaches have achieved some progress in recent years, the performance was still unsatisfactory. This paper proposes a novel knowledge graph embedding method named TripleRE with two versions. The ?rst version of TripleRE creatively divide the relationship vector into three parts. The second version takes advantage of the concept of residual and achieves better performance. In addition, attempts on using NodePiece to encode entities achieved promising results in reducing the parametric size, and solved the problems of scalability. Experiments show that our approach achieved state-of-the-art performance on the large-scale knowledge graph dataset ogbl-wikikg2 , and competitive performance on other datasets."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"From Ties to Events in the Analysis of Interorganizational Exchange Relations,The distinction between degree- and intensity-based network effects is crucial to our understanding of the dynamics of interorganizational dependence and exchange relations.,""Federica Bianchi, A. Lomi"",Organizational Research Methods,,5.195 (247),10.1177/10944281211058469,https://journals.sagepub.com/doi/pdf/10.1177/10944281211058469,2022,3,https://doi.org/10.1177/10944281211058469,https://semanticscholar.org/paper/cf93dc1c0acc561f3f8405d608019943ed669864,""Relational event models expand the analytical possibilities of existing statistical models for interorganizational networks by: (i) making efficient use of information contained in the sequential ordering of observed events connecting sending and receiving units; (ii) accounting for the intensity of the relation between exchange partners, and (iii) distinguishing between short- and long-term network effects. We introduce a recently developed relational event model (REM) for the analysis of continuously observed interorganizational exchange relations. The combination of efficient sampling algorithms and sender-based stratification makes the models that we present particularly useful for the analysis of very large samples of relational event data generated by interaction among heterogeneous actors. We demonstrate the empirical value of event-oriented network models in two different settings for interorganizational exchange relations—that is, high-frequency overnight transactions among European banks and patient-sharing relations within a community of Italian hospitals. We focus on patterns of direct and generalized reciprocity while accounting for more complex forms of dependence present in the data. Empirical results suggest that distinguishing between degree- and intensity-based network effects, and between short- and long-term effects is",crucial to our,understanding of the dynamics of interorganiz,atio,nal dependence and exchange,rela,tions.,We,discuss the,gen,era,l impl,ication,s of the,se results,f,or the an,aly,sis of social,interactio,n data,routi,nely,c,ollec,ted,in,orga,niz,ationa,l resea,rch,to,exa,mine,the,evolu,tio,nary,dyn,amics,of,soci,al,ne,two,rks,wit,hin,and,betw,een,or,ga,ni,za,ti,ons,"."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Analyzing Transformers in Embedding Space,""At least in part, we can abstract away model specifics and understand Transformers in the embedding space."",""Guy Dar, Mor Geva, Ankit Gupta, Jonathan Berant"",ArXiv,,,10.48550/arXiv.2209.02535,,2022,2,https://doi.org/10.48550/arXiv.2209.02535,https://semanticscholar.org/paper/c7fa5c2172a4624d6baa91e66344e4520d3028ad,""Understanding Transformer-based models has attracted signi?cant attention, as they lie at the heart of recent technological advances across machine learning. While most interpretability methods rely on running models over inputs, recent work has shown that an input-independent approach, where parameters are interpreted directly without a forward/back-ward pass is feasible for some Transformer parameters, and for two-layer attention networks. In this work, we present a conceptual framework where all parameters of a trained Transformer are interpreted by projecting them into the embedding space , that is, the space of vocabulary items they operate on. Focusing mostly on GPT-2 for this paper, we provide di-verse evidence to support our argument. First, an empirical analysis showing that parameters of both pretrained and ?ne-tuned models can be interpreted in embedding space. Second, we present two applications of our framework: (a) aligning the parameters of different models that share a vocabulary, and (b) construct-ing a classi?er without training by “translat-ing” the parameters of a ?ne-tuned classi?er to parameters of a different model that was only pretrained. Overall, our ?ndings show that at least in part, we can abstract away model speci?cs and understand Transformers in the embedding space."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"TransVG++: End-to-End Visual Grounding with Language Conditioned Vision Transformer,The core fusion Transformer in TransVG is stand-alone against uni-modal encoders.,""Jiajun Deng, Zhengyuan Yang, Daqing Liu, Tianlang Chen, Wen-gang Zhou, Yanyong Zhang, Houqiang Li, Wanli Ouyang"",ArXiv,,,10.48550/arXiv.2206.06619,,2022,1,https://doi.org/10.48550/arXiv.2206.06619,https://semanticscholar.org/paper/35fccd11326e799ebf724f4150acef12a6538953,""—In this work, we explore neat yet effective Transformer-based frameworks for visual grounding. The previous methods generally address the core problem of visual grounding, i.e. , multi-modal fusion and reasoning, with manually-designed mechanisms. Such heuristic designs are not only complicated but also make models easily over?t speci?c data distributions. To avoid this, we ?rst propose TransVG, which establishes multi-modal correspondences by Transformers and localizes referred regions by directly regressing box coordinates. We empirically show that complicated fusion modules can be replaced by a simple stack of Transformer encoder layers with higher performance. However, the core fusion Transformer in TransVG is stand-alone against uni-modal encoders, and thus should be trained from scratch on limited visual grounding data, which makes it hard to be optimized and leads to sub-optimal performance. To this end, we further introduce TransVG++ to make two-fold improvements. For one thing, we upgrade our framework to a purely Transformer-based one by leveraging Vision Transformer (ViT) for vision feature encoding. For another, we devise Language Conditioned Vision Transformer that removes external fusion modules and reuses the uni-modal ViT for vision-language fusion at the intermediate layers. We conduct extensive experiments on ?ve prevalent datasets, and report a series of state-of-the-art records."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"""TranSyT, an innovative framework for identifying transport systems"",The Transport Systems Tracker is the next iteration of TRIAGE.,""D. Lagoa, José P. Faria, Filipe Liu, Emanuel Cunha, C. Henry, Oscar Días"",bioRxiv,,,10.1101/2021.04.29.441738,https://www.biorxiv.org/content/biorxiv/early/2021/04/30/2021.04.29.441738.full.pdf,2022,1,https://doi.org/10.1101/2021.04.29.441738,https://semanticscholar.org/paper/1fafde53f799f8f9bf35c19fc30808a011a88671,""The importance and rate of development of genome-scale metabolic models have been growing for the last years, increasing the demand for software solutions that automate several steps of this process. However, since TRIAGE’s release, software development for automatic integration of transport reactions into models has stalled. Here we present the Transport Systems Tracker (TranSyT), the next iteration of TRIAGE. Unlike its predecessor, TranSyT does not rely on manual curation to expand its internal database, derived from highly-curated records retrieved from the Transporters Classification Database and complemented with information from other data sources. TranSyT compiles information regarding transporters families, transport proteins, and derives reactions into its internal database, making it available for rapid annotation of complete genomes. All transport reactions have GPR associations and can be exported with identifiers from four different metabolite databases. TranSyT is currently available as a plugin for merlin v4.0 and an app for KBase."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"TransHER: Translating Knowledge Graph Embedding with Hyper-Ellipsoidal Restriction,The relation-specific translation provides TransHER with a more direct guidance in optimization and the ability to learn semantic characteristics of entities with complex relations.,""Yizhi Li, Wei Fan, Chaochun Liu, Chenghua Lin, Jiang Qian"",ArXiv,,,10.48550/arXiv.2204.13221,,2022,,https://doi.org/10.48550/arXiv.2204.13221,https://semanticscholar.org/paper/0b896e8d641bc99f5cc81f63b407781eb615033d,""Knowledge graph embedding methods are important for knowledge graph completion (link prediction) due to their robust performance and efficiency on large-magnitude datasets. One state-of-the-art method, PairRE, leverages two separate vectors for relations to model complex relations (i.e., 1-to-N, N-to-1, and N-to-N) in knowledge graphs. However, such a method strictly restricts entities on the hyper-ellipsoid surface and thus limits the optimization of entity distribution, which largely hinders the performance of knowledge graph completion. To address this problem, we propose a novel score function TransHER , which leverages relation-specific translations between head and tail entities restricted on separate hyper-ellipsoids. Specifically, given a triplet, our model first maps entities onto two separate hyper-ellipsoids and then conducts a relation-specific translation on one of them. The relation-specific translation provides TransHER with a more direct guidance in optimization and the ability to learn semantic characteristics of entities with complex relations. Experimental results show that TransHER can achieve state-of-the-art performance and generalize to datasets in different domains and scales. All our code will be publicly available."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"TranSHER: Translating Knowledge Graph Embedding with Hyper-Ellipsoidal Restriction,The TranSHER score function leverages relation-specific translations between head and tail entities to relax the constraint of hyper-ellipsoid restrictions.,""Yizhi Li, Wei Fan, Chaochun Liu, Chenghua Lin, Jiang Qian"",Conference on Empirical Methods in Natural Language Processing,,,10.48550/arXiv.2204.13221,,2022,,https://doi.org/10.48550/arXiv.2204.13221,https://semanticscholar.org/paper/4a3dfe9f4085591e17c19d6a5438c1bb94279183,""Knowledge graph embedding methods are important for the knowledge graph completion (or link prediction) task.One state-of-the-art method, PairRE, leverages two separate vectors to model complex relations (i.e., 1-to-N, N-to-1, and N-to-N) in knowledge graphs. However, such a method strictly restricts entities on the hyper-ellipsoid surfaces which limits the optimization of entity distribution, leading to suboptimal performance of knowledge graph completion. To address this issue, we propose a novel score function TranSHER, which leverages relation-specific translations between head and tail entities to relax the constraint of hyper-ellipsoid restrictions. By introducing an intuitive and simple relation-specific translation, TranSHER can provide more direct guidance on optimization and capture more semantic characteristics of entities with complex relations. Experimental results show that TranSHER achieves state-of-the-art performance on link prediction and generalizes well to datasets in different domains and scales. Our codes are public available athttps://github.com/yizhilll/TranSHER."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Translation-Based Embeddings with Octonion for Knowledge Graph Completion,Existing methods do not well capture the latent dependencies between all components of entities and relations in knowledge graph completion tasks.,""Mei Yu, Chen Bai, Jian Yu, Mankun Zhao, Tianyi Xu, Hongwei Liu, Xuewei Li, Ruiguo Yu"",Applied Sciences,,0.44 (11182),10.3390/app12083935,https://www.mdpi.com/2076-3417/12/8/3935/pdf?version=1649905772,2022,1,https://doi.org/10.3390/app12083935,https://semanticscholar.org/paper/6d31de103e0aa063955f11f49ed6657f9ddb7607,""Knowledge representation learning achieves the automatic completion of knowledge graphs (KGs) by embedding entities into continuous low-dimensional vector space. In knowledge graph completion (KGC) tasks, the inter-dependencies and hierarchical information in KGs have gained attention. Existing methods do not well capture the latent dependencies between all components of entities and relations. To address this, we introduce the mathematical theories of octonion, a more expressive generalized form of complex number and quaternion, and propose a translation-based KGC model with octonion (TransO). TransO models entities as octonion coordinate vectors, relations as the combination of octonion component matrices and coordinate vectors, and uses specific grouping calculation rules to interact between entities and relations. In addition, since hyperbolic Poincaré space in non-Euclidean mathematics can represent hierarchical data more accurately and effectively than traditional Euclidean space, we propose a Poincaré-extended TransO model (PTransO). PTransO transforms octonion coordinate vectors into hyperbolic embeddings by exponential mapping, and integrates the Euclidean-based calculations into hyperbolic space by operations such as Möbius addition and hyperbolic distance. The experimental results of link prediction indicate that TransO outpe",rforms other t,"ranslation-based models on the WN18 benchmark,",and,PTransO further achieves s,tate-,of-the,#NAME?,t performance,in,lo,w-dime,nsional,space o,n the well,#NAME?,stablishe,d W,N18RR and FB1,5k-237 benc,hmarks,"."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Less is More: Rethinking State-of-the-art Continual Relation Extraction Models with a Frustratingly Easy but Effective Approach,The Fast Adaption stage unleashes the potential of memory data for the subsequent finetuning.,""Peiyi Wang, Yifan Song, Tianyu Liu, Rundong Gao, Binghuai Lin, Yunbo Cao, Zhifang Sui"",ArXiv,,,10.48550/arXiv.2209.00243,,2022,1,https://doi.org/10.48550/arXiv.2209.00243,https://semanticscholar.org/paper/7ba02123df5c2601d52a138da519939d7ccf62e8,""Continual relation extraction (CRE) requires the model to continually learn new relations from class-incremental data streams. In this paper, we propose a Frustratingly easy but Effective Approach (F EA ) method with two learning stages for CRE: 1) Fast Adaption (FA) warms up the model with only new data. 2) Balanced Tuning (BT) ?netunes the model on the balanced memory data. Despite its simplicity, F EA achieves comparable (on T ACRED ) or superior (on F EWREL ) performance compared with the state-of-the-art baselines. With care-ful examinations, we ?nd that the data imbalance between new and old relations leads to a skewed decision boundary in the head clas-si?ers over the pretrained encoders, thus hurt-ing the overall performance. In F EA , the FA stage unleashes the potential of memory data for the subsequent ?netuning, while the BT stage helps establish a more balanced decision boundary. With a uni?ed view, we ?nd that two strong CRE baselines can be subsumed into the proposed training pipeline. The success of F EA also provides actionable insights and suggestions for future model designing in CRE."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"TransTab: Learning Transferable Tabular Transformers Across Tables,TransTab is a generalizable embedding vector for tables.,""Zifeng Wang, Jimeng Sun"",ArXiv,,,10.48550/arXiv.2205.09328,,2022,7,https://doi.org/10.48550/arXiv.2205.09328,https://semanticscholar.org/paper/39f0f28848990f74eeb9019f579c6ebcc8ef3ea1,""Tabular data (or tables) are the most widely used data format in machine learning (ML). However, ML models often assume the table structure keeps ?xed in training and testing. Before ML modeling, heavy data cleaning is required to merge disparate tables with different columns. This preprocessing often incurs signi?cant data waste (e.g., removing unmatched columns and samples). How to learn ML models from multiple tables with partially overlapping columns? How to incrementally update ML models as more columns become available over time? Can we leverage model pretraining on multiple distinct tables? How to train an ML model which can predict on an unseen table? To answer all those questions, we propose to relax ?xed table structures by in-troducing a Transferable Tabular Transformer ( TransTab ) for tables. The goal of TransTab is to convert each sample (a row in the table) to a generalizable embedding vector, and then apply stacked transformers for feature encoding. One methodology insight is combining column description and table cells as the raw input to a gated transformer model. The other insight is to introduce supervised and self-supervised pretraining to improve model performance. We compare TransTab with multiple baseline methods on diverse benchmark datasets and ?ve oncology clinical trial datasets. Overall, TransTab ranks 1.00, 1.00, 1.78 out of 12 methods in supervised learning, feature incremental learning, and transfer learning scenarios, respectively; and the proposed pretraining leads to 2.3% AUC lift on average over the supervised learning. 1"",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"TransTab: Learning Transferable Tabular Transformers Across Tables,TransTab is a generalizable embedding vector for tables.,""Zifeng Wang, Jimeng Sun"",ArXiv,,,10.48550/arXiv.2205.09328,,2022,2,https://doi.org/10.48550/arXiv.2205.09328,https://semanticscholar.org/paper/ace353fb410e94d7def8b7ed19ae569d02034f4d,""Tabular data (or tables) are the most widely used data format in machine learning (ML). However, ML models often assume the table structure keeps ?xed in training and testing. Before ML modeling, heavy data cleaning is required to merge disparate tables with different columns. This preprocessing often incurs signi?cant data waste (e.g., removing unmatched columns and samples). How to learn ML models from multiple tables with partially overlapping columns? How to incrementally update ML models as more columns become available over time? Can we leverage model pretraining on multiple distinct tables? How to train an ML model which can predict on an unseen table? To answer all those questions, we propose to relax ?xed table structures by in-troducing a Transferable Tabular Transformer ( TransTab ) for tables. The goal of TransTab is to convert each sample (a row in the table) to a generalizable embedding vector, and then apply stacked transformers for feature encoding. One methodology insight is combining column description and table cells as the raw input to a gated transformer model. The other insight is to introduce supervised and self-supervised pretraining to improve model performance. We compare TransTab with multiple baseline methods on diverse benchmark datasets and ?ve oncology clinical trial datasets. Overall, TransTab ranks 1.00, 1.00, 1.78 out of 12 methods in supervised learning, feature incremental learning, and transfer learning scenarios, respectively; and the proposed pretraining leads to 2.3% AUC lift on average over the supervised learning. 1"",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"AA-TransUNet: Attention Augmented TransUNet For Nowcasting Tasks,The proposed model outperforms other examined models on both tested datasets.,""Yimin Yang, S. Mehrkanoon"",IEEE International Joint Conference on Neural Network,,,10.1109/IJCNN55064.2022.9892376,http://arxiv.org/pdf/2202.04996,2022,4,https://doi.org/10.1109/IJCNN55064.2022.9892376,https://semanticscholar.org/paper/edd80013e8b9fcba9231cf99884f32e5236ff329,""Data driven modeling based approaches have recently gained a lot of attention in many challenging meteoro-logical applications including weather element forecasting. This paper introduces a novel data-driven predictive model based on TransUNet for precipitation nowcasting task. The TransUNet model which combines the Transformer and U-Net models has been previously successfully applied in medical segmentation tasks. Here, TransUnet is used as a core model and is further equipped with Convolutional Block Attention Modules (CBAM) and Depthwise-separable Convolution (DSC). The proposed Attention Augmented TransUNet (AA- TransUNet) model is evaluated on two distinct datasets: the Dutch precipitation map dataset and the French cloud cover dataset. The obtained results show that the proposed model outperforms other examined models on both tested datasets. Furthermore, the uncertainty analysis of the proposed AA-TransUNet is provided to give additional insights on its predictions."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Two flexible translation-based models for knowledge graph embedding,The models significantly surpass the classical translation models in both tasks of triplet classification and link prediction.,""Zepeng Li, Rikui Huang, Yufeng Zhang, Jianghong Zhu, B. Hu"",Journal of Intelligent &amp; Fuzzy Systems,,,10.3233/jifs-211553,,2022,,https://doi.org/10.3233/jifs-211553,https://semanticscholar.org/paper/2baa7e32107894c4cda3a6d9241b82686fe51485,""Knowledge Graph Embedding (KGE), which aims to embed the entities and relations of a knowledge gxraph into a low-dimensional continuous space, has been proven to be an effective method for completing a knowledge graph and improving the quality of the knowledge graph. The translation-based models represented by TransE, TransH, TransR and TransD have achieved great success in this regard. There is still potential for improvement in dealing with complex relations. In this paper, we find that the lack of flexibility in entity embedding limits the model’s ability to model complex relations. Therefore, we propose single-directional-flexible (sdf) models and multi-directional-flexible (mdf) models to increase the flexibility and expressiveness of entity embeddings. These two methods can be applied to the TransD model and its variant models without increasing any time cost and space cost. We conduct experiments on benchmarks such as WN18 and FB15k. The experimental results show that the models significantly surpasses the classical translation models in both tasks of triplet classification and link prediction. In particular, for Hits@1 of link prediction of WN18, we get 71.7% after applying our method to TransD, which is much better than 24.1% of TransD."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Exploring Transformer Backbones for Heterogeneous Treatment Effect Estimation,Transformers as treatment effect estimators can serve as a general-purpose treatment effect estimator.,""Yi-Fan Zhang, Hanlin Zhang, Zachary Chase Lipton, Li Erran Li, Eric P. Xing"",,,,,,2022,2,,https://semanticscholar.org/paper/fd3add408393673f70bf94de1d4cf9de1376377a,""Neural networks (NNs) are often leveraged to represent structural similarities of potential outcomes (POs) of different treatment groups to obtain better ?nite-sample estimates of treatment effects. However, despite their wide use, existing works handcraft treatment-speci?c (sub)network architectures for representing various POs, which limit their applicability and generalizability. To remedy these issues, we develop a framework called Trans formers as T reatment E ffect E stimators (TransTEE) where attention layers govern interactions among treatments and covariates to exploit structural similarities of POs for confounding control. Using this framework, through extensive experiments, we show that TransTEE can: (1) serve as a general-purpose treatment effect estimator which signi?cantly outperforms competitive baselines on a variety of challenging TEE problems (e.g., discrete, continuous, structured, or dosage-associated treatments.) and is applicable both when covariates are tabular and when they consist of structural data (e.g., texts, graphs); (2) yield multiple advantages: compatibility with propensity score modeling, parameter ef?ciency, robustness to continuous treatment value distribution shifts, interpretability in covariate adjustment, and real-world utility in debugging pre-trained language models. 1"",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"TransVG++: End-to-End Visual Grounding with Language Conditioned Vision Transformer,The core fusion Transformer in TransVG is stand-alone against uni-modal encoders.,""Jiajun Deng, Zhengyuan Yang, Daqing Liu, Tianlang Chen, Wen-gang Zhou, Yanyong Zhang, Houqiang Li, Wanli Ouyang"",ArXiv,,,10.48550/arXiv.2206.06619,,2022,,https://doi.org/10.48550/arXiv.2206.06619,https://semanticscholar.org/paper/9d1ffe3da2f363fe6f9abddc0ab6dc0c381c5cb2,""In this work, we explore neat yet effective Transformer-based frameworks for visual grounding. The previous methods generally address the core problem of visual grounding, i.e., multi-modal fusion and reasoning, with manually-designed mechanisms. Such heuristic designs are not only complicated but also make models easily overfit specific data distributions. To avoid this, we first propose TransVG, which establishes multi-modal correspondences by Transformers and localizes referred regions by directly regressing box coordinates. We empirically show that complicated fusion modules can be replaced by a simple stack of Transformer encoder layers with higher performance. However, the core fusion Transformer in TransVG is stand-alone against uni-modal encoders, and thus should be trained from scratch on limited visual grounding data, which makes it hard to be optimized and leads to sub-optimal performance. To this end, we further introduce TransVG++ to make two-fold improvements. For one thing, we upgrade our framework to a purely Transformer-based one by leveraging Vision Transformer (ViT) for vision feature encoding. For another, we devise Language Conditioned Vision Transformer that removes external fusion modules and reuses the uni-modal ViT for vision-language fusion at the intermediate layers. We conduct extensive experiments on five prevalent datasets, and report a series of state-of-the-art records."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Beyond Hard-Core Bosons in Transmon Arrays,Boson stacks can be naturally interpreted as interacting quasiparticles.,""Olli Mansikkamäki, S. Laine, Atte Piltonen, M. Silveri"",PRX Quantum,,,10.1103/PRXQuantum.3.040314,http://link.aps.org/pdf/10.1103/PRXQuantum.3.040314,2022,3,https://doi.org/10.1103/PRXQuantum.3.040314,https://semanticscholar.org/paper/53f1a3ac4eec360d1974c07faa0da45059afdb25,""Arrays of transmons have proven to be a viable medium for quantum information science and quantum simulations. Despite their widespread popularity as qubit arrays, there remains yet untapped potential beyond the two-level approximation or, equivalently, the hard-core boson model. With the higher excited levels included, coupled transmons naturally realize the attractive Bose-Hubbard model. The dynamics of the full model has been di?cult to study due to the unfavorable scaling of the dimensionality of the Hilbert space with the system size. In this work, we present a framework for describing the e?ective unitary dynamics of highly-excited states of coupled transmons based on high-order degenerate perturbation theory. This allows us to describe various collective phenomena – such as bosons stacked onto a single site behaving as a single particle, edge-localization, and e?ective longer-range interactions – in a uni?ed, compact, and accurate manner. A further bene?t of our approach is that boson stacks can be naturally interpreted as interacting quasiparticles, enabling transmon arrays to be used to explore and study additional lattice models besides the standard Bose-Hubbard one. While our examples deal with one-dimensional chains of transmons for the sake of clarity, the theory can be readily applied to more general geometries."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"A Unifying Approach to Distributional Limits for Empirical Optimal Transport,Kantorovich duality requires Fc to be sufficiently rich.,""Shayan Hundrieser, M. Klatt, T. Staudt, A. Munk"",,,,,,2022,7,,https://semanticscholar.org/paper/73ee9addf90fc4e07cf5c7e80054019eff483c4a,""We provide a unifying approach to central limit type theorems for empirical optimal transport (OT). In general, the limit distributions are characterized as suprema of Gaussian processes. We explicitly characterize when the limit distribution is centered normal or degenerates to a Dirac measure. Moreover, in contrast to recent contributions on distributional limit laws for empirical OT on Euclidean spaces which require centering around its expectation, the distributional limits obtained here are centered around the population quantity, which is well-suited for statistical applications. At the heart of our theory is Kantorovich duality representing OT as a supremum over a function class Fc for an underlying sufficiently regular cost function c. In this regard, OT is considered as a functional defined on ` (Fc) the Banach space of bounded functionals from Fc to R and equipped with uniform norm. We prove the OT functional to be Hadamard directional differentiable and conclude distributional convergence via a functional delta method that necessitates weak convergence of an underlying empirical process in ` (Fc). The latter can be dealt with empirical process theory and requires Fc to be a Donsker class. We give sufficient conditions depending on the dimension of the ground space, the underlying cost function and the probability measures under consideration to guarantee the Donsker property. Overall, our approach reveals a noteworthy trade-off inherent in central limit theorems for empirical OT: Kantorovich duality requires Fc to be sufficiently rich, while the empirical processes only converges weakly if",Fc is not too,"complex."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Connection-minimal Abduction in EL via Translation to FOL - Technical Report,Existing minimality notions are insufficient.,""Fajar Haifani, P. Koopmann, Sophie Tourret, Christoph Weidenbach"",International Joint Conference on Automated Reasoning,,,10.48550/arXiv.2205.08449,,2022,3,https://doi.org/10.48550/arXiv.2205.08449,https://semanticscholar.org/paper/5d38a67b20076ed8387a54b7854352dbe8928a57,"". Abduction in description logics ?nds extensions of a knowledge base to make it entail an observation. As such, it can be used to explain why the observation does not follow, to repair incomplete knowledge bases, and to provide possible explanations for unexpected observations. We consider TBox abduction in the lightweight description logic EL , where the observation is a concept inclusion and the background knowledge is a TBox, i.e., a set of concept inclusions. To avoid useless answers, such problems usually come with further restrictions on the solution space and/or minimality criteria that help sort the cha? from the grain. We argue that existing minimality notions are insu?cient, and introduce connection minimality. This criterion follows Occam’s razor by rejecting hypotheses that use concept inclusions unrelated to the problem at hand. We show how to compute a special class of connection-minimal hypotheses in a sound and complete way. Our technique is based on a translation to ?rst-order logic, and constructs hypotheses based on prime implicates. We evaluate a prototype implementation of our approach on ontologies from the medical domain."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"A Normalizing Flow-Based Co-Embedding Model for Attributed Networks,The quality of embeddings generated by our model is improved to the state-of-the-art attributed network embedding methods.,""Shangsong Liang, Zhuo Ouyang, Zaiqiao Meng"",ACM Transactions on Knowledge Discovery from Data,,1.566 (1946),10.1145/3477049,,2022,2,https://doi.org/10.1145/3477049,https://semanticscholar.org/paper/4e8f5a9b0f6ec971e87e301ba406d14e18655be2,""Network embedding is a technique that aims at inferring the low-dimensional representations of nodes in a semantic space. In this article, we study the problem of inferring the low-dimensional representations of both nodes and attributes for attributed networks in the same semantic space such that the affinity between a node and an attribute can be effectively measured. Intuitively, this problem can be addressed by simply utilizing existing variational auto-encoder (VAE) based network embedding algorithms. However, the variational posterior distribution in previous VAE based network embedding algorithms is often assumed and restricted to be a mean-field Gaussian distribution or other simple distribution families, which results in poor inference of the embeddings. To alleviate the above defect, we propose a novel VAE-based co-embedding method for attributed network, F-CAN, where posterior distributions are flexible, complex, and scalable distributions constructed through the normalizing flow. We evaluate our proposed models on a number of network tasks with several benchmark datasets. Experimental results demonstrate that there are clear improvements in the qualities of embeddings generated by our model to the state-of-the-art attributed network embedding methods."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"""Transseries, Model Theory, and Hardy Fields"",Transseries are formal series in a variable x using exp and log.,L. van den Dries,Notices of the American Mathematical Society,,0.257 (16217),10.1090/noti2459,https://doi.org/10.1090/noti2459,2022,,https://doi.org/10.1090/noti2459,https://semanticscholar.org/paper/752e527c16bb430f860710f8ca42a4f3ce7731ef,""1. What Are Transseries? Transseries are formal series in a variable x using exp and log. Typical example: 7 ee?x ?3 ex +5x?2?log log x+?+ 1 x + 2 x2 + 3 x3 +?+ 1 ex . Think of x as positive infinite: x > R; alternatively, transseries are written as series in the positive infinitesimal variable t ?= x?1; the x-notation, however, works better. The “monomials” here, called transmonomials, are arranged from left to right in decreasing order, with real coefficients. The leftmost transmonomial in a nonzero transseries is called its leading transmonomial: ee?x in the example above. A transseries has an infinite part, a constant term (a real number), and an infinitesimal part. In the"",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Trans-eQTL mapping in gene sets identifies network effects of genetic variants,Trans-PCO is a powerful and reliable tool that detects trans regulators of cellular pathways and networks.,""Lili Wang, Nikita Babushkin, Zhonghua Liu, Xuanyao Liu"",bioRxiv,,,10.1101/2022.11.11.516189,https://www.biorxiv.org/content/biorxiv/early/2022/11/11/2022.11.11.516189.full.pdf,2022,,https://doi.org/10.1101/2022.11.11.516189,https://semanticscholar.org/paper/f4a4139a264e26ded6730bb2ba66a1979f9da53a,""Nearly all trait-associated variants identified in GWAS are non-coding. The cis regulatory effects of these variants have been extensively characterized, but how they impact gene regulation in trans has been the subject of much fewer studies. Mapping trans genetic effects is very challenging because their effect sizes tend to be small and a large multiple testing burden reduces the power to detect them. In addition, read mapping biases can lead to many false positives. To reduce mapping biases and substantially improve power to map trans-eQTLs, we developed a pipeline called trans-PCO, which combines careful read and gene filters with a principal component (PC)-based multivariate association test. Our simulations demonstrate that trans-PCO substantially outperforms existing trans-eQTL mapping methods, including univariate and primary PC-based methods. We applied trans-PCO to two gene expression datasets from whole blood, DGN (N = 913) and eQTLGen (N = 31,684), to identify trans-eQTLs associated with gene co-expression networks and hallmark gene sets representing well-defined biological processes. In total, we identified 14,985 high-quality trans-eQTLs associated with 197 co-expression gene modules and biological processes. To better understand the effects of trait-associated variants on gene regulatory networks, we performed colocalization analyses between GWAS loci of 46 complex traits and",trans-eQTLs i,dentified in DGN. We highlight several example,s wh,ere our map of trans effect,s hel,ps us,und,erstand how t,rai,t-a,ssocia,ted var,iants im,pact gene,re,gulatory,net,works and bio,logical pat,hways.,For e,xamp,le,", we",fou,nd,that,a l,ocus a,ssociat,ed,wit,h pl,atel,et t,raits,nea,r ARH,GEF,3 tra,ns-,regul,at,es,a s,et o,f c,o-e,xpre,ssed,gen,es,si,gn,if,ic,ant,"ly enriched in the platelet activation pathway. Additionally, six red blood cell trait-associated loci trans-regulate a gene set representing heme metabolism, a crucial process in erythropoiesis. In conclusion, trans-PCO is a powerful and reliable tool that detects trans regulators of cellular pathways and networks, which opens up new opportunities to learn the impact of trait-associated loci on gene regulatory networks."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"TransDrift: Modeling Word-Embedding Drift using Transformer,TransDrift is a transformer-based prediction model for word embeddings.,""Nishtha Madaan, Prateek Chaudhury, N. Kumar, Srikanta J. Bedathur"",ArXiv,,,10.48550/arXiv.2206.08081,,2022,,https://doi.org/10.48550/arXiv.2206.08081,https://semanticscholar.org/paper/00e0fcf643fa239474f6a8219c55f5819b0d3f2a,""In modern NLP applications, word embeddings are a crucial backbone that can be readily shared across a number of tasks. However as the text distributions change and word semantics evolve over time, the downstream applications using the embeddings can suffer if the word representations do not conform to the data drift. Thus, maintaining word embeddings to be consistent with the underlying data distribution is a key problem. In this work, we tackle this problem and propose TransDrift, a transformer-based prediction model for word embeddings. Leveraging the flexibility of transformer, our model accurately learns the dynamics of the embedding drift and predicts the future embedding. In experiments, we compare with existing methods and show that our model makes significantly more accurate predictions of the word embedding than the baselines. Crucially, by applying the predicted embeddings as a backbone for downstream classification tasks, we show that our embeddings lead to superior performance compared to the previous methods. We will release the code and datasets at https://github.com/transdrift/"",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"TransDrift: Modeling Word-Embedding Drift using Transformer,TransDrift is a transformer-based prediction model for word embeddings.,""Nishtha Madaan, Prateek Chaudhury, N. Kumar, Srikanta J. Bedathur"",ArXiv,,,10.48550/arXiv.2206.08081,,2022,,https://doi.org/10.48550/arXiv.2206.08081,https://semanticscholar.org/paper/3141ba7cade660f35ba3cf958322ac61c317af24,""In modern NLP applications, word embeddings are a crucial backbone that can be read-ily shared across a number of tasks. However as the text distributions change and word semantics evolve over time, the downstream applications using the embeddings can suffer if the word representations do not conform to the data drift. Thus, maintaining word embeddings to be consistent with the underlying data distribution is a key problem. In this work, we tackle this problem and propose TransDrift, a transformer-based prediction model for word embeddings. Leveraging the ?exibility of transformer, our model accurately learns the dynamics of the embedding drift and predicts the future embedding. In experiments, we compare with existing methods and show that our model makes signi?cantly more accurate predictions of the word embedding than the baselines. Crucially, by applying the predicted embeddings as a backbone for downstream classi?cation tasks, we show that our embeddings lead to superior performance compared to the previous methods. We will release the code and datasets at https://github.com/transdrift/"",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Extension of selected configuration interaction for transcorrelated methods.,The selection criteria based on either the first order coefficient or the second order energy lead to significantly different convergence rates in the usual transcorrelated energy.,""A. Ammar, A. Scemama, E. Giner"",Journal of Chemical Physics,,1.103 (3522),10.1063/5.0115524,http://arxiv.org/pdf/2207.08399,2022,1,https://doi.org/10.1063/5.0115524,https://semanticscholar.org/paper/520128fcb4d5874cb1004f05864b87e5d29c94a5,""In this work, we present an extension of popular selected configuration interaction (SCI) algorithms to the Transcorrelated (TC) framework. Although we used in this work the recently introduced one-parameter correlation factor [E. Giner, J. Chem. Phys. 154, 084119 (2021)], the theory presented here is valid for any correlation factor. Thanks to the formalization of the non-Hermitian TC eigenvalue problem as a search of stationary points for a specific functional depending on both left- and right-functions, we obtain a general framework, allowing for different choices for both the selection criterion in SCI and the second order perturbative correction to the energy. After numerical investigations on different second-row atomic and molecular systems in increasingly large basis sets, we found that taking into account the non-Hermitian character of the TC Hamiltonian in the selection criterion is mandatory to obtain a fast convergence of the TC energy. In addition, selection criteria based on either the first order coefficient or the second order energy lead to significantly different convergence rates, which is typically not the case in the usual Hermitian SCI. Regarding the convergence of the total second order perturbation energy, we find that the quality of the left-function used in the equations strongly affects the quality of the results. Within the near-optimal algorithm pro","posed here, we",find that the SCI expansion in the TC framewo,rk c,onverges faster than the us,ual S,CI in,ter,ms of both th,e b,asi,s set,and the,number,of Slater,de,terminant,"s.""",",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Transcepts: Connecting Entity Representations Across Conceptual Views on Spatial Information (Short Paper),The same set of air pollution points may be regarded as field values if they are considered pollution measurements and objects if they are considered locations of measurement devices.,""Eric Top, S. Scheider"",Conference On Spatial Information Theory,,,10.4230/LIPIcs.COSIT.2022.19,,2022,,https://doi.org/10.4230/LIPIcs.COSIT.2022.19,https://semanticscholar.org/paper/0936e2ead491c588fd865e82ed7f8e1626ded82d,""Analysts interpret geographic and other spatial data to check the validity of methods in reaching an analytical goal. However, the meaning of data is elusive. The same data may constitute one concept in one view and another concept in another. For example, the same set of air pollution points may be regarded as field values if they are considered pollution measurements and objects if they are considered locations of measurement devices. In this work we adopt a framework of conceptual spaces and viewpoints and show how entity representations in one semantic interpretation may be related to entity representations in others in terms of what we call transcepts. A transcept captures which things represent the same entity. We define and use transcepts in the framework to explain how different views of geographic data may relate to one another."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"TransFuser: Imitation with Transformer-Based Sensor Fusion for Autonomous Driving,TransFuser outperforms all prior work on the CARLA leaderboard in terms of driving score by a large margin.,""Kashyap Chitta, Aditya Prakash, Bernhard Jaeger, Zehao Yu, Katrin Renz, Andreas Geiger"",IEEE Transactions on Pattern Analysis and Machine Intelligence,,8.269 (105),10.48550/arXiv.2205.15997,,2022,12,https://doi.org/10.48550/arXiv.2205.15997,https://semanticscholar.org/paper/1a8ac422f4e594155af1721837009264ce14fe32,""How should we integrate representations from complementary sensors for autonomous driving? Geometry-based fusion has shown promise for perception (e.g. object detection, motion forecasting). However, in the context of end-to-end driving, we find that imitation learning based on existing sensor fusion methods underperforms in complex driving scenarios with a high density of dynamic agents. Therefore, we propose TransFuser, a mechanism to integrate image and LiDAR representations using self-attention. Our approach uses transformer modules at multiple resolutions to fuse perspective view and bird's eye view feature maps. We experimentally validate its efficacy on a challenging new benchmark with long routes and dense traffic, as well as the official leaderboard of the CARLA urban driving simulator. At the time of submission, TransFuser outperforms all prior work on the CARLA leaderboard in terms of driving score by a large margin. Compared to geometry-based fusion, TransFuser reduces the average collisions per kilometer by 48%."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Paper title,Abstract summary,Authors,Journal,Influential citations,Scimago Journal Rank,DOI,PDF,Year,Citations,DOI URL,Semantic Scholar URL,Abstract,Takeaway suggests yes/no,Study type",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"ArcaneQA: Dynamic Program Induction and Contextualized Encoding for Knowledge Base Question Answering,A generation-based model addresses both the large search space and the schema linking challenges in a unified framework.,""Yu Gu, Yu Su"",International Conference on Computational Linguistics,,,10.48550/arXiv.2204.08109,,2022,6,https://doi.org/10.48550/arXiv.2204.08109,https://semanticscholar.org/paper/7766e38adc9d48d25aebf87ebc8608e8a7b193cf,""Question answering on knowledge bases (KBQA) poses a unique challenge for semantic parsing research due to two intertwined challenges: large search space and ambiguities in schema linking. Conventional ranking-based KBQA models, which rely on a candidate enumeration step to reduce the search space, struggle with flexibility in predicting complicated queries and have impractical running time. In this paper, we present ArcaneQA, a novel generation-based model that addresses both the large search space and the schema linking challenges in a unified framework with two mutually boosting ingredients: dynamic program induction for tackling the large search space and dynamic contextualized encoding for schema linking. Experimental results on multiple popular KBQA datasets demonstrate the highly competitive performance of ArcaneQA in both effectiveness and efficiency."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"ArcaneQA: Dynamic Program Induction and Contextualized Encoding for Knowledge Base Question Answering,A generation-based model addresses both the large search space and the schema linking challenges in a unified framework.,""Yu Gu, Yu Su"",ArXiv,,,10.48550/arXiv.2204.08109,,2022,1,https://doi.org/10.48550/arXiv.2204.08109,https://semanticscholar.org/paper/e12f83499e9f0f408ab9424a6fb20ae510d37b6b,""Question answering on knowledge bases (KBQA) poses a unique challenge for semantic parsing research due to two intertwined challenges: large search space and ambiguities in schema linking . Conventional ranking-based KBQA models, which rely on a candidate enumeration step to reduce the search space, struggle with ?exibility in predicting complicated queries and have impractical running time. In this paper, we present ArcaneQA, a novel generation-based model that addresses both the large search space and the schema linking challenges in a uni?ed framework with two mutually boosting ingredients: dynamic program induction for tackling the large search space and dynamic contextualized encoding for schema linking. Experimental results on multiple popular KBQA datasets demonstrate the highly competitive performance of ArcaneQA in both effectiveness and ef?ciency. 1"",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Logical Form Generation via Multi-task Learning for Complex Question Answering over Knowledge Bases,""A multi-task model jointly learns entity disambiguation, relation classification, and logical form generation achieves state-of-the-art results on both ComplexWebQuestions and WebQuestionsSP datasets."",""Xixin Hu, X. Wu, Yiheng Shu, Yuzhong Qu"",International Conference on Computational Linguistics,,,,,2022,1,,https://semanticscholar.org/paper/9ec3166f4a9f00c37ce080c4dc1fff04b719dccf,""Question answering over knowledge bases (KBQA) for complex questions is a challenging task in natural language processing. Recently, generation-based methods that translate natural language questions to executable logical forms have achieved promising performance. These methods use auxiliary information to augment the logical form generation of questions with unseen KB items or novel combinations, but the noise introduced can also leads to more incorrect results. In this work, we propose GMT-KBQA, a Generation-based KBQA method via Multi-Task learning, to better retrieve and utilize auxiliary information. GMT-KBQA first obtains candidate entities and relations through dense retrieval, and then introduces a multi-task model which jointly learns entity disambiguation, relation classification, and logical form generation. Experimental results show that GMT-KBQA achieves state-of-the-art results on both ComplexWebQuestions and WebQuestionsSP datasets. Furthermore, the","detailed evaluation demonstrates that GMT-KBQA benefits from the auxiliary tasks and has a strong generalization capability."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Knowledge Base Question Answering by Case-based Reasoning over Subgraphs,A semiparametric model can answer queries requiring subgraph reasoning patterns.,""R. Das, Ameya Godbole, Ankita Rajaram Naik, Elliot Tower, Robin Jia, M. Zaheer, Hannaneh Hajishirzi, A. McCallum"",International Conference on Machine Learning,,,,,2022,9,,https://semanticscholar.org/paper/d7f9bc1acde978072050b6fe2dfdb237f94e480e,""Question answering (QA) over knowledge bases (KBs) is challenging because of the diverse, es-sentially unbounded, types of reasoning patterns needed. However, we hypothesize in a large KB, reasoning patterns required to answer a query type reoccur for various entities in their respective subgraph neighborhoods. Leveraging this structural similarity between local neighborhoods of different subgraphs, we introduce a semiparametric model (C BR - SUBG ) with (i) a nonparametric component that for each query, dynamically retrieves other similar k -nearest neighbor (KNN) training queries along with query-speci?c subgraphs and (ii) a parametric component that is trained to identify the (latent) reasoning patterns from the subgraphs of KNN queries and then apply them to the subgraph of the target query. We also propose an adaptive subgraph collection strategy to select a query-speci?c compact subgraph, allowing us to scale to full Freebase KB containing billions of facts. We show that C BR - SUBG can answer queries requiring subgraph reasoning patterns an",d performs competitively with the best models on several KBQA benchmarks. Our subgraph collection strategy also produces more compact subgraphs (e.g. 55% reduction,in size,for,WebQSP,while,incr,ea,sin,g an,sw,er,r,ecall,by,4.85%),1 .,""",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Inductive Logical Query Answering in Knowledge Graphs,Inductive models are able to perform logical reasoning at inference time over unseen nodes generalizing to graphs up to 500% larger than training ones.,""Mikhail Galkin, Zhaocheng Zhu, Hongyu Ren, Jian Tang"",ArXiv,,,10.48550/arXiv.2210.08008,,2022,3,https://doi.org/10.48550/arXiv.2210.08008,https://semanticscholar.org/paper/d2c177f6386e7b88b406e2f741ed5387e4ced3b0,""Formulating and answering logical queries is a standard communication interface for knowledge graphs (KGs). Alleviating the notorious incompleteness of real-world KGs, neural methods achieved impressive results in link prediction and complex query answering tasks by learning representations of entities, relations, and queries. Still, most existing query answering methods rely on transductive entity embeddings and cannot generalize to KGs containing new entities without retraining the entity embeddings. In this work, we study the inductive query answering task where inference is performed on a graph containing new entities with queries over both seen and unseen entities. To this end, we devise two mechanisms lever-aging inductive node and relational structure representations powered by graph neural networks (GNNs). Experimentally, we show that inductive models are able to perform logical reasoning at inference time over unseen nodes generalizing to graphs up to 500% larger than training ones. Exploring the ef?ciency–effectiveness","trade-off, we ?nd the inductive relational structure representation method generally achieves higher performance, while the inductive node representation method is",able t,o an,swer co,mplex,queri,es,in,the,i,nf,er,ence-,only,regim,e wi,"thout any training on queries and scales to graphs of millions of nodes. Code is available at https://github.com/DeepGraphLearning/InductiveQE ."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Knowledge Base Completion using Web-Based Question Answering and Multimodal Fusion,A web-based question answering system can achieve good performance with very few questions.,""Yang Peng, D. Wang"",ArXiv,,,10.48550/arXiv.2211.07098,,2022,2,https://doi.org/10.48550/arXiv.2211.07098,https://semanticscholar.org/paper/c94f549124efce89cac112ece4839bc4d0b0cb4a,""Over the past few years, large knowledge bases have been con-structed to store massive amounts of knowledge. However, these knowledge bases are highly incomplete. To solve this problem, we propose a web-based question answering system system with multimodal fusion of unstructured and structured information, to fill in missing information for knowledge bases. To utilize unstructured information from the Web for knowledge base completion, we design a web-based question answering system using multimodal features and question templates to extract missing facts, which can achieve good performance with very few questions. To help improve extraction quality, the question answering system employs structured information from knowledge bases, such as entity types and entity-to-entity relatedness."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Knowledge Base Question Answering: A Semantic Parsing Perspective,The literature of semantic parsing has been overlooked by existing knowledge base research.,""Yu Gu, Vardaan Pahuja, Gong Cheng, Yu Su"",ArXiv,,,10.48550/arXiv.2209.04994,,2022,5,https://doi.org/10.48550/arXiv.2209.04994,https://semanticscholar.org/paper/1d06912b36677cd70e778e909c6d7329a200941c,""Recent advances in deep learning have greatly propelled the research on semantic parsing. Im-provement has since been made in many downstream tasks, including natural language interface to web APIs, text-to-SQL generation, among others. However, despite the close connection shared with these tasks, research on question answering over knowledge bases (KBQA) has compara-tively been progressing slowly. We identify and attribute this to two unique challenges of KBQA, schema-level complexity and fact-level complexity . In this survey, we situate KBQA in the broader literature of semantic parsing and give a comprehensive account of how existing KBQA approaches attempt to address the unique challenges. Regardless of the unique challenges, we argue that we can still take much inspiration from the literature of semantic parsing, which has been overlooked by existing research on KBQA. Based on our discussion, we can better understand the bottleneck of current KBQA research and shed light on promising directions for KBQA to keep up with the literature of semantic parsing, particularly in the era of","pre-trained language models."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Mask and Reason: Pre-Training Knowledge Graph Transformers for Complex Logical Queries,Knowledge graph transformers can consistently outperform both knowledge graph embedding-based baselines and advanced encoders on nine in-domain and out-domain reasoning tasks.,""Xiao Liu, Shiyu Zhao, Kai Su, Yukuo Cen, J. Qiu, Mengdi Zhang, Wei Wu, Yuxiao Dong, Jie Tang"",Knowledge Discovery and Data Mining,,,10.1145/3534678.3539472,https://dl.acm.org/doi/pdf/10.1145/3534678.3539472,2022,3,https://doi.org/10.1145/3534678.3539472,https://semanticscholar.org/paper/334f4d63c8974c685389ffee8d8ea907c8b583f3,""Knowledge graph (KG) embeddings have been a mainstream approach for reasoning over incomplete KGs. However, limited by their inherently shallow and static architectures, they can hardly deal with the rising focus on complex logical queries, which comprise logical operators, imputed edges, multiple source entities, and unknown intermediate entities. In this work, we present the Knowledge Graph Transformer (kgTransformer) with masked pre-training and fine-tuning strategies. We design a KG triple transformation method to enable Transformer to handle KGs, which is further strengthened by the Mixture-of-Experts (MoE) sparse activation. We then formulate the complex logical queries as masked prediction and introduce a two-stage masked pre-training strategy to improve transferability and generalizability.Extensive experiments on two benchmarks demonstrate that kgTra","nsformer can consistently outperform both KG embedding-based baselines and advanced encoders on nine in-domain and out-of-domain reasoning tasks. Additionally, kgTr",ansform,er c,an reas,on wit,h exp,la,ina,bili,ty,v,ia,prov,idin,g the,full,"reasoning paths to interpret given answers."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Query-Driven Knowledge Base Completion using Multimodal Path Fusion over Multimodal Knowledge Graph,""A multimodal path fusion algorithm to rank candidate answers based on different paths in the multimodal knowledge graphs achieves much better performance than question answering, rule inference and a baseline fusion algorithm."",""Yang Peng, D. Wang"",ArXiv,,,10.48550/arXiv.2212.01923,,2022,1,https://doi.org/10.48550/arXiv.2212.01923,https://semanticscholar.org/paper/a24df174f9479efa6c54f0a3026b94b18f999554,""Over the past few years, large knowledge bases have been constructed to store massive amounts of knowledge. However, these knowledge bases are highly incomplete, for example, over 70% of people in Freebase have no known place of birth. To solve this problem, we propose a query-driven knowledge base completion system with multimodal fusion of unstructured and structured information. To effectively fuse unstructured information from the Web and structured information in knowledge bases to achieve good performance, our system builds multimodal knowledge graphs based on question answering and rule inference. We propose a multimodal path fusion algorithm to rank candidate answers based on different paths in the multimodal knowledge graphs, achieving much better performance than question answering, rule inference and a baseline fusion algorithm. To improve system efficiency, query-driven techniques are utilized to reduce the runtime of our system,","providing fast responses to user queries. Extensive experiments have been conducted to demonstrate the effectiveness and efficiency of our system."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Neural Methods for Logical Reasoning over Knowledge Graphs,Neural network models achieve a 10% relative increase over the best performing state of the art.,""Alfonso Amayuelas, Shuai Zhang, Susie Xi Rao, Ce Zhang"",International Conference on Learning Representations,,,10.48550/arXiv.2209.14464,,2022,4,https://doi.org/10.48550/arXiv.2209.14464,https://semanticscholar.org/paper/2d80d0b053179988f2155ea9eaf57b60a7742c16,""Reasoning is a fundamental problem for computers and deeply studied in Arti?cial Intelligence. In this paper, we speci?cally focus on answering multi-hop logical queries on Knowledge Graphs (KGs). This is a complicated task because, in real-world scenarios, the graphs tend to be large and incomplete. Most previous works have been unable to create models that accept full First-Order Logical (FOL) queries, which include negative queries, and have only been able to process a limited set of query structures. Additionally, most methods present logic operators that can only perform the logical operation they are made for. We introduce a set of models that use Neural Networks to create one-point vector embeddings to answer the queries. The versatility of neural networks allows the framework to handle FOL queries with Conjunction ( ? ), Disjunction ( ? ) and Negation ( ¬ ) operators. We demonstrate experimentally the performance of our model through extensive experimentation on well-known benchmarking datasets. Besides having more versat","ile operators, the models achieve a 10% relative increase over the best performing state of the art and more than 30% over the original method based on single-point",vector,emb,eddings,"."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Incorporating Context Graph with Logical Reasoning for Inductive Relation Prediction,The context graph is introduced to process the subgraph and context graph respectively.,""Qika Lin, Jun Liu, Fangzhi Xu, Yudai Pan, Yifan Zhu, Lingling Zhang, Tianzhe Zhao"",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,,,10.1145/3477495.3531996,,2022,5,https://doi.org/10.1145/3477495.3531996,https://semanticscholar.org/paper/8c720eb939259971bcb87f46c92ebb0d2d5497c7,""Relation prediction on knowledge graphs (KGs) aims to infer missing valid triples from observed ones. Although this task has been deeply studied, most previous studies are limited to the transductive setting and cannot handle emerging entities. Actually, the inductive setting is closer to real-life scenarios because it allows entities in the testing phase to be unseen during training. However, it is challenging to precisely conduct inductive relation prediction as there exists requirements of entity-independent relation modeling and discrete logical reasoning for interoperability. To this end, we propose a novel model ConGLR to incorporate context graph with logical reasoning. Firstly, the enclosing subgraph w.r.t. target head and tail entities are extracted and initialized by the double radius labeling. And then the context graph involving relational paths, relations and entities is introduced. Secondly, two graph convolutional networks (GCNs) with",the information interaction of entities and relations are carried out to process the subgraph and context graph respectively. Considering the influence of differen,t edges,and,target,relat,"ions,",w,e i,ntro,du,ce,e,dge-a,ware,and r,elat,"ion-aware attention mechanisms for the subgraph GCN. Finally, by treating the relational path as rule body and target relation as rule head, we integrate neural calculating and logical reasoning to obtain inductive scores. And to focus on the specific modeling goals of each module, the stop-gradient is utilized in the information interaction between context graph and subgraph GCNs in the training process. In this way, ConGLR satisfies two inductive requirements at the same time. Extensive experiments demonstrate that ConGLR obtains outstanding performance against state-of-the-art baselines on twelve inductive dataset versions of three common KGs."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Neural-Symbolic Models for Logical Queries on Knowledge Graphs,A neural-symbolic model can answer complex first-order logic queries on knowledge graphs.,""Zhaocheng Zhu, Mikhail Galkin, Zuobai Zhang, Jian Tang"",International Conference on Machine Learning,,,10.48550/arXiv.2205.10128,,2022,11,https://doi.org/10.48550/arXiv.2205.10128,https://semanticscholar.org/paper/53eecd3d126a11911b53c639a7a808cac4fbf127,""Answering complex ?rst-order logic (FOL) queries on knowledge graphs is a fundamental task for multi-hop reasoning. Traditional symbolic methods traverse a complete knowledge graph to extract the answers, which provides good interpretation for each step. Recent neural methods learn geometric embeddings for complex queries. These methods can generalize to incomplete knowledge graphs, but their reasoning process is hard to interpret. In this paper, we propose Graph Neural Network Query Executor (GNN-QE), a neural-symbolic model that enjoys the advantages of both worlds. GNN-QE decomposes a complex FOL query into relation projections and logical operations over fuzzy sets, which provides interpretability for intermediate variables. To reason about the missing links, GNN-QE adapts a graph neural network from knowledge graph completion to execute the relation projections, and models the logical operations with product fuzzy logic. Experiments on 3 datasets show that GNN-QE signi?cantly improves over previous state-of-the-art models in answering","FOL queries. Mean-while, GNN-QE can predict the number of answers without explicit supervision, and provide visualizations for intermediate variables. 1"",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Low-Rank Constraints for Fast Inference in Structured Models,A low-rank constraint can trade off model expressivity and speed via the rank.,""Justin T Chiu, Yuntian Deng, Alexander M. Rush"",Neural Information Processing Systems,,,,,2022,6,,https://semanticscholar.org/paper/34db717eac67fdc929f2f7006d26a32873f6063a,""Structured distributions, i.e. distributions over combinatorial spaces, are commonly used to learn latent probabilistic representations from observed data. However, scaling these models is bottlenecked by the high computational and memory complexity with respect to the size of the latent representations. Common models such as Hidden Markov Models (HMMs) and Probabilistic Context-Free Grammars (PCFGs) require time and space quadratic and cubic in the number of hidden states respectively. This work demonstrates a simple approach to reduce the computational and memory complexity of a large class of structured models. We show that by viewing the central inference step as a matrix-vector product and using a low-rank constraint, we can trade off model expressivity and speed via the rank. Experiments with neural parameterized structured models for language modeling, polyphonic music modeling, unsupervised grammar induction, and video modeling show that our approach matches the accuracy of standard models at large state spaces while providing practical speedups."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"An ASP Approach for Reasoning on Neural Networks under a Finitely Many-Valued Semantics for Weighted Conditional Knowledge Bases,The proposed approach for checking properties of trained MLPs is experimented for checking properties of trained MLPs.,""Laura Giordano, Daniele Theseider Dupré"",Theory and Practice of Logic Programming,,0.778 (5965),10.1017/S1471068422000163,https://www.cambridge.org/core/services/aop-cambridge-core/content/view/08394A4B59178E072CB9AEC3285FD332/S1471068422000163a.pdf/div-class-title-an-asp-approach-for-reasoning-on-neural-networks-under-a-finitely-many-valued-semantics-for-weighted-conditional-knowledge-bases-div.pdf,2022,7,https://doi.org/10.1017/S1471068422000163,https://semanticscholar.org/paper/93fc10b3c0d721a109ff07de8a3b9a22ddb3065a,""Abstract Weighted knowledge bases for description logics with typicality have been recently considered under a “concept-wise” multipreference semantics (in both the two-valued and fuzzy case), as the basis of a logical semantics of multilayer perceptrons (MLPs). In this paper we consider weighted conditional",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"knowledge bases with typicality in the finitely many-valued case, through three different semantic constructions. For the boolean fragment",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Relational Structure-Aware Knowledge Graph Representation in Complex Space,""A novel knowledge graph representation model in complex space can well preserve various relation patterns, as well as structural information in knowledge graphs."",""Ke Sun, Shuo Yu, Ciyuan Peng, Yueru Wang, O. Alfarraj, Amr M. Tolba, Feng Xia"",Mathematics,,0.538 (9300),10.3390/math10111930,,2022,1,https://doi.org/10.3390/math10111930,https://semanticscholar.org/paper/f19405b6237b988aacaa6384f68140e723d32d1b,""Relations in knowledge graphs have rich relational structures and various binary relational patterns. Various relation modelling strategies are proposed for embedding knowledge graphs, but they fail to fully capture both features of relations, rich relational structures and various binary relational patterns. To address the problem of insufficient embedding due to the complexity of the relations, we propose a novel knowledge graph representation model in complex space, namely MARS, to exploit complex relations to embed knowledge graphs. MARS takes the mechanisms of complex numbers and message-passing and then embeds triplets into relation-specific complex hyperplanes. Thus, MARS can well preserve various relation patterns, as well as structural information in knowledge graphs. In addition, we find that the scores generated from the score function approximate a Gaussian distribution. The scores in the tail cannot effectively represent triplets. To address this part","icular issue and improve the precision of embeddings, we use the standard deviation to limit the dispersion of the score distribution, resulting in more accurate em",bedding,s of,triple,ts. Co,mpreh,en,siv,e ex,pe,ri,me,nts o,n mu,ltiple,ben,"chmarks demonstrate that our model significantly outperforms existing state-of-the-art models for link prediction and triple classification."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Towards Loosely-Coupling Knowledge Graph Embeddings and Ontology-based Reasoning,The prediction accuracy of knowledge graph embeddings is enhanced by domain knowledge that may not be included in the input knowledge graph.,""Zoi Kaoudi, Abelardo Carlos Mart??nez Lorenzo, V. Markl"",ArXiv,,,,,2022,2,,https://semanticscholar.org/paper/8ef2e6b11b519b609bfaa7ed056f621cee15d552,""Knowledge graph completion (a.k.a. link prediction), i.e., the task of inferring missing information from knowledge graphs, is a widely used task in many applications, such as product recommendation and question answering. The state-of-the-art approaches of knowledge graph embeddings and/or rule mining and reasoning are data-driven and, thus, solely based on the information the input knowledge graph contains. This leads to unsatisfactory prediction results which make such solutions inapplicable to crucial domains such as healthcare. To further enhance the accuracy of knowledge graph completion we propose to loosely-couple the data-driven power of knowledge graph embeddings with domain-specific reasoning stem-ming from experts or entailment regimes (e.g., OWL2). In this way, we not only enhance the prediction accuracy with domain knowledge that may not be included in the input knowledge graph but also allow users to plugin their own knowledge graph embedding and reasoning method. Our initial results show that we enhance the MRR accuracy of vanilla knowledge graph embeddings b","y up to 3x and outperform hybrid solutions that combine knowledge graph embeddings with rule mining and reasoning up to 3.5x MRR."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"BertNet: Harvesting Knowledge Graphs from Pretrained Language Models,""The knowledge harvested with our approach shows competitive quality, diversity, and novelty."",""Shibo Hao, Bowen Tan, Kaiwen Tang, Hengzhe Zhang, E. Xing, Zhiting Hu"",ArXiv,,,10.48550/arXiv.2206.14268,,2022,9,https://doi.org/10.48550/arXiv.2206.14268,https://semanticscholar.org/paper/a11fa157d6d80b57016f548dbdf5ca94a3cd5a36,""Symbolic knowledge graphs (KGs) have been constructed either by expensive human crowdsourcing or with complex text mining pipelines. The emerging large pretrained language models (LMs), such as B ERT , have shown to implicitly encode massive knowledge which can be queried with properly designed prompts. However, compared to the explicit KGs, the implict knowledge in the black-box LMs is often dif?cult to access or edit and lacks explainability. In this work, we aim at harvesting symbolic KGs from the LMs, and propose a new framework for automatic KG construction empowered by the neural LMs’ ?exibility and scalability. Compared to prior works that often rely on large human annotated data or existing massive KGs, our approach requires only the minimal de?nition of relations as inputs, and hence is suitable for extracting knowledge of rich new relations that are instantly assigned and not available before. The framework automatically generates diverse prompts, and performs ef?cient knowledge search within a given LM for consistent outputs. The knowledge ha","rvested with our approach shows competitive quality, diversity, and novelty. As a result, we derive from diverse LMs a family of new KGs (e.g., B ERT N ET and R O B",ERT A N,ET,) that,contai,n a r,ic,her,set,o,f,re,latio,"ns,",includ,ing,"some complex ones (e.g., """"A is capable of but not good at B"""" ) that cannot be extracted with previous methods. Besides, the resulting KGs also serve as a vehicle to interpret the respective source LMs, leading to new insights into the varying knowledge capability of different LMs."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Knowledge Graph Completion by Jointly Learning Structural Features and Soft Logical Rules,A novel knowledge graph embedding model can learn more expressive embedding of entities and relations.,""Weidong Li, Rong Peng, Zhi Li"",IEEE Transactions on Knowledge and Data Engineering,,2.431 (883),10.1109/TKDE.2021.3108224,,2023,3,https://doi.org/10.1109/TKDE.2021.3108224,https://semanticscholar.org/paper/2acfa599b8f6d6a25d650fc3030f87004c9f7d99,""With the rapid development and widespread application of Knowledge graphs (KGs) in many artificial intelligence tasks, a large number of efforts have been made to refine them and increase their quality. Knowedge graph embedding (KGE) has become one of the main refinement tasks, which aims to predict missing facts based on existing ones in KGs. However, there are still mainly two difficult unresolved challenges: (i) how to leverage the local structural features of entities and the potential soft logical rules to learn more expressive embedding of entites and relations; and (ii) how to combine these two learning processes into one unified model. To conquer these problems, we propose a novel KGE model named JSSKGE, which can Jointly learn the local Structural features of entities and Soft logical rules. First, we employ graph attention networks which are specially designed for graph-structured data to aggregate the local structural information of nodes. Then, we utilize soft logical rules implicated in KGs as a","n expert to further rectify the embeddings of entities and relations. By jointly learning, we can obtain more informative embeddings to predict new facts. With expe",riments,on,four co,mmonly,used,d,ata,sets,",",th,e,JSSKG,E ob,tains,bett,"er performance than state-of-the-art approaches."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Knowledge Graph Reasoning with Logics and Embeddings: Survey and Perspective,Logic-based and embedding-based methods are integrated in knowledge graph reasoning.,""Wen Zhang, Jiaoyan Chen, Juan Li, Zezhong Xu, Jeff Z. Pan, Huajun Chen"",ArXiv,,,,,2022,3,,https://semanticscholar.org/paper/4baf6f668b6b10a33a16f12aa51b0edef02b1c35,""Knowledge graph (KG) reasoning is becoming increasingly popular in both academia and industry. Conventional KG reasoning based on symbolic logic is deterministic, with reasoning results being explainable, while modern embedding-based reasoning can deal with uncertainty and predict plausible knowledge, often with high efficiency via vector computation. A promising direction is to integrate both logic-based and embedding-based methods, with the vision to have advantages of both. It has attracted wide research attention with more and more works published in recent years. In this paper, we comprehensively survey these works, focusing on how logics and embeddings are integrated. We first briefly introduce preliminaries, then systematically categorize and discuss works of logic and embedding-aware KG reasoning from different perspectives, and finally conclude and discuss the challenges and further directions."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Meta-Learning Based Knowledge Extrapolation for Knowledge Graphs in the Federated Setting,A model trained on an existing knowledge graph needs to embed an emerging knowledge graph with unseen entities and relations.,""Mingyang Chen, Wen Zhang, Zhen Yao, Xian-gan Chen, Mengxiao Ding, Fei Huang, Huajun Chen"",International Joint Conference on Artificial Intelligence,,,10.48550/arXiv.2205.04692,,2022,5,https://doi.org/10.48550/arXiv.2205.04692,https://semanticscholar.org/paper/c943efc1e766a08f67b1364c13292092b17592b1,""We study the knowledge extrapolation problem to embed new components (i.e., entities and relations) that come with emerging knowledge graphs (KGs) in the federated setting. In this problem, a model trained on an existing KG needs to embed an emerging KG with unseen entities and relations. To solve this problem, we introduce the meta-learning setting, where a set of tasks are sampled on the existing KG to mimic the link prediction task on the emerging KG. Based on sampled tasks, we meta-train a graph neural network framework that can construct features for unseen components based on structural information and output embeddings for them. Experimental results show that our proposed method can effectively embed unseen components and outperforms models that consider inductive settings for KGs and baselines that directly use conventional KG embedding methods."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Multi-level Recommendation Reasoning over Knowledge Graphs with Reinforcement Learning,A multi-level reasoning path extraction method is proposed.,""Xiting Wang, Kunpeng Liu, Dongjie Wang, Le Wu, Yanjie Fu, Xing Xie"",WWW,,,10.1145/3485447.3512083,,2022,13,https://doi.org/10.1145/3485447.3512083,https://semanticscholar.org/paper/55ffe44c1dcec3f88136d2d0c81d961da8e0e3ad,""Knowledge graphs (KGs) have been widely used to improve recommendation accuracy. The multi-hop paths on KGs also enable recommendation reasoning, which is considered a crystal type of explainability. In this paper, we propose a reinforcement learning framework for multi-level recommendation reasoning over KGs, which leverages both ontology-view and instance-view KGs to model multi-level user interests. This framework ensures convergence to a more satisfying solution by effectively transferring high-level knowledge to lower levels. Based on the framework, we propose a multi-level reasoning path extraction method, which automatically selects between high-level concepts and low-level ones to form reasoning paths that better reveal user interests. Experiments on three datasets demonstrate the effectiveness of our method."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"A Modular Reasoning Approach to Knowledge Graph,The proposed approach can deal with large-scale Knowledge Graphs in a modular way with less time and memory.,""Changlong Wang, Siyun Bi, Rong Zhang, Qibin Fu, Tingting Gan"",International Conference on Advanced Computer Theory and Engineering,,,10.1109/ICACTE55855.2022.9943760,,2022,,https://doi.org/10.1109/ICACTE55855.2022.9943760,https://semanticscholar.org/paper/6050e5291b75f3e8621f559b0a2672509fe42d86,""The construction and application of Knowledge Graph require effective reasoning support. However, the standard reasoning engines can not effectively deal with large-scale Knowledge Graphs because they load and compute Knowledge Graphs as a whole. This paper proposes a modular reasoning approach to Knowledge Graph. Firstly, the facts in the Knowledge Graph are partitioned into modules according to the predicate type and entity. Then the concepts and attributes involved in the fact module are used as seed signatures to extract the ontology module from the schema. During the reasoning procedure, the reasoning engine partially loads fact modules and the related ontology modules. Experiments show that the proposed approach can deal with large-scale Knowledge Graphs in a modular way with less time and memory."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Reasoning in Knowledge Graphs,Knowledge graphs are becoming increasingly popular in the industry and academia.,""Ricardo Guimarães, A. Ozaki"",,,,,,2022,,,https://semanticscholar.org/paper/c32e70cf97faa8d8b5b49e0eacdfe778efc4e337,""Knowledge Graphs (KGs) are becoming increasingly popular in the industry and academia. They can be represented as labelled graphs conveying structured knowledge in a domain of interest, where nodes and edges are enriched with metaknowledge such as time validity, provenance, language, among others. Once the data is structured as a labelled graph one can apply reasoning techniques to extract relevant and insightful information. We provide an overview of deductive and inductive reasoning approaches for reasoning in KGs. 2012 ACM Subject Classification Computing methodologies ? Knowledge representation and reasoning"",,Review",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"A*Net: A Scalable Path-based Reasoning Approach for Knowledge Graphs,A*Net achieves competitive performance with existing state-of-the-art path-based methods.,""Zhaocheng Zhu, Xinyu Yuan, Mikhail Galkin, Sophie Xhonneux, Ming Zhang, Maxime Gazeau, Jian Tang"",,,,,,2022,,,https://semanticscholar.org/paper/e8fd5c34e0be01c5d7c707b90ad245cd46738448,""Reasoning on large-scale knowledge graphs has been long dominated by embedding methods. While path-based methods possess the inductive capacity that embeddings lack, they suffer from the scalability issue due to the exponential number of paths. Here we present A*Net, a scalable path-based method for knowledge graph reasoning. Inspired by the A* algorithm for shortest path problems, our A*Net learns a priority function to select important nodes and edges at each iteration, to reduce time and memory footprint for both training and inference. The ratio of selected nodes and edges can be specified to trade off between performance and efficiency. Experiments on both transductive and inductive knowledge graph reasoning benchmarks show that A*Net achieves competitive performance with existing state-of-the-art path-based methods, while merely visiting 10% nodes and 10% edges at each iteration. On a million-scale dataset ogbl-wikikg2, A*Net achieves competitive performance with embedding methods and converges faster. To our best knowledge, A*Net is the first path-based method for knowledge graph reasoning at such a scale."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Reinforcement Recommendation Reasoning through Knowledge Graphs for Explanation Path Quality,Existing explainable recommendation approaches based on KG merely optimize the selected reasoning paths for product relevance.,""Giacomo Balloccu, Ludovico Boratto, G. Fenu, M. Marras"",Knowledge-Based Systems,,2.192 (1076),10.48550/arXiv.2209.04954,,2022,1,https://doi.org/10.48550/arXiv.2209.04954,https://semanticscholar.org/paper/bd14740c229ce4cea669186b97f4a468fa0bef3e,""Numerous Knowledge Graphs (KGs) are being created to make Recommender Systems (RSs) not only intelligent but also knowl-edgeable. Integrating a KG in the recommendation process allows the underlying model to extract reasoning paths between recommended products and already experienced products from the KG. These paths can be leveraged to generate textual explanations to be provided to the user for a given recommendation. However, the existing explainable recommendation approaches based on KG merely optimize the selected reasoning paths for product relevance, without considering any user-level property of the paths for explanation. In this paper, we propose a series of quantitative properties that monitor the quality of the reasoning paths from an explanation perspective, based on recency, popularity, and diversity. We then combine in- and post-processing approaches to optimize for both recommendation quality and reasoning path quality. Experiments on three public data sets show that our approaches sig-ni?cantly increase reasoning path quality according to the proposed properties, while preserving recommendation quality. Source code, data sets, and KGs are available at https://tinyurl.com/bdbfzr4n ."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Hierarchical Multihop Reasoning on Knowledge Graphs,A hierarchical reinforcement learning algorithm to model the reasoning process more effectively.,""Zikang Wang, Linjing Li, D. Zeng"",IEEE Intelligent Systems,,1.572 (1933),10.1109/MIS.2021.3095055,,2022,,https://doi.org/10.1109/MIS.2021.3095055,https://semanticscholar.org/paper/a31a9098380f08b03ec9ec59b35bee1154c381d5,""Multihop knowledge reasoning aims to find missing entities for incomplete triples by finding paths on knowledge graphs. It is a fundamental and important task. In this article, we devise a hierarchical reinforcement learning algorithm to model the reasoning process more effectively. Unlike existing methods directly reason on entities and relations, we adopt a high-level reasoning layer to deal with abstract concepts, which guides the reasoning process conducted at the low level for concrete entities and relations. Our approach yields competitive results on link prediction on both NELL-995 and FB15k-237 datasets. The comparison to baselines also demonstrates the effectiveness of the hierarchical structure."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Knowledge Graph Reasoning with Logics and Embeddings: Survey and Perspective,Logic-based and embedding-based methods are integrated in knowledge graph reasoning.,""Wen Zhang, Jiaoyan Chen, Juan Li, Zezhong Xu, Jeff Z. Pan, Huajun Chen"",ArXiv,,,,,2022,3,,https://semanticscholar.org/paper/4baf6f668b6b10a33a16f12aa51b0edef02b1c35,""Knowledge graph (KG) reasoning is becoming increasingly popular in both academia and industry. Conventional KG reasoning based on symbolic logic is deterministic, with reasoning results being explainable, while modern embedding-based reasoning can deal with uncertainty and predict plausible knowledge, often with high efficiency via vector computation. A promising direction is to integrate both logic-based and embedding-based methods, with the vision to have advantages of both. It has attracted wide research attention with more and more works published in recent years. In this paper, we comprehensively survey these works, focusing on how logics and embeddings are integrated. We first briefly introduce preliminaries, then systematically categorize and discuss works of logic and embedding-aware KG reasoning from different perspectives, and finally conclude and discuss the challenges and further directions."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"An Overview of Knowledge Graph Reasoning: Key Technologies and Applications,Knowledge graph-oriented knowledge reasoning aims to deduce new knowledge or identify wrong knowledge from existing knowledge.,""Yonghong Chen, Hao Li, Han Li, Wenhao Liu, Yirui Wu, Qian Huang, Shaohua Wan"",J. Sens. Actuator Networks,,,10.3390/jsan11040078,https://www.mdpi.com/2224-2708/11/4/78/pdf?version=1669276833,2022,1,https://doi.org/10.3390/jsan11040078,https://semanticscholar.org/paper/f80ee5510c9b8259250013887e141b0556bb5464,""In recent years, with the rapid development of Internet technology and applications, the scale of Internet data has exploded, which contains a significant amount of valuable knowledge. The best methods for the organization, expression, calculation, and deep analysis of this knowledge have attracted a great deal of attention. The knowledge graph has emerged as a rich and intuitive way to express knowledge. Knowledge reasoning based on knowledge graphs is one of the current research hot spots in knowledge graphs and has played an important role in wireless communication networks, intelligent question answering, and other applications. Knowledge graph-oriented knowledge reasoning aims to deduce new knowledge or identify wrong knowledge from existing knowledge. Different from traditional knowledge reasoning, knowledge reasoning methods oriented to knowledge graphs are more diversified due to the concise, intuitive, flexible, and rich knowledge expression forms in knowledge graphs. Based on the basic concepts of knowledge graphs and knowledge graph reasoning, this paper introduces the latest research progress in knowledge graph-oriented knowledge reasoning methods in recent years. Specifically, according to different reasoning methods, knowledge graph reasoning includes rule-based reasoning, distributed representation-based reasoning, neural network-based reasoning, and mixed reasoning. These methods are summarized in detail, and the future research directions and prospects of knowledge reasoning based on knowledge graphs are discussed and prospected."",,Review",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Towards Loosely-Coupling Knowledge Graph Embeddings and Ontology-based Reasoning,The prediction accuracy of knowledge graph embeddings is enhanced by domain knowledge that may not be included in the input knowledge graph.,""Zoi Kaoudi, Abelardo Carlos Mart??nez Lorenzo, V. Markl"",ArXiv,,,,,2022,2,,https://semanticscholar.org/paper/8ef2e6b11b519b609bfaa7ed056f621cee15d552,""Knowledge graph completion (a.k.a. link prediction), i.e., the task of inferring missing information from knowledge graphs, is a widely used task in many applications, such as product recommendation and question answering. The state-of-the-art approaches of knowledge graph embeddings and/or rule mining and reasoning are data-driven and, thus, solely based on the information the input knowledge graph contains. This leads to unsatisfactory prediction results which make such solutions inapplicable to crucial domains such as healthcare. To further enhance the accuracy of knowledge graph completion we propose to loosely-couple the data-driven power of knowledge graph embeddings with domain-specific reasoning stem-ming from experts or entailment regimes (e.g., OWL2). In this way, we not only enhance the prediction accuracy with domain knowledge that may not be included in the input knowledge graph but also allow users to plugin their own knowledge graph embedding and reasoning method. Our initial results show that we enhance the MRR accuracy of vanilla knowledge graph embeddings by up to 3x and outperform hybrid solutions that combine knowledge graph embeddings with rule mining and reasoning up to 3.5x MRR."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Graph Intention Neural Network for Knowledge Graph Reasoning,The external-intention can capture relevancy among the reasoning hops.,""Weihao Jiang, Yao Fu, Hong Zhao, Junhong Wan, Shi Pu"",IEEE International Joint Conference on Neural Network,,,10.1109/IJCNN55064.2022.9892730,,2022,,https://doi.org/10.1109/IJCNN55064.2022.9892730,https://semanticscholar.org/paper/fbd32c616c0d74aecea410594c88fdfb723e085b,""Reasoning over knowledge graph explores valuable information for amounts of tasks. However, most methods adopt the coarse-grained and single representation of each entity for reasoning, ignoring simultaneously processing various semantics contained in internal information and external information. On the one hand, the surrounding nodes and relations existing in the graph structure express the internal information of the entity, which contains abundant graph context information, but the extracted internal features are still limited. On the other hand, different scenarios as the external information focus on different aspects of the certain entity, meanwhile the external information should have message interaction with the internal information to learn the adaptive embedding, both of which are seldom considered by the existing methods. In this paper, we propose a Graph Intention Neural Network (GINN) for knowledge graph reasoning to explore fine-grained entity representations, which use external-intention and internal-intention simultaneously. For external-intention, a novel constructed matrix is used to calculate the triple-attention that determines the aggregated information to learn different embeddings adapting to the different scenarios. Furthermore, a communication bridge is leveraged to have message interaction between the external information and the internal information. For the internal-intention, the surrounding nodes and relations are integrated to update the entity embedding with the consideration of the interaction features between the external and internal information. The triple-attention can capture relevancy among the reasoning hops, which contributes to figuring out reasonable paths. We evaluate our approach on real-world datasets, achieving better performance compared to the state-of-the-art methods and showing plausible interpretability for the results."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Multi-level Recommendation Reasoning over Knowledge Graphs with Reinforcement Learning,A multi-level reasoning path extraction method is proposed.,""Xiting Wang, Kunpeng Liu, Dongjie Wang, Le Wu, Yanjie Fu, Xing Xie"",WWW,,,10.1145/3485447.3512083,,2022,13,https://doi.org/10.1145/3485447.3512083,https://semanticscholar.org/paper/55ffe44c1dcec3f88136d2d0c81d961da8e0e3ad,""Knowledge graphs (KGs) have been widely used to improve recommendation accuracy. The multi-hop paths on KGs also enable recommendation reasoning, which is considered a crystal type of explainability. In this paper, we propose a reinforcement learning framework for multi-level recommendation reasoning over KGs, which leverages both ontology-view and instance-view KGs to model multi-level user interests. This framework ensures convergence to a more satisfying solution by effectively transferring high-level knowledge to lower levels. Based on the framework, we propose a multi-level reasoning path extraction method, which automatically selects between high-level concepts and low-level ones to form reasoning paths that better reveal user interests. Experiments on three datasets demonstrate the effectiveness of our method."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Learning to Efficiently Propagate for Reasoning on Knowledge Graphs,A*Net achieves competitive performance with existing state-of-the-art path-based methods.,""Zhaocheng Zhu, Xinyu Yuan, Louis-Pascal Xhonneux, Ming Zhang, M. Gazeau, Jian Tang"",ArXiv,,,10.48550/arXiv.2206.04798,,2022,,https://doi.org/10.48550/arXiv.2206.04798,https://semanticscholar.org/paper/db7558d3cd8c621f3ebd563e85815092c003747c,""Path-based methods are more appealing solutions than embedding methods for knowledge graph reasoning, due to their interpretability and generalization ability to unseen graphs. However, path-based methods usually suffer from the problem of scalability, as the time complexity grows exponentially w.r.t. the length of paths. While recent methods compute reasoning paths with the Bellman-Ford algorithm in polynomial time, the time and memory cost remains very high, as they need to propagate through all the nodes and edges in the graph. In this paper, we propose A*Net, an efficient model for path-based reasoning on knowledge graphs. Inspired by the classical A* algorithm for shortest path problems, our A*Net prioritizes important nodes and edges at each propagation step, to reduce the time and memory footprint. Unlike the classical A* algorithm that uses a heuristic function, we propose to learn the priority function for each node to capture the complex semantics in knowledge graphs. The priority function and the propagation steps are jointly optimized through backpropagation. Experiments on both transductive and inductive knowledge graph reasoning benchmarks show that A*Net achieves competitive performance with existing state-of-the-art path-based methods, and meanwhile reduces the number of messages, the time and the memory cost up to 7.2×, 3.4× and 4.9× respectively."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"A Joint Knowledge Graph Reasoning Method,Traditional knowledge graph reasoning methods can not meet the requirements of MEC for low latency and fewer resources.,""Wenqing Yang, Xiaochao Li, Peng Wang, J. Hou, Qianmu Li, N. Zhang"",""2022 IEEE Intl Conf on Dependable, Autonomic and Secure Computing, Intl Conf on Pervasive Intelligence and Computing, Intl Conf on Cloud and Big Data Computing, Intl Conf on Cyber Science and Technology Congress (DASC/PiCom/CBDCom/CyberSciTech)"",,,10.1109/DASC/PiCom/CBDCom/Cy55231.2022.9927812,,2022,,https://doi.org/10.1109/DASC/PiCom/CBDCom/Cy55231.2022.9927812,https://semanticscholar.org/paper/3e4b7a6d5ea1d1f2369e70452b79b4c17762ef6e,""Facing the massive data generated by edge intelligent interconnection applications in the mobile edge computing (MEC) environment, timely and efficient data mining has become an urgent technical problem to be solved. Knowledge graph reasoning is a promising solution to the above challenges. However, the traditional knowledge graph reasoning method can not meet the requirements of MEC for low latency and fewer resources. This paper presents a MEC-oriented knowledge graph reasoning method gate recursive unit for logic reasoning (GRULR). Specifically, the technology regards logical rules as variables and trains two models in an iterative manner under the MEC architecture, namely, Rule Miner and Reasoning Evaluator. The two models are deployed in the central cloud and the edge cloud respectively, jointly trained and mutually enhanced. Rule Miner generates rule sequences based on gate recurrent unit (GRU) network, and optimizes network parameters by using high-quality rules generated by Reasoning Evaluator. Experiments show that this method has a good edge reasoning effect, and can generate high-quality logic rules and send them to the central cloud server for sharing."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Towards Unsupervised Machine Learning Approaches for Knowledge Graphs,A proposed approach can defeat current state-of-the-art unsupervised methods.,""Filippo Minutella, F. Falchi, P. Manghi, M. Bonis, Nicola Messina"",Italian Research Conference on Digital Library Management Systems,,,,,2022,,,https://semanticscholar.org/paper/9ad697897f63312f1747d042c8cd7381aab07b57,""Nowadays, a lot of data is in the form of Knowledge Graphs aiming at representing information as a set of nodes and relationships between them. This paper proposes an efficient framework to create informative embeddings for node classification on large knowledge graphs. Such embeddings capture how a particular node of the graph interacts with his neighborhood and indicate if it is either isolated or part of a bigger clique. Since a homogeneous graph is necessary to perform this kind of analysis, the framework exploits the metapath approach to split the heterogeneous graph into multiple homogeneous graphs. The proposed pipeline includes an unsupervised attentive neural network to merge different metapaths and produce node embeddings suitable for classification. Preliminary experiments on the IMDb dataset demonstrate the validity of the proposed approach, which can defeat current state-of-the-art unsupervised methods."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Neural Methods for Logical Reasoning over Knowledge Graphs,Neural network models achieve a 10% relative increase over the best performing state of the art.,""Alfonso Amayuelas, Shuai Zhang, Susie Xi Rao, Ce Zhang"",International Conference on Learning Representations,,,10.48550/arXiv.2209.14464,,2022,4,https://doi.org/10.48550/arXiv.2209.14464,https://semanticscholar.org/paper/2d80d0b053179988f2155ea9eaf57b60a7742c16,""Reasoning is a fundamental problem for computers and deeply studied in Arti?cial Intelligence. In this paper, we speci?cally focus on answering multi-hop logical queries on Knowledge Graphs (KGs). This is a complicated task because, in real-world scenarios, the graphs tend to be large and incomplete. Most previous works have been unable to create models that accept full First-Order Logical (FOL) queries, which include negative queries, and have only been able to process a limited set of query structures. Additionally, most methods present logic operators that can only perform the logical operation they are made for. We introduce a set of models that use Neural Networks to create one-point vector embeddings to answer the queries. The versatility of neural networks allows the framework to handle FOL queries with Conjunction ( ? ), Disjunction ( ? ) and Negation ( ¬ ) operators. We demonstrate experimentally the performance of our model through extensive experimentation on well-known benchmarking datasets. Besides having more versatile operators, the models achieve a 10% relative increase over the best performing state of the art and more than 30% over the original method based on single-point vector embeddings."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Reasoning Through Memorization: Nearest Neighbor Knowledge Graph Embeddings,A knowledge graph embedding approach with pre-trained language models can allow rare or emerging entities to be memorized explicitly rather than implicitly in model parameters.,""Ningyu Zhang, Xin Xie, Xiang Chen, Shumin Deng, Chuanqi Tan, Fei Huang, Xu Cheng, Huajun Chen"",ArXiv,,,,,2022,7,,https://semanticscholar.org/paper/072f7b3b68c930c4e01fc2ed1c54fcdc5e916a04,""Previous knowledge graph embedding approaches usually map entities to representations and utilize score functions to predict the target entities, yet they typically struggle to reason rare or emerging unseen entities. In this paper, we propose kNN-KGE, a new knowledge graph embedding approach with pre-trained language models, by linearly interpolating its entity distribution with k-nearest neighbors. We compute the nearest neighbors based on the distance in the entity embedding space from the knowledge store. Our approach can allow rare or emerging entities to be memorized explicitly rather than implicitly in model parameters. Experimental results demonstrate that our approach can improve inductive and transductive link prediction results and yield better performance for low-resource settings with only a few triples, which might be easier to reason via explicit memory. Code is available at https://github.com/zjunlp/KNN-KG."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Reasoning Through Memorization: Nearest Neighbor Knowledge Graph Embeddings,A knowledge graph embedding approach with pre-trained language models can allow rare or emerging entities to be memorized explicitly rather than implicitly in model parameters.,""Ningyu Zhang, Xin Xie, Xiang Chen, Shumin Deng, Chuanqi Tan, Fei Huang, Xu Cheng, Huajun Chen"",ArXiv,,,,,2022,7,,https://semanticscholar.org/paper/b30759d87369a5fadd7d252ec8514abfba68ca10,""Previous knowledge graph embedding approaches usually map entities to representations and utilize score functions to predict the target entities, yet they struggle to reason rare or emerging unseen entities. In this paper, we propose kNN-KGE, a new knowledge graph embedding approach with pre-trained language models, by linearly interpolating its entity distribution with k-nearest neighbors.We compute the nearest neighbors based on the distance in the entity embedding space from the knowledge store. Our approach can allow rare or emerging entities to be memorized explicitly rather than implicitly in model parameters. Experimental results demonstrate that our approach can improve inductive and transductive link prediction results and yield better performance for low-resource settings with only a few triples, which might be easier to reason via explicit memory1."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Reinforcement Recommendation Reasoning through Knowledge Graphs for Explanation Path Quality,The proposed quantitative properties monitor the quality of reasoning paths.,""Giacomo Balloccu, Ludovico Boratto, G. Fenu, M. Marras"",,,,,,2022,,,https://semanticscholar.org/paper/17b3579e426174c0869f19dc738f88cb8912a291,""Numerous Knowledge Graphs (KGs) are being created to make recommender systems not only intelligent but also knowledgeable. Reinforcement recommendation reasoning is a recent approach able to model high-order userproduct relations, according to the KG. This type of approach makes it possible to extract reasoning paths between the recommended product and already experienced products. These paths can be in turn translated into textual explanations to be provided to the user for a given recommendation. However, none of the existing approaches has investigated user-level properties of a single or a group of reasoning paths. In this paper, we propose a series of quantitative properties that monitor the quality of the reasoning paths, based on recency, popularity, and diversity. We then combine inand post-processing approaches to optimize for both recommendation quality and reasoning path quality. Experiments on three public data sets show that our approaches significantly increase reasoning path quality according to the proposed properties, while preserving recommendation quality. Source code, data sets, and KGs are available at https://tinyurl.com/bdbfzr4n."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Knowledge Reasoning via Jointly Modeling Knowledge Graphs and Soft Rules,A proposed approach combines the benefits of both rules and knowledge graph embeddings.,""Yinyu Lan, Shizhu He, Kang Liu, Jun Zhao"",ArXiv,,,10.48550/arXiv.2301.02781,,2023,,https://doi.org/10.48550/arXiv.2301.02781,https://semanticscholar.org/paper/c51525467eb7929f375c6c759c8c057b09cabd92,""Knowledge graphs (KGs) play a crucial role in many applications, such as question answering, but incom-pleteness is an urgent issue for their broad application. Much research in knowledge graph completion (KGC) has been performed to resolve this issue. The methods of KGC can be classi?ed into two major categories: rule-based reasoning and embedding-based reasoning. The former has high accuracy and good interpretability, but a major challenge is to obtain e?ective rules on large-scale KGs. The latter has good e?ciency and scalability, but it relies heavily on data richness and cannot fully use domain knowledge in the form of logical rules. We propose a novel method that injects rules and learns representations iteratively to take full advantage of rules and embeddings. Speci?cally, we model the conclusions of rule groundings as 0-1 variables and use a rule con?dence regularizer to remove the uncertainty of the conclusions. The proposed approach has the following advantages: 1) It combines the bene?ts of both rules and knowledge graph embeddings (KGEs) and achieves a good balance between e?ciency and scalability. 2) It uses an iterative method to continuously improve KGEs and remove incorrect rule conclusions. Evaluations on two public datasets show that our method outperforms the current state-of-the-art methods, improving performance by 2.7% and 4.3% in mean reciprocal rank (MRR)."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Analysis of Knowledge Graph Path Reasoning Based on Variational Reasoning,Knowledge graph reasoning improves model accuracy and enhancing model learning and reasoning capabilities.,""Hongmei Tang, Wenzhong Tang, Ruichen Li, Yanyang Wang, Shuai Wang, Lihong Wang"",Applied Sciences,,0.44 (11182),10.3390/app12126168,https://www.mdpi.com/2076-3417/12/12/6168/pdf?version=1655459548,2022,,https://doi.org/10.3390/app12126168,https://semanticscholar.org/paper/8f56e567f1b6df0d3e80e1604520bf2cd5c23209,""Knowledge graph (KG) reasoning improves the perception ability of graph structure features, improving model accuracy and enhancing model learning and reasoning capabilities. This paper proposes a new GraphDIVA model based on the variational reasoning divergent autoencoder (DIVA) model. The network structures and calculation processes of the models are analyzed. The GraphSAGE algorithm is introduced into the path reasoning module to solve the inability of the original model to perceive the features of the graph structure, which leads to a decline in the accuracy rate. Hence, GraphDIVA can achieve a higher accuracy rate with fewer learning iterations. The experiments show the efficiency and effectiveness of our model and proves that our method has a better effect on the accuracy rate and training difficulty than the baseline model on the FB15k-237 and NELL-995 benchmark datasets."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Towards Hybrid Logic-based and Embedding-based Reasoning on Financial Knowledge Graphs,A framework that jointly uses logic-based reasoning and knowledge graph embeddings to provide a scalable alternative to basic isomorphism checks in ontological reasoning.,""A. Vlad, S. Vahdati, M. Nayyeri, Luigi Bellomarini, Emanuel Sallinger"",EDBT/ICDT Workshops,,,,,2022,,,https://semanticscholar.org/paper/54e41154a861067345343804cdc5d060f29ed145,""Warded Datalog+/- is a Datalog-based KRR language that guarantees decidability and tractability of the ontological reasoning task, thanks to its favourable theoretical properties. The Vadalog reasoning system exploits Warded Datalog+/- to provide a practical implementation of different reasoning tasks via basic isomorphism checks. However, these can be prohibitive in space and time complexity especially in the economic and financial context which is characterised by extreme-scale data stores and complex societal network dynamics. Recently, Knowledge Graph Embeddings (KGEs) have gained great interest in the scientific community and have extensively improved learning and knowledge discovery techniques. In this paper, we present and provide an experimental evaluation of Vada-ER, a framework that jointly uses logic-based reasoning and KGEs to provide a scalable alternative to basic isomorphism checks in ontological reasoning. With our work, we aim to improve the synergy between the reasoning and the embedding technologies and communities."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Reasoning over Different Types of Knowledge Graphs: Static, Temporal and Multi-Modal,Knowledge graph reasoning is a fast-growing research direction.,""K. Liang, Lingyuan Meng, Meng Liu, Yue Liu, Wenxuan Tu, Siwei Wang, Sihang Zhou, Xinwang Liu, Fu Sun"",ArXiv,,,10.48550/arXiv.2212.05767,,2022,3,https://doi.org/10.48550/arXiv.2212.05767,https://semanticscholar.org/paper/4b963961f9990dea41133cd09109da1b3fed531f,""—Knowledge graph reasoning (KGR), aiming to deduce new facts from existing facts based on mined logic rules underlying knowledge graphs (KGs), has become a fast-growing research direction. It has been proven to signi?cantly bene?t the usage of KGs in many AI applications, such as question answering and recommendation systems, etc. According to the graph types, the existing KGR models can be roughly divided into three categories, i.e., static models, temporal models, and multi-modal models. The early works in this domain mainly focus on static KGR and tend to directly apply general knowledge graph embedding models to the reasoning task. However, these models are not suitable for more complex but practical tasks, such as inductive static KGR, temporal KGR, and multi-modal KGR. To this end, multiple works have been developed recently, but no survey papers and open-source repositories comprehensively summarize and discuss models in this important direction. To ?ll the gap, we conduct a survey for knowledge graph reasoning tracing from static to temporal and then to multi-modal KGs. Concretely, the preliminaries, summaries of KGR models, and typical datasets are introduced and discussed consequently. Moreover, we discuss the challenges and potential opportunities. The corresponding open-source repository is shared on GitHub: https://github.com/LIANGKE23/Awesome-Knowledge-Graph-Reasoning."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Reasoning Through Memorization: Nearest Neighbor Knowledge Graph Embeddings,A knowledge graph embedding approach can allow rare or emerging entities to be memorized explicitly rather than implicitly in model parameters.,""Ningyu Zhang, Xin Xie, Xiang Chen, Shumin Deng, Chuanqi Tan, Fei Huang, Xu Cheng, Huajun Chen"",ArXiv,,,,,2022,5,,https://semanticscholar.org/paper/5a61585cea70ad0ec228d47acddc623103efca1b,""Previous knowledge graph embedding approaches usually map entities to representations and utilize score functions to predict the target entities, yet they struggle to reason rare or emerging unseen entities. In this paper, we propose kNN-KGE, a new knowledge graph embedding approach, by linearly interpolating its entity distribution with knearest neighbors. We compute the nearest neighbors based on the distance in the entity embedding space from the knowledge store. Our approach can allow rare or emerging entities to be memorized explicitly rather than implicitly in model parameters. Experimental results demonstrate that our approach can improve inductive and transductive link prediction results and yield better performance for low-resource settings with only a few triples, which might be easier to reason via explicit memory1."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Heuristic-based Reasoning on Financial Knowledge Graphs,A fitting heuristic that guides the reasoning process provides an optimized way to answer a BCQ.,""Teodoro Baldazzi, Davide Benedetto, M. Brandetti, A. Vlad, Luigi Bellomarini"",EDBT/ICDT Workshops,,,,,2022,,,https://semanticscholar.org/paper/5f2a4e7e66aaea7a4a1ce71db259ff51a07a58dc,""When reasoning over large knowledge graphs, Datalog+/- languages offer a good trade-off between expressive power and computational complexity. However, in case of considerably large inputs and in the presence of recursive rules, even state-of-the-art reasoners struggle to accomplish reasoning tasks, e.g. answering Boolean Conjuctive Queries (BCQs). To address this problem, we introduce the notion of heuristic-based reasoning, that is, evaluating Datalog+/- rules according to an order of the facts determined via a user-defined heuristic. We show that adopting a fitting heuristic that guides the reasoning process provides an optimized way to answer a BCQ. To achieve this behaviour in practice, we enrich Datalog+/- programs with a context-aware operator, which we name Dynamic Hint Operator. We apply our new methodology to efficiently solve the Close Link problem on the knowledge graph of Italian companies, a relevant financial problem that estimates the risk to grant a specific loan to a company that is backed by collateral issued by another company."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Reasoning over Different Types of Knowledge Graphs: Static, Temporal and Multi-Modal,Knowledge graph reasoning is a fast-growing research direction.,""K. Liang, Lingyuan Meng, Meng Liu, Yue Liu, Wenxuan Tu, Siwei Wang, Sihang Zhou, Xinwang Liu, Fu Sun"",ArXiv,,,10.48550/arXiv.2212.05767,,2022,3,https://doi.org/10.48550/arXiv.2212.05767,https://semanticscholar.org/paper/3cf49f9962183823dcdab4c799e292b6ea9faede,""—Knowledge graph reasoning (KGR), aiming to deduce new facts from existing facts based on mined logic rules underlying knowledge graphs (KGs), has become a fast-growing research direction. It has been proven to signi?cantly bene?t the usage of KGs in many AI applications, such as question answering and recommendation systems, etc. According to the graph types, the existing KGR models can be roughly divided into three categories, i.e., static models, temporal models, and multi-modal models. The early works in this domain mainly focus on static KGR and tend to directly apply general knowledge graph embedding models to the reasoning task. However, these models are not suitable for more complex but practical tasks, such as inductive static KGR, temporal KGR, and multi-modal KGR. To this end, multiple works have been developed recently, but no survey papers and open-source repositories comprehensively summarize and discuss models in this important direction. To ?ll the gap, we conduct a survey for knowledge graph reasoning tracing from static to temporal and then to multi-modal KGs. Concretely, the preliminaries, summaries of KGR models, and typical datasets are introduced and discussed consequently. Moreover, we discuss the challenges and potential opportunities. The corresponding open-source repository is shared on GitHub: https://github.com/LIANGKE23/Awesome-Knowledge-Graph-Reasoning."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Inductive Knowledge Graph Reasoning for Multi-batch Emerging Entities,A graph convolutional network with adaptive relation aggregation is designed to encode and update entities using their neighboring relations.,""Yuanning Cui, Yuxin Wang, Zequn Sun, Wenqiang Liu, Yiqiao Jiang, Kexin Han, Wei Hu"",International Conference on Information and Knowledge Management,,,10.1145/3511808.3557361,http://arxiv.org/pdf/2208.10378,2022,2,https://doi.org/10.1145/3511808.3557361,https://semanticscholar.org/paper/80d3e96228da4309edc768145ceffdc841776d6a,""Over the years, reasoning over knowledge graphs (KGs), which aims to infer new conclusions from known facts, has mostly focused on static KGs. The unceasing growth of knowledge in real life raises the necessity to enable the inductive reasoning ability on expanding KGs. Existing inductive work assumes that new entities all emerge once in a batch, which oversimplifies the real scenario that new entities continually appear. This study dives into a more realistic and challenging setting where new entities emerge in multiple batches. We propose a walk-based inductive reasoning model to tackle the new setting. Specifically, a graph convolutional network with adaptive relation aggregation is designed to encode and update entities using their neighboring relations. To capture the varying neighbor importance, we employ a query-aware feedback attention mechanism during the aggregation. Furthermore, to alleviate the sparse link problem of new entities, we propose a link augmentation strategy to add trustworthy facts into KGs. We construct three new datasets for simulating this multi-batch emergence scenario. The experimental results show that our proposed model outperforms state-of-the-art embedding-based, walk-based and rule-based models on inductive KG reasoning."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Comparative Reasoning for Knowledge Graph Fact Checking,A graph neural network based model INSPECTOR for pair-wise fact checking outperforms state-of-the-art methods.,""Lihui Liu, Houxiang Ji, Jiejun Xu, H. Tong"",2022 IEEE International Conference on Big Data (Big Data),,,10.1109/BigData55660.2022.10020991,,2022,,https://doi.org/10.1109/BigData55660.2022.10020991,https://semanticscholar.org/paper/93a28b3b6afae5268867a712c219a62141d60e01,""Knowledge graph has been widely used in fact checking, owing to its capability to provide crucial background knowledge to help verify claims. Traditional fact checking works mainly focus on analyzing a single claim but have largely ignored analysis on the semantic consistency of pair-wise claims, despite its key importance in the real-world applications, e.g., multimodal fake news detection. This paper proposes a graph neural network based model INSPECTOR for pair-wise fact checking. Given a pair of claims, INSPECTOR aims to detect the potential semantic inconsistency of the input claims. The main idea of INSPECTOR is to use a graph attention neural network to learn a graph embedding for each claim in the pair, then use a tensor neural network to classify this pair of claims as consistent vs. inconsistent. The experiment results show that our algorithm outperforms state-of-the-art methods, with a higher accuracy and a lower variance."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Defining a Knowledge Graph Development Process Through a Systematic Review,A proposed process suggests a unified approach and provides guidance for both researchers and practitioners when constructing and managing knowledge graphs.,""Gyt? Tamašauskait?, Paul Groth"",ACM Transactions on Software Engineering and Methodology,,1.7 (1681),10.1145/3522586,https://dl.acm.org/doi/pdf/10.1145/3522586,2022,2,https://doi.org/10.1145/3522586,https://semanticscholar.org/paper/b5013706bf4e23886b2d6abf06567aad006d37cc,""Knowledge graphs are widely used in industry and studied within the academic community. However, the models applied in the development of knowledge graphs vary. Analysing and providing a synthesis of the commonly used approaches to knowledge graph development would provide researchers and practitioners a better understanding of the overall process and methods involved. Hence, this paper aims to define the overall process of knowledge graph development and its key constituent steps. For this purpose, a systematic review and a conceptual analysis of the literature was conducted. The resulting process was compared to case studies to evaluate its applicability. The proposed process suggests a unified approach and provides guidance for both researchers and practitioners when constructing and managing knowledge graphs."",,Systematic Review",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"HyperKGQA: Question Answering over Knowledge Graphs using Hyperbolic Representation Learning,""A method that embeds the knowledge graph in a hyperbolic manifold, then learns an adaptive transformation of pre-trained sentence representations into the space of entities and relations."",""Nadya Abdel Madjid, Ola El Khatib, Shuang Gao, D. Difallah"",Industrial Conference on Data Mining,,,10.1109/ICDM54844.2022.00041,,2022,1,https://doi.org/10.1109/ICDM54844.2022.00041,https://semanticscholar.org/paper/bc5271c98d1d1fa70a443bd1803cbf98f55a86e5,""Knowledge Graph Question Answering (KGQA) models enable users to acquire entity-based answers from a Knowledge Graph by asking natural language questions (NLQs) without the need to learn a specialized graph query language or knowing the underlying schema of the knowledge graph. This work investigates hyperbolic graph representation learning methods to effectively and efficiently represent knowledge base items and natural questions. Our system, HyperKGQA, proposes a technique that embeds the knowledge graph in a hyperbolic manifold, then learns an adaptive transformation of pre-trained sentence representations into the space of entities and relations. Finally, a post-processing step refines the ranking of the candidate answers by computing the relevance score of the set of relations and the question. An extensive set of experiments conducted on two datasets shows that our method outperforms the current state-of-the-art models when reasoning over sparse graphs to answer multi-hop questions."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"TransDTI: Transformer-Based Language Models for Estimating DTIs and Building a Drug Recommendation Workflow,Transformer-based language models effectively predict novel drug-target interactions from sequence data.,""Yogesh Kalakoti, Shashank Yadav, D. Sundar"",ACS Omega,,0.708 (6756),10.1021/acsomega.1c05203,https://pubs.acs.org/doi/pdf/10.1021/acsomega.1c05203,2022,5,https://doi.org/10.1021/acsomega.1c05203,https://semanticscholar.org/paper/1caafc36c79ac4f9518d0480b49a91d83b753468,""The identification of novel drug–target interactions is a labor-intensive and low-throughput process. In silico alternatives have proved to be of immense importance in assisting the drug discovery process. Here, we present TransDTI, a multiclass classification and regression workflow employing transformer-based language models to segregate interactions between drug–target pairs as active, inactive, and intermediate. The models were trained with large-scale drug–target interaction (DTI) data sets, which reported an improvement in performance in terms of the area under receiver operating characteristic (auROC), the area under precision recall (auPR), Matthew’s correlation coefficient (MCC), and R2 over baseline methods. The results showed that models based on transformer-based language models effectively predict novel drug–target interactions from sequence data. The proposed models significantly outperformed existing methods like DeepConvDTI, DeepDTA, and DeepDTI on a test data set. Further, the validity of novel interactions predicted by TransDTI was found to be backed by molecular docking and simulation analysis, where the model prediction had similar or better interaction potential for MAP2k and transforming growth factor-? (TGF?) and their known inhibitors. Proposed approaches can have a significant impact on the development of personalized therapy and clinical decision making."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"TransDTI: Transformer-Based Language Models for Estimating DTIs and Building a Drug Recommendation Workflow,Transformer-based language models effectively predict novel drug-target interactions from sequence data.,""Yogesh  Kalakoti, Shashank  Yadav, Durai  Sundar"",ACS omega,,0.708 (6756),10.1021/acsomega.1c05203,https://pubs.acs.org/doi/pdf/10.1021/acsomega.1c05203,2022,1,https://doi.org/10.1021/acsomega.1c05203,https://semanticscholar.org/paper/e51713a71fcd40355c5fb165e20420412ab913b8,""The identification of novel drug–target interactions is a labor-intensive and low-throughput process. In silico alternatives have proved to be of immense importance in assisting the drug discovery process. Here, we present TransDTI, a multiclass classification and regression workflow employing transformer-based language models to segregate interactions between drug–target pairs as active, inactive, and intermediate. The models were trained with large-scale drug–target interaction (DTI) data sets, which reported an improvement in performance in terms of the area under receiver operating characteristic (auROC), the area under precision recall (auPR), Matthew’s correlation coefficient (MCC), and R2 over baseline methods. The results showed that models based on transformer-based language models effectively predict novel drug–target interactions from sequence data. The proposed models significantly outperformed existing methods like DeepConvDTI, DeepDTA, and DeepDTI on a test data set. Further, the validity of novel interactions predicted by TransDTI was found to be backed by molecular docking and simulation analysis, where the model prediction had similar or better interaction potential for MAP2k and transforming growth factor-? (TGF?) and their known inhibitors. Proposed approaches can have a significant impact on the development of personalized therapy and clinical decision making."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"PHTrans: Parallelly Aggregating Global and Local Representations for Medical Image Segmentation,A hybrid architecture for medical image segmentation called PHTrans achieves impressive performance.,""Wentao Liu, Tong Tian, Weijing Xu, Huihua Yang, Xipeng Pan"",International Conference on Medical Image Computing and Computer-Assisted Intervention,,,10.48550/arXiv.2203.04568,,2022,5,https://doi.org/10.48550/arXiv.2203.04568,https://semanticscholar.org/paper/08642469f80670a449349e0a18757d52de679b6f,"". The success of Transformer in computer vision has attracted increasing attention in the medical imaging community. Especially for medical image segmentation, many excellent hybrid architectures based on convolutional neural networks (CNNs) and Transformer have been presented and achieve impressive performance. However, most of these methods, which embed modular Transformer into CNNs, struggle to reach their full potential. In this paper, we propose a novel hybrid architecture for medical image segmentation called PHTrans, which parallelly hybridizes Transformer and CNN in main building blocks to produce hierarchical representations from global and local features and adap-tively aggregate them, aiming to fully exploit their strengths to obtain better segmentation performance. Speci?cally, PHTrans follows the U-shaped encoder-decoder design and introduces the parallel hybird module in deep stages, where convolution blocks and the modi?ed 3D Swin Transformer learn local features and global dependencies separately, then a sequence-to-volume operation uni?es the dimensions of the outputs to achieve feature aggregation. Extensive experimental results on both Multi-Atlas Labeling Beyond the Cranial Vault and Automated Cardiac Diagnosis Challeng datasets corroborate its e?ectiveness, consis-tently outperforming state-of-the-art methods. The code is available at: https://github.com/lseventeen/PHTrans."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"TransVPR: Transformer-based place recognition with multi-level attention aggregation,The output tokens from Transformer layers filtered by the fused attention mask are considered as key-patch descriptors.,""Ruotong  Wang, Yanqing  Shen, Weiliang  Zuo, Sanping  Zhou, Nanning  Zheng"",ArXiv,,,,,2022,2,,https://semanticscholar.org/paper/c871878ddb18dd610c111292f9d33f11d8f2f294,""Visual place recognition is a challenging task for applications such as autonomous driving navigation and mobile robot localization. Distracting elements presenting in complex scenes often lead to deviations in the perception of visual place. To address this problem, it is crucial to integrate information from only task-relevant regions into image representations. In this paper, we introduce a novel holistic place recognition model, TransVPR, based on vision Transformers. It benefits from the desirable property of the self-attention operation in Transformers which can naturally ag-gregate task-relevant features. Attentions from multiple levels of the Transformer, which focus on different regions of interest, are further combined to generate a global image representation. In addition, the output tokens from Transformer layers filtered by the fused attention mask are considered as key-patch descriptors, which are used to perform spatial matching to re-rank the candidates retrieved by the global image features. The whole model allows end-to-end training with a single objective and image-level supervision. TransVPR achieves state-of-the-art performance on several real-world benchmarks while maintaining low computational time and storage requirements. abstract the whole image into a compact feature vector without geometrical information. Patch-level descriptors"",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"UNeXt: MLP-based Rapid Medical Image Segmentation Network,The tokenized MLP block reduces the number of parameters and computational complexity while being able to result in a better representation to help segmentation.,""Jeya Maria Jose Valanarasu, Vishal M. Patel"",International Conference on Medical Image Computing and Computer-Assisted Intervention,,,10.48550/arXiv.2203.04967,,2022,21,https://doi.org/10.48550/arXiv.2203.04967,https://semanticscholar.org/paper/ccb5a70f8a6f7b7fc923b9d4c18488b2837daa6f,""UNet and its latest extensions like TransUNet have been the leading medical image segmentation methods in recent years. However, these networks cannot be effectively adopted for rapid image segmentation in point-of-care applications as they are parameter-heavy, computationally complex and slow to use. To this end, we propose UNeXt which is a Convolutional multilayer perceptron (MLP) based network for image segmentation. We design UNeXt in an effective way with an early convolutional stage and a MLP stage in the latent stage. We propose a tokenized MLP block where we efficiently tokenize and project the convolutional features and use MLPs to model the representation. To further boost the performance, we propose shifting the channels of the inputs while feeding in to MLPs so as to focus on learning local dependencies. Using tokenized MLPs in latent space reduces the number of parameters and computational complexity while being able to result in a better representation to help segmentation. The network also consists of skip connections between various levels of encoder and decoder. We test UNeXt on multiple medical image segmentation datasets and show that we reduce the number of parameters by 72x, decrease the computational complexity by 68x, and improve the inference speed by 10x while also obtaining better segmentation performance over the state-ofthe-art medical image segmentation architectures. Code is available at https://github.com/jeya-maria-jose/UNeXt-pytorch"",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"TransNorm: Transformer Provides a Strong Spatial Normalization Mechanism for a Deep Segmentation Model,The expedient design of skip-connections can be crucial for accurate segmentation as it can assist feature fusion between the expanding and contracting paths.,""Reza Azad, Mohammad T. Al-Antary, Moein Heidari, D. Merhof"",IEEE Access,,0.927 (4581),10.1109/ACCESS.2022.3211501,http://arxiv.org/pdf/2207.13415,2022,7,https://doi.org/10.1109/ACCESS.2022.3211501,https://semanticscholar.org/paper/e252df8b96c4443bf42ac49c325df4819e5029a4,""In the past few years, convolutional neural networks (CNNs), particularly U-Net, have been the prevailing technique in the medical image processing era. Specifically, the U-Net model, as well as its alternatives, have successfully managed to address a wide variety of medical image segmentation tasks. However, these architectures are intrinsically imperfect as they fail to exhibit long-range interactions and spatial dependencies leading to a severe performance drop in the segmentation of medical images with variable shapes and structures. Transformers, preliminary proposed for sequence-to-sequence prediction, have arisen as surrogate architectures to precisely model global information assisted by the self-attention mechanism. Despite being feasibly designed, utilizing a pure Transformer for image segmentation purposes can result in limited localization capacity stemming from inadequate low-level features. Thus, a line of research strives to design robust variants of Transformer-based U-Net. In this paper, we propose Trans-Norm, a novel deep segmentation framework which concomitantly consolidates a Transformer module into both encoder and skip-connections of the standard U-Net. We argue that the expedient design of skip-connections can be crucial for accurate segmentation as it can assist feature fusion between the expanding and contracting paths. In this respect, we derive a Spatial Normalization mechanism from the Transformer module to adaptively recalibrate the skip connection path. Extensive experiments across three typical tasks",for medical image,segmentation demonstrate the effective,nes,s o,f T,rans,Norm.,T,he,"codes and trained models are publicly available at github."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"TransBO: Hyperparameter Optimization via Two-Phase Transfer Learning,A novel two-phase transfer learning framework for automatic hyperparameter optimization can deal with the complementary nature among source tasks and dynamics during knowledge aggregation issues simultaneously.,""Yang Li, Yang Li, Yu Shen, Huaijun Jiang, Wentao Zhang, Zhi Yang, Ce Zhang, Bin Cui"",Knowledge Discovery and Data Mining,,,10.1145/3534678.3539255,http://arxiv.org/pdf/2206.02663,2022,3,https://doi.org/10.1145/3534678.3539255,https://semanticscholar.org/paper/cc9f5a5cee3354159fb40c26979648f254e19b22,""With the extensive applications of machine learning models, automatic hyperparameter optimization (HPO) has become increasingly important. Motivated by the tuning behaviors of human experts, it is intuitive to leverage auxiliary knowledge from past HPO tasks to accelerate the current HPO task. In this paper, we propose TransBO, a novel two-phase transfer learning framework for HPO, which can deal with the complementary nature among source tasks and dynamics during knowledge aggregation issues simultaneously. This framework extracts and aggregates source and target knowledge jointly and adaptively, where the weights can be learned in a principled manner. The extensive experiments, including static and dynamic transfer learning settings and neural architecture search, demonstrate the superiority of TransBO over the state-of-the-arts."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"TrajGAT: A Graph-based Long-term Dependency Modeling Approach for Trajectory Similarity Computation,TrajGAT can capture the long-term dependencies of trajectories while reducing the GPU memory usage of Transformer.,""Di Yao, Haonan Hu, Lun Du, Gao Cong, Shi Han, Jingping Bi"",Knowledge Discovery and Data Mining,,,10.1145/3534678.3539358,https://dl.acm.org/doi/pdf/10.1145/3534678.3539358,2022,4,https://doi.org/10.1145/3534678.3539358,https://semanticscholar.org/paper/4af4dd14fc2d9ddcb94f15d354e9e3e227eb7140,""Computing trajectory similarities is a critical and fundamental task for various spatial-temporal applications, such as clustering, prediction, and anomaly detection. Traditional similarity metrics, i.e. DTW and Hausdorff, suffer from quadratic computation complexity, leading to their inability on large-scale data. To solve this problem, many trajectory representation learning techniques are proposed to approximate the metric space while reducing the complexity of similarity computation. Nevertheless, these works are designed based on RNN backend, resulting in a serious performance decline on long trajectories. In this paper, we propose a novel graph-based method, namely TrajGAT, to explicitly model the hierarchical spatial structure and improve the performance of long trajectory similarity computation. TrajGAT consists of two main modules, i.e. , graph construction and trajectory encoding. For graph construction, TrajGAT first employs PR quadtree to build the hierarchical structure of the whole spatial area, and then constructs a graph for each trajectory based on the original records and the leaf nodes of the quadtree. For trajectory encoding, we replace the self-attention in Transformer with graph attention and design an encoder to represent the generated graph trajectory. With these two modules, TrajGAT can capture the long-term dependencies of trajectories while reducing the GPU memory usage of Transformer. Our experiments on two real-life datasets show that TrajGAT not only improves the performance on long trajectories but also outperforms the state-",of-the-art methods,on mixture trajectories significantly.,""",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"PaRoutes: towards a framework for benchmarking retrosynthesis route predictions,A framework for benchmarking multi-step retrosynthesis methods is called PaRoutes.,""S. Genheden, E. Bjerrum"",Digital Discovery,,,10.1039/d2dd00015f,https://pubs.rsc.org/en/content/articlepdf/2022/dd/d2dd00015f,2022,5,https://doi.org/10.1039/d2dd00015f,https://semanticscholar.org/paper/0caaf9a019fe438ae14bf1949e2ee0ec5b2d5b12,""We introduce a framework for benchmarking multi-step retrosynthesis methods, i.e. route predictions, called PaRoutes. The framework consists of two sets of 10,000 synthetic routes extracted from the patent literature, a..."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"TransPhos: A Deep-Learning Model for General Phosphorylation Site Prediction Based on Transformer-Encoder Architecture,TransPhos performs better than several deep learning models.,""Xun Wang, Zhiyuan Zhang, Chaogang Zhang, Xiangyu Meng, Xin Shi, Peng Qu"",International Journal of Molecular Sciences,,1.176 (3161),10.3390/ijms23084263,https://www.mdpi.com/1422-0067/23/8/4263/pdf?version=1650014525,2022,4,https://doi.org/10.3390/ijms23084263,https://semanticscholar.org/paper/7b8e8c796c7d970b29b9f93e14da9040291bcf2d,""Protein phosphorylation is one of the most critical post-translational modifications of proteins in eukaryotes, which is essential for a variety of biological processes. Plenty of attempts have been made to improve the performance of computational predictors for phosphorylation site prediction. However, most of them are based on extra domain knowledge or feature selection. In this article, we present a novel deep learning-based predictor, named TransPhos, which is constructed using a transformer encoder and densely connected convolutional neural network blocks, for predicting phosphorylation sites. Data experiments are conducted on the datasets of PPA (version 3.0) and Phospho. ELM. The experimental results show that our TransPhos performs better than several deep learning models, including Convolutional Neural Networks (CNN), Long-term and short-term memory networks (LSTM), Recurrent neural networks (RNN) and Fully connected neural networks (FCNN), and some state-of-the-art deep learning-based prediction tools, including GPS2.1, NetPhos, PPRED, Musite, PhosphoSVM, SKIPHOS, and DeepPhos. Our model achieves a good performance on the training datasets of Serine (S), Threonine (T), and Tyrosine (Y), with AUC values of 0.8579, 0.8335, and 0.6953 using 10-fold cross-validation tests, respectively, and demonstrates that the presented TransPhos tool considerably outperforms competing predictors in general protein phosphorylation site prediction."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"TransPolymer: a Transformer-based Language Model for Polymer Property Predictions,TransPolymer achieves superior performance in all ten downstream tasks.,""Changwen Xu, Yuyang Wang, A. Farimani"",ArXiv,,,10.48550/arXiv.2209.01307,,2022,5,https://doi.org/10.48550/arXiv.2209.01307,https://semanticscholar.org/paper/933b23c1a0fba9eb1ca582448e29b56666d5d7ca,""Accurate and efficient prediction of polymer properties is of great significance in polymer development and design. Conventionally, expensive and time-consuming experiments or simulations are required to evaluate the function of polymers. Recently, Transformer models, equipped with attention mechanisms, have exhibited superior performance in various natural language processing tasks. However, such methods have not been investigated in polymer sciences. Herein, we report TransPolymer, a Transformer-based language model for polymer property prediction. Owing to our proposed polymer tokenizer with chemical awareness, TransPolymer can learn representations directly from polymer sequences. The model learns expressive representations by pretraining on a large unlabeled dataset via masked language modeling, followed by finetuning the model on downstream datasets concerning various polymer properties. TransPolymer achieves superior performance in all ten downstream tasks and surpasses other baselines significantly on most downstream tasks. Moreover, the improvement by the pretrained TransPolymer over supervised TransPolymer and other language models strengthens the significant benefits of pretraining on large unlabeled data in representation learning. Experiment results further demonstrate the important role of the attention mechanism in understanding polymer sequences. We highlight this model as a promising computational tool for promoting rational polymer design and understanding structure-property relationships in a data science view."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Transkimmer: Transformer Learns to Layer-wise Skim,Transkimmer achieves 10.97x average speedup on GLUE benchmark compared with vanilla BERT-base baseline with less than 1% accuracy degradation.,""Yue Guan, Zhengyi Li, Jingwen Leng, Zhouhan Lin, Minyi Guo"",Annual Meeting of the Association for Computational Linguistics,,,10.48550/arXiv.2205.07324,,2022,5,https://doi.org/10.48550/arXiv.2205.07324,https://semanticscholar.org/paper/81b234a1e6da7bc8131e8585a9455dca5dd68754,""Transformer architecture has become the de-facto model for many machine learning tasks from natural language processing and computer vision. As such, improving its computational efficiency becomes paramount. One of the major computational inefficiency of Transformer based models is that they spend the identical amount of computation throughout all layers. Prior works have proposed to augment the Transformer model with the capability of skimming tokens to improve its computational efficiency. However, they suffer from not having effectual and end-to-end optimization of the discrete skimming predictor. To address the above limitations, we propose the Transkimmer architecture, which learns to identify hidden state tokens that are not required by each layer. The skimmed tokens are then forwarded directly to the final output, thus reducing the computation of the successive layers. The key idea in Transkimmer is to add a parameterized predictor before each layer that learns to make the skimming decision. We also propose to adopt reparameterization trick and add skim loss for the end-to-end training of Transkimmer. Transkimmer achieves 10.97x average speedup on GLUE benchmark compared with vanilla BERT-base baseline with less than 1% accuracy degradation."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"TransVG++: End-to-End Visual Grounding with Language Conditioned Vision Transformer,The core fusion Transformer in TransVG is stand-alone against uni-modal encoders.,""Jiajun Deng, Zhengyuan Yang, Daqing Liu, Tianlang Chen, Wen-gang Zhou, Yanyong Zhang, Houqiang Li, Wanli Ouyang"",ArXiv,,,10.48550/arXiv.2206.06619,,2022,1,https://doi.org/10.48550/arXiv.2206.06619,https://semanticscholar.org/paper/35fccd11326e799ebf724f4150acef12a6538953,""—In this work, we explore neat yet effective Transformer-based frameworks for visual grounding. The previous methods generally address the core problem of visual grounding, i.e. , multi-modal fusion and reasoning, with manually-designed mechanisms. Such heuristic designs are not only complicated but also make models easily over?t speci?c data distributions. To avoid this, we ?rst propose TransVG, which establishes multi-modal correspondences by Transformers and localizes referred regions by directly regressing box coordinates. We empirically show that complicated fusion modules can be replaced by a simple stack of Transformer encoder layers with higher performance. However, the core fusion Transformer in TransVG is stand-alone against uni-modal encoders, and thus should be trained from scratch on limited visual grounding data, which makes it hard to be optimized and leads to sub-optimal performance. To this end, we further introduce TransVG++ to make two-fold improvements. For one thing, we upgrade our framework to a purely Transformer-based one by leveraging Vision Transformer (ViT) for vision feature encoding. For another, we devise Language Conditioned Vision Transformer that removes external fusion modules and reuses the uni-modal ViT for vision-language fusion at the intermediate layers. We conduct extensive experiments on ?ve prevalent datasets, and report a series of state-of-the-art records."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"TransCL: Transformer Makes Strong and Flexible Compressive Learning,TransCL can achieve state-of-the-art performance in image classification and semantic segmentation tasks.,""Chong Mou, Jian Zhang"",IEEE Transactions on Pattern Analysis and Machine Intelligence,,8.269 (105),10.1109/TPAMI.2022.3194001,http://arxiv.org/pdf/2207.11972,2022,1,https://doi.org/10.1109/TPAMI.2022.3194001,https://semanticscholar.org/paper/b516154ea05b1c58168b898f84127791faa99b0a,""Compressive learning (CL) is an emerging framework that integrates signal acquisition via compressed sensing (CS) and machine learning for inference tasks directly on a small number of measurements. It can be a promising alternative to classical image-domain methods and enjoys great advantages in memory saving and computational efficiency. However, previous attempts on CL are not only limited to a fixed CS ratio, which lacks flexibility, but also limited to MNIST/CIFAR-like datasets and do not scale to complex real-world high-resolution (HR) data or vision tasks. In this paper, a novel transformer-based compressive learning framework on large-scale images with arbitrary CS ratios, dubbed TransCL, is proposed. Specifically, TransCL first utilizes the strategy of learnable block-based compressed sensing and proposes a flexible linear projection strategy to enable CL to be performed on large-scale images in an efficient block-by-block manner with arbitrary CS ratios. Then, regarding CS measurements from all blocks as a sequence, a pure transformer-based backbone is deployed to perform vision tasks with various task-oriented heads. Our sufficient analysis presents that TransCL exhibits strong resistance to interference and robust adaptability to arbitrary CS ratios. Extensive experiments for complex HR data demonstrate that the proposed TransCL can achieve state-of-the-art performance in image classification and semantic segmentation tasks. In particular, TransCL with a CS ratio of 10% can obtain almost the same performance as when operating directly on the original data and can still obtain satisfying performa",nce even with an e,xtremely low CS ratio of 1%. The source,co,des,of,our,prop,os,ed,"TransCL is available at https://github.com/MC-E/TransCL/."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"DCS-TransUperNet: Road Segmentation Network Based on CSwin Transformer with Dual Resolution,A dual-resolution road segmentation network was proposed for road segmentation.,""Zheng Zhang, Chunle Miao, Chang'an Liu, Qing Tian"",Applied Sciences,,0.44 (11182),10.3390/app12073511,https://www.mdpi.com/2076-3417/12/7/3511/pdf?version=1648643882,2022,8,https://doi.org/10.3390/app12073511,https://semanticscholar.org/paper/fff17eef727dba5e6159dc8b45c7be5845f0b50a,""Recent advances in deep learning have shown remarkable performance in road segmentation from remotely sensed images. However, these methods based on convolutional neural networks (CNNs) cannot obtain long-range dependency and global contextual information because of the intrinsic inductive biases. Motivated by the success of Transformer in computer vision (CV), excellent models based on Transformer are emerging endlessly. However, patches with a fixed scale limit the further improvement of the model performance. To address this problem, a dual-resolution road segmentation network (DCS-TransUperNet) with a features fusion module (FFM) was proposed for road segmentation. Firstly, the encoder of DCS-TransUperNet was designed based on CSwin Transformer, which uses dual subnetwork encoders of different scales to obtain the coarse and fine-grained feature representations. Secondly, a new FFM was constructed to build enhanced feature representation with global dependencies, using different scale features from the subnetwork encoders. Thirdly, a mixed loss function was designed to avoid the local optimum caused by the imbalance between road and background pixels. Experiments using the Massachusetts dataset and DeepGlobe dataset showed that the proposed DCS-TransUperNet could effectively solve the discontinuity problem and preserve the integrity of the road segmentation results, achieving a higher IoU (65.36% on Massachusetts dataset and 56.74% on DeepGlobe) of road segmentation compared to other state-of-the-art methods. The considerable performance also proves the powerful generation ability of our method."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"An Efficient Calculation for TI-LFA Rerouting Path,The average tunnel lengths are at most 2.0 to 2.2 hops regardless of the size of the network.,Kazuya Suzuki,IEICE transactions on communications,,0.248 (16498),10.1587/transcom.2021cep0003,https://www.jstage.jst.go.jp/article/transcom/E105.B/2/E105.B_2021CEP0003/_pdf,2022,2,https://doi.org/10.1587/transcom.2021cep0003,https://semanticscholar.org/paper/fb940838126f7525cd6cff118307951aa2ee6947,""SUMMARY Recently, segment routing, which is a modern forwarding mechanism, and Topology Independent Loop-free Alternate, which is an IP fast-reroute method using segment routing, have been proposed and have begun to be applied to real networks. When a failure occurs in a network, TI-LFA quickly restores packet forwarding without waiting for other nodes to update their routing tables. It does so by using segment routing to forward sections that may cause loops in the rerouting path. However, determining the segment routing sections has a high computational cost because it requires computation for each destination. This paper therefore proposes an algorithm to determine the egress node that is the exit of the segment routing section for all destination nodes with only three shortest- path tree calculations. The evaluation results of the proposed algorithm showed that the average tunnel lengths are at most 2.0 to 2.2 hops regardless of the size of the network. I also showed that the computational complexity of the proposed algorithm is O ( N log N ) ."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"End-to-End Video Text Spotting with Transformer,""The first end-to-end trainable video text spotting framework achieves state-of-the-art performance on detection, tracking, and spotting tasks."",""Weijia Wu, Debing Zhang, Ying Fu, Chunhua Shen, Hong Zhou, Yuanqiang Cai, Ping Luo"",ArXiv,,,10.48550/arXiv.2203.10539,,2022,5,https://doi.org/10.48550/arXiv.2203.10539,https://semanticscholar.org/paper/819f98991cdee539102a67a02cb0c721bcbf8308,""Recent video text spotting methods usually require the three-staged pipeline, i.e., detecting text in individual images, recognizing localized text, tracking text streams with post-processing to generate ?nal results. The previous methods typically follow the tracking-by-match paradigm and develop sophisticated pipelines, which is an not effective solution. In this paper, rooted in Transformer sequence modeling, we propose a simple, yet effective end-to-end trainable video text D Etection, T racking, and R ecognition framework ( Trans D E TR ), which views the VTS task as a direct long-range temporal modeling problem. Trans D E TR mainly includes two advantages: 1) Different from the explicit match paradigm in the adjacent frame, the proposed Trans D E TR tracks and recognizes each text implicitly by the different query termed ‘text query’ over long-range temporal sequence (more than 7 frames). 2) Trans D E TR is the ?rst end-to-end trainable video text spotting framework, which simultaneously addresses the three sub-tasks ( e.g., text detection, tracking, recognition). Extensive experiments on four video text datasets ( e.g., ICDAR2013 Video, ICDAR2015 Video) are conducted to demonstrate that Trans D E TR achieves the state-of-the-art performance with up to 11 . 0% improvements on detection, tracking, and spotting tasks. The code can be found at github . com / weijiawu / TransDETR ."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"TransRepair: Context-aware Program Repair for Compilation Errors,TransRepair outperforms the state-of-the-art in both single repair accuracy and full repair accuracy.,""X. Li, Shangqing Liu, Ruitao Feng, Guozhu Meng, Xiaofei Xie, Kai Chen, Yang Liu"",International Conference on Automated Software Engineering,,,10.1145/3551349.3560422,https://dl.acm.org/doi/pdf/10.1145/3551349.3560422,2022,3,https://doi.org/10.1145/3551349.3560422,https://semanticscholar.org/paper/fdd42410e559fa9cdb1a092a35cfa54da150bd90,""Automatically fixing compilation errors can greatly raise the productivity of software development, by guiding the novice or AI programmers to write and debug code. Recently, learning-based program repair has gained extensive attention and became the state-of-the-art in practice. But it still leaves plenty of space for improvement. In this paper, we propose an end-to-end solution TransRepair to locate the error lines and create the correct substitute for a C program simultaneously. Superior to the counterpart, our approach takes into account the context of erroneous code and diagnostic compilation feedback. Then we devise a Transformer-based neural network to learn the ways of repair from the erroneous code as well as its context and the diagnostic feedback. To increase the effectiveness of TransRepair, we summarize 5 types and 74 fine-grained sub-types of compilations errors from two real-world program datasets and the Internet. Then a program corruption technique is developed to synthesize a large dataset with 1,821,275 erroneous C programs. Through the extensive experiments, we demonstrate that TransRepair outperforms the state-of-the-art in both single repair accuracy and full repair accuracy. Further analysis sheds light on the strengths and weaknesses in the contemporary solutions for future improvement."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"TransER: Homogeneous Transfer Learning for Entity Resolution,Transfer learning can overcome this expensive labelling task by utilising existing training data from a semantically related source domain to classify instances in a target domain where no training data are available.,""Nishadi Kirielle, P. Christen, T. Ranbaduge"",International Conference on Extending Database Technology,,,10.48786/edbt.2022.03,,2022,2,https://doi.org/10.48786/edbt.2022.03,https://semanticscholar.org/paper/51dcd4d256d1a22f06b0e822233409bc13fc2a25,""Entity resolution (ER) is the process of linking records that refer to the same entity across one or more databases. While recent advances in supervised learning can provide high quality results for ER, these often come with large efforts to obtain labelled training data. Transfer learning (TL) can overcome this expensive labelling task by utilising existing training data from a semantically related source domain to classify instances in a target domain where no training data are available. However, most existing TL solutions for ER involve deep learning models that have shown to be mostly useful for long textual and unstructured attributes. These models are less successful for short structured attributes such as personal data that are known to contain variations and typographical errors. In this paper, we propose a novel TL framework for resolving entities in structured data. We assume homogeneous domains that have the same feature space (same attribute types and similarity functions) for transferring. As records are sourced from different domains, there however can be three key challenges. The marginal probability distributions of the data in the two domains can be different, there can be feature vectors that have contradicting labels in the two domains resulting in different class conditional probability distributions, and the class imbalance and bi-modal data distributions common in ER make it challenging to apply existing TL methods. We address these challenges with three contributions: an instance selector to choose source instances",with a high confi,dence and a similar local structure to,the,ta,rge,t do,"main,",a,l,"abel generator that creates pseudo labels for target instances, and a final classifier that labels target instances using only high confidence pseudo labels. On seven data sets we show that our framework outperforms the best of several state-of-the-art methods by up to 13% in precision and 50% in recall, while also being substantially faster."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Translation-Based Embeddings with Octonion for Knowledge Graph Completion,The translation-based knowledge graph completion model with octonion outperforms other translation-based models on the WN18 benchmark.,""Mei Yu, Chen Bai, Jian Yu, Mankun Zhao, Tianyi Xu, Hongwei Liu, Xuewei Li, Ruiguo Yu"",Applied Sciences,,0.44 (11182),10.3390/app12083935,https://www.mdpi.com/2076-3417/12/8/3935/pdf?version=1649905772,2022,1,https://doi.org/10.3390/app12083935,https://semanticscholar.org/paper/6d31de103e0aa063955f11f49ed6657f9ddb7607,""Knowledge representation learning achieves the automatic completion of knowledge graphs (KGs) by embedding entities into continuous low-dimensional vector space. In knowledge graph completion (KGC) tasks, the inter-dependencies and hierarchical information in KGs have gained attention. Existing methods do not well capture the latent dependencies between all components of entities and relations. To address this, we introduce the mathematical theories of octonion, a more expressive generalized form of complex number and quaternion, and propose a translation-based KGC model with octonion (TransO). TransO models entities as octonion coordinate vectors, relations as the combination of octonion component matrices and coordinate vectors, and uses specific grouping calculation rules to interact between entities and relations. In addition, since hyperbolic Poincaré space in non-Euclidean mathematics can represent hierarchical data more accurately and effectively than traditional Euclidean space, we propose a Poincaré-extended TransO model (PTransO). PTransO transforms octonion coordinate vectors into hyperbolic embeddings by exponential mapping, and integrates the Euclidean-based calculations into hyperbolic space by operations such as Möbius addition and hyperbolic distance. The experimental results of link prediction indicate that TransO outperforms other translation-based models on the WN18 benchmark, and PTransO further achieves state-of-the-art performance in low-dimensional space on the well-established WN18RR and FB15k-237 benchmarks."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"PiTE: TCR-epitope Binding Affinity Prediction Pipeline using Transformer-based Sequence Encoder.,Advanced sequence encoder on top of pre-trained representation significantly improves performance of the TCR-epitope binding affinity prediction model.,""Pengfei Zhang, Seo-Jin Bang, Heewook Lee"",Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing,,0.71 (6734),10.1142/9789811270611_0032,,2022,1,https://doi.org/10.1142/9789811270611_0032,https://semanticscholar.org/paper/8d10426dedf4f1655e5373a45b82f32820475410,""Accurate prediction of TCR binding affinity to a target antigen is important for development of immunotherapy strategies. Recent computational methods were built on various deep neural networks and used the evolutionary-based distance matrix BLOSUM to embed amino acids of TCR and epitope sequences to numeric values. A pre-trained language model of amino acids is an alternative embedding method where each amino acid in a peptide is embedded as a continuous numeric vector. Little attention has yet been given to summarize the amino-acid-wise embedding vectors to sequence-wise representations. In this paper, we propose PiTE, a two-step pipeline for the TCR-epitope binding affinity prediction. First, we use an amino acids embedding model pre-trained on a large number of unlabeled TCR sequences and obtain a real-valued representation from a string representation of amino acid sequences. Second, we train a binding affinity prediction model that consists of two sequence encoders and a stack of linear layers predicting the affinity score of a given TCR and epitope pair. In particular, we explore various types of neural network architectures for the sequence encoders in the two-step binding affinity prediction pipeline. We show that our Transformer-like sequence encoder achieves a state-of-the-art performance and significantly outperforms the others, perhaps due to the model's ability to capture contextual information between amino acids in each sequence. Our work highlights that an advanced sequence encoder on top of pre-trained representation sign",ificantly improves,performance of the TCR-epitope binding,af,fin,ity,pre,dicti,on,".""",",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"TransRec: Learning Transferable Recommendation from Mixture-of-Modality Feedback,Learning neural recommendation models from mixture-of-modality feedback provides a promising way to realize universal recommender systems.,""Jie Wang, Fajie Yuan, Mingyue Cheng, J. Jose, Chenyun Yu, Beibei Kong, Zhijin Wang, Bo Hu, Zang Li"",ArXiv,,,10.48550/arXiv.2206.06190,,2022,3,https://doi.org/10.48550/arXiv.2206.06190,https://semanticscholar.org/paper/f7c9551e19fabf5d534115a5704a5f8fea097534,""Learning large-scale pre-trained models on broad-ranging data and then transfer to a wide range of target tasks has become the de facto paradigm in many machine learning (ML) communities. Such big models are not only strong performers in practice but also offer a promising way to break out of the task-specific modeling restrictions, thereby enabling task-agnostic and unified ML systems. However, such a popular paradigm is mainly unexplored by the recommender systems (RS) community. A critical issue is that standard recommendation models are primarily built on categorical identity features. That is, the users and the interacted items are represented by their unique IDs, which are generally not shareable across different systems or platforms. To pursue the transferable recommendations, we propose studying pre-trained RS models in a novel scenario where a user’s interaction feedback involves a mixture-of-modality (MoM) items, e.g., text and images. We then present TransRec, a very simple modification made on the popular ID-based RS framework. TransRec learns directly from the raw features of the MoM items in an end-to-end training manner and thus enables effective transfer learning under various scenarios without relying on overlapped users or items. We empirically study the transferring ability of TransRec across four different real-world recommendation settings. Besides, we look at its effects by scaling source and target data size. Our results suggest that learning neural recommendation models from MoM feedback provides a promising way to realize universal RS. We will release our codes",and pre-trained p,"arameters for reproducibility. 1"",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"RDF Query Path Optimization Using Hybrid Genetic Algorithms,A hybrid genetic algorithm for query path optimization makes significant improvements in the overall performance.,""Qazi Mudassar Ilyas, Muneer Ahmad, Sonia Rauf, D. Irfan"",International Journal of Cloud Applications and Computing,,,10.4018/ijcac.2022010101,,2022,2,https://doi.org/10.4018/ijcac.2022010101,https://semanticscholar.org/paper/94f1c54c3b9af873c097b422dbbbf66a5adf0da7,""Resource Description Framework (RDF) inherently supports data mergers from various resources into a single federated graph that can become very large even for an application of modest size. This results in severe performance degradation in the execution of RDF queries. As every RDF query essentially traverses a graph to find the output of the Query, an efficient path traversal reduces the execution time of RDF queries. Hence, query path optimization is required to reduce the execution time as well as the cost of a query. Query path optimization is an NP-hard problem that cannot be solved in polynomial time. Genetic algorithms have proven to be very useful in optimization problems. We propose a hybrid genetic algorithm for query path optimization. The proposed algorithm selects an initial population using iterative improvement thus reducing the initial solution space for the genetic algorithm. The proposed algorithm makes significant improvements in the overall performance. We show that the overall number of joins for complex queries is reduced considerably, resulting in reduced cost."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Time- and Space-Efficient Regular Path Queries,A time- and space-efficient technique to solve regular path queries over labeled graphs.,""Diego Arroyuelo, A. Hogan, G. Navarro, J. Rojas-Ledesma"",IEEE International Conference on Data Engineering,,,10.1109/icde53745.2022.00277,,2022,2,https://doi.org/10.1109/icde53745.2022.00277,https://semanticscholar.org/paper/7741499529ede9fe4237b81a01bfd147b2edb0d2,""We introduce a time- and space-efficient technique to solve regular path queries over labeled (RDF) graphs. We combine a bit-parallel simulation of the Glushkov automaton of the regular expression with the ring index introduced by Arroyuelo et al., exploiting its wavelet tree representation in order to efficiently reach relevant states of the product graph. Our algorithm is able to simultaneously process several automaton states, as well as several graph nodes/labels. Our experiments show that our approach uses 3–5 times less space than existing state-of-the-art systems, while generally outperforming them in query times (nearly 3 times faster than the next best, on average)."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Optimization-Based Path-Planning for Connected and non-Connected Automated Vehicles,Connected automated vehicles are more efficient than non-connected automated vehicles.,""Panagiotis  Typaldos, Markos  Papageorgiou, Ioannis  Papamichail"",Transportation Research Part C: Emerging Technologies,,3.211 (531),10.1016/j.trc.2021.103487,http://arxiv.org/pdf/2104.06778,2022,2,https://doi.org/10.1016/j.trc.2021.103487,https://semanticscholar.org/paper/8a6201d40867dad1bbe1461cac4d064b37a2426c,""A path-planning algorithm for connected and non-connected automated road vehicles on multilane motorways is derived from the opportune formulation of an optimal control problem. In this framework, the objective function to be minimized contains appropriate respective terms to reflect: the goals of vehicle advancement; passenger comfort; and avoidance of collisions with other vehicles, of road departures and of negative speeds. Connectivity implies that connected vehicles are able to exchange with each other (V2V) or the infrastructure (V2I), real-time information about their last generated path. For the numerical solution of the optimal control problem, an efficient feasible direction algorithm is used. To ensure high-quality local minima, a simplified Dynamic Programming algorithm is also conceived to deliver the initial guess trajectory for the feasible direction algorithm. Thanks to low computation times, the approach is readily executable within a model predictive control (MPC) framework. The proposed MPC-based approach is embedded within the Aimsun microsimulation platform, which enables the evaluation of a plethora of realistic vehicle driving and advancement scenarios. Results obtained on a multilane motorway stretch indicate higher efficiency of the optimally controlled vehicles in driving closer","to their desired speed, compared",to ordinary Aimsun vehicle,s. Increased penetration,rates of automated vehicles are found to increase the,efficiency of the overall traffic flow,", benefiting manua",l vehicles,as well.,"Moreover, connected",controlled vehicles,appear,to,"be more efficient compared to the corresponding non-connected controlled vehicles, due to the improved real-time information and short-term prediction."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Retraction based Direct Search Methods for Derivative Free Riemannian Optimization,Direct search methods represent a robust and reliable class of algorithms for solving black-box optimization problems.,""V. Kungurtsev, F. Rinaldi, Damiano Zeffiro"",,,,,,2022,1,,https://semanticscholar.org/paper/01f61b94d2993549f0df70c7e06037ef848a1ff0,""Direct search methods represent a robust and reliable class of algorithms for solving black-box optimization problems. In this paper, we explore the application of those strategies to Riemannian optimization, wherein minimization is to be performed with respect to variables restricted to lie on a manifold. More speci?cally, we consider classic and line search extrapolated variants of direct search, and, by making use of retractions, we devise tailored strategies for the minimization of both smooth and nonsmooth functions. As such we analyze, for the ?rst time in the literature, a class of retraction based algorithms for minimizing nonsmooth objectives on a Riemannian manifold without having access to (sub)derivatives. Along with convergence guarantees we provide a set of numerical performance illustrations on a standard set of problems."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Expensive Multiobjective Optimization by Relation Learning and Prediction,A relation model for evolutionary multiobjective optimization is proposed.,""Hao Hao, Aimin Zhou, Hong Qian, Hu Zhang"",IEEE Transactions on Evolutionary Computation,,6.078 (187),10.1109/TEVC.2022.3152582,,2022,2,https://doi.org/10.1109/TEVC.2022.3152582,https://semanticscholar.org/paper/afab7fa97a7ac65e0663d6735640932ffefbf2ec,""Expensive multiobjective optimization problems pose great challenges to evolutionary algorithms due to their costly evaluation. Building cheap surrogate models to replace the expensive real models has been proved to be a practical way to reduce the number of costly evaluations. Supervised learning techniques from the community of machine learning have been widely applied to build either regressors, which approximate the fitness values of candidate solutions, or classifiers, which estimate the categories of candidate solutions. Considering the characteristics of the data produced in optimization, this article proposes a new surrogate model, called a relation model, for evolutionary multiobjective optimization. Instead of estimating the qualities of candidate solutions directly, the relation model tries to estimate the relationship between a pair of solutions <inline-formula> <tex-math notation=""""LaTeX"""">$\langle \mathbf {x}, \mathbf {y}\rangle $ </tex-math></inline-formula>, i.e., <inline-formula> <tex-math notation=""""LaTeX"""">$\mathbf {x}$ </tex-math></inline-formula> dominates <inline-formula> <tex-math notation=""""LaTeX"""">$\mathbf {y}$ </tex-math></inline-formula>, <inline-formula> <tex-math notation=""""LaTeX"""">$\mathbf {x}$ </tex-math></inline-formula> is dominated by <inline-formula> <tex-math notation=""""LaTeX"""">$\mathbf {y}$ </tex-math></inline-formula>, or <inline-formula> <tex-math n","otation=""""LaTeX"""">$\mathbf {x}$ <",/tex-math></inline-formula>,is nondominated with <i,"nline-formula> <tex-math notation=""""LaTeX"""">$\mathbf {",y}$ </tex-math></inline-formula> in the,case of multiobje,ctive opti,mization.,To implement this i,"dea, first a balance",d train,ing,"set is prepared, then a classifier is built based on the training data set to learn the relationship, and finally, the classifier with a voting-scoring strategy is applied to estimate the relationship between the candidate solutions and parent solutions. By this way, the promising candidate solutions are recognized and evaluated by the real models. The new approach is applied to three well-known benchmark suites and two real-world applications, and the experimental results suggest that the proposed method outperforms some state-of-the-art methods based on regression and classification models on the given instances."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"BPOMP: A Bilevel Path Optimization Formulation for Motion Planning,A bilevel path optimization formulation for motion planning is introduced.,""Changhao Wang, Hsien-Chung Lin, Shiyu Jin, Xinghao Zhu, Liting Sun, M. Tomizuka"",American Control Conference,,,10.23919/ACC53348.2022.9867454,,2022,1,https://doi.org/10.23919/ACC53348.2022.9867454,https://semanticscholar.org/paper/9a486751d92537ae378b37b1070b1f7d20f8c4f8,""Balancing computation efficiency and success rate is challenging for path optimization. To obtain a collision-free path, each waypoint along the path should be collision-free, and the waypoints should be dense. As a consequence, the solutions are computationally expensive to obtain. This paper introduces a bilevel path optimization formulation for motion planning (BPOMP). Different from standard formulations that only consider the collision on each waypoint, BPOMP additionally considers the collision that may happen in the middle by computing the closest position to the obstacle along the continuous path. Intuitively, if the closest position is out of collision, the entire path should be collision-free. The problem is formulated as a bilevel optimization and then relaxed to canonical nonlinear programming (NLP), which can be solved classically. Comparison results in both simulations and experiments are provided to show the effeteness of the proposed formulation. Videos are available at https://changhaowang.github.io/BPOMP/BPOMP.html."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Optimization of Joint Decision of Transport Mode and Path in Multi-Mode Freight Transportation Network,The proposed algorithm can successfully find the solution for the joint decision of transportation mode and path in the complex network.,""Yang Lu, Shuaiqi Wang"",Italian National Conference on Sensors,,,10.3390/s22134887,https://www.mdpi.com/1424-8220/22/13/4887/pdf?version=1656423206,2022,1,https://doi.org/10.3390/s22134887,https://semanticscholar.org/paper/95e80c74149f9c43f13169b482633dd3c20c35a8,""This paper mainly studies the joint decision of transportation mode and path in the multi-mode transportation network to provide the optimal plan for freights. This paper constructs a multi-mode transportation network system by setting virtual connections between networks with different transportation modes. The Dijkstra and multi-objective optimization algorithms are used to select the path in the network. After determining the optimal path, the paths’ time, cost, and risk functions are established. The multi-objective function is converted into a single objective function by setting constraint conditions through the analytic hierarchy process. Then, the function is optimized by using the gradient descent method. Finally, the transportation plan for the case of chemical freights is formulated by using the above algorithms. The results show that the proposed algorithm can successfully find the solution for the joint decision of transportation mode and path in the complex network. After a quantitative analysis of the planned effect, the optimization actions of changing the initial transportation time and adjusting the upper limit of resources are proposed. The study findings provide a theoretical basis for improving the efficiency of the comprehensive transportation network."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Error Bounds for Discrete-Continuous Shortest Path Problems with Application to Free Flight Trajectory Optimization,Highly efficient discrete shortest path algorithms exist and can be used directly for computing starting points for locally convergent optimal control methods.,""R. Borndörfer, Fabian Danecker, M. Weiser"",ArXiv,,,10.48550/arXiv.2204.05853,,2022,2,https://doi.org/10.48550/arXiv.2204.05853,https://semanticscholar.org/paper/3a56df6c123532c94b1c8a31c7624b58750e546a,""Two-stage methods addressing continuous shortest path problems start local minimization from discrete shortest paths in a spatial graph. The convergence of such hybrid methods to global minimizers hinges on the discretization error induced by restricting the discrete global optimization to the graph, with corresponding implications on choosing an appropriate graph density. A prime example is ?ight planning, i.e., the computation of optimal routes in view of ?ight time and fuel consumption under given weather conditions. Highly ef?cient discrete shortest path algorithms exist and can be used directly for computing starting points for locally convergent optimal control methods.Wederive a priori and localized error bounds for the ?ight time of discrete paths relative to the optimal continuous trajectory, in terms of the graph density and the given wind ?eld. These bounds allow designing graphs with an optimal local connectivity structure. The properties of the bounds are illustrated on a set of benchmark problems. It turns out that local-ization improves the error bound by four orders of magnitude, but still leaves ample opportunities for tighter error bounds by a posteriori estimators."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Constrained Differential Dynamic Programming: A primal-dual augmented Lagrangian approach,A Newton-like algorithm for solving constrained trajectory optimization problems is proposed.,""Wilson Jallet, Antoine Bambade, N. Mansard, Justin Carpentier"",IEEE/RJS International Conference on Intelligent RObots and Systems,,,10.1109/IROS47612.2022.9981586,https://hal.science/hal-03597630/document,2022,6,https://doi.org/10.1109/IROS47612.2022.9981586,https://semanticscholar.org/paper/37e6193f7d628902b0314e076c2895bbc6f13e4a,""Trajectory optimization is an efficient approach for solving optimal control problems for complex robotic systems. It relies on two key components: first the transcription into a sparse nonlinear program, and second the corresponding solver to iteratively compute its solution. On one hand, differential dynamic programming (DDP) provides an efficient approach to transcribe the optimal control problem into a finite-dimensional problem while optimally exploiting the sparsity induced by time. On the other hand, augmented Lagrangian methods make it possible to formulate efficient algorithms with advanced constraint-satisfaction strategies. In this paper, we propose to combine these two approaches into an efficient optimal control algorithm accepting both equality and inequality constraints. Based on the augmented Lagrangian literature, we first derive a generic primal-dual augmented Lagrangian strategy for nonlinear problems with equality and inequality constraints. We then apply it to the dynamic programming principle to solve the value-greedy optimization problems inherent to the backward pass of DDP, which we combine with a dedicated globalization strategy, resulting in a Newton-like algorithm for solving constrained trajectory optimization problems. Contrary to previous at",tempts of formu-lating an augment,ed Lagrangian version of DD,"P, our approach exhibits",adequate convergence properties without any switch in,strategies. We empirically demonstrate,its interest with,several c,ase-studi,es from the robotics,"literature."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"A Representation Learning Method of Knowledge Graph Integrating Ordered Relation Path and Entity Description Information,The model has higher accuracy than existing baselines.,""Haoxiang Ma, Xuesong Jiang, Huihui Chai, Xiumei Wei"",""IEEE International Conference on Systems, Man and Cybernetics"",,,10.1109/SMC53654.2022.9945592,,2022,1,https://doi.org/10.1109/SMC53654.2022.9945592,https://semanticscholar.org/paper/6139af5179527be9c7fab7293f0317b08eb584ce,""Knowledge graph representation learning aims to obtain its vector representation by mapping entities and relations in knowledge graphs to a continuous low-dimensional vector space by learning methods. Most of the existing knowledge graph representation learning methods only consider the single-step relation between entities from the perspective of triples and fail to effectively utilize important information such as ordered multi-step relation paths and entity descriptions, thus affecting the ability of knowledge representation learning. We propose a knowledge graph representation learning model that integrates ordered relation paths and entity descriptions in response to the above problems. The model can integrate the triple representation in the knowledge graph, the semantic representation of entity description, and the representation of ordered relation paths for training. On the FB15K, WN18, FB15K-237, and WN18RR datasets, the proposed model and baselines are run on the link prediction task. Experimental results show that the model has higher accuracy than existing baselines, demonstrating the effectiveness and superiority of the method."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Path route layout design optimization using genetic algorithm: based on control mechanisms for on-line crossover intersection positions and bit targeted mutation,Genetic algorithms are effective narrowing the search-space and focusing on interesting regions.,""Zikrija  Avdagic, Amir  Smajevic, Samir  Omanovic, Ingmar  Besic"",J. Ambient Intell. Humaniz. Comput.,,,10.1007/S12652-021-02937-Z,,2022,2,https://doi.org/10.1007/S12652-021-02937-Z,https://semanticscholar.org/paper/0770a1c600aebfcda84c781c5e0db345f2fae15d,""Path route layout design is very actual and complex problem, important for improvement of transportation, traffic, travel or roads planning. Solution domain is huge and finding satisfying solution is not an easy task. Increase of number of route path points and/or increase of their resolution significantly influences search-space. This paper is focused on use of genetic algorithm for effective narrowing the search-space and focusing on interesting regions. The importance of its main parameters, their impact on the performance and the precision of the genetic algorithm are elaborated in this paper. Three domain specific solution classes based on step-by-step improvements have been presented. In order to gain high efficiency and effectiveness, guidelines for a proper set-up of genetic algorithm are given. Encoding of parameters, build-up of the fitness function, evaluation and reproduction of chromosomes, elitism and convergence affinity are discussed in detail. Advanced built-in mechanisms have been emphasized with discussion of performance improvement."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Combining heuristics and Exact Algorithms: A Review,Mathematical programming methods and metaheuristics should be combined for achieving those benefits.,H. Fakhravar,,,,,,2022,2,,https://semanticscholar.org/paper/b519f0736f6d3f8a1425b12d640ff6abc1b9d98b,""Several different ways exist for approaching hard optimization problems. Mathematical programming techniques, including (integer) linear programming based methods, and metaheuristic approaches are two highly successful streams for combinatorial problems. These two have been established by different communities more or less in isolation from each other. Only over several years ago a larger number of researchers recognized the advantages and huge potentials of building hybrids of mathematical programming methods and metaheuristics. In fact, many problems can be practically solved much better by exploiting synergies between these different approaches than by “pure” traditional algorithms. The crucial issue is how mathematical programming methods and metaheuristics should be combined for achieving those benefits. This paper surveys existing techniques for such combinations and provide some examples of using them for vehicle routing problem. Index Terms matheuristics, optimization-based heuristics, VRP, survey,"",,Review",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Efficiently Answering Quality Constrained Shortest Distance Queries in Large Graphs,The shortest distance between two vertices s and t along valid edges in the graphs is critical in many real-world applications.,""You Peng, Zhuo Ma, W. Zhang, Xuemin Lin, Y. Zhang, Xiaoshuang Chen"",ArXiv,,,10.48550/arXiv.2211.08648,,2022,1,https://doi.org/10.48550/arXiv.2211.08648,https://semanticscholar.org/paper/91c7006ead76a018a6109a05ca38343bdee12d62,""—The shortest-path distance is a fundamental concept in graph analytics and has been extensively studied in the literature. In many real-world applications, quality constraints are naturally associated with edges in the graphs and ?nding the shortest distance between two vertices s and t along only valid edges (i.e., edges that satisfy a given quality constraint) is also critical. In this paper, we investigate this novel and important problem of quality constraint shortest distance queries. We propose an ef?cient index structure based on 2-hop labeling approaches. Supported by a path dominance relationship incor-porating both quality and length information, we demonstrate the minimal property of the new index. An ef?cient query processing algorithm is also developed. Extensive experimental studies over real-life datasets demonstrates ef?ciency and effectiveness of our techniques."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Optimal Path Selection for a Universal Relation View of Relational Databases,Unskilled users may easily query databases using a universal relation approach and joins based on an optimal path selection procedure for ease of querying.,""Divij G. Singh, Y. Watanobe"",International Conference on Computer Science and Software Engineering,,,10.1109/CSASE51777.2022.9759556,,2022,,https://doi.org/10.1109/CSASE51777.2022.9759556,https://semanticscholar.org/paper/5bcbafb4718a299ebea7bb4adfa7056d07b40636,""Querying complex relational databases can be a complex process for skilled and unskilled users. Adapting Universal Relation View provides a system to make this easier for all users. This system is meant to be implemented as a layer over a traditional view using a querying language. This paper considers that in order to implement this system, two components are needed; a query language, for ease of use, and a query algorithm. The study proposes a universal relation approach and joins based on an optimal path selection procedure for ease of querying. Using this system, unskilled users may easily query databases, and skilled users may find it easier than standard querying."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Enhancing Relation Extraction by Using Shortest Dependency Paths Between Entities with Pre-trained Language Models,The shortest dependency path between entities is obtained by traversing the terms in the dependency tree of a sentence.,""Haluk Alper Karaevli, Tunga Güngör"",International Symposium on INnovations in Intelligent SysTems and Applications,,,10.1109/inista55318.2022.9894216,,2022,,https://doi.org/10.1109/inista55318.2022.9894216,https://semanticscholar.org/paper/ccfd618f7164115c20611e72f613662a93259166,""Relation Extraction (RE) is the task of finding the relation between entities in a plain text. As the length of the sentences increases, finding the relation becomes more challenging. The shortest dependency path (SDP) between two entities, obtained by traversing the terms in the dependency tree of a sentence, provides a view focused on the entities by pruning noisy words. In the supervised form of the relation extraction task, Relation Classification, the state-of-the-art methods generally integrate a pre-trained language model (PLM) into their approaches. However, none of them incorporates the shortest dependency paths to the best of our knowledge.This paper investigates the effects of using shortest dependency paths with pre-trained language models by taking the R-BERT relation classification model as the baseline and building upon it. Our novel approach enhances the baseline model by adding the sequence representation of the shortest dependency path between entities, collected from PLMs, as an additional embedding. In the experiments, we evaluated the proposed model’s performance for each combination of SDPs generated from Stanford, HPSG, and LAL dependency parsers with BERT and XLNet PLMs in two datasets, SemEval-2010 Task 8 and TACRED. We improved the baseline model by","absolute 1.41% and 3.60% scores,",increasing the rankings of,the model from 8th to 7,th and from 18th to 7th in SemEval-2010 Task 8 and TAC,"RED, respectively."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Multi-Agent Path Finding on Strongly Connected Digraphs,A multi-agent pathfinding problem with at least two holes can be checked in linear time with respect to the number of nodes.,""S. Ardizzoni, Irene Saccani, L. Consolini, M. Locatelli"",IEEE Conference on Decision and Control,,,10.1109/CDC51059.2022.9992727,,2022,2,https://doi.org/10.1109/CDC51059.2022.9992727,https://semanticscholar.org/paper/0e85ae701785e549a74ead4575444405d937493b,""On an assigned graph, the problem of Multi-Agent Pathfinding (MAPF) consists in finding paths for multiple agents, avoiding collisions. Finding the minimum-length solution is known to be NP-hard, and computation times grows exponentially with the number of agents. However, in industrial applications, it is important to find feasible, suboptimal solutions, in a time that grows polynomially with the number of agents. Such algorithms exist for undirected and biconnected directed graphs. Our main contribution is to generalize these algorithms to the more general case of strongly connected directed graphs. In particular, given a MAPF problem with at least two holes, we present an algorithm that checks the problem feasibility in linear time with respect to the number of nodes, and provides a feasible solution in polynomial time."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Constrained Structured Optimization and Augmented Lagrangian Proximal Methods,A general and flexible algorithm is proposed that interlaces proximal methods and safeguarded augmented Lagrangian schemes.,A. Marchi,,,,,,2022,5,,https://semanticscholar.org/paper/8670ad12feccb9c3d1e84645be0905430a317fc3,""We investigate and develop numerical methods for ?nite-dimensional constrained structured optimization problems. O ? ering a comprehensive yet simple and expressive language, this problem class provides a modeling framework for a variety of applications. A general and ?exible algorithm is proposed that interlaces proximal methods and safeguarded augmented Lagrangian schemes. We provide a theoretical character-ization of the algorithm and its asymptotic properties, deriving convergence results for fully nonconvex problems. Adopting a proximal gradient method with an oracle as a formal tool, it is demonstrated how the inner subproblems can be solved by o ? -the-shelf methods for composite optimization, without introducing slack variables and despite the appearance of set-valued projections. Finally, we describe our open-source matrix-free implementation of the proposed algorithm and test it numerically. Illustrative examples show the versatility of constrained structured programs as a modeling tool, expose di ? culties arising in this vast problem class and highlight bene?ts of the implicit approach developed."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Constrained Structured Optimization and Augmented Lagrangian Proximal Methods,A general and flexible algorithm is proposed that interlaces proximal methods and safeguarded augmented Lagrangian schemes.,""A. Marchi, Xiao-Yao Jia, C. Kanzow, P. Mehlitz"",,,,,,2022,3,,https://semanticscholar.org/paper/cab7e5644607c3a44dbb8103905cbd80051e3866,""We investigate and develop numerical methods for ?nite-dimensional constrained structured optimization problems. O ? ering a comprehensive yet simple and expressive language, this problem class provides a modeling framework for a variety of applications. A general and ?exible algorithm is proposed that interlaces proximal methods and safeguarded augmented Lagrangian schemes. We provide a theoretical character-ization of the algorithm and its asymptotic properties, deriving convergence results for fully nonconvex problems. Adopting a proximal gradient method with an oracle as a formal tool, it is demonstrated how the inner subproblems can be solved by o ? -the-shelf methods for composite optimization, without introducing slack variables and despite the appearance of set-valued projections. Finally, we describe our open-source matrix-free implementation of the proposed algorithm and test it numerically. Illustrative examples show the versatility of constrained structured programs as a modeling tool, expose di ? culties arising in this vast problem class and highlight bene?ts of the implicit approach developed."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Optimization with access to auxiliary information,The Hessian similarity between the target and side information can benefit from this framework.,""El Mahdi Chayti, Sai Praneeth Karimireddy"",ArXiv,,,10.48550/arXiv.2206.00395,,2022,5,https://doi.org/10.48550/arXiv.2206.00395,https://semanticscholar.org/paper/055b3e0df88506bbb23892f2aa7654bdcb1b71a2,""We investigate the fundamental optimization question of minimizing a target function f(x) whose gradients are expensive to compute or have limited availability, given access to some auxiliary side function h(x) whose gradients are cheap or more available. This formulation captures many settings of practical relevance such as i) re-using batches in SGD, ii) transfer learning, iii) federated learning, iv) training with compressed models/dropout, etc. We propose two generic new algorithms which are applicable in all these settings and prove using only an assumption on the Hessian similarity between the target and side information that we can benefit from this framework."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"""A New Hybrid Optimization Method, Application to a Single Objective Active Flow Control Test Case"",A hybrid optimization method combines the virtues of genetic and gradient based algorithms.,""M. Coma, N. M. Tousi, J. Pons-Prats, G. Bugeda, J. M. Bergadà"",Applied Sciences,,0.44 (11182),10.3390/app12083894,https://www.mdpi.com/2076-3417/12/8/3894/pdf?version=1649829056,2022,1,https://doi.org/10.3390/app12083894,https://semanticscholar.org/paper/980174fc6606e5aab902918a8ad46c0acc80bb56,""Genetic Algorithms (GA) are useful optimization methods for exploration of the search space, but they usually have slowness problems to exploit and converge to the minimum. On the other hand, gradient based methods converge faster to local minimums, although are not so robust (e.g., flat areas and discontinuities can cause problems) and they lack exploration capabilities. This article presents a hybrid optimization method trying to combine the virtues of genetic and gradient based algorithms, and to overcome their corresponding drawbacks. The performance of the Hybrid Method is compared against a gradient based method and a Genetic Algorithm, both used alone. The rate of convergence of the methods is used to compare their performance. To take into account the robustness of the methods, each one has been executed more than once, with different starting points for the gradient based method and different random seeds for the Genetic Algorithm and the Hybrid Method. The performance of the different methods is tested against an optimization Active Flow Control (AFC) problem over a 2D Selig–Donovan 7003 (SD7003) airfoil at Reynolds number 6×104 and a 14 degree angle of attack. Five design variables are considered: jet position, jet width, momentum coefficient, forcing frequency and jet inclination angle. The",objective function is defined as,minus the lift coefficient,"(?Cl), so it is defined",as a minimization problem. The proposed Hybrid Method,enables working with N optimization al,"gorithms, multiple",objective,function,s and design variabl,es per optimization,algorit,hm.,""",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Adaptive Weight of Unreliable Relation Module for Semi-supervised Multi-label Image Recognition,A selective relation module can be added to a variety of relation-based multi-label classification methods.,""Ziyuan Wang, Zhen Zhao, Lei Qi, Yinghuan Shi, Yang Gao"",International Conference on Cloud Computing and Intelligence Systems,,,10.1109/ccis57298.2022.10016315,,2022,,https://doi.org/10.1109/ccis57298.2022.10016315,https://semanticscholar.org/paper/c02d70921e5c3100aaa55c428004c1e1fb250215,""Semi-supervised multi-label classification is a challenging task due to the insufficient training guidance and unknown label co-occurrence probabilities. For papers in recent years, relation modules are widely utilized to explore the potential label relationships, but the severe frequency-biased issue between a global relationship and local images significantly degrades their effectiveness. Besides, the difference in data distribution between training and testing sets further affects the performance, especially when the labeled data is limited. To address these problems, we propose a simple selective relation module to learn an adaptive weight of relation module for each image and enforce the consistency between relation-based predictions and initial predictions. In addition, we exploit the augmentation-based consistency loss to generate more confident relation-based pseudo-labels and more robust relation-importance predictions. Our methods can be added to a variety of relation-based multi-label classification methods and we show our improvements in the classification accuracy on Pascal VOC dataset."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Consistent Representation Learning for Continual Relation Extraction,A proposed method can better learn consistent representations to alleviate forgetting effectively.,""Kang Zhao, Hua Xu, Jian Yang, Kai Gao"",Findings,,,10.48550/arXiv.2203.02721,,2022,5,https://doi.org/10.48550/arXiv.2203.02721,https://semanticscholar.org/paper/51c2e8b2a85c23ac89561b238c0512f0413a5cd9,""Continual relation extraction (CRE) aims to continuously train a model on data with new relations while avoiding forgetting old ones. Some previous work has proved that storing a few typical samples of old relations and replaying them when learning new relations can effectively avoid forgetting. However, these memory-based methods tend to overfit the memory samples and perform poorly on imbalanced datasets. To solve these challenges, a consistent representation learning method is proposed, which maintains the stability of the relation embedding by adopting contrastive learning and knowledge distillation when replaying memory. Specifically, supervised contrastive learning based on a memory bank is first used to train each new task so that the model can effectively learn the relation representation. Then, contrastive replay is conducted of the samples in memory and makes the model retain the knowledge of historical relations through memory knowledge distillation to prevent the catastrophic forgetting of the old task. The proposed method can better learn consistent representations to alleviate forgetting effectively. Extensive experiments on FewRel and TACRED datasets show that our method significantly outperforms state-of-the-art baselines and yield strong robustness on the imbalanced dataset."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"RRL-GAT: Graph Attention Network-Driven Multilabel Image Robust Representation Learning,A robust representation learning method for multilabel images driven by graph attention network is significantly better than all current state-of-the-art methods.,""Bin Hu, Kehua Guo, Xiaokang Wang, Jian Zhang, Di Zhou"",IEEE Internet of Things Journal,,3.848 (408),10.1109/jiot.2021.3089180,,2022,14,https://doi.org/10.1109/jiot.2021.3089180,https://semanticscholar.org/paper/ffb49012ed82f028bc404763564b3afbff3976c5,""Exploring the characterization laws of image data and improving the efficiency of image data characterization knowledge is essential to promote the development of the Internet of Things technology. Considering that images in the real world usually contain multiple objects, and the objects are closely dependent. For these reasons, it brings great challenges to the robust representation learning of multilabel images. In general, researchers model the relationship between objects based on a class activation map and use graph convolution to mine the dependencies between objects. However, graph structure data often contain noise, which means that the edges between nodes are sometimes not so reliable, and the relative importance of neighbors is also different. Based on this, our goal is to reduce noisy connections and false connections between objects, eliminate multilabel image representation bias, and learn robust representations. Therefore, we propose a robust representation learning method for multilabel images driven by graph attention network (RRL-GAT). Specifically, to reduce the accidental false connection of objects in the image, we propose the class attention graph convolution module (C-GAT) to mine the strong association structure between categories. Besides, for the dynamic correlation between objects in the image, w",e propose an adaptive graph attention convolution module (A-GAT),to capture the subtle dynamic dependencies in the image. The results on two authoritative data sets,show,that,our me,thod is,significantly,better,than,all current state-of-the,#NAME?,meth,od,s.,"Besides, the visualization results show that RRL-GAT can capture the semantic relationship of a specific input image and has sufficient recognizability."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Probing the Robustness of Independent Mechanism Analysis for Representation Learning,Independent mechanism analysis helps recovering the true latents.,""Joanna Sliwa, Shubhangi Ghosh, Vincent Stimper, Luigi Gresele, B. Scholkopf"",ArXiv,,,10.48550/arXiv.2207.06137,,2022,1,https://doi.org/10.48550/arXiv.2207.06137,https://semanticscholar.org/paper/f33f84555a855a1c2d3d8ec91822652d9340c0ff,""One aim of representation learning is to recover the original latent code that generated the data, a task which requires additional information or inductive biases. A recently proposed approach termed Independent Mechanism Analysis (IMA) postu-lates that each latent source should in?uence the observed mixtures independently , complementing standard nonlinear independent component analysis, and taking inspiration from the principle of independent causal mechanisms. While it was shown in theory and experiments that IMA helps recovering the true latents, the method’s performance was so far only characterized when the modeling assumptions are exactly satis?ed. Here, we test the method’s robustness to violations of the underlying assumptions. We ?nd that the bene?ts of IMA-based regularization for recovering the true sources extend to mixing functions with various degrees of violation of the IMA principle, while standard reg-ularizers do not provide the same merits. Moreover, we show that unregularized maximum likelihood recovers mixing functions which systematically deviate from the IMA principle, and provide an argument elucidating the bene?ts of IMA-based regularization."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Weakly Supervised Representation Learning with Sparse Perturbations,""If the perturbations are applied only on mutually exclusive blocks of latent variables, identification is achievable under unknown continuous latent distributions."",""Kartik Ahuja, Jason S. Hartford, Yoshua Bengio"",ArXiv,,,10.48550/arXiv.2206.01101,,2022,7,https://doi.org/10.48550/arXiv.2206.01101,https://semanticscholar.org/paper/b78748e923f6bcf9599d0731f180e6aaf4c67222,""The theory of representation learning aims to build methods that provably invert the data generating process with minimal domain knowledge or any source of supervision. Most prior approaches require strong distributional assumptions on the latent variables and weak supervision (auxiliary information such as timestamps) to provide provable identi?cation guarantees. In this work, we show that if one has weak supervision from observations generated by sparse perturbations of the latent variables–e.g. images in a reinforcement learning environment where actions move individual sprites–identi?cation is achievable under unknown continuous latent distributions. We show that if the perturbations are applied only on mutually exclusive blocks of latents, we identify the latents up to those blocks. We also show that if these perturbation blocks overlap, we identify latents up to the smallest blocks shared across perturbations. Consequently, if there are blocks that intersect in one latent variable only, then such latents are identi?ed up to permutation and scaling. We propose a natural estimation procedure based on this theory and illustrate it on low-dimensional synthetic and image-based experiments."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Semi-Supervised Semantic Segmentation Using Unreliable Pseudo-Labels,Unreliable pixels can be convincingly treated as negative samples to those most unlikely categories.,""Yuchao Wang, Haochen Wang, Yujun Shen, Jingjing Fei, Wei Li, Guoqiang Jin, Liwei Wu, Rui Zhao, Xinyi Le"",Computer Vision and Pattern Recognition,,,10.1109/CVPR52688.2022.00421,http://arxiv.org/pdf/2203.03884,2022,39,https://doi.org/10.1109/CVPR52688.2022.00421,https://semanticscholar.org/paper/9f01c919215565217a2e58cbcd66e3e8ee16f0a3,""The crux of semi-supervised semantic segmentation is to assign adequate pseudo-labels to the pixels of unlabeled images. A common practice is to select the highly confident predictions as the pseudo ground-truth, but it leads to a problem that most pixels may be left unused due to their unreliability. We argue that every pixel matters to the model training, even its prediction is ambiguous. Intuitively, an unreliable prediction may get confused among the top classes (i.e., those with the highest probabilities), however, it should be confident about the pixel not belonging to the remaining classes. Hence, such a pixel can be convincingly treated as a negative sample to those most unlikely categories. Based on this insight, we develop an effective pipeline to make sufficient use of unlabeled data. Concretely, we separate reliable and unreliable pixels via the entropy of predictions, push each unreliable pixel to a category-wise queue that consists of negative samples, and manage to train the model with all candidate pixels. Considering the training evolution, where the prediction becomes more and more accurate, we adaptively adjust the threshold for the reliable-unreliable partition. Experimental results on various benchmarks and training settings demonstrate the superiority of our approach over the state-of-the-art alter","natives. 11Project: https://haochen-wang409.github.io/U2PL."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"R-DFCIL: Relation-Guided Representation Learning for Data-Free Class Incremental Learning,R-DFCIL can guide the current model to learn representations of new classes better compatible with representations of previous classes.,""Qiankun Gao, Chen Zhao, Bernard Ghanem, Jian Zhang"",European Conference on Computer Vision,,,10.48550/arXiv.2203.13104,,2022,3,https://doi.org/10.48550/arXiv.2203.13104,https://semanticscholar.org/paper/a7e6ca5e08f425bcd463e8aae2bd688860425a0b,"". Class-Incremental Learning (CIL) struggles with catastrophic forgetting when learning new knowledge, and Data-Free CIL (DFCIL) is even more challenging without access to the training data of previously learned classes. Though recent DFCIL works introduce techniques such as model inversion to synthesize data for previous classes, they fail to overcome forgetting due to the severe domain gap between the synthetic and real data. To address this issue, this paper proposes relation-guided representation learning (RRL) for DFCIL, dubbed R-DFCIL. In RRL, we introduce relational knowledge distillation to flexibly transfer the structural relation of new data from the old model to the current model. Our RRL-boosted DFCIL can guide the current model to learn representations of new classes better compatible with representations of previous classes, which greatly reduces forgetting while improving plasticity. To avoid the mutual interference between representation and classifier learning, we employ local rather than global classification loss during RRL. After RRL, the classification head is refined with global class-balanced classification loss to address the data imbalance issue as well as learn the decision boundaries between new and previous classes. Extensive experiments on CIFAR100, Tiny-ImageNet200, and ImageNet100 demonstrate that our R-DFCIL significantly s",urpasses previous approaches and achieves a new state-of-the-art,performance for DFCIL. Code is available at https://github.com/jianzhangcs/R-DFCIL We propose relat,ion-g,uided,repres,entatio,n learning (RRL,) for,DFCIL,(R-DFCIL) to address the,cat,astro,ph,ic,"forgetting caused by the severe domain gap"",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"De-biased Representation Learning for Fairness with Unreliable Labels,The de-biased learning framework advocates not to use unreliable labels for supervision when sensitive information benefits the prediction of unreliable labels.,""Yixuan Zhang, Feng Zhou, Zhidong Li, Yang Wang, Fang Chen"",ArXiv,,,10.48550/arXiv.2208.00651,,2022,,https://doi.org/10.48550/arXiv.2208.00651,https://semanticscholar.org/paper/00daf22cc79fa492667f228d320ec6fd3178e1a2,""Removing bias while keeping all task-relevant information is challenging for fair representation learning methods since they would yield random or degenerate representations w.r.t. labels when the sensitive attributes correlate with labels. Existing works proposed to inject the label information into the learning procedure to overcome such issues. However, the assumption that the observed labels are clean is not always met. In fact, label bias is acknowledged as the primary source inducing discrimination. In other words, the fair pre-processing methods ignore the discrimination encoded in the labels either during the learning procedure or the evaluation stage. This contradiction puts a question mark on the fairness of the learned representations. To circumvent this issue, we explore the following question: Can we learn fair representations predictable to latent ideal fair labels given only access to unreliable labels? In this work, we propose a D e- B iased R epresentation Learning for F airness (DBRF) framework which disentangles the sensitive information from non-sensitive attributes whilst keeping the learned representations predictable to ideal fair labels rather than observed biased ones. We formulate the de-biased learning framework through information-theoretic concepts such as mutual information and information bottleneck. The core concept is that DBRF advocates not to",use unreliable labels for supervision when sensitive informatio,n bene?ts the prediction of unreliable labels. Experiment results over both synthetic and real-world,data,demo,nstrate,that D,BRF effectively,learn,s de-,biased representations to,ward,s ide,al,l,"abels."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"A Representation Learning Method of Knowledge Graph Integrating Ordered Relation Path and Entity Description Information,The model has higher accuracy than existing baselines.,""Haoxiang Ma, Xuesong Jiang, Huihui Chai, Xiumei Wei"",""IEEE International Conference on Systems, Man and Cybernetics"",,,10.1109/SMC53654.2022.9945592,,2022,1,https://doi.org/10.1109/SMC53654.2022.9945592,https://semanticscholar.org/paper/6139af5179527be9c7fab7293f0317b08eb584ce,""Knowledge graph representation learning aims to obtain its vector representation by mapping entities and relations in knowledge graphs to a continuous low-dimensional vector space by learning methods. Most of the existing knowledge graph representation learning methods only consider the single-step relation between entities from the perspective of triples and fail to effectively utilize important information such as ordered multi-step relation paths and entity descriptions, thus affecting the ability of knowledge representation learning. We propose a knowledge graph representation learning model that integrates ordered relation paths and entity descriptions in response to the above problems. The model can integrate the triple representation in the knowledge graph, the semantic representation of entity description, and the representation of ordered relation paths for training. On the FB15K, WN18, FB15K-237, and WN18RR datasets, the proposed model and baselines are run on the link prediction task. Experimental results show that the model has higher accuracy than existing baselines, demonstrating the effectiveness and superiority of the method."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Task-Agnostic Robust Representation Learning,A robustness regularizer is task-independent.,""A. Nguyen, S. Lim, Philip H. S. Torr"",ArXiv,,,10.48550/arXiv.2203.07596,,2022,2,https://doi.org/10.48550/arXiv.2203.07596,https://semanticscholar.org/paper/7f299aa0593069ebbbaf1e2f1c312f5d620b37e2,""It has been reported that deep learning models are extremely vulnerable to small but intentionally chosen perturbations of its input. In particular, a deep network, despite its near-optimal accuracy on the clean images, often mis-classifies an image with a worst-case but humanly imperceptible perturbation (so-called adversarial examples). To tackle this problem, a great amount of research has been done to study the training procedure of a network to improve its robustness. However, most of the research so far has focused on the case of supervised learning. With the increasing popularity of self-supervised learning methods, it is also important to study and improve the robustness of their resulting representation on the downstream tasks. In this paper, we study the problem of robust representation learning with unlabeled data in a task-agnostic manner. Specifically, we first derive an upper bound on the adversarial loss of a prediction model (which is based on the learned representation) on any downstream task, using its loss on the clean data and a robustness regularizer. Moreover, the regularizer is task-independent, thus we propose to minimize it directly during the representation learning phase to make the downstream prediction model more robust. Extensive experiments show that our method achieves preferable adversarial performance compared to relevant baselines."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Learning Relation-Specific Representations for Few-shot Knowledge Graph Completion,The embeddings of two entities are insufficient to represent the semantic information of their relationship.,""Yuling Li, Kui Yu, Yuhong Zhang, Xindong Wu"",ArXiv,,,10.48550/arXiv.2203.11639,,2022,1,https://doi.org/10.48550/arXiv.2203.11639,https://semanticscholar.org/paper/cffe596ef04dc60604b9977ddfe0a791d057c0e4,""Recent years have witnessed increasing interest in few-shot knowledge graph completion (FKGC), which aims to infer unseen query triples for a few-shot relation using a handful of reference triples of the relation. The primary focus of existing FKGC methods lies in learning the relation representations that can reflect the common information shared by the query and reference triples. To this end, these methods learn the embeddings of entities with their direct neighbors, and use the concatenation of the entity embeddings as the relation representations. However, the entity embeddings learned only from direct neighborhoods may have low expressiveness when the entity has sparse neighbors or shares a common local neighborhood with other entities. Moreover, the embeddings of two entities are insufficient to represent the semantic information of their relationship, especially when they have multiple relations. To address these issues, we propose a Relation-Specific Context Learning (RSCL) framework, which exploits graph contexts of triples to capture the semantic information of relations and entities simultaneously. Specifically, we first extract graph contexts for each triple, which can provide long-term entity-relation dependencies. To model the graph contexts, we then develop a hierarchical relation-specific learner to learn global and local relation-specific representations for relations by capturing contextualized information of",triples and incorporating local information of entities. Finall,"y, we utilize the learned representations to predict the likelihood of the query triples. Experiment",al re,sults,on two,public,datasets demon,strate,that,RSCL outperforms state-o,f-th,e-art,F,KG,"C methods."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Debiased Contrastive Learning of Unsupervised Sentence Representations,Contrastive learning has been shown to be effective in improving pre-trained language models to derive high-quality sentence representations.,""Kun Zhou, Beichen Zhang, Wayne Xin Zhao, Ji-rong Wen"",Annual Meeting of the Association for Computational Linguistics,,,10.48550/arXiv.2205.00656,,2022,12,https://doi.org/10.48550/arXiv.2205.00656,https://semanticscholar.org/paper/0f8261b01eb0a150904729cf70f78d9e1bc26617,""Recently, contrastive learning has been shown to be effective in improving pre-trained language models (PLM) to derive high-quality sentence representations. It aims to pull close positive examples to enhance the alignment while push apart irrelevant negatives for the uniformity of the whole representation space.However, previous works mostly adopt in-batch negatives or sample from training data at random. Such a way may cause the sampling bias that improper negatives (false negatives and anisotropy representations) are used to learn sentence representations, which will hurt the uniformity of the representation space.To address it, we present a new framework DCLR (Debiased Contrastive Learning of unsupervised sentence Representations) to alleviate the influence of these improper negatives.In DCLR, we design an instance weighting method to punish false negatives and generate noise-based negatives to guarantee the uniformity of the representation space.Experiments on seven semantic textual similarity tasks show that our approach is more effective than competitive baselines. Our code and data are publicly available at the link: bluehttps://github.com/RUCAIBox/DCLR."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Evaluation Methods for Representation Learning: A Survey,Representation learning algorithms have exhibited state-of-the-art performance on several machine learning tasks.,""Kento Nozawa, Issei Sato"",International Joint Conference on Artificial Intelligence,,,10.24963/ijcai.2022/776,https://www.ijcai.org/proceedings/2022/0776.pdf,2022,1,https://doi.org/10.24963/ijcai.2022/776,https://semanticscholar.org/paper/70e8b89f4dde78113a1c3f3a2359a6af702e38f0,""Representation learning enables us to automatically extract generic feature representations from a dataset to solve another machine learning task. Recently, extracted feature representations by a representation learning algorithm and a simple predictor have exhibited state-of-the-art performance on several machine learning tasks. Despite its remarkable progress, there exist various ways to evaluate representation learning algorithms depending on the application because of the flexibility of representation learning. To understand the current applications of representation learning, we review evaluation methods of representation learning algorithms. On the basis of our evaluation survey, we also discuss the future direction of representation learning. The extended version, https://arxiv.org/abs/2204.08226, gives more detailed discussions and a survey on theoretical analyses."",,Review",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"DRK: Discriminative Rule-based Knowledge for Relieving Prediction Confusions in Few-shot Relation Extraction,Existing meta-learning methods still fall into prediction confusions owing to the limited inference ability over shallow text features.,""Mengru Wang, Jianming Zheng, Fei Cai, Taihua Shao, Honghui Chen"",International Conference on Computational Linguistics,,,,,2022,1,,https://semanticscholar.org/paper/03bc9cc3b8afc5fbeddd1928f39520666657866a,""Few-shot relation extraction aims to identify the relation type between entities in a given text in the low-resource scenario. Albeit much progress, existing meta-learning methods still fall into prediction confusions owing to the limited inference ability over shallow text features. To relieve these confusions, this paper proposes a discriminative rule-based knowledge (DRK) method. Specifically, DRK adopts a logic-aware inference module to ease the word-overlap confusion, which introduces a logic rule to constrain the inference process, thereby avoiding the adverse effect of shallow text features. Also, DRK employs a discrimination finding module to alleviate the entity-type confusion, which explores distinguishable text features via a hierarchical contrastive learning. We conduct extensive experiments on four types of meta tasks and the results show promising improvements from DRK (6.0% accuracy gains on average). Besides, error analyses reveal the word-overlap and entity-type errors are the main courses of mispredictions in few-shot relation extraction."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"A Unified Causal View of Domain Invariant Representation Learning,""Causal relationships are invariant, but non-causal relationships may vary."",""Zihao Wang, Victor Veitch"",ArXiv,,,10.48550/arXiv.2208.06987,,2022,5,https://doi.org/10.48550/arXiv.2208.06987,https://semanticscholar.org/paper/6558db469aa51df4b43a8aafb8441957e49d1daf,""Machine learning methods can be unreliable when deployed in domains that differ from the domains on which they were trained. To address this, we may wish to learn representations of data that are domain-invariant in the sense that we preserve data structure that is stable across domains, but throw out spuriously-varying parts. There are many representation-learning approaches of this type, including methods based on data augmentation, distributional invariances, and risk invariance. Unfortunately, when faced with any particular real-world domain shift, it is unclear which, if any, of these methods might be expected to work. The purpose of this paper is to show how the different methods relate to each other, and clarify the real-world circumstances under which each is expected to succeed. The key tool is a new notion of domain shift relying on the idea that causal relationships are invariant, but non-causal relationships (e.g., due to confounding) may vary."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"A Unified Causal View of Domain Invariant Representation Learning,""Causal relationships are invariant, but non-causal relationships may vary."",""Zihao Wang, Victor Veitch"",ArXiv,,,10.48550/arXiv.2208.06987,,2022,5,https://doi.org/10.48550/arXiv.2208.06987,https://semanticscholar.org/paper/846096ebb8fb7d475c09cccd952335c4c8344fe8,""Machine learning methods can be unreliable when deployed in domains that differ from the domains on which they were trained. To address this, we may wish to learn representations of data that are domain-invariant in the sense that we preserve data structure that is stable across domains, but throw out spuriously-varying parts. There are many representation-learning approaches of this type, including methods based on data augmentation, distributional invariances, and risk invariance. Unfortunately, when faced with any particular real-world domain shift, it is unclear which, if any, of these methods might be expected to work. The purpose of this paper is to show how the different methods relate to each other, and clarify the real-world circumstances under which each is expected to succeed. The key tool is a new notion of domain shift relying on the idea that causal relationships are invariant, but non-causal relationships (e.g., due to confounding) may vary."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Dual Contrastive Prediction for Incomplete Multi-View Representation Learning.,""The proposed method remarkably outperforms 20 competitive multi-view learning methods on six datasets in terms of clustering, classification, and human action recognition."",""Yijie Lin, Yuanbiao Gou, Xiaotian Liu, Jinfeng Bai, Jiancheng Lv, Xiaocui Peng"",IEEE Transactions on Pattern Analysis and Machine Intelligence,,8.269 (105),10.1109/TPAMI.2022.3197238,,2022,5,https://doi.org/10.1109/TPAMI.2022.3197238,https://semanticscholar.org/paper/5f6f564c90f4e47cbdd361433cb0b1b58291c339,""In this article, we propose a unified framework to solve the following two challenging problems in incomplete multi-view representation learning: i) how to learn a consistent representation unifying different views, and ii) how to recover the missing views. To address the challenges, we provide an information theoretical framework under which the consistency learning and data recovery are treated as a whole. With the theoretical framework, we propose a novel objective function which jointly solves the aforementioned two problems and achieves a provable sufficient and minimal representation. In detail, the consistency learning is performed by maximizing the mutual information of different views through contrastive learning, and the missing views are recovered by minimizing the conditional entropy through dual prediction. To the best of our knowledge, this is one of the first works to theoretically unify the cross-view consistency learning and data recovery for representation learning. Extensive experimental results show that the proposed method remarkably outperforms 20 competitive multi-view learning methods on six datasets in terms of clustering, classification, and human action recognition. The code could be accessed from https://pengxi.me."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Evaluating and Improving Robustness of Self-Supervised Representations to Spurious Correlations,Classic approaches in combating spurious correlations during SSL do not consistently lead to invariant representations.,""Kimia Hamidieh, Haoran Zhang, M. Ghassemi"",,,,,,2022,1,,https://semanticscholar.org/paper/02a0e07b73d34d057151a7aa716858222e8d4cef,""Recent empirical studies have found inductive biases in supervised learning toward simple features that may be spuriously correlated with the label, resulting in suboptimal performance on minority subgroups. Despite the growing popularity of methods which learn representations from unlabeled data, it is unclear how potential spurious features may be manifested in the learnt representations. In this work, we explore whether recent Self-Supervised Learning (SSL) methods would produce representations which exhibit similar be-haviors under spurious correlation. First, we show that classical approaches in combating spurious correlations, such as dataset re-sampling during SSL, do not consistently lead to invariant representation. Second, we find that spurious information is represented disproportionately heavily in the later layers of the encoder. Motivated by these findings, we propose a method to remove spurious information from these representations during pre-training, by pruning or re-initializing later layers of the encoder. We find that our method produces representations which outperform the baseline on three datasets, without the need for group or label information during SSL."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Leveraging Relational Information for Learning Weakly Disentangled Representations,The learned representations can separate the relevant factors of variation in the data.,""Andrea Valenti, D. Bacciu"",IEEE International Joint Conference on Neural Network,,,10.1109/IJCNN55064.2022.9892093,http://arxiv.org/pdf/2205.10056,2022,1,https://doi.org/10.1109/IJCNN55064.2022.9892093,https://semanticscholar.org/paper/9ff9b8a2aa7582ba7cf6a450073660a2957391c7,""Disentanglement is a difficult property to enforce in neural representations. This might be due, in part, to a formalization of the disentanglement problem that focuses too heavily on separating relevant factors of variation of the data in single isolated dimensions of the neural representation. We argue that such a definition might be too restrictive and not necessarily beneficial in terms of downstream tasks. In this work, we present an alternative view over learning (weakly) disentangled representations, which leverages concepts from relational learning. We identify the regions of the latent space that correspond to specific instances of generative factors, and we learn the relationships among these regions in order to perform controlled changes to the latent codes. We also introduce a compound generative model that implements such a weak disentanglement approach. Our experiments shows that the learned representations can separate the relevant factors of variation in the data, while preserving the information needed for effectively generating high quality data samples."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Simple Unsupervised Graph Representation Learning,The proposed multiplet loss explores the complementary information between the structural information and neighbor information to enlarge the inter-class variation.,""Yujie Mo, Liang Peng, J. Xu, Xiaoshuang Shi, Xiao-lan Zhu"",AAAI Conference on Artificial Intelligence,,,10.1609/aaai.v36i7.20748,https://ojs.aaai.org/index.php/AAAI/article/download/20748/20507,2022,21,https://doi.org/10.1609/aaai.v36i7.20748,https://semanticscholar.org/paper/3cb7c04c80c1c75cd8df17c5b7ab6a5399563a65,""In this paper, we propose a simple unsupervised graph representation learning method to conduct effective and efficient contrastive learning. Specifically, the proposed multiplet loss explores the complementary information between the structural information and neighbor information to enlarge the inter-class variation, as well as adds an upper bound loss to achieve the finite distance between positive embeddings and anchor embeddings for reducing the intra-class variation. As a result, both enlarging inter-class variation and reducing intra-class variation result in small generalization error, thereby obtaining an effective model. Furthermore, our method removes widely used data augmentation and discriminator from previous graph contrastive learning methods, meanwhile available to output low-dimensional embeddings, leading to an efficient model. Experimental results on various real-world datasets demonstrate the effectiveness and efficiency of our method, compared to state-of-the-art methods. The source codes are released at https://github.com/YujieMo/SUGRL."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Empirical Evaluation and Theoretical Analysis for Representation Learning: A Survey,Representation learning algorithms have exhibited state-of-the-art performance on several machine learning tasks.,""Kento Nozawa, Issei Sato"",ArXiv,,,10.48550/arXiv.2204.08226,,2022,1,https://doi.org/10.48550/arXiv.2204.08226,https://semanticscholar.org/paper/f097fb79d7ab0743d96167d419788d4aad8197d7,""Representation learning enables us to automatically extract generic feature representations from a dataset to solve another machine learning task. Recently, extracted feature representations by a representation learning algorithm and a simple predictor have exhibited state-of-the-art performance on several machine learning tasks. Despite its remarkable progress, there exist various ways to evaluate representation learning algorithms depending on the application because of the ?exibility of representation learning. To understand the current representation learning, we review evaluation methods of representation learning algorithms and theoretical analyses. On the basis of our evaluation survey, we also discuss the future direction of representation learning. Note that this survey is the extended version of Nozawa and Sato [1]."",,Review",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"ACE: A Coarse-to-Fine Learning Framework for Reliable Representation Learning Against Label Noise,,""Chenbin Zhang, Xiangli Yang, Jian Liang, Bing Bai, Kun Bai, Irwin King, Zenglin Xu"",IEEE International Joint Conference on Neural Network,,,10.1109/IJCNN55064.2022.9892045,,2022,,https://doi.org/10.1109/IJCNN55064.2022.9892045,https://semanticscholar.org/paper/a30ac02360836fbfe098d3356d3fe0a4b48dce8b,""The prosperity of deep neural networks in various computer vision applications heavily depends on large-scale high-quality annotated datasets. However, inaccurate annotations are often inevitable when building hand-labeled datasets, which can lead to imperfectly supervision problems. Most existing methods to address these problems mainly use noisy labels to learn latent representations, which may be corrupted when the noise rate is high, thus limiting the predictions for clean test data set. In this paper, we propose a flexible coarse-to-fine representation learning framework to improve the quality of latent representations by exploiting the reliable geometry information from raw features. This framework includes: (i) an anchored representation learner, which is a coarse mechanism for learning reasonable feature-similarity to avoid feature corruption, (ii) a confident representation learner, which is used to learn confident data pairs, and (iii) an exploratory representation learner, which is proposed for learning from feasible unconfident pairs and performing label refurbishment. Comprehensive experiments have demonstrated the effectiveness of our proposed method, especially when the noise level is high and the task is relatively difficult."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Review of Methods for Handling Class-Imbalanced in Classification Problems,,""Satyendra Singh Rawat, A. Mishra"",ArXiv,,,10.48550/arXiv.2211.05456,,2022,,https://doi.org/10.48550/arXiv.2211.05456,https://semanticscholar.org/paper/a6cf85fcfe885bd27583bcaf2bdf90a9356f9a72,""Learning classifiers using skewed or imbalanced datasets can occasionally lead to classification issues; this is a serious issue. In some cases, one class contains the majority of examples while the other, which is frequently the more important class, is nevertheless represented by a smaller proportion of examples. Using this kind of data could make many carefully designed machine-learning systems ineffective. High training fidelity was a term used to describe biases vs. all other instances of the class. The best approach to all possible remedies to this issue is typically to gain from the minority class. The article examines the most widely used methods for addressing the problem of learning with a class imbalance, including data-level, algorithm-level, hybrid, cost-sensitive learning, and deep learning, etc. including their advantages and limitations. The efficiency and performance of the classifier are assessed using a myriad of evaluation metrics."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"A Noise-Aware Method With Type Constraint Pattern for Neural Relation Extraction,,""Jianfeng Qu, Wen Hua, D. Ouyang, Xiaofang Zhou"",IEEE Transactions on Knowledge and Data Engineering,,2.431 (883),10.1109/TKDE.2021.3108547,,2023,3,https://doi.org/10.1109/TKDE.2021.3108547,https://semanticscholar.org/paper/7fae53b92dc2b57fa4fa9a01f13b287edb9ef394,""Distant supervision is an efficient way to generate large-scale training data for relation extraction without human efforts. However, the accompanying challenges have been plaguing the advance of the extractor: (1) the automatically annotated labels for training data contain much noisy data and hurt the performance of the extractor; (2) the annotations, based on bag-level (cluster of sentences) instead of sentence-level (single sentence), are too coarse to train an accurate extractor; (3) hetergeneous sentences are hard for a denoising model to capture the underlying commonness among valid relational expressions. To address these issues, we bulid a novel sentence representation and craft reinforcement learning to select the expressive sentence for each relation mentioned in a bag. More specifically, we introduce entity-free sentence pattern incorporated with attentive type information. Furthermore, multiple interactions between entity-specific and entity-free representation are proposed to generate complementary sentence features (for challenge 3). Then we design a fine-grained reward function, and model the sentence selection process as an auction where different relations for a bag need to compete together to achieve the possession of a specific sentence based on its expressiveness. In this way, our model can be dynamically self-adapted, and eventually implements the accurate one-to-one mapping from a relation label to its chosen expressive sentence, which serves as training",instances for the extractor (for challenge 1 and 2). The experi,mental results on two public datasets demonstrate the superiority of our model compared with current,stat,e-of-,the-art,method,s for distantly,super,vised,"relation extraction."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Probing Representation Forgetting in Supervised and Unsupervised Continual Learning,,""Mohammad-Javad Davari, Nader Asadi, S. Mudur, Rahaf Aljundi, Eugene Belilovsky"",Computer Vision and Pattern Recognition,,,10.1109/CVPR52688.2022.01621,,2022,12,https://doi.org/10.1109/CVPR52688.2022.01621,https://semanticscholar.org/paper/1d05f76a422d776ad80fde02bb1fbd064ae2bc89,""Continual Learning (CL) research typically focuses on tackling the phenomenon of catastrophic forgetting in neural networks. Catastrophic forgetting is associated with an abrupt loss of knowledge previously learned by a model when the task, or more broadly the data distribution, being trained on changes. In supervised learning problems this forgetting, resulting from a change in the model's representation, is typically measured or observed by evaluating the decrease in old task performance. However, a model's representation can change without losing knowledge about prior tasks. In this work we consider the concept of representation forgetting, observed by using the difference in performance of an optimal linear classifier before and after a new task is introduced. Using this tool we revisit a number of standard continual learning benchmarks and observe that, through this lens, model representations trained without any explicit control for forgetting often experience small representation forgetting and can sometimes be comparable to methods which explicitly control for forgetting, especially in longer task sequences. We also show that representation forgetting can lead to new insights on the effect of model capacity and loss function used in continual learning. Based on our results, we show that a simple yet competitive approach is to learn representations continually with standard supervised contrastive learning while constructing prototypes of class samples",when queried on old samples.11The code to reproduce our results,"is publicly available at: https://github.com/rezazzr/Probing-Representation-Forgetting"",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Incorporating Context Graph with Logical Reasoning for Inductive Relation Prediction,,""Qika Lin, Jun Liu, Fangzhi Xu, Yudai Pan, Yifan Zhu, Lingling Zhang, Tianzhe Zhao"",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,,,10.1145/3477495.3531996,,2022,5,https://doi.org/10.1145/3477495.3531996,https://semanticscholar.org/paper/8c720eb939259971bcb87f46c92ebb0d2d5497c7,""Relation prediction on knowledge graphs (KGs) aims to infer missing valid triples from observed ones. Although this task has been deeply studied, most previous studies are limited to the transductive setting and cannot handle emerging entities. Actually, the inductive setting is closer to real-life scenarios because it allows entities in the testing phase to be unseen during training. However, it is challenging to precisely conduct inductive relation prediction as there exists requirements of entity-independent relation modeling and discrete logical reasoning for interoperability. To this end, we propose a novel model ConGLR to incorporate context graph with logical reasoning. Firstly, the enclosing subgraph w.r.t. target head and tail entities are extracted and initialized by the double radius labeling. And then the context graph involving relational paths, relations and entities is introduced. Secondly, two graph convolutional networks (GCNs) with the information interaction of entities and relations are carried out to process the subgraph and context graph respectively. Considering the influence of different edges and target relations, we introduce edge-aware and relation-aware attention mechanisms for the subgraph GCN. Finally, by treating the relational path as rule body and target relation as rule head, we integrate neural calculating and logical reasoning to obtain inductive scores. And to focus on the s","pecific modeling goals of each module, the stop-gradient is util",ized in the information interaction between context graph and subgraph GCNs in the training process.,In t,his w,"ay, Con",GLR sat,isfies two indu,ctive,requi,rements at the same time.,Ext,ensiv,e,ex,"periments demonstrate that ConGLR obtains outstanding performance against state-of-the-art baselines on twelve inductive dataset versions of three common KGs."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Balanced Contrastive Learning for Long-Tailed Visual Recognition,,""Jianggang Zhu, Z. Wang, Jingjing Chen, Yi-Ping Phoebe Chen, Yueping Jiang"",Computer Vision and Pattern Recognition,,,10.1109/CVPR52688.2022.00678,,2022,14,https://doi.org/10.1109/CVPR52688.2022.00678,https://semanticscholar.org/paper/cda7a9f058fde65956252831f2c6dd2a8dc370e8,""Real-world data typically follow a long-tailed distribution, where a few majority categories occupy most of the data while most minority categories contain a limited number of samples. Classification models minimizing crossentropy struggle to represent and classify the tail classes. Although the problem of learning unbiased classifiers has been well studied, methods for representing imbalanced data are under-explored. In this paper, we focus on representation learning for imbalanced data. Recently, supervised contrastive learning has shown promising performance on balanced data recently. However, through our theoretical analysis, we find that for long-tailed data, it fails to form a regular simplex which is an ideal geometric configuration for representation learning. To correct the optimization behavior of SCL and further improve the performance of long-tailed visual recognition, we propose a novel loss for balanced contrastive learning (BCL). Compared with SCL, we have two improvements in BCL: classaveraging, which balances the gradient contribution of negative classes; class-complement, which allows all classes to appear in every mini-batch. The proposed balanced contrastive learning (BCL) method satisfies the condition of forming a regular simplex and assists the optimization of cross-entropy. Equipped with BCL, the proposed two-branch framework can obtain a stronger feature representation and achieve competitive performance on long-tailed benchmark datasets such as CIFAR-10-LT",", CIFAR-100-LT, ImageNet-LT, and iNaturalist2018."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Class-Incremental Learning by Knowledge Distillation with Adaptive Feature Consolidation,,""Minsoo Kang, Jaeyoo Park, Bohyung Han"",Computer Vision and Pattern Recognition,,,10.1109/CVPR52688.2022.01560,,2022,10,https://doi.org/10.1109/CVPR52688.2022.01560,https://semanticscholar.org/paper/66ef5dd4c713bebbb33b4696fdf4b703203eb3b1,""We present a novel class incremental learning approach based on deep neural networks, which continually learns new tasks with limited memory for storing examples in the previous tasks. Our algorithm is based on knowledge distillation and provides a principled way to maintain the representations of old models while adjusting to new tasks effectively. The proposed method estimates the relationship between the representation changes and the resulting loss increases incurred by model updates. It minimizes the upper bound of the loss increases using the representations, which exploits the estimated importance of each feature map within a backbone model. Based on the importance, the model restricts updates of important features for robustness while allowing changes in less critical features for flexibility. This optimization strategy effectively alleviates the notorious catastrophic forgetting problem despite the limited accessibility of data in the previous tasks. The experimental results show significant accuracy improvement of the proposed algorithm over the existing methods on the standard datasets. Code is available.11https://github.com/kminsoo/AFC"",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Analysis of Knowledge Graph Path Reasoning Based on Variational Reasoning,Knowledge graph reasoning improves model accuracy and enhancing model learning and reasoning capabilities.,""Hongmei Tang, Wenzhong Tang, Ruichen Li, Yanyang Wang, Shuai Wang, Lihong Wang"",Applied Sciences,,0.44 (11182),10.3390/app12126168,https://www.mdpi.com/2076-3417/12/12/6168/pdf?version=1655459548,2022,,https://doi.org/10.3390/app12126168,https://semanticscholar.org/paper/8f56e567f1b6df0d3e80e1604520bf2cd5c23209,""Knowledge graph (KG) reasoning improves the perception ability of graph structure features, improving model accuracy and enhancing model learning and reasoning capabilities. This paper proposes a new GraphDIVA model based on the variational reasoning divergent autoencoder (DIVA) model. The network structures and calculation processes of the models are analyzed. The GraphSAGE algorithm is introduced into the path reasoning module to solve the inability of the original model to perceive the features of the graph structure, which leads to a decline in the accuracy rate. Hence, GraphDIVA can achieve a higher accuracy rate with fewer learning iterations. The experiments show the efficiency and effectiveness of our model and proves that our method has a better effect on the accuracy rate and training difficulty than the baseline model on the FB15k-237 and NELL-995 benchmark datasets."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Learning the Dynamics of Visual Relational Reasoning via Reinforced Path Routing,Reinforced path routing is a method to learn the reasoning dynamics of visual relational reasoning by casting it as a path routing task.,""Chenchen Jing, Yunde Jia, Yuwei Wu, Chuanhao Li, Qi Wu"",AAAI Conference on Artificial Intelligence,,,10.1609/aaai.v36i1.19997,https://ojs.aaai.org/index.php/AAAI/article/download/19997/19756,2022,1,https://doi.org/10.1609/aaai.v36i1.19997,https://semanticscholar.org/paper/6bb962d694f6be9a5c74cd9a18d0cf2a6f6319d7,""Reasoning is a dynamic process. In cognitive theories, the dynamics of reasoning refers to reasoning states over time after successive state transitions. Modeling the cognitive dynamics is of utmost importance to simulate human reasoning capability. In this paper, we propose to learn the reasoning dynamics of visual relational reasoning by casting it as a path routing task. We present a reinforced path routing method that represents an input image via a structured visual graph and introduces a reinforcement learning based model to explore paths (sequences of nodes) over the graph based on an input sentence to infer reasoning results. By exploring such paths, the proposed method represents reasoning states clearly and characterizes state transitions explicitly to fully model the reasoning dynamics for accurate and transparent visual relational reasoning. Extensive experiments on referring expression comprehension and visual question answering demonstrate the effectiveness of our method."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Fair Representation Learning through Implicit Path Alignment,The proposed bi-level objective is demonstrated to fulfill the sufficiency rule.,""Changjian Shui, Qi Chen, Jiaqi Li, Boyu Wang, Christian Gagn'e"",International Conference on Machine Learning,,,10.48550/arXiv.2205.13316,,2022,6,https://doi.org/10.48550/arXiv.2205.13316,https://semanticscholar.org/paper/0f0a396d0479c98fece998077f0ea285791c6470,""We consider a fair representation learning perspective, where optimal predictors, on top of the data representation, are ensured to be invariant with respect to different sub-groups. Speci?cally, we formulate this intuition as a bi-level optimization, where the representation is learned in the outer-loop, and invariant optimal group predictors are updated in the inner-loop. Moreover, the proposed bi-level objective is demonstrated to ful?ll the suf?ciency rule , which is desirable in various practical scenarios but was not commonly studied in the fair learning. Besides, to avoid the high computational and memory cost of differentiating in the inner-loop of bi-level objective, we propose an implicit path alignment algorithm, which only relies on the solution of inner optimization and the implicit differentiation rather than the exact optimization path. We further analyze the error gap of the implicit approach and empirically validate the proposed method in both classi?cation and regression settings. Experimental results show the consistently better trade-off in prediction performance and fairness measurement."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Multi-Semantic Path Representation Learning for Travel Time Estimation,A multi-semantic path representation method to exploit information in Euclidean space and non-Euclidean space simultaneously is proposed.,""Liangzhe Han, Bowen Du, Jingjing Lin, Leilei Sun, Xucheng Li, Yizhou Peng"",IEEE transactions on intelligent transportation systems (Print),,,10.1109/TITS.2021.3119887,,2022,3,https://doi.org/10.1109/TITS.2021.3119887,https://semanticscholar.org/paper/c87fdb849bac8edd37b0ed09800d6b41ecb7c7d0,""Travel time estimation of a given path is a crucial task of Intelligent Transportation Systems (ITS). Accurate travel time estimation can benefit multiple downstream applications such as route planning, real-time navigation, and urban construction. However, it is a challenging problem since the travel time is largely affected by multiple complicated factors including spatial factors, temporal factors and external factors, and obtaining informative representations of a given path is not trivial. Most previous works solved this problem in either Euclidean space or non-Euclidean space, which was unilateral to represent the actual traveling path and led to relatively poor performance. To address this, this paper proposes a multi-semantic path representation method to exploit information in Euclidean space and non-Euclidean space simultaneously. First, since the path is composed of several segments, we generate semantic representations of segments in non-Euclidean space by taking both the time information and the historical co-occurrence into consideration. Second, as the path could be equally represented as several travelled intersections, semantic representations of intersection sequences are also extracted to improve the capability of the method by considering information in Euclidean space. Meanwhile, semantic representations from properties, including the length and the type of segments, are","also incorporated into the model. Finally, a",se,quenc,e l,ear,nin,g c,omp,onent,is,add,ed,on,t,he,top,to,agg,"regate the information along the entire path and provides the final estimation. Extensive experiments were conducted on two real-world taxi trajectories datasets, and the experimental results demonstrate the superiority of the proposed method."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"A*Net: A Scalable Path-based Reasoning Approach for Knowledge Graphs,A*Net achieves competitive performance with existing state-of-the-art path-based methods.,""Zhaocheng Zhu, Xinyu Yuan, Mikhail Galkin, Sophie Xhonneux, Ming Zhang, Maxime Gazeau, Jian Tang"",,,,,,2022,,,https://semanticscholar.org/paper/e8fd5c34e0be01c5d7c707b90ad245cd46738448,""Reasoning on large-scale knowledge graphs has been long dominated by embedding methods. While path-based methods possess the inductive capacity that embeddings lack, they suffer from the scalability issue due to the exponential number of paths. Here we present A*Net, a scalable path-based method for knowledge graph reasoning. Inspired by the A* algorithm for shortest path problems, our A*Net learns a priority function to select important nodes and edges at each iteration, to reduce time and memory footprint for both training and inference. The ratio of selected nodes and edges can be specified to trade off between performance and efficiency. Experiments on both transductive and inductive knowledge graph reasoning benchmarks show that A*Net achieves competitive performance with existing state-of-the-art path-based methods, while merely visiting 10% nodes and 10% edges at each iteration. On a million-scale dataset ogbl-wikikg2, A*Net achieves competitive performance with embedding methods and converges faster. To our best knowledge, A*Net is the first path-based method for knowledge graph reasoning at such a scale."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"A Representation Learning Method of Knowledge Graph Integrating Ordered Relation Path and Entity Description Information,The model has higher accuracy than existing baselines.,""Haoxiang Ma, Xuesong Jiang, Huihui Chai, Xiumei Wei"",""IEEE International Conference on Systems, Man and Cybernetics"",,,10.1109/SMC53654.2022.9945592,,2022,1,https://doi.org/10.1109/SMC53654.2022.9945592,https://semanticscholar.org/paper/6139af5179527be9c7fab7293f0317b08eb584ce,""Knowledge graph representation learning aims to obtain its vector representation by mapping entities and relations in knowledge graphs to a continuous low-dimensional vector space by learning methods. Most of the existing knowledge graph representation learning methods only consider the single-step relation between entities from the perspective of triples and fail to effectively utilize important information such as ordered multi-step relation paths and entity descriptions, thus affecting the ability of knowledge representation learning. We propose a knowledge graph representation learning model that integrates ordered relation paths and entity descriptions in response to the above problems. The model can integrate the triple representation in the knowledge graph, the semantic representation of entity description, and the representation of ordered relation paths for training. On the FB15K, WN18, FB15K-237, and WN18RR datasets, the proposed model and baselines are run on the link prediction task. Experimental results show that the model has higher accuracy than existing baselines, demonstrating the effectiveness and superiority of the method."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"SQUIRE: A Sequence-to-sequence Framework for Multi-hop Knowledge Graph Reasoning,A transformer model can generate the path in an end-to-end fashion.,""Yushi Bai, Xin Lv, Juanzi Li, Lei Hou, Yincen Qu, Zelin Dai, Feiyu Xiong"",Conference on Empirical Methods in Natural Language Processing,,,,,2022,4,,https://semanticscholar.org/paper/412bc1caf92614838749dcfce104776a36fdb7d7,""Multi-hop knowledge graph (KG) reasoning has been widely studied in recent years to provide interpretable predictions on missing links with evidential paths. Most previous works use reinforcement learning (RL) based methods that learn to navigate the path towards the target entity. However, these methods suffer from slow and poor convergence, and they may fail to infer a certain path when there is a missing edge along the path. Here we present SQUIRE, the first Sequence-to-sequence based multi-hop reasoning framework, which utilizes an encoder-decoder Transformer structure to translate the query to a path. Our framework brings about two benefits: (1) It can learn and predict in an end-to-end fashion, which gives better and faster convergence; (2) Our transformer model does not rely on existing edges to generate the path, and has the flexibility to complete missing edges along the path, especially in sparse KGs. Experiments on standard and sparse KGs show that our approach yields significant improvement over prior methods, while converging 4x-7x faster."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Path Representation Learning in Road Networks,The pre-trained path-node discriminator can enhance supervised learning methods.,Sean Bin Yang,,,,10.54337/aau510734142,https://vbn.aau.dk/ws/files/510734142/PHD_SBY.pdf,2022,,https://doi.org/10.54337/aau510734142,https://semanticscholar.org/paper/0c495c8ef9706aeb019444021ef97a6f43c62a23,""With the continued digitization of transportation systems, there is an increasing demand for path-based smart city applications which require appropriate path representations. To support path-based applications, different techniques have been proposed to learn path representations. However, existing studies suffer from the following limitations: (1) Supervised methods learn a task-specific path representation and require a large amount of labeled training data, which works well on the labeled task, but generalizes poorly on other tasks; (2) Although graph representation learning based methods learn a task-unspecific path representation, they cannot capture sequential dependencies and fail to introduce the temporal information into the learned path representations; (3) Existing works mainly focus on accuracy improvement, ignoring the mode scalability and size, which plays a critical role in resourceconstrained environments. In this thesis, we investigate the task-unspecific path representation learning approaches that are able to generalize well for different downstream tasks. More specifically, we focus on the following specific works. (1) Context-aware path ranking in road networks. (2) Unsupervised path representation learning. (3) Weakly-supervised contrastive curriculum path representation learning. (4) Lightweight and scalable path representation learning. First, we study the path ranking framework PathRank. This framework learns task-specific path representations, which are used to rank candidate paths. In particular, we propose a training data enri",chment strategy to enhance the learning proce,ss.,Subs,equ,ent,"ly,",we,pr,opose,an,end,#NAME?,o-e,nd,c,onte,xta,ware,"multi-task framework to enable the PathRank. We conduct extensive experiments on one realworld dataset to verify the effectiveness of the PathRank. Second, we study the unsupervised path representation learning framework Path InfoMax (PIM) by maximizing the mutual information. PIM takes as input a path and output task-unspecific path representations. In particular, we first propose a curriculum negative sampling strategy to enhance the PIM training. Then, we propose a path-path discriminator and path-node discriminator to jointly learn taskunspecific path representations by capturing the global and local information of the path. Finally, we conduct extensive experiments on two downstream tasks under two real-world datasets. The results illustrate our PIM is more effective than other baseline methods. In addition, the pre-trained PIM can enhance supervised learning methods. Third, we study a weakly-supervised contrastive curriculum temporal path representation learning framework by leveraging the information from weak labels and considering both spatial and temporal correlations. This framework takes as input a temporal path (a path with a departure time) and returns task-unspecific temporal path representations. We first introduce the weak label to capture the temporal variation of traffic. Then, we study the weakly-supervised contrastive learning method to enable the temporal path encoder training. Subsequently, we combine weakly-supervised contrastive learning with a two-stage curriculum learning strategy to improve the performance of weakly-supervised contrastive learning. Finally, we conduct extensive experiments on three downstream tasks under three real-world datasets. The results show the effectiveness of our proposals. Finally, we study the lightweight and scalable path representation framework LightPath. This framework aims at learning task-unspecific path representations by reducing resource consumption and enabling model scalability with respect to path length. In particular, we first propose a sparse auto-encoder that guarantees LightPath with good scalability of path length. Then, we propose cross-network and crossview relational reasoning to train sparse path encoders jointly. Subsequently, we propose global-local knowledge distillation to reduce the model size and improve the performance of the learned path representations. Finally, extensive experiments are conducted, and the results demonstrate the efficiency and scalability of the LightPath. Members of the assessment committee are Associate Professor Álvaro Torralba, Aalborg University, Professor Gao Cong, Nanyang Technological University, and Professor Baihua Zheng, Singapore Management University. Professor Bin Yang is Sean Bin Yang’s supervisor. The moderator Associate Professor Álvaro Torralba. All interested parties are welcome."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"MERIt: Meta-Path Guided Contrastive Learning for Logical Reasoning,A strategy based on meta-path is devised to discover the logical structure in natural texts.,""Fangkai Jiao, Yangyang Guo, Xuemeng Song, Liqiang Nie"",Findings,,,10.48550/arXiv.2203.00357,,2022,3,https://doi.org/10.48550/arXiv.2203.00357,https://semanticscholar.org/paper/75994b6305d5c4c002e28d7f914d6b3edc6da8bf,""Logical reasoning is of vital importance to natural language understanding. Previous studies either employ graph-based models to incorporate prior knowledge about logical relations, or introduce symbolic logic into neural models through data augmentation. These methods, however, heavily depend on annotated training data, and thus suffer from over-fitting and poor generalization problems due to the dataset sparsity. To address these two problems, in this paper, we propose MERIt, a MEta-path guided contrastive learning method for logical ReasonIng of text, to perform self-supervised pre-training on abundant unlabeled text data. Two novel strategies serve as indispensable components of our method. In particular, a strategy based on meta-path is devised to discover the logical structure in natural texts, followed by a counterfactual data augmentation strategy to eliminate the information shortcut induced by pre-training. The experimental results on two challenging logical reasoning benchmarks, i.e., ReClor and LogiQA, demonstrate that our method outperforms the SOTA baselines with significant improvements."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Multi-level Recommendation Reasoning over Knowledge Graphs with Reinforcement Learning,A multi-level reasoning path extraction method is proposed.,""Xiting Wang, Kunpeng Liu, Dongjie Wang, Le Wu, Yanjie Fu, Xing Xie"",WWW,,,10.1145/3485447.3512083,,2022,13,https://doi.org/10.1145/3485447.3512083,https://semanticscholar.org/paper/55ffe44c1dcec3f88136d2d0c81d961da8e0e3ad,""Knowledge graphs (KGs) have been widely used to improve recommendation accuracy. The multi-hop paths on KGs also enable recommendation reasoning, which is considered a crystal type of explainability. In this paper, we propose a reinforcement learning framework for multi-level recommendation reasoning over KGs, which leverages both ontology-view and instance-view KGs to model multi-level user interests. This framework ensures convergence to a more satisfying solution by effectively transferring high-level knowledge to lower levels. Based on the framework, we propose a multi-level reasoning path extraction method, which automatically selects between high-level concepts and low-level ones to form reasoning paths that better reveal user interests. Experiments on three datasets demonstrate the effectiveness of our method."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Learning Adaptive Propagation for Knowledge Graph Reasoning,The answer entity can be close to queried one.,""Yongqi Zhang, Zhanke Zhou, Quanming Yao, X. Chu, Bo Han"",ArXiv,,,10.48550/arXiv.2205.15319,,2022,1,https://doi.org/10.48550/arXiv.2205.15319,https://semanticscholar.org/paper/d6a19fe3df9782a466281d99f2fbbabdcdda86ed,""Due to the success of Graph Neural Networks (GNNs) in learning from graph-structured data, various GNN-based methods have been introduced to learn from knowledge graphs (KGs). In this paper, to reveal the key factors underneath existing GNN-based methods, we revisit exemplar works from the lens of the propagation path. We ?nd that the answer entity can be close to queried one, but the information dependency can be long. Thus, better reasoning performance can be obtained by exploring longer propagation paths. However, identifying such a long-range dependency in KG is hard since the number of involved entities grows exponentially. This motivates us to learn an adaptive propagation path that ?lters out irrelevant entities while preserving promising targets during the propagation. First, we design an incremental sampling mechanism where the close and promising target can be preserved. Second, we design a learning-based sampling distribution to identify the targets with fewer involved entities. In this way, GNN can go deeper to capture long-range information. Extensive experiments show that our method is ef?cient and achieves state-of-the-art performances in both transductive and inductive reasoning settings, bene?ting from the deeper propagation. 1"",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Path Language Modeling over Knowledge Graphsfor Explainable Recommendation,Existing explainable models provide a KG-grounded path for each user-recommended item.,""Shijie Geng, Zuohui Fu, Juntao Tan, Yingqiang Ge, Gerard de Melo, Yongfeng Zhang"",The Web Conference,,,10.1145/3485447.3511937,,2022,14,https://doi.org/10.1145/3485447.3511937,https://semanticscholar.org/paper/75f4423820a6d2de93535fda5f80e17ae051dc47,""To facilitate human decisions with credible suggestions, personalized recommender systems should have the ability to generate corresponding explanations while making recommendations. Knowledge graphs (KG), which contain comprehensive information about users and products, are widely used to enable this. By reasoning over a KG in a node-by-node manner, existing explainable models provide a KG-grounded path for each user-recommended item. Such paths serve as an explanation and reflect the historical behavior pattern of the user. However, not all items can be reached following the connections within the constructed KG under finite hops. Hence, previous approaches are constrained by a recall bias in terms of existing connectivity of KG structures. To overcome this, we propose a novel Path Language Modeling Recommendation (PLM-Rec) framework, learning a language model over KG paths consisting of entities and edges. Through path sequence decoding, PLM-Rec unifies recommendation and explanation in a single step and fulfills them simultaneously. As a result, PLM-Rec not only captures the user behaviors but also eliminates the restriction to pre-existing KG connections, thereby alleviating the aforementioned recall bias. Moreover, the proposed technique makes it possible to conduct explainable recommendation even when the KG is sparse or possesses a large number of relations. Experiments and extensive ablation studies on three Amazon e-commerce datasets demonstrate the effectiveness and","explainability of the PLM-Rec framework."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Path Language Modeling over Knowledge Graphsfor Explainable Recommendation,Existing explainable models provide a KG-grounded path for each user-recommended item.,""Shijie  Geng, Zuohui  Fu, Juntao  Tan, Yingqiang  Ge, Gerard  de Melo, Yongfeng  Zhang"",WWW,,,10.1145/3485447.3511937,,2022,1,https://doi.org/10.1145/3485447.3511937,https://semanticscholar.org/paper/e38203ca41d66a1046634e883200e55c514b63d6,""To facilitate human decisions with credible suggestions, personalized recommender systems should have the ability to generate corresponding explanations while making recommendations. Knowledge graphs (KG), which contain comprehensive information about users and products, are widely used to enable this. By reasoning over a KG in a node-by-node manner, existing explainable models provide a KG-grounded path for each user-recommended item. Such paths serve as an explanation and reflect the historical behavior pattern of the user. However, not all items can be reached following the connections within the constructed KG under finite hops. Hence, previous approaches are constrained by a recall bias in terms of existing connectivity of KG structures. To overcome this, we propose a novel Path Language Modeling Recommendation (PLM-Rec) framework, learning a language model over KG paths consisting of entities and edges. Through path sequence decoding, PLM-Rec unifies recommendation and explanation in a single step and fulfills them simultaneously. As a result, PLM-Rec not only captures the user behaviors but also eliminates the restriction to pre-existing KG connections, thereby alleviating the aforementioned recall bias. Moreover, the proposed technique makes it possible to conduct explainable recommendation even when the KG is sparse or possesses a large number of relations. Experiments and extensive ablation studies on three Amazon e-commerce datasets demonstrate the effectiveness and explainabi","lity of the PLM-Rec framework."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"The CLRS Algorithmic Reasoning Benchmark,Learning representations of algorithms is an emerging area of machine learning.,""Petar Velivckovi'c, Adrià Puigdomènech Badia, D. Budden, Razvan Pascanu, Andrea Banino, Mikhail Dashevskiy, R. Hadsell, C. Blundell"",International Conference on Machine Learning,,,10.48550/arXiv.2205.15659,,2022,14,https://doi.org/10.48550/arXiv.2205.15659,https://semanticscholar.org/paper/9332dd9afa389d8d273e1713a6e1ca98797c6e5f,""Learning representations of algorithms is an emerging area of machine learning, seeking to bridge concepts from neural networks with classical algorithms. Several important works have investigated whether neural networks can effectively reason like algorithms, typically by learning to execute them. The common trend in the area, however, is to generate targeted kinds of algorithmic data to evaluate speci?c hypotheses, making results hard to transfer across publications, and increasing the barrier of entry. To consolidate progress and work towards uni?ed evaluation, we propose the CLRS Algorithmic Reasoning Benchmark, covering classical algorithms from the Introduction to Algorithms textbook. Our benchmark spans a variety of algorithmic reasoning procedures, including sorting, searching, dynamic programming, graph algorithms, string algorithms and geometric algorithms. We perform extensive experiments to demonstrate how several popular algorithmic reasoning baselines perform on these tasks, and consequently, highlight links to several open challenges. Our library is readily available at https://github.com/deepmind/clrs ."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Representation Learning for Context-Dependent Decision-Making,A learning and transfer context-dependent representations algorithm significantly outperforms the existing ones that do not learn representations adaptively.,""Yuzhen Qin, Tommaso Menara, Samet Oymak, S. Ching, F. Pasqualetti"",American Control Conference,,,10.23919/ACC53348.2022.9867204,http://arxiv.org/pdf/2205.05820,2022,2,https://doi.org/10.23919/ACC53348.2022.9867204,https://semanticscholar.org/paper/f0c38fd0ea522fc9582ed11276f78ca759bb4caf,""Humans are capable of adjusting to changing environments flexibly and quickly. Empirical evidence has revealed that representation learning plays a crucial role in endowing humans with such a capability. Inspired by this observation, we study representation learning in the sequential decision-making scenario with contextual changes. We propose an online algorithm that is able to learn and transfer context-dependent representations and show that it significantly outperforms the existing ones that do not learn representations adaptively. As a case study, we apply our algorithm to the Wisconsin Card Sorting Task, a well-established test for the mental flexibility of humans in sequential decision-making. By comparing our algorithm with the standard Q-learning and Deep-Q learning algorithms, we demonstrate the benefits of adaptive representation learning."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"RLogic: Recursive Logical Rule Learning from Knowledge Graphs,RLogic is superior to existing state-of-the-art algorithms in terms of both efficiency and effectiveness.,""Kewei Cheng, Jiahao Liu, Wei Wang, Yizhou Sun"",Knowledge Discovery and Data Mining,,,10.1145/3534678.3539421,https://dl.acm.org/doi/pdf/10.1145/3534678.3539421,2022,2,https://doi.org/10.1145/3534678.3539421,https://semanticscholar.org/paper/bf8a6cfecb03073b90c246def9fcf5b363f2cd64,""Logical rules are widely used to represent domain knowledge and hypothesis, which is fundamental to symbolic reasoning-based human intelligence. Very recently, it has been demonstrated that integrating logical rules into regular learning tasks can further enhance learning performance in a label-efficient manner. Many attempts have been made to learn logical rules automatically from knowledge graphs (KGs). However, a majority of existing methods entirely rely on observed rule instances to define the score function for rule evaluation and thus lack generalization ability and suffer from severe computational inefficiency. Instead of completely relying on rule instances for rule evaluation, RLogic defines a predicate representation learning-based scoring model, which is trained by sampled rule instances. In addition, RLogic incorporates one of the most significant properties of logical rules, the deductive nature, into rule learning, which is critical especially when a rule lacks supporting evidence. To push deductive reasoning deeper into rule learning, RLogic breaks a big sequential model into small atomic models in a recursive way. Extensive experiments have demonstrated that RLogic is superior to existing state-of-the-art algorithms in terms of both efficiency and effectiveness."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Graph Representation Learning Meets Computer Vision: A Survey,Graph representation algorithms are applied in various vision tasks.,""Licheng Jiao, Jing Chen, F. Liu, Shuyuan Yang, Chao You, Xu Liu, Lingling Li, B. Hou"",IEEE Transactions on Artificial Intelligence,,,10.1109/TAI.2022.3194869,,2023,4,https://doi.org/10.1109/TAI.2022.3194869,https://semanticscholar.org/paper/3ee47cb3789bb85efd7b39ed15ba83ebd9f86189,""A graph structure is a powerful mathematical abstraction, which can not only represent information about individuals but also capture the interactions between individuals for reasoning. Geometric modeling and relational inference based on graph data is a long-standing topic of interest in the computer vision community. In this article, we provide a systematic review of graph representation learning and its applications in computer vision. First, we sort out the evolution of representation learning on graphs, categorizing them into the nonneural network and neural network methods based on the way the nodes are encoded. Specifically, nonneural network methods, such as graph embedding and probabilistic graphical models, are introduced, and neural network methods, such as graph recurrent neural networks, graph convolutional networks, and variants of graph neural networks, are also presented. Then, we organize the applications of graph representation algorithms in various vision tasks (such as image classification, semantic segmentation, object detection, and tracking) for review and reference, and the typical graph construction approaches in computer vision are also summarized. Finally, on the background of biology and brain inspiration, we discuss the existing challenges and future directions of graph representation learning and computer vision."",,Systematic Review",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Towards Understanding Grokking: An Effective Theory of Representation Learning,""The grokking phase stays closer to the memorization phase, leading to delayed generalization."",""Ziming Liu, O. Kitouni, N. Nolte, Eric J. Michaud, Max Tegmark, Mike Williams"",ArXiv,,,10.48550/arXiv.2205.10343,,2022,9,https://doi.org/10.48550/arXiv.2205.10343,https://semanticscholar.org/paper/20de79ec4fe682b68930eb4dcd91b1801b8d4731,""We aim to understand grokking , a phenomenon where models generalize long after over?tting their training set. We present both a microscopic analysis anchored by an effective theory and a macroscopic analysis of phase diagrams describing learning performance across hyperparameters. We ?nd that generalization originates from structured representations whose training dynamics and dependence on training set size can be predicted by our effective theory in a toy setting. We observe empirically the presence of four learning phases: comprehension , grokking , memorization , and confusion . We ?nd representation learning to occur only in a “Goldilocks zone” (including comprehension and grokking) between memorization and confusion. Compared to the comprehension phase, the grokking phase stays closer to the memorization phase, leading to delayed generalization. The Goldilocks phase is reminiscent of “intelligence from starvation” in Darwinian evolution, where resource limitations drive discovery of more ef?cient solutions. This study not only provides intuitive explanations of the origin of grokking, but also highlights the usefulness of physics-inspired tools, e.g., effective theories and phase diagrams, for understanding deep learning."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Layerwise Bregman Representation Learning with Applications to Knowledge Distillation,A Bregman divergence based on the layer's transfer function allows exporting the learned representation as a fixed layer with a non-linearity.,""E. Amid, Rohan Anil, Christopher Fifty, Manfred K. Warmuth"",ArXiv,,,10.48550/arXiv.2209.07080,,2022,1,https://doi.org/10.48550/arXiv.2209.07080,https://semanticscholar.org/paper/3c3121b977a88c3001b2cf4578103cc9a532380c,""In this work, we propose a novel approach for layerwise representation learning of a trained neural network. In particular, we form a Bregman divergence based on the layer’s transfer function and construct an extension of the original Bregman PCA formulation by incorporating a mean vector and normalizing the principal directions with respect to the geometry of the local convex function around the mean. This generalization allows exporting the learned representation as a ?xed layer with a non-linearity. As an application to knowledge distillation, we cast the learning problem for the student network as predicting the compression coe?cients of the teacher’s representations, which are passed as the input to the imported layer. Our empirical ?ndings indicate that our approach is substantially more e?ective for transferring information between networks than typical teacher-student training using the teacher’s penultimate layer representations and soft labels."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Computing Rule-Based Explanations of Machine Learning Classifiers using Knowledge Graphs,A novel method for extracting and representing black-box explanations of a machine learning classifier's operation in the form of first-order logic rules expressed in the terminology of the knowledge graph.,""Edmund Dervakos, Orfeas Menis-Mastromichalakis, A. Chortaras, G. Stamou"",ArXiv,,,,,2022,3,,https://semanticscholar.org/paper/9eb933a666c527f6142ed65033a088215d76006d,""The use of symbolic knowledge representation and reasoning as a way to resolve the lack of transparency of machine learning classifiers is a research area that lately attracts many researchers. In this work, we use knowledge graphs as the underlying framework providing the terminology for representing explanations for the operation of a machine learning classifier. In particular, given a description of the application domain of the classifier in the form of a knowledge graph, we introduce a novel method for extracting and representing black-box explanations of its operation, in the form of firstorder logic rules expressed in the terminology of the knowledge graph."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Towards Teachable Reasoning Systems,Users judge that a majority of generated chains are faithful and truthful.,""Bhavana Dalvi, Oyvind Tafjord, Peter Clark"",ArXiv,,,10.48550/arXiv.2204.13074,,2022,10,https://doi.org/10.48550/arXiv.2204.13074,https://semanticscholar.org/paper/36589346063ff26506330451976280011273b935,""Our goal is a teachable reasoning system for question-answering (QA), where a user can interact with faithful answer explanations, and correct errors so that the system improves over time. Our approach is three-fold: First, generated chains of reasoning show how answers are implied by the system’s own internal beliefs . Second, users can interact with the explanations to identify erroneous model beliefs and provide corrections. Third, we augment the model with a dynamic memory of such corrections. Retrievals from memory are used as additional context for QA, to help avoid previous mistakes in similar new situations - a novel type of memory-based continuous learning. To our knowledge, this is the ?rst system to generate chains that are both faithful (the answer follows from the reasoning) and truthful (the chain re?ects the system’s own beliefs, as ascertained by self-querying). In evaluation, users judge that a majority (65%+) of generated chains clearly show how an answer follows from a set of facts - substantially better than a high-performance baseline. We also ?nd that using simulated feedback, our system (called EntailmentWriter) continually improves with time, requiring feedback on only 25% of training examples to reach within 1% of the upper-bound (feedback on all examples). We observe a similar trend with real users. This suggests new opportunities for using language models in an interactive setting where users can inspect, debug, correct, and improve a system’s performance over time."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Life-long Learning for Reasoning-based Semantic Communication,The receiver can learn from previously received messages and automatically update the rules for reasoning the hidden information when new unknown semantic entities and relations have been discovered.,""Jingming Liang, Yong Xiao, Yingyu Li, Guangming Shi, M. Bennis"",2022 IEEE International Conference on Communications Workshops (ICC Workshops),,,10.1109/iccworkshops53468.2022.9814575,http://jultika.oulu.fi/files/nbnfi-fe2023021026785.pdf,2022,10,https://doi.org/10.1109/iccworkshops53468.2022.9814575,https://semanticscholar.org/paper/66a41831e95aba4c945ebaba035589e1fc7f365d,""Semantic communication is an emerging paradigm that focuses on understanding and delivering semantics or meaning of messages. Most existing semantic communication solutions define semantic meaning as the labels of objects recognized from a given form of source signal, while ignoring intrinsic information that cannot be directly observed. Since the models for recognizing labels need to be pre-trained with labelled dataset, the total number of semantic objects are often limited by a fixed set. In this paper, we propose a novel reasoning-based semantic communication architecture in which the semantic meaning is represented by a graph-based knowledge structure in terms of semantic-entity, relationships, and reasoning rules. An embedding-based semantic interpretation framework is proposed to convert the high-dimensional graph-based representation of semantic meaning into a low-dimensional representation, which is efficient for channel transmission. We develop a novel inference function-based approach that can automatically infer hidden information such as missing entities and relations that cannot be directly observed from the message. Finally, we introduce a life-long model updating approach in which the receiver can learn from previously received messages and",automatically update the rules for reasoning,th,e hid,den,in,for,mat,ion,when,ne,w un,kn,own,s,em,anti,c e,ntit,"ies and relations have been discovered. Extensive experiments are conducted based on a real-world knowledge database and numerical results show that our proposed solution achieves 76% interpretation accuracy of the hidden meaning at the receiver when some entities are missing in the transmitted message."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Representation Learning of Knowledge Graph Integrating Entity Description and Language Morphological Structure Information,The Hit@10s of head entity prediction for N-1 relations and tail entity prediction for 1-N relations improved on FB15K database.,""Xiaojuan Du, Yizheng Tao, Gongliang Li"",2022 IEEE 2nd International Conference on Information Communication and Software Engineering (ICICSE),,,10.1109/icicse55337.2022.9828957,,2022,,https://doi.org/10.1109/icicse55337.2022.9828957,https://semanticscholar.org/paper/6bfb4f3c053b3824a0b8c90a4d831032bc1118e3,""Knowledge graph embedding, which projects the symbolic relations and entities onto low-dimension continuous spaces, is the key to knowledge graph completion. The representation learning methods based on translation, such as TransE, TransH and TransR, only consider the triple information of knowledge graph, and fail to make effective use of other information of entity. To solve these problems, in this paper, we propose a knowledge graph representation learning method which integrates entity description and language morphological structure information to deal with complex relations (i.e. 1-N, N-1 and N-N relations). Firstly, the fastText model which considers affix of words is used to get the embedding of all entity description information. Then, the triple embedding, entity description embedding are spliced to obtain the representation of the final entity embedding. In addition, we propose a new score function-distcos–man, which considers the similarity of entity vector not only from the value of each dimension, but also from the direction of vectors. Experiments show that our method achieves substantial improvements against state-of-the-art baselines, especially the Hit@10s of head entity prediction for N-1 relations and tail entity prediction for 1-N relations improved by about 11.6% and 17.9% on FB15K database respectively."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Logic Tensor Networks,A neural-symbolic system supports learning and reasoning through the introduction of a many-valued end-to-end differentiable first-order logic called Real Logic as a representation language for deep learning.,""Samy  Badreddine, Artur d'Avila Garcez, Luciano  Serafini, Michael  Spranger"",Artif. Intell.,,,10.1016/j.artint.2021.103649,https://openaccess.city.ac.uk/id/eprint/27580/1/2012.13635.pdf,2022,12,https://doi.org/10.1016/j.artint.2021.103649,https://semanticscholar.org/paper/6027247d7f4256c10bdc71b8584d5927e616fa37,""Artificial Intelligence agents are required to learn from their surroundings and to reason about the knowledge that has been learned in order to make decisions. While state-of-the-art learning from data typically use sub-symbolic distributed representations, reasoning is normally useful at a higher level of abstraction with the use of a first-order logic language for knowledge representation. As a result, attempts at combining symbolic AI and neural computation into neural-symbolic systems have been on the increase. In this paper, we present Logic Tensor Networks (LTN), a neurosymbolic formalism and computational model that supports learning and reasoning through the introduction of a many-valued, end-to-end differentiable first-order logic called Real Logic as a representation language for deep learning. We show that LTN provides a uniform language for the specification and the computation of several AI tasks such as data clustering, multi-label classification, relational learning, query answering, semi-supervised learning, regression and embedding learning. We implement and illustrate each of the above tasks with a number of simple explanatory examples using TensorFlow 2."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Temporal Abstractions-Augmented Temporally Contrastive Learning: An Alternative to the Laplacian in RL,A simple augmentation of the representation objective with the learned temporal abstractions improves dynamics-awareness and helps exploration.,""Akram Erraqabi, Marlos C. Machado, Mingde Zhao, Sainbayar Sukhbaatar, A. Lazaric, Ludovic Denoyer, Y. Bengio"",Conference on Uncertainty in Artificial Intelligence,,,10.48550/arXiv.2203.11369,,2022,5,https://doi.org/10.48550/arXiv.2203.11369,https://semanticscholar.org/paper/fb8038a47940820527af13460b0e6f1dafd1b511,""In reinforcement learning, the graph Laplacian has proved to be a valuable tool in the task-agnostic setting, with applications ranging from skill discovery to reward shaping. Recently, learning the Laplacian representation has been framed as the optimization of a temporally-contrastive objective to overcome its computational limitations in large (or continuous) state spaces. However, this approach requires uniform access to all states in the state space, overlooking the exploration problem that emerges during the representation learning process. In this work, we propose an alternative method that is able to recover, in a non-uniform-prior setting , the expressiveness and the desired properties of the Laplacian representation. We do so by combin-ing the representation learning with a skill-based covering policy, which provides a better training distribution to extend and re?ne the representation. We also show that a simple augmentation of the representation objective with the learned temporal abstractions improves dynamics-awareness and helps exploration. We ?nd that our method succeeds as an alternative to the Laplacian in the non-uniform setting and scales to challenging continuous control environments. Finally, even if our method is not optimized for skill discovery, the learned skills can successfully solve dif?cult continuous","navigation tasks with sparse rewards, where",sta,ndard,sk,ill,di,sco,ver,y app,roa,ches,a,re,no,s,o ef,fec,tive,"."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Mind's Eye: Grounded Language Model Reasoning through Simulation,Current language models miss the grounded experience of humans in the real-world.,""Ruibo Liu, Jason Wei, S. Gu, Te-Yen Wu, Soroush Vosoughi, Claire Cui, Denny Zhou, Andrew M. Dai"",ArXiv,,,10.48550/arXiv.2210.05359,,2022,5,https://doi.org/10.48550/arXiv.2210.05359,https://semanticscholar.org/paper/2cb97b2bb6ab2eb17add9ffe69d5cbeaca2b29c8,""Successful and effective communication between humans and AI relies on a shared experience of the world. By training solely on written text, current language models (LMs) miss the grounded experience of humans in the real-world—their failure to relate language to the physical world causes knowledge to be misrepresented and obvious mistakes in their reasoning. We present Mind’s Eye, a paradigm to ground language model reasoning in the physical world. Given a physical reasoning question, we use a computational physics engine (DeepMind’s MuJoCo) to simulate the possible outcomes, and then use the simulation results as part of the input, which enables language models to perform reasoning. Experiments on 39 tasks in a physics alignment benchmark demonstrate that Mind’s Eye can improve reasoning ability by a large margin (27.9% zero-shot, and 46.0% few-shot absolute accuracy improvement on average). Smaller language models armed with Mind’s Eye can obtain similar performance to models that are 100 × larger. Finally, we con?rm the robustness of Mind’s Eye through ablation studies."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Teaching Algorithmic Reasoning via In-context Learning,Large language models are unable to solve algorithmic reasoning problems.,""Hattie Zhou, Azade Nova, H. Larochelle, Aaron C. Courville, Behnam Neyshabur, Hanie Sedghi"",ArXiv,,,10.48550/arXiv.2211.09066,,2022,6,https://doi.org/10.48550/arXiv.2211.09066,https://semanticscholar.org/paper/4d17732d90440682b0500f4e209c6cc4fac20e0e,""Large language models (LLMs) have shown increasing in-context learning capabilities through scaling up model and data size. Despite this progress, LLMs are still unable to solve algorithmic reasoning problems. While providing a rationale with the ?nal answer has led to further improvements in multi-step reasoning problems, Anil et al. (2022) showed that even simple algorithmic reasoning tasks such as parity are far from solved. In this work, we identify and study four key stages for successfully teaching algorithmic reasoning to LLMs: (1) formulating algorithms as skills, (2) teaching multiple skills simultaneously (skill accumulation), (3) teaching how to combine skills (skill composition) and (4) teaching how to use skills as tools. We show that it is possible to teach algorithmic reasoning to LLMs via in-context learning, which we refer to as algorithmic prompting . We evaluate our approach on a variety of arithmetic and quantitative reasoning tasks, and demonstrate signi?cant boosts in performance over existing prompting techniques. In particular, for long parity, addition, multiplication and subtraction, we achieve an error reduction of approximately 10x, 9x, 5x and 2x respectively compared to the best available baselines."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"STaR: Bootstrapping Reasoning With Reasoning,A model can improve itself by learning from its own generated reasoning.,""E. Zelikman, Yuhuai Wu, Noah D. Goodman"",ArXiv,,,10.48550/arXiv.2203.14465,,2022,53,https://doi.org/10.48550/arXiv.2203.14465,https://semanticscholar.org/paper/23dd78e424d32f6a48660dcd67ce994b8a7db8be,""Generating step-by-step""""chain-of-thought""""rationales improves language model performance on complex reasoning tasks like mathematics or commonsense question-answering. However, inducing language model rationale generation currently requires either constructing massive rationale datasets or sacrificing accuracy by using only few-shot inference. We propose a technique to iteratively leverage a small number of rationale examples and a large dataset without rationales, to bootstrap the ability to perform successively more complex reasoning. This technique, the""""Self-Taught Reasoner""""(STaR), relies on a simple loop: generate rationales to answer many questions, prompted with a few rationale examples; if the generated answers are wrong, try again to generate a rationale given the correct answer; fine-tune on all the rationales that ultimately yielded correct answers; repeat. We show that STaR significantly improves performance on multiple datasets compared to a model fine-tuned to directly predict final answers, and performs comparably to fine-tuning a 30$\times$ larger state-of-the-art language model on CommensenseQA. Thus, STaR lets a model improve itself by learning from its own generated reasoning."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Dynamic Heterogeneous Information Network Embedding With Meta-Path Based Proximity,A novel dynamic HIN embedding model outperforms the state-of-the-arts in terms of effectiveness and efficiency.,""Xiao Wang, Yuanfu Lu, C. Shi, Ruijia Wang, Peng Cui, Shuai Mou"",IEEE Transactions on Knowledge and Data Engineering,,2.431 (883),10.1109/tkde.2020.2993870,,2022,37,https://doi.org/10.1109/tkde.2020.2993870,https://semanticscholar.org/paper/83b1453cc9b618e05b0365c94cfb6c72969d2471,""Heterogeneous",infor,mation network (HIN) embedding aims at learning the low-dimensional,representation,of nodes while preserving structure and,semantic,s in,a HIN,. Existing methods mainly focus on,static net,"works, while a real HIN usually evolves o",ver time with the additio,n (d,eletion),o,f m,ulti,ple,types,o,f nod,es,and,edg,es. Becaus,e even a,tiny change,can influence,the wh,ole,stru,ct,ure,and,semanti,"cs, the conventio",nal,HI,N embedding,method,s need,to be,r,et,rained,to,get,the upd,ated,"embeddings, which i",s time-cons,uming,and u,nrealistic.,In,this pape,"r,",w,e investigate,the problem,of,dy,namic,HIN em,bedding and,pro,pose a,novel,Dy,nam,ic HIN Em,bedding,model (DyHNE),with,met,a-path based,proximity.,S,pecifica,"lly,",w,e introduce th,e meta-path,based,f,irst- and,second-o,rder,proximitie,s to,pre,serve,structure,and,semantics i,n HINs.,As the,HIN,evolves,ove,r ti,"me,",we naturally,capt,ure,changes wi,th,the p,erturbation,of,meta-pat,h augment,ed adja,cency mat,rices.,Therea,fter,", we",learn the,no,de embeddin,"gs by solving generalized eigenvalue problem effectively and employ eigenvalue perturbation to derive the updated embeddings efficiently without retraining. Experiments show that DyHNE outperforms the state-of-the-arts in terms of effectiveness and efficiency."",,"
"Subgraph Matching With Effective Matching Order and Indexing,A bigraph index for candidate vertices and their selected neighbors in the data graph outperforms the state of the art by orders of magnitude.,""Shixuan Sun, Qiong Luo"",IEEE Transactions on Knowledge and Data Engineering,,2.431 (883),10.1109/tkde.2020.2980257,,2022,10,https://doi.org/10.1109/tkde.2020.2980257,https://semanticscholar.org/paper/2fa20e26e1b42743c683806940b0da45bef88cb5,""Subgraph matching finds all embeddings from",a data,graph that are identical to a query graph. Recent algorithms work b,y generating a,tree-structured index on the data graph,based on,the,query,"graph, ordering the vertices path",#NAME?,"the tree, and enumerating the embeddings",following the matching o,rder,. Howeve,"r,",we,fin,d s,uch pa,th,#NAME?,d,orde,ring,and tree-,structur,ed index bas,ed enumeration,inhere,ntly,lim,it,th,e pe,rformanc,e due to the lack,of,co,nsideration,on the,edges,among,t,he,verti,ces,acr,oss tree,pat,hs. To address this,"problem, we",prop,ose an,approach th,at,generates,t,he,matching orde,r based on,a c,ost,model,consi,dering both,the,edges,among,qu,ery,vertices,and the,number of ca,ndida,tes.,"Furthermore,",we create,a,bigraph,ind,ex,for candidate,vertices a,nd the,ir,selected,neighbor,s in,the data g,raph,", an",d use,this inde,x to,perform enu,meratio,n along,the,matchin,g or,der.,Our,experiments,on b,oth,real-world,an,d syn,thetic data,sets,show th,at our me,thod ou,tperforms,the s,tate of,the,art,by orders,of,magnitude.,""",,"
"Probabilistic Compositional Embeddings for Multimodal Image Retrieval,A multimodal probabilistic composer can flexibly encode the semantics of various queries.,""Andrei Neculai, Yanbei Chen, Zeynep Akata"",2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW),,,10.1109/CVPRW56347.2022.00501,http://arxiv.org/pdf/2204.05845,2022,3,https://doi.org/10.1109/CVPRW56347.2022.00501,https://semanticscholar.org/paper/2a1906f9405d865917308358b55e6653eacfea13,""Existing",works,in image retrieval often consider retrieving images with one or two,"query inputs,",which do not generalize to multiple que,ries. In,this,"work,",we investigate a more challenging,scenario f,or composing multiple multi-modal queries,in image retrieval. Give,n an,arbitra,ry,nu,mber,of,query,i,mages,a,nd (,or),"texts, our",goal is,to retrieve,target images,contai,ning,the,s,ema,ntic,concept,s specified in mu,lti,ple,multimodal,querie,s. To,learn,an,i,nforma,tiv,e em,bedding,that,can flexibly encode,the semant,ics o,f vari,"ous queries,",w,e propose,a,no,vel multimodal,probabilis,tic,co,mposer,(MPC),. Specifica,"lly,",we mo,del in,put,im,ages and,texts as,probabilisti,c emb,eddi,"ngs, which ca",n be furth,er,compose,d by,a,probabilistic,compositio,n rule,t,o facilit,ate image,ret,rieval with,mul,tipl,e mul,timodal qu,erie,s. We propos,e a new,benchm,ark,based on,the,MS-,COCO,dataset and,eval,uat,e our model,on,vari,ous setups,that,compose,multiple,images,and (or),text,queries,for,mul,timodal im,age,retrieval.,"Without bells and whistles, we show that our probabilistic model formulation significantly outperforms existing related methods on multimodal image retrieval while generalizing well to query with different amounts of inputs given in arbitrary visual and (or) textual modalities. Code is here: https://github.com/andreineculai/MPC."",,"
"Disentangling Visual Embeddings for Attributes and Objects,A novel architecture can disentangle attribute and object features in the visual space.,""Nirat Saini, Khoi Pham, Abhinav Shrivastava"",Computer Vision and Pattern Recognition,,,10.1109/CVPR52688.2022.01329,http://arxiv.org/pdf/2205.08536,2022,6,https://doi.org/10.1109/CVPR52688.2022.01329,https://semanticscholar.org/paper/b3c514de08f3953e00464f63464e1241396b54b8,""We study the problem of compositional zero-shot learning for object",#NAME?,bute recognition. Prior works use visual features extracted with a b,ackbone networ,"k, pre-trained for object classification",and thus,do,not ca,pture the subtly distinct features,associated,with attributes. To overcome this challe,"nge, these studies employ",sup,ervision,f,rom,the,li,nguist,ic,spac,"e,",and,use,pre-train,ed word,embeddings t,o better separ,ate and,com,pose,a,ttr,ibut,e-object,pairs for recogn,iti,on.,Analogous,to ling,uistic,embed,di,ng,space,", w",hich,already,has,unique and agnostic,embeddings,for,object,and attribu,te,", we shift",t,he,focus back to,the visual,sp,ace,and p,ropose,a novel ar,chit,ecture,that,can,di,sentangle,attribu,te and object,feat,ures,in the visua,l space. W,e,use visu,al d,ec,omposed featur,es to hallu,cinate,e,mbeddings,that are,rep,resentative,for,the,seen,and novel,com,positions to,better,regula,rize,the lea,rnin,g of,our,model. Exte,nsive,ex,periments s,how,that,our method,out,performs,existing,work w,ith signi,ficant,margin,on,thre,e datasets,: M,"IT-States,","UT-Zappos, and a new benchmark created based on VAW. The code, models, and dataset splits are publicly available at https://github.com/nirat1606/OADis."",,"
"Cross-Modal Retrieval with Heterogeneous Graph Embedding,The embedding from one modality will be compensated with the aggregated embeddings from the other modality.,""Dapeng Chen, Min Wang, Haobin Chen, Lin Wu, Jing Qin, Wei Peng"",ACM Multimedia,,,10.1145/3503161.3548195,,2022,5,https://doi.org/10.1145/3503161.3548195,https://semanticscholar.org/paper/862146b91347d199ad17f5a99de9ae5a229e8d1d,""Conventional methods address the cross-modal retrieval problem by projecting the multi-modal dat",a into,a shared representation space. Such a strategy will inevitably lose,the modality-,"specific information, leading to decreas",ed retrie,val,accura,"cy. In this paper, we propose hete",rogeneous g,raph embeddings to preserve more abundant,cross-modal information.,The,embeddi,ng,fr,om o,ne,modali,ty,will,b,e co,mpen,sated with,the agg,regated embe,ddings from th,e other,mod,alit,y.,In,par,"ticular,",a self-denoising,tr,ee,search is d,esigned,to re,duce t,he,"""","""label",no,"ise""",""" proble","m, m",aking the heterogene,ous neighbo,rhood,more,semantically,r,elevant. T,he,d,ual-path aggre,gation tack,les,th,"e """"mo",dality,"imbalance""",""" pr","oblem,",givin,g e,ach,sample c,omprehen,sive dual-mod,ality,inf,ormation. The,final het,er,ogeneous,gra,ph,embedding is,obtained by,feedi,ng,the aggr,egated du,al-m,odality fea,ture,s to,the,cross-moda,l se,lf-attention,module,. Exper,imen,ts condu,cted,on,cros,s-modality p,erson,re,#NAME?,tio,n and,image-text,ret,rieval t,ask valid,ate the,superior,ity an,d gener,alit,y of,the propo,sed,"method."",,",
"How to Compose Shortest Paths,Divide and conquer is an effective method for reducing the computation time of many algorithms.,J. Master,ArXiv,,,10.48550/arXiv.2205.15306,,2022,2,https://doi.org/10.48550/arXiv.2205.15306,https://semanticscholar.org/paper/17584a78125df396f57b50353ad11a057a914bcf,""2 A Composition Problem Divide and conquer is an effective method for reducing the computation time of many algorithms. With this strategy, a problem may be broken up into subdomains, the problem",is so,"lved on the subdomains, and then joined together to obtain the final",solution. Thi,s last step of recombination is the main,topic of,stu,dy for,this paper and may be phrased in,categorical,terms. We work in the following abstract,"setting"",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Lightweight Compositional Embeddings for Incremental Streaming Recommendation,A compositional recommendation model supports incremental updates under low computational cost.,""Mengyue Hang, Tobias Schnabel, Longqi Yang, Jennifer Neville"",ArXiv,,,,,2022,2,,https://semanticscholar.org/paper/cebc7bc086f56bbee87237ad91c35d291c4bf7ac,""Most work in graph-based recommender systems considers a static setting where all information about test nodes (i.e., users and items) is available upfront at t",rainin,"g time. However, this static setting makes little sense for many rea",l world applic,ations where data comes in continuously,as a stre,am o,f new,"edges and nodes, and one has to up",date model,predictions incrementally to reflect the,latest state. To fully ca,pita,lize on,th,e n,ewly,av,ailabl,e,data,in,the,str,"eam, recen",t graph-,based recomm,endation model,s would,nee,d to,b,e r,epea,tedly re,"trained, which is",in,fea,sible in pr,actice.,In th,is pap,er,",",we stu,dy,the,graph-ba,sed,streaming recommenda,tion settin,g and,propo,se a composi,ti,onal recom,me,nd,ation model—Li,ghtweight C,omp,osi,tional,Embed,ding (LCE)—,that,suppo,rts in,cre,men,tal updat,es under,low computat,ional,cos,t. Instead of,learning,ex,plicit e,mbed,di,ngs for the fu,ll set of n,"odes,",LC,E learns,explicit,embe,ddings for,only,a s,ubset,of nodes,and,represents t,he othe,r nodes,imp,"licitly,",thr,ough,a c,omposition f,uncti,on,based on th,eir,inte,ractions in,the,graph.,This prov,ides an,effectiv,"e, yet",effici,"ent,",mea,ns to leve,rag,e streaming,"graph data when one node type (e.g., items) is more amenable to static representation. We conduct an extensive empirical study to compare LCE to a set of competitive baselines on three large-scale user-item recommendation datasets with interactions under a streaming setting. The results demonstrate the superior performance of LCE, showing that it achieves nearly skyline performance with significantly fewer parameters than alternative graph-based models."",,"
"XYLayoutLM: Towards Layout-Aware Multimodal Networks For Visually-Rich Document Understanding,A robust layout-aware multimodal network achieves competitive results on document understanding tasks.,""Zhangxuan Gu, Changhua Meng, Ke Wang, Jun Lan, Weiqiang Wang, Ming Gu, Liqing Zhang"",Computer Vision and Pattern Recognition,,,10.1109/CVPR52688.2022.00454,http://arxiv.org/pdf/2203.06947,2022,12,https://doi.org/10.1109/CVPR52688.2022.00454,https://semanticscholar.org/paper/93c1dffe2bae737da8",f342fd,"749aa783df572a14,""Recently, various multimodal networks for Visually",#NAME?,"Understanding(VRDU) have been proposed,",showing,the,promot,ion of transformers by integrating,visual and,layout information with the text embeddi,"ngs. However, most existi",ng a,pproache,s,uti,lize,th,e posi,ti,on em,be,ddin,gs t,o incorpor,ate the,sequence inf,"ormation, negl",ecting,the,nois,y,imp,rope,r readin,g order obtained,by,OCR,tools. In,this pa,"per, w",e prop,os,e,a robu,st,layo,ut-aware,mul,timodal network name,d XYLayoutL,M to,captur,e and levera,ge,rich layo,ut,i,nformation fro,m proper re,adi,ng,orders,produ,ced by our,Augm,ented,XY Cut,. M,ore,"over, a D",ilated C,onditional Po,sitio,n En,coding module,is propos,ed,to deal,wit,h,the input sequ,ence of var,iable,le,"ngths, an",d it addi,tion,ally extrac,ts l,ocal,layo,ut informa,tion,from both t,extual,and vi-,sual,modalit,ies,whil,e ge,nerating pos,ition,em,beddings. E,xpe,rimen,t results s,how,that our,XYLayout,LM achi,eves comp,etitiv,e resul,ts o,n do,cument und,ers,tanding tas,"ks."",,"
"DensE: An enhanced non-commutative representation for knowledge graph embedding with adaptive semantic hierarchy,A novel knowledge graph embedding method provides sufficient modeling capacity for complex composition patterns.,""Haonan  Lu, Hailin  Hu"",Neurocomputing,,1.66 (1770),10.1016/j.neucom.2021.12.079,http://arxiv.org/pdf/2008.04548,2022,7,https://doi.org/10.1016/j.neucom.2021.12.079,https://semanticscholar.org/paper/b6839f89a59132f0e62011a218ec229a27ffff6b,""Capturing the compositi",on pat,terns of relations is a vital task in knowledge graph completion. It,also serves a,s a fundamental step towards multi-hop r,easoning,over,learn,"ed knowledge. Previously, rotation",#NAME?,"slational methods, e.g., RotatE, have bee",n developed to model comp,osit,e relati,on,s u,sing,th,e prod,uc,t of,a,seri,es o,f complex-,valued d,iagonal matr,"ices. However,",RotatE,mak,es s,ev,era,l ov,ersimpli,fied assumptions,on,the,compositio,n patte,"rns, f",orcing,t,he,relat,ion,s to,be comm,utat,"ive, independent fro",m entities,and f,ixed i,n scale. To,ta,ckle this,pr,ob,"lem, we have d",eveloped a,nov,el,knowle,dge gr,aph embeddi,ng m,"ethod,",named,De,nsE,", to prov",ide suff,icient modeli,ng ca,paci,ty for comple,x composit,io,n patter,ns.,In,"particular, o",ur method d,ecompo,se,s each re,lation in,to a,n SO(3) gro,up-b,ased,rota,tion opera,tor,and a scalin,g opera,tor in,the,three di,mens,iona,l (3,-D) Euclidea,n spa,ce.,The advant,age,s of,our method,are,twofold:,(1) For,composi,te relati,"ons, t",he corr,espo,ndin,g diagonal,re,lation matr,"ices can be non-commutative and related with entity embeddings; (2) It extends the concept of RotatE to a more expressive setting with lower model complexity and preserves the direct geometrical interpretations, which reveals how relations with distinct patterns (i.e., symmetry/anti-symmetry, inversion and composition) are modeled. Experimental results on multiple benchmark knowledge graphs show that DensE outperforms the current state-of-the-art models for missing link prediction, especially on composite relations."",,"
"Well Path Design and Optimization Using Composite Cubic Bezier Curves,The automatically generated well path using composite Bezier curves is smoother with a smaller dogleg severity.,""Jie Cao, D. Sui"",SPE Journal,,1.05 (3792),10.2118/209830-pa,,2022,1,https://doi.org/10.2118/209830-pa,https://semanticscholar.org/paper/0a95291c42f3cee187fba1fc7a0cde69561cf6ae,""Well path design is a primary part of the well plan for well drilling. The main objective of well path design is to generate a con",tinuou,s and smooth trajectory from a start point to a target point under v,arious design,constraints. The conventional approaches,usually,cons,ist of,a number of circular arcs and str,aight lines,", representing build and turn sections an","d hold sections, respecti",vely,. This s,tu,dy,pres,ent,s a ne,w,metho,do,logy,to,generate a,continu,ous and smoo,th well path t,rajecto,ry w,ith,lo,w d,ogle,g severi,ty (DLS) using co,mpo,sit,e Bezier cu,rves. T,he tra,jector,y,co,nsists,of,a n,umber of,pie,cewise cubic Bezier,curves that,sati,sfy C1,and/or C2 c,on,tinuity co,nd,it,"ions, meaning",that the jo,ini,ng,curves,share,the first,and,second,deriv,ati,ves,at the j,oining p,"oints, respec",tivel,y. T,he comprehens,ive method,ol,ogy for,dete,rm,ining the comp,osite curve,and t,he,primary,propertie,s of,the well t,raje,ctor,y is,presented.,The,ir advantage,s regar,ding fe,asib,ility an,d ef,fici,ency,are demonst,rated,in,case studi,es.,The,proposed me,thod,is also,applied,in a fi,"eld case,",where,the au,toma,tica,lly genera,ted,well path,"using composite Bezier curves is smoother with a smaller DLS. It can also be quickly updated if a real-time anticollision adjustment is required. The presented work has strong potential to be an efficient and automatic tool for path design and optimization in well planning."",,"
"Complexity and Algorithms for ISOMETRIC PATH COVER on Chordal Graphs and Beyond,The complexity and algorithms for isometric path cover on chordal graphs and beyond are discussed.,""Dibyayan Chakraborty, Antoine Dailly, Sandip Das, Florent Foucaud, Harmender Gahlawat, Subir Kumar Ghosh"",International Symposium on Algorithms and Computation,,,10.4230/LIPIcs.ISAAC.2022.12,,2022,3,https://doi.org/10.4230/LIPIcs.ISAAC.2022.12,https://semanticscholar.org/paper/6904512cca38931e9e6343ef7cbfa28dd",61f878,"2,"","",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Depth Completion Using Geometry-Aware Embedding,The proposed method outperforms previous works.,""Wenchao Du, Hu Chen, Hong-ling Yang, Yan Zhang"",IEEE International Conference on Robotics and Automation,,,10.48550/arXiv.2203.10912,,2022,4,https://doi.org/10.48550/arXiv.2203.10912,https://semanticscholar.org/paper/bba225bd34e145fdeadbf20c389b3ac63f25ae89,""Exploiting internal spatial geometric constraints of sparse LiDARs is beneficial to depth completion, however, has been not explored we",ll. Th,is paper proposes an efficient method to learn geometry-aware embedd,"ing, which enc",odes the local and global geometric stru,cture inf,orma,tion f,"rom 3D points, e.g., scene layout,",object's s,"izes and shapes, to guide dense depth est","imation. Specifically, we",uti,lize the,d,yna,mic,gra,ph rep,re,senta,ti,on t,o mo,del genera,lized ge,ometric rela,tionship from,irregul,ar p,oint,c,lou,ds i,n a flex,ible and efficien,t m,ann,er. Further,", we jo",int th,is emb,ed,di,ng and,co,rres,ponded R,GB a,ppearance informatio,n to infer,missi,ng dep,ths of the s,ce,ne with we,ll,s,tructure-prese,rved detail,s.,The,key t,o our,method is t,o in,tegrat,e impl,ici,t 3,D geometr,ic repre,sentation int,o a 2,D le,arning archit,"ecture, wh",ic,h leads,to a,b,etter trade-of,f between t,he per,fo,rmance an,d efficie,ncy.,Extensive,expe,rime,nts d,emonstrate,tha,t the propos,ed meth,od outp,erfo,rms prev,ious,wor,ks a,nd could rec,onstr,uct,fine depth,s w,ith c,risp bounda,ries,in regi,ons that,are ove,r-smoothe,d by t,hem. Th,e ab,lati,on study g,ive,s more insi,"ghts into our method that could achieve significant gains with a simple design, while having better generalization capability and stability. The code is available at https://github.com/Wenchao-Du/GAENet."",,"
"Permutation Invariant Representations with Applications to Graph Deep Learning,The sorting-based embedding is globally bi-Lipschitz and admits a low dimensional target space.,""R. Balan, Naveed Haghani, M. Singh"",ArXiv,,,10.48550/arXiv.2203.07546,,2022,3,https://doi.org/10.48550/arXiv.2203.07546,https://semanticscholar.org/paper/5cf1db9772c234d9100ce42d17c875fe13cae65c,""This paper presents primarily two Euclidean embeddings of the quotient space generated by matrices that are identified",modulo,arbitrary row permutations. The original application is in deep lea,rning on graph,s where the learning task is invariant t,o node re,labe,ling.,Two embedding schemes are introduc,"ed, one bas",ed on sorting and the other based on alge,bras of multivariate poly,nomi,als. Whi,le,bo,th e,mbe,ddings,e,xhibi,t,a co,mput,ational co,mplexity,exponential,in problem si,"ze, the",sor,ting,b,ase,d em,bedding,is globally bi-Li,psc,hit,z and admit,s a low,dimen,sional,t,ar,get sp,ace,. Ad,ditional,"ly,",an almost everywhere,injective,schem,e can,be implement,ed,with mini,ma,l,redundancy and,low comput,ati,ona,l cost,. In t,"urn, this p",rove,s that,almos,t a,ny,classifie,r can be,implemented,with,an a,rbitrary smal,l loss of,pe,rformanc,e. N,um,erical experim,ents are ca,rried,ou,t on two,data sets,", a",chemical co,mpou,nd d,ata s,et (QM9) a,nd a,proteins da,ta set,(PROTEI,NS F,"ULL)."",,",,,,,,,,,,,,,,,,,,,,,,,
"Learning Backward Compatible Embeddings,The best method maintains backward compatibility with existing unintended tasks even after multiple model version updates.,""Weihua Hu, Rajas Bansal, Kaidi Cao, Nikhil S. Rao, Karthik Subbian, J. Leskovec"",Knowledge Discovery and Data Mining,,,10.1145/3534678.3539194,http://arxiv.org/pdf/2206.03040,2022,3,https://doi.org/10.1145/3534678.3539194,https://semanticscholar.org/paper/acc682841729ec95416aa61589d7e1a91d2c2b77,""Embeddings, low-dimensional v",ector,"representation of objects, are fundamental in building modern machin",e learning sys,"tems. In industrial settings, there is u",sually an,emb,edding,team that trains an embedding mod,el to solve,"intended tasks (e.g., product recommenda",tion). The produced embed,ding,s are th,en,wi,dely,co,nsumed,b,y con,su,mer,team,s to solve,their u,nintended ta,"sks (e.g., fra",ud dete,ctio,n).,Ho,wev,"er,",as the e,mbedding model ge,ts,upd,ated and re,trained,to im,prove,pe,rf,ormanc,e o,n th,e intend,ed t,"ask, the newly-gener",ated embedd,ings,are no,longer comp,at,ible with,th,e,existing consu,mer models.,Th,is,means,that h,istorical v,ersi,ons of,the e,mbe,ddi,ngs can n,ever be,retired or al,l con,sume,r teams have,to retrain,t,heir mod,els,to,make them com,patible wit,h the,la,test vers,ion of th,e em,"beddings, b",oth,of w,hich,are extrem,ely,costly in pr,actice.,Here w,e st,udy the,prob,lem,of e,mbedding ver,sion,upd,ates and th,eir,back,ward compat,ibil,ity. We,formalize,the pr,oblem whe,re the,goal i,s fo,r th,e embeddin,g t,eam to keep,"updating the embedding version, while the consumer teams do not have to retrain their models. We develop a solution based on learning backward compatible embeddings, which allows the embedding model version to be updated frequently, while also allowing the latest version of the embedding to be quickly transformed into any backward compatible historical version of it, so that consumer teams do not have to retrain their models. Our key idea is that whenever a new embedding model is trained, we learn it together with a light-weight backward compatibility transformation that aligns the new embedding to the previous version of it. Our learned backward transformations can then be composed to produce any historical version of embedding. Under our framework, we explore six methods and systematically evaluate them on a real-world recommender system application. We show that the best method, which we call BC-Aligner, maintains backward compatibility with existing unintended tasks even after multiple model version updates. Simultaneously, BC-Aligner achieves the intended task performance similar to the embedding model that is solely optimized for the intended task. Code is publicly available at https://github.com/snap-stanford/bc-emb"",,"
"Embedding Comparator: Visualizing Differences in Global Structure and Local Neighborhoods via Small Multiples,The Embedding Comparator accelerates comparisons by shifting from laborious manual specification to browsing and manipulating visualizations.,""Angie  Boggust, Brandon  Carter, Arvind  Satyanarayan"",IUI,,,10.1145/3490099.3511122,https://dl.acm.org/doi/pdf/10.1145/3490099.3511122,2022,8,https://doi.org/10.1145/3490099.3511122,https://semanticscholar.org/paper/ff9ad694b2ee40ae62bc5",dcdc80,"82082a75ef107,""Embeddings mapping high-dimensional discrete input to",lower-dimensi,onal continuous vector spaces have been,widely ad,opte,d in m,achine learning applications as a,way to capt,ure domain semantics. Interviewing 13 emb,edding users across disci,plin,"es, we f",in,d c,ompa,rin,g embe,dd,ings,is,a k,ey t,ask for de,ployment,or downstre,am analysis bu,t unfol,ds i,n a,te,dio,us f,ashion t,hat poorly suppor,ts,sys,tematic exp,loratio,n. In,respon,se,",",we pre,sen,t th,e Embedd,ing,"Comparator, an inter",active syst,em th,at pre,sents a glob,al,compariso,n,of,embedding spa,ces alongsi,de,fin,e-grai,ned in,spection of,loc,al nei,ghborh,ood,s.,It system,atically,surfaces poi,nts o,f co,mparison by c,omputing t,he,similar,ity,of,the k-nearest,neighbors,of eve,ry,embedded,object b,etwe,en a pair o,f sp,aces,. Thr,ough case,stud,ies across m,ultiple,modali,ties,", we dem",onst,rate,our,system rapi,dly r,eve,als insight,"s,",such,as semantic,cha,nges fol,lowing fi,ne-tuni,"ng, langu",age ch,anges o,ver,time,", and diff",ere,nces betwee,"n seemingly similar models. In evaluations with 15 participants, we find our system accelerates comparisons by shifting from laborious manual specification to browsing and manipulating visualizations."",,"
"Geometry-Aware Planar Embedding of Treelike Structures,A planar embedding of 3D treelike structures using their skeleton representations is generated by minimizing an energy function based on branch length and the 2D angles.,""Ping Hu, S. Boorboor, Joseph Marino, A. Kaufman"",IEEE Transactions on Visualization and Computer Graphics,,1.753 (1583),10.1109/TVCG.2022.3153871,http://arxiv.org/pdf/2202.10551,2022,2,https://doi.org/10.1109/TVCG.2022.3153871,https://semanticscholar.org/paper/36aa",0a4a7f,"87e5ec05958263c36be41cb04b99ea,""The growing complexity of spatial an",d structural i,nformation in 3D data makes data inspect,ion and v,isua,lizati,on a challenging task. We describe,a method t,o create a planar embedding of 3D treelik,e structures using their,skel,eton rep,re,sen,tati,ons,. Our,me,thod,ma,inta,ins,the origin,al geome,"try, without","overlaps, to",the bes,t ex,tent,p,oss,ible,", allowi",ng exploration of,th,e t,opology wit,hin a s,ingle,view.,We,p,resent,a,nove,l camera,vie,w generation method,which maxim,izes,the vi,sible geomet,ri,c attribut,es,(,segment shape,and relativ,e p,lac,ement,betwee,n segments),. Ca,mera v,iews a,re,cre,ated for,individu,al segments a,nd ar,e us,ed to determi,ne local b,en,ding ang,les,at,each node by,projecting,them t,o,2D. The f,inal embe,ddin,g is genera,ted,by m,inimi,zing an en,ergy,function (t,he weig,hts of,whic,h are us,er a,djus,tabl,e) based on,branc,h l,ength and t,he,2D an,"gles, while",avo,iding in,tersectio,ns. The,user can,also,interac,tive,ly m,odify segm,ent,placement,"within the 2D embedding, and the overall embedding will update accordingly. A global to local interactive exploration is provided using hierarchical camera views that are created for subtrees within the structure. We evaluate our method both qualitatively and quantitatively and demonstrate our results by constructing planar visualizations of line data (traced neurons) and volume data (CT vascular and bronchial data)."",,"
"Improving Node Embedding by a Compact Neighborhood Representation,A compact representation of a node's neighborhood can be used as an additional dimension to enrich node embedding to ensure accuracy.,""I. Oluigbo, H. Seba, Mohammed Haddad"",,,,,,2022,1,,https://semanticscholar.org/paper/094adc5e1f5532b41848e04407340a2b7173ee31,""Graph Embedding, a learning paradigm that represents graph vertices, edges, and other semantic information about a graph into low dimensional vectors, has found wi",de app,"lications in di?erent machine learning tasks. In the past few years,",we have had a,plethora of methods centered on graph e,mbedding,usin,g di?e,rent techniques such as spectral c,lassi?catio,"n, matrix factorization and learning. In","this context, choosing th",e ap,propriat,e,dim,ensi,on,of the,o,btain,ed,emb,eddi,ng remains,a funda,mental issue,. In this pape,"r, we p",ropo,se a,c,omp,act,represen,tation of a node’,s n,eig,"hborhood, i",ncludin,g attr,ibutes,a,nd,struc,tur,"e, t",hat can,be u,sed as an additional,dimension,to en,rich n,ode embeddin,"g,",to ensure,a,cc,uracy. This co,mpact repre,sen,tat,ion en,sures,that both s,eman,tic an,d stru,ctu,ral,properti,es of a,node’s neighb,oring,#NAME?,d are properl,y captured,i,n a sing,le d,im,ension. Conseq,"uently, we",improv,e,the learn,ed embedd,ing,from state-,of-t,he-a,rt mo,dels by in,trod,ucing the ne,ighborh,ood com,pact,represe,ntat,ion,for,each node as,an a,ddi,tional laye,r o,f dim,ensionality,. We,leverag,e on this,neighb,orhood en,coding,techni,que,and,compare wi,th,embedding f,"rom state-of-the-art models on two learning tasks: node classi?cation and link prediction. The performance evaluation show that our approach gives a better prediction and classi?cation accuracy in both tasks."",,"
"Stream Processing of Shortest Path Query in Dynamic Road Networks,Existing batch algorithms either assume the batch queries are finely decomposed or just process them without differentiation.,""Mengxuan Zhang, Lei Li, Wen Hua, Xiaofang Zhou"",IEEE Transactions on Knowledge and Data Engineering,,2.431 (883),10.1109/tkde.2020.3010005,,2022,7,https://doi.org/10.1109/tkde.2020.3010005,https://semanticscholar.org/paper/665a0283a6c6e403f4a8a7a65df20dd4ca2d48d6,""Shortest path query in road netwo",rk is,pervasive in various location-based services nowadays. As the busine,"ss expands, th",e scalability issue becomes severer and,more serv,ers,are de,"ployed to cope with it. Moreover,",as the traf,"fic condition keeps changing over time, t",he existing index-based a,ppro,aches ca,n,har,dly,ada,pt to,th,e rea,l-,life,dyn,amic envir,onment.,"Therefore, b",atch shortest,path al,gori,thms,h,ave,bee,n propos,ed recently to an,swe,r a,set of que,ries to,gether,using,s,ha,reable,co,mput,ation. B,esid,"es, they can also wo",rk in a hig,hly d,ynamic,environment,a,s no index,i,s,needed. Howeve,"r, the exis",tin,g b,atch a,lgorit,hms either,assu,me the,batch,qu,eri,es are fi,nely dec,omposed or ju,st pr,oces,s them withou,t differen,ti,"ation, r",esul,ti,ng in poor que,ry efficien,cy. In,t,"his work,",we assum,e th,e traffic c,ondi,tion,is s,table over,a s,hort period,and tre,at the,issu,ed queri,es w,ithi,n th,at period as,a st,rea,m of query,set,s. Sp,"ecifically,",we,first pr,opose thr,ee quer,y set dec,omposi,tion me,thod,s to,cluster o,ne,query set i,"nto multiple query subsets: Zigzag that considers the 1-N shared computation; Co-Clustering that considers the source and target's spatial locality; and Search-Space-Aware that further incorporates search space estimation. After that, we propose two batch algorithms that take advantage of the previously decomposed query sets for efficient query answering: R2R that finds a set of approximate shortest paths from one region to another with bounded error; and Local Cache that improves the existing Global Cache with higher cache hit ratio. Finally, we design three efficient stream processing methods for intra-batch shared computation. The experiments on a large real-world query sets verify the effectiveness and efficiency of our decomposition methods compared with the state-of-the-art batch algorithms."",,"
"Composable and Modular Code Generation in MLIR: A Structured and Retargetable Approach to Tensor Compiler Construction,A structured approach to the construction of domain-specific code generators for tensor compilers aims to improve the productivity of both compiler engineers and end-users.,""Nicolas Vasilache, O. Zinenko, Aart J. C. Bik, Mahesh Ravishankar, Thomas Raoux, Alexander Belyaev, M. Springer, Tobias Gysi, Diego Caballero, S. Herhut, Stella Laurenzo, Albert Cohen"",ArXiv,,,,,202","2,8,,h",ttps://semanticscholar.org/paper/facccd0d80009d560d2fb2edc8b11b8f1d1,"d3a21,""Despite",significant investment in software infr,astructur,"e, m",achine,"learning systems, runtimes and co",mpilers do,not compose properly. We propose a new de,sign aiming at providing,unpr,ecedente,d,deg,rees,of,modul,ar,"ity,",co,mpos,abil,ity and ge,nericity,. This paper,discusses a s,tructur,ed a,ppro,ac,h t,o th,e constr,uction of domain-,spe,cif,ic code gen,erators,for t,ensor,co,mp,"ilers,",wi,th t,he state,d go,al of improving the,productivit,y of,both c,ompiler engi,ne,ers and en,d-,us,ers. The appro,ach leverag,es,the,natur,al str,ucture of t,enso,r alge,bra. I,t h,as,been the,main dri,ver for the d,esign,of,progressive l,owering pa,th,s in MLI,R. T,he,proposed abst,ractions an,d tran,sf,ormations,span dat,a st,ructures an,d co,ntro,l flo,w with bot,h fu,nctional (SS,A form),and im,pera,tive (si,de-e,ffec,ting,) semantics.,We d,isc,uss the imp,lic,ation,s of this i,nfra,structur,e on comp,iler co,nstructio,n and,present,pre,limi,nary exper,ime,ntal result,"s."",,"
"Description Logic EL++ Embeddings with Intersectional Closure,The intersection of boxes is a box.,""X. Peng, Zhenwei Tang, Maxat Kulmanov, Kexin Niu, R. Hoehndorf"",ArXiv,,,,,2022,3,,https://semanticscholar.org/paper/6a3eb23a94823b2dd745330270663079f8e15fd1,""Many ontologies, in particular in the biomedical domain, are based on the Description Logic EL. Several efforts have been made to interpret and exploit ELontologies by distributed representation learning. Specifically, concepts within",ELthe,ories have been represented as n-balls within an n-dimensional embed,ding space. Ho,"wever, the intersectional closure is not",satisfie,d wh,en usi,ng n-balls to represent concepts b,ecause the,intersection of two n-balls is not an n-b,all. This leads to challe,nges,when me,as,uri,ng t,he,distan,ce,betw,ee,n co,ncep,ts and inf,erring e,quivalence b,etween concept,s. To t,his,"end,",w,e d,evel,oped EL,Box Embedding (EL,BE),to,learn Desc,ription,Logic,ELemb,ed,di,ngs us,ing,axi,s-parall,el b,oxes. We generate sp,ecially des,igned,box-b,ased geometr,ic,constrain,ts,f,rom ELaxioms f,or model tr,ain,ing,. Sinc,e the,intersectio,n of,boxes,remai,ns,as,"a box, th",e inters,ectional clos,ure i,s sa,tisfied. We r,eport exte,ns,ive expe,rime,nt,al results on,three datas,ets an,d,present a,case stu,dy t,o demonstra,te t,he e,ffect,iveness of,the,proposed me,"thod."",",",",,,,,,,,,,,,,,,,,,,,,,,,,
"How to Compose Shortest Paths,Divide and conquer is an effective method for reducing the computation time of many algorithms.,J. Master,ArXiv,,,10.48550/arXiv.2205.15306,,2022,1,https://doi.org/10.48550/arXiv.2205.15306,https://semanticscholar.org/paper/66555bb1c0930e4a4cbe6ff3efbe52fef9ff5d1d,""2 A Composition Problem Divide and conquer is an effective method for reducing the computation time of many algorithms. With this strategy, a problem may be broken up into subdomains, the problem",is so,"lved on the subdomains, and then joined together to obtain the final",solution. Thi,s last step of recombination is the main,topic of,stu,dy for,this paper and may be phrased in,categorical,terms. We work in the following abstract,"setting"",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Point Set Self-Embedding,The self-embedded point set can function as the ordinary downsampled one and be visualized efficiently on mobile devices.,""Ruihui Li, Xianzhi Li, T. Wong, Chi-Wing Fu"",IEEE Transactions on Visualization and Computer Graphics,,1.753 (1583),10.1109/TVCG.2022.3155808,,2022,2,https://doi.org/10.1109/TVCG.2022.3155808,https://semanticscholar.org/paper/4a27c290faa58814255c4bbd5ffc64f1546f13d9,""This work presents an innovative method for point set self-embedding, that",encode,s the structural information of a dense point set into its sparser v,ersion in a vi,sual but imperceptible form. The self-em,bedded po,int,set ca,n function as the ordinary downsam,pled one an,d be visualized efficiently on mobile dev,"ices. Particularly, we ca",n le,verage t,he,se,lf-e,mbe,dded i,nf,ormat,io,n to,ful,ly restore,the ori,ginal point,set for detail,ed anal,ysis,on,re,mot,e se,rvers. T,his new task is c,hal,len,"ging, cause",both t,he sel,f-embe,dd,ed,point,se,t an,d restor,ed p,oint set should rese,mble the or,igina,l one.,To achieve,a,learnable,se,lf,#NAME?,"eme, we des",ign,a,novel,framew,ork with tw,o jo,intly-,traine,d n,etw,orks: one,to enco,de the input,point,set,into its sel,f-embedded,s,parse po,int,se,t and the othe,r to levera,ge the,e,mbedded i,nformatio,n fo,r inverting,the,ori,ginal,point set,bac,"k. Further,",we deve,lop a p,air,of up-sh,uffl,e an,d do,wn-shuffle u,nits,in,the two net,wor,"ks, a",nd formulat,e lo,ss terms,to encou,rage th,e shape s,imilar,ity and,poi,nt d,istributio,n i,n the resul,"ts. Extensive qualitative and quantitative results demonstrate the effectiveness of our method on both synthetic and real-scanned datasets. The source code and trained models will be publicly available at https://github.com/liruihui/Self-Embedding."",,"
"Multi-Semantic Path Representation Learning for Travel Time Estimation,A multi-semantic path representation method to exploit information in Euclidean space and non-Euclidean space simultaneously is proposed.,""Liangzhe Han, Bowen Du, Jingjing Lin, Leilei Sun, Xucheng Li, Yizhou Peng"",IEEE transactions on intelligent transportation systems (Print),,,10.1109/TITS.2021.3119887,,2022,3,https://doi.org/10.1109/TITS.2021.3119887,https://semanticscholar.org/paper/c87fdb849bac8edd37b0ed09800d6b",41ecb7,"c7d0,""Travel time estimation of a given path is a crucial task of In",telligent Tran,sportation Systems (ITS). Accurate trave,l time es,tima,tion c,an benefit multiple downstream app,lications s,"uch as route planning, real-time navigati","on, and urban constructio",n. H,"owever,",it,is,a c,hal,lengin,g,probl,em,sin,ce t,he travel,time is,largely affe,cted by multip,le comp,lica,ted,fa,cto,rs i,ncluding,"spatial factors,",te,mpo,ral factors,and ex,ternal,facto,rs,",",and ob,tai,ning,informa,tive,representations of,a given pat,h is,not tr,ivial. Most,pr,evious wor,ks,s,olved this pro,blem in eit,her,Eu,clidea,n spac,e or non-Eu,clid,ean sp,"ace, w",hic,h w,as unilat,eral to,represent the,actu,al t,raveling path,and led t,o,relative,ly p,oo,r performance.,To address,"this,",t,his paper,proposes,a m,ulti-semant,ic p,ath,repre,sentation,meth,od to exploi,t infor,mation,in E,uclidean,spa,ce a,nd n,on-Euclidean,spac,e s,imultaneous,ly.,Firs,"t, since th",e pa,th is co,mposed of,severa,l segment,"s, we",generat,e se,mant,ic represe,nta,tions of se,"gments in non-Euclidean space by taking both the time information and the historical co-occurrence into consideration. Second, as the path could be equally represented as several travelled intersections, semantic representations of intersection sequences are also extracted to improve the capability of the method by considering information in Euclidean space. Meanwhile, semantic representations from properties, including the length and the type of segments, are also incorporated into the model. Finally, a sequence learning component is added on the top to aggregate the information along the entire path and provides the final estimation. Extensive experiments were conducted on two real-world taxi trajectories datasets, and the experimental results demonstrate the superiority of the proposed method."",,"
"Box Embeddings for the Description Logic EL++,BoxEL outperforms traditional knowledge graph embedding methods as well as state-of-the-art EL embedding approaches.,""Bo Xiong, Nico Potyka, T. Tran, M. Nayyeri, Steffen Staab"",ArXiv,,,,,2022,1,,https://semanticscholar.org/paper/33fefb53e67bd7c6c21d1caae74d15284e42eecd,""Recently, various methods for representation learning on Knowledge Bases (KBs) have been developed. However, these approaches either only focus on learning the embeddings of",the da,ta-level knowledge (ABox) or exhibit inherent limitations when deali,ng with the co,"ncept-level knowledge (TBox), e.g., not",properly,mode,lling,the structure of the logical knowl,edge. We pr,"esent BoxEL, a geometric KB embedding app",roach that allows for bet,ter,capturin,g,log,ical,st,ructur,e,expre,ss,ed i,n th,e theories,of Desc,ription Logi,c EL. BoxEL mo,dels co,ncep,ts i,n,a K,B as,axis-pa,rallel boxes exhi,bit,ing,the advant,age of,inters,ection,al,c,losure,", e",ntit,ies as p,oint,"s inside boxes, and",relations b,etwee,n conc,epts/entitie,s,as affine,tr,an,sformations. W,e show theo,ret,ica,l guar,antees,(soundness,) of,BoxEL,for p,res,erv,ing logic,al struc,"ture. Namely,",the,trai,ned model of,BoxEL embe,dd,ing with,los,s,0 is a (logica,l) model of,the K,B.,Experime,ntal resu,lts,on subsumpt,ion,reas,oning,s and a re,al-w,orld applica,tion–pr,otein-p,rote,in predi,ctio,n sh,ow t,hat BoxEL ou,tperf,orm,s tradition,al,knowl,edge graph,embe,dding me,thods as,well as,state-of,#NAME?,rt EL e,mbed,ding,approache,"s.""",",,",
"Image-Text Embedding Learning via Visual and Textual Semantic Reasoning,The simple global matching strategy can still be very effective and efficient.,""Kunpeng Li, Yulun Zhang, Kai Li, Yuanyuan Li, Y. Fu"",IEEE Transactions on Pattern Analysis and Machine Intelligence,,8.269 (105),10.1109/TPAMI.2022.3148470,,2022,10,https://doi.org/10.1109/TPAMI.2022.3148470,https://semanticscholar.org/paper/75c4f57e8028efa26c0739253459a2d6c2ff55bf,""As a bridge between language and vision domains, cross-",modal,retrieval between images and texts is a hot research topic in recent,years. It rem,ains challenging because the current ima,ge repres,enta,tions,usually lack semantic concepts in,the corresp,onding sentence captions. To address this,"issue, we introduce an i",ntui,tive and,i,nte,rpre,tab,le mod,el,to l,ea,rn a,com,mon embedd,ing spac,e for alignm,ents between i,mages a,nd t,ext,de,scr,ipti,ons. Spe,"cifically, our mo",del,fi,rst incorpo,rates t,he sem,antic,re,la,tionsh,ip,info,rmation,into,visual and textual,features by,perf,orming,region or w,or,d relation,sh,ip,reasoning. Th,en it utili,zes,th,e gate,and m,emory mecha,nism,to pe,rform,glo,bal,semantic,reasoni,ng on these r,elati,onsh,ip-enhanced f,"eatures, s",el,ect the,disc,ri,minative infor,mation and,gradua,ll,y grow re,presentat,ions,for the wh,ole,scen,e. Th,rough the,alig,nment learni,"ng, the",learne,d vi,sual rep,rese,ntat,ions,capture key,obje,cts,and semant,ic,conce,pts of a sc,ene,as in th,e corresp,onding,text capt,ion. E,xperime,nts,on M,S-COCO [1],an,d Flickr30K,"[2] datasets validate that our method surpasses many recent state-of-the-arts with a clear margin. In addition to the effectiveness, our methods are also very efficient at the inference stage. Thanks to the effective overall representation learning with visual semantic reasoning, our methods can already achieve very strong performance by only relying on the simple inner-product to obtain similarity scores between images and captions. Experiments validate the proposed methods are more than 30-75 times faster than many recent methods with code public available. Instead of following the recent trend of using complex local matching strategies [3], [4], [5], [6] to pursue good performance while sacrificing efficiency, we show that the simple global matching strategy can still be very effective, efficient and achieve even better performance based on our framework."",,"
"Efficient and Effective Similar Subtrajectory Search: A Spatial-aware Comprehension Approach,A spatial-aware grid embedding module aims to model the sequential information of trajectories.,""Liwei Deng, Hao Sun, Rui Sun, Yan Zhao, Han Su"",ACM Transactions on Intelligent Systems and Technology,,2.766 (687),10.1145/3456723,,2022,7,https://doi.org/10.1145/3456723,https://semanticscholar.org/paper/cb72b48853c00474818fbbceb32392807b91342f,""Although many applications take subtrajectories as ba",sic un,"its for analysis, there is little research on the similar subtraject",ory search pro,blem aiming to return a portion of a tra,jectory (,i.e.,", subt","rajectory), which is the most simi",lar to a qu,ery trajectory. We find that in some spec,"ial cases, when a grid-ba",sed,metric i,s,use,"d, t",his,probl,em,can,be,for,mula,ted as a r,eading c,omprehension,"problem, whic",h has b,een,stud,ie,d e,xten,sively i,n the field of na,tur,al,language pr,ocessin,g (NLP,). By,th,is,formu,lat,"ion,",we can,obta,in faster models wit,h better pe,rform,ance t,han existing,m,ethods. Ho,we,ve,"r, due to the",difference,bet,wee,n natu,ral la,nguage and,traj,ectory,(e.g.,", s",pat,ial relat,ionship),", it is impos",sible,to,directly appl,y NLP mode,ls,to this,pro,bl,"em. Therefore,",we propose,a Sim,il,ar Subtra,jectory S,earc,h with a Gr,aph,Neur,al Ne,tworks fra,mewo,rk. This fra,mework,contain,s fo,ur modul,es i,nclu,ding,a spatial-a,ware,gri,d embedding,mo,"dule,",a trajecto,ry e,mbedding,"module,",a query,#NAME?,trajec,tory fu,sion,mod,"ule, and a",sp,an predicti,"on module. Specifically, in the spatial-aware grid embedding module, the spatial-based grid adjacency is constructed and delivered to the graph neural network to learn spatial-aware grid embedding. The trajectory embedding module aims to model the sequential information of trajectories. The purpose of the query-context trajectory fusion module is to fuse the information of the query trajectory to each grid of the context trajectories. Finally, the span prediction module aims to predict the start and the end of a subtrajectory for the context trajectory, which is the most similar to the query trajectory. We conduct comprehensive experiments on two real world datasets, where the proposed framework outperforms the state-of-the-art baselines consistently and significantly."",,"
"Environment Generation for Zero-Shot Compositional Reinforcement Learning,A new benchmark framework for generating compositional tasks is compositional MiniGrid and gMiniWoB for web navigation.,""Izzeddin Gur, Natasha Jaques, Yingjie Miao, Jongwook Choi, Manoj Tiwari, Honglak Lee, Aleksandra Faust"",Neural Information Processing Systems,,,,,2022,14,,https://semanticscholar.org/paper/b4e644ef70f1df3c80d246730efa29069f70fd36,""Many real-world problems are compositional – solving them require",s comp,"leting interdependent sub-tasks, either in series or in parallel, th",at can be repr,esented as a dependency graph. Deep rein,forcement,lea,rning,(RL) agents often struggle to lear,n such comp,lex tasks due to the long time horizons a,nd sparse rewards. To add,ress,this pr,ob,lem,", we",pr,esent,Co,mposi,ti,onal,Des,ign of Env,ironment,"s (CoDE), wh",ich trains a G,enerato,r ag,ent,to,au,toma,tically,build a series of,co,mpo,sitional ta,sks tai,lored,to the,R,L,agent’,s c,urre,nt skill,lev,el. This automatic c,urriculum n,ot on,ly ena,bles the age,nt,to learn,mo,re,complex tasks,than it co,uld,ha,ve oth,erwise,", but also",sele,cts ta,sks wh,ere,th,e agent’s,perform,"ance is weak,",enha,ncin,g its robustn,ess and ab,il,ity to g,ener,al,ize zero-shot,to unseen t,asks a,t,test-time,. We anal,yze,why current,env,iron,ment,generation,tec,hniques are,insuffi,cient f,or t,he probl,em o,f ge,nera,ting composi,tiona,l t,"asks, and p",rop,ose a,new algori,thm,that add,resses th,ese iss,ues. Our,result,s asses,s le,arni,ng and gen,era,lization ac,"ross multiple compositional tasks, including the real-world problem of learning to navigate and interact with web pages. We learn to generate environments composed of multiple pages or rooms, and train RL agents capable of completing wide-range of complex tasks in those environments. We contribute two new benchmark frameworks for generating compositional tasks, compositional MiniGrid and gMiniWoB for web navigation. CoDE yields 4x higher success rate than the strongest baseline, and demonstrates strong performance of real websites learned on 3500 primitive tasks."",,"
"""Binarized Embeddings for Fast, Space-Efficient Knowledge Graph Completion"",Existing embedding models generate storage-inefficient representations.,""Katsuhiko Hayashi, Koki Kishimoto, M. Shimbo"",IEEE Transactions on Knowledge and Data Engineering,,2.431 (883),10.1109/TKDE.2021.3075070,https://ieeexplore.ieee.org/ielx7/69/4358933/09411687.pdf,2023,1,https://doi.org/10.1109/TKDE.2021.3075070,https://semanticscholar.org/paper/8c39476130cc7a8669bb9e7fdc9079524d5bce14,""Methods based on vecto",r embe,ddings of knowledge graphs have been actively pursued as a promising,approach to k,"nowledge graph completion. However, exis",ting embe,ddin,g mode,ls generate storage-inefficient re,presentatio,"ns, particularly when the number of entit","ies and relations, and th",e di,mensiona,li,ty,of t,he,real-v,al,ued e,mb,eddi,ng v,ectors are,large.,We present a,binarized CAN,DECOMP/,PARA,FAC,(C,P),deco,mpositio,"n algorithm, whic",h w,e r,efer to as,"B-CP, w",here r,eal-va,lu,ed,param,ete,rs a,re repla,ced,by binary values to,reduce mode,l siz,e. Mor,"eover, a fas",t,score comp,ut,at,ion technique,is develope,d w,ith,bitwi,se ope,rations. We,pro,ve tha,t B-CP,is,fu,lly expre,ssive gi,ven a suffici,ently,lar,ge dimensiona,lity of em,be,dding ve,ctor,s.,Experimental,results on,severa,l,benchmark,datasets,dem,onstrate th,at t,he p,ropos,ed method,succ,essfully red,uces mo,del siz,e by,more th,an a,n or,der,of magnitude,whil,e m,aintaining,tas,k per,formance at,the,same le,vel as th,e real-,valued CP,model,"."",,",,,,,,
"Embeddings between partial combinatory algebras,An embedding between two relativized models exists if and only if there exists a particular reduction between the oracles.,""A. Golov, S. Terwijn"",ArXiv,,,10.48550/arXiv.2204.03553,,2022,1,https://doi.org/10.48550/arXiv.2204.03553,https://semanticscholar.org/paper/75bace27c2b5b8e18615180508983308690144fc,""Partial combinatory algebras are algebraic structures that serve as generalized models of computation. In this paper, we study embeddings",of pc,"as. In particular, we systematize the embeddings between relativizat",ions of Kleene,"'s models, of van Oosten's sequential co",mputation,mod,"el, an","d of Scott's graph model, showing",that an emb,edding between two relativized models exi,sts if and only if there,exis,ts a par,ti,cul,ar r,edu,ction,be,tween,t,he o,racl,es. We obt,ain a si,milar result,for the lambd,a calcu,"lus,",sho,wi,ng,in p,articula,r that it cannot,be,emb,edded in Kl,eene's,first,model.,""",",",",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Adaptive Path Selection for Dynamic Image Captioning,A model can achieve a robust visual representation by exploring potential visual feature extraction paths.,""Tiantao Xian, Zhixin Li, Zhenjun Tang, Huifang Ma"",IEEE transactions on circuits and systems for video technology (Print),,,10.1109/TCSVT.2022.3155795,,2022,2,https://doi.org/10.1109/TCSVT.2022.3155795,https://semanticscholar.org/paper/30a12c17253b5033c208e6bf43e9a4f4525aa705,""Image captioning is a challenging task, i.e., given",an ima,ge machine automatically generates natural language that matches its,semantic cont,ent and has attracted much attention in,recent ye,ars.,Howev,"er, most existing models are desig",ned manuall,"y, and their performance depends heavily",on the expert experience,of t,he desig,ne,r.,In a,ddi,"tion,",th,e com,pu,tati,onal,flow of t,he model,is predefin,"ed, and hard a",nd easy,sam,ples,w,ill,sha,re the s,ame coding path a,nd,eas,ily interfe,re with,each,"other,",t,hu,s conf,usi,ng t,he learn,ing,of the model. In thi,"s paper, we",prop,ose a,Dynamic Tran,sf,ormer to c,ha,ng,e the encoding,procedure,fro,m s,equent,ial to,"adaptive,",i.e.,", data",#NAME?,den,t c,omputing,paths. S,"pecifically,",we de,sign,three differ,ent types,of,visual,feat,ur,e extraction b,locks and d,eploy,th,em in par,allel at,each,layer to c,onst,ruct,a mu,lti-layer,rout,ing space in,a full,y conne,cted,manner.,Eac,h bl,ock,contains a c,alcul,ati,on unit tha,t p,erfor,ms the corr,espo,nding op,erations,and a r,outing ga,te tha,t learn,s to,ada,ptively se,lec,t the direc,"tion to pass the signal based on the input image. Thus, our model can achieve a robust visual representation by exploring potential visual feature extraction paths. We evaluate our method quantitatively and qualitatively using a benchmark MSCOCO image caption dataset and perform extensive ablation studies to investigate the reasons behind its effectiveness. The experimental results show that our method is significantly superior to previous state-of-the-art methods."",,"
"Path Development Network with Finite-dimensional Lie Group Representation,The path development consistently and significantly outperforms signature features on several empirical datasets on several empirical datasets on several empirical datasets on several empirical datasets on several empirical datasets on several empirical datasets on several empirical datasets on several empirical datasets on several empirical datasets on several empirical datasets on several empirical datasets on s",everal,empirical datasets on several empirical datasets on several empiric,al datasets on,several empirical datasets on several e,"mpirical,","""Han","Lou,","Siran Li, Hao Ni"",ArXiv,,,10.48550",/arXiv.2204,".00740,,2022,,https://doi.org/10.48550/ar","Xiv.2204.00740,https://se",mant,icschola,r.,org,/pap,er/,eaad16,0c,10cf3,7a,3164,939e,f9029df496,"77527bb,","""BSTRACT The",path signatur,"e, a ma",them,atic,al,ly,prin,cipled a,nd universal feat,ure,of,sequential,"data,",leads,to a p,er,fo,rmance,bo,ost,of deep,lear,ning-based models in,various se,quent,ial da,ta tasks as,a,compliment,ar,y,feature. Howev,"er, it suff",ers,fr,om the,curse,of dimensi,onal,ity wh,en the,pa,th,dimension,is high,. To tackle t,his p,robl,"em, we propos","e a novel,",t,rainable,pat,h,development la,"yer, which",exploi,ts,represen,tations o,f se,quential da,ta w,ith,the h,elp of ?ni,te-d,imensional m,atrix L,ie grou,ps.,We also,desi,gn t,he b,ackpropagati,on al,gor,ithm of the,de,velop,ment layer,via,an optim,isation m,ethod o,n manifol,ds kno,wn as t,rivi,alis,ation. Num,eri,cal experim,"ents demonstrate that the path development consistently and signi?cantly outperforms, in terms of accuracy and dimensionality, signature features on several empirical datasets. Moreover, stacking the LSTM with the development layer with a suitable matrix Lie group is empirically proven to alleviate the gradient issues of LSTMs and the resulting hybrid model achieves the state-of-the-art performance."",,"
"Deeper Shallow Embeddings,Deep embeddings are almost as straightforward to implement as shallow ones.,""Jacob Prinz, G. A. Kavvos, Leonidas Lampropoulos"",International Conference on Interactive Theorem Proving,,,10.4230/LIPIcs.ITP.2022.28,,2022,1,https://doi.org/10.4230/LIPIcs.ITP.2022.28,https://semanticscholar.org/paper/cb38831517028e148afbd42918a8fc37db8df350,""8 Deep and shallow embeddings are two popular techniques for embedding a language in a host lan- 9 guage with complementary st",rength,"s and weaknesses. In a deep embedding, embedded constructs 10 are de",fined as data,in the host: this allows for syntax mani,pulation,and,facili,"tates metatheoretic 11 reasoning,",but is chal,lenging to implement—especially in the ca,se of dependently typed e,mbed,ded 12 l,an,gua,ges.,In,a sha,ll,ow em,be,ddin,"g, b",y contrast,", constr",ucts are enc,oded using fea,tures o,f th,e ho,st,: 1,3 th,is makes,them quite strai,ght,for,ward to imp,"lement,",but l,imits,th,ei,r use,in,prac,tice. 14,In,"this paper, we attem",pt to bridg,e the,gap b,etween the t,wo,", by prese",nt,in,g a general te,chnique 15,for,ex,tendin,g a sh,allow embed,ding,of a,type t,heo,ry,with a de,ep embed,ding of its t,yping,der,iva- 16 tions,. Such emb,ed,dings ar,e al,mo,st as straight,forward to,implem,en,t as shal,"low ones,",but,come with,17 c,apab,iliti,es traditi,onal,ly associate,d with,deep on,es.,We demon,stra,te t,hese,increased c,apabi,lit,ies in 18 a,nu,mber,of case stu,dies,; includ,ing a DSL,that o,nly holds,a?ine,"terms,",and,a d,ependently,ty,ped 19 core,"language with computational beta reduction that leverages function extensionality. This material is based upon work supported by NSF award #2107206, E?icient 24 and Trustworthy Proof Engineering (any opinions, findings and conclusions or recommendations 25 expressed in this material are those of the authors and do not necessarily reflect the views of the 26 NSF)."",,"
"Undirected (1+??)-shortest paths via minor-aggregates: near-optimal deterministic parallel and distributed algorithms,""A local iterative approach for reducing shortest path computations """"up to distance D"""" to computing low-diameter decompositions """"up to distance D/2"""" is simpler, suitable for distributed algorithms."",""Václav Rozho?, C. Grunau, Bernhard Haeupler, Goran Zuzic, Jason Li"",Symposium on the Theory of Computing,,,10.1145/3519935.3520074,,2022,5,https://doi.org/10.1145/351993",5.352,"074,https://semanticscholar.org/paper/9e689dcbb5fcc1ad5b7baeac297935","89c29a21ca,""Th",is paper presents near-optimal determini,stic para,llel,and d,istributed algorithms for computin,g (1+eps)-a,pproximate single-source shortest paths i,n any undirected weighted,gra,ph. On a,h,igh,lev,"el,",we de,te,rmini,st,ical,ly r,educe this,and oth,er shortest-,path problems,to Õ(1),Min,or-A,gg,reg,atio,ns. A Mi,nor-Aggregation c,omp,ute,s an aggreg,ate (e.,"g., ma",x or s,um,),of nod,e-v,alue,s for ev,ery,connected component,of some sub,graph,. Our,reduction im,me,diately im,pl,ie,s: Optimal det,erministic,par,all,el (PR,AM) al,gorithms wi,th Õ,(1) de,pth an,d n,ear,#NAME?,ork. Uni,versally-opti,mal d,eter,ministic dist,ributed (C,ON,GEST) al,gori,th,"ms, whenever d",eterministi,c Mino,r-,Aggregate,algorith,ms e,xist. For e,xamp,"le,",an op,timal Õ(ho,pDia,meterG)-roun,d deter,ministi,c CO,NGEST al,gori,thm,for,excluded-min,or ne,two,rks. Severa,l n,ovel,tools devel,oped,for the,above re,sults a,re intere,sting,in thei,r ow,n ri,ght: A loc,al,iterative a,"pproach for reducing shortest path computations “up to distance D” to computing low-diameter decompositions “up to distance D/2”. Compared to the recursive vertex-reduction approach of [Li20], our approach is simpler, suitable for distributed algorithms, and eliminates many derandomization barriers. A simple graph-based Õ(1)-competitive ?1-oblivious routing based on low-diameter decompositions that can be evaluated in near-linear work. The previous such routing [ZGY+20] was no(1)-competitive and required no(1) more work. A deterministic algorithm to round any fractional single-source transshipment flow into an integral tree solution. The first distributed algorithms for computing Eulerian orientations."",,"
"Automatic Datapath Optimization using E-Graphs,Modern rewriting frameworks can adequately capture a wide variety of complex optimizations performed by human designers on bit-vector manipulating code.,""Samuel Coward, G. Constantinides, Theo Drane"",IEEE Symposium on Computer Arithmetic,,,10.1109/ARITH54963.2022.00016,http://arxiv.org/pdf/2204.11478,2022,2,https://doi.org/10.1109/ARITH54963.2022.00016,https://semanticscholar.org/paper/70d166759b853ebaf38452e5c469cdd85fa04660,""Manual optimi",zation,of Register Transfer Level (RTL) datapath is commonplace in industr,y but holds ba,ck development as it can be very time co,nsuming.,We u,tilize,the fact that a complex transform,ation of on,e RTL into another equivalent RTL can be,broken down into a sequen,ce o,f smalle,"r,",lo,cali,zed,trans,fo,rmati,on,s. B,y re,presenting,RTL as,a graph and,deploying mode,rn grap,h re,writ,in,g t,echn,iques we,can automate the,ci,rcu,it design s,pace ex,plorat,"ion, a",ll,ow,ing us,to,dis,cover fu,ncti,onally equivalent bu,t optimized,arch,itectu,res. We demo,ns,trate that,m,od,ern rewriting,frameworks,can,ad,equate,ly cap,ture a wide,var,iety o,f comp,lex,op,timizatio,ns perfo,rmed by human,desi,gner,s on bit-vect,or manipul,at,ing code,", in",cl,uding signific,ant error-p,rone s,ub,tleties r,egarding,the,validity of,tra,nsfo,rmati,ons under,comp,lex interact,ions of,bitwid,ths.,The pro,pose,d au,toma,ted optimiza,tion,app,roach is ab,le,to re,produce the,res,ults of,typical i,ndustri,al manual,optim,ization,", re",sult,ing in a r,edu,ction in ci,"rcuit area by up to 71%. Not only does our tool discover optimized RTL, but also correctly identifies that the optimal architecture to implement a given arithmetic expression can depend on the width of the operands, thus producing a library of optimized designs rather than the single design point typically generated by manual optimization. In addition, we demonstrate that prior academic work on maximally exploiting carry-save representation and on multiple constant multiplication are both generalized and extended, falling out as special cases of this paper."",,"
"Compositional embeddings of domain-specific languages,A compositional embedding enables various forms of linguistic reuse that are characteristic of shallow embeddings.,""Yaozhu Sun, Utkarsh Dhandhania, B. C. D. S. Oliveira"",Proc. ACM Program. Lang.,,,10.1145/3563294,https://dl.acm.org/doi/pdf/10.1145/3563294,2022,1,https://doi.org/10.1145/3563294,https://semanticscholar.org/paper/b86dc06f43ae511ffc49df8a65fbb79012f032db,""A common approach to defining domain-specific languages (DSLs) is",via a,direct embedding into a host language. There are several well-known,techniques to,"do such embeddings, including shallow an",d deep em,bedd,ings.,"However, such embeddings come with",various tr,ade-offs in existing programming language,s. Owing to such trade-of,"fs,",many emb,ed,ded,DSL,s e,nd up,us,ing a,m,ix o,f ap,proaches i,n practi,"ce, requirin",g a substantia,l amoun,t of,cod,"e,",as,wel,l as som,e advanced coding,te,chn,iques. In t,his pap,"er, we",show,th,at,the r,ece,ntly,propose,d Co,mpositional Programm,ing paradig,m and,the C,P language p,ro,vide impro,ve,d,support for em,bedded DSLs,. I,n C,P we o,btain,a new form,of e,mbeddi,"ng, wh",ich,we,call a c,ompositi,onal embeddin,"g, th",at h,as most of th,e advantag,es,of both,sha,ll,ow and deep em,beddings. O,n the,on,"e hand, c",ompositio,nal,embeddings,enab,le v,ariou,s forms of,lin,guistic reus,e that,are cha,ract,eristic,of s,hall,ow e,"mbeddings, i",nclud,ing,the abilit,y t,o reu,se host-lan,guag,e optimi,zations i,n the D,SL and ad,d new,DSL con,stru,cts,easily. On,th,e other han,"d, similarly to deep embeddings, compositional embeddings support definitions by pattern matching or dynamic dispatching (including dependent interpretations, transformations, and optimizations) over the abstract syntax of the DSL and have the ability to add new interpretations. We illustrate an instance of compositional embeddings with a DSL for document authoring called ExT. The DSL is highly flexible and extensible, allowing users to create various non-trivial extensions easily. For instance, ExT supports various extensions that enable the production of wiki-like documents, LaTeX documents, vector graphics or charts. The viability of compositional embeddings for ExT is evaluated with three applications."",,"
"An Embedding Framework for the Design and Analysis of Consistent Polyhedral Surrogates,Every discrete loss is embedded by some polyhedral loss.,""J. Finocchiaro, Rafael M. Frongillo, Bo Waggoner"",ArXiv,,,10.48550/arXiv.2206.14707,,2022,2,https://doi.org/10.48550/arXiv.2206.14707,https://semanticscholar.org/paper/93502133541f5e095b3facd33231d296d20bbb81,""We formalize and study the natural approach of designing convex surrogate loss functions via embeddings, for problems such as classifica","tion,","ranking, or structured prediction. In this approach, one embeds each",of the finite,ly many predictions (e.g. rankings) as a,point in,"R,",assign,s the original loss values to thes,"e points, a",nd “convexifies” the loss in some way to,obtain a surrogate. We es,tabl,ish a st,ro,ng,conn,ect,ion be,tw,een t,hi,s ap,proa,ch and pol,yhedral,(piecewise-l,inear convex),surroga,te l,osse,s:,ev,ery,discrete,loss is embedded,by,so,me polyhedr,al loss,", and",every,po,ly,hedral,lo,ss e,mbeds so,me d,iscrete loss. Moreov,"er, an embe",dding,gives,rise to a c,on,sistent li,nk,f,unction as wel,l as linear,su,rro,gate r,egret,bounds. Our,res,ults a,re con,str,uct,"ive, as w",e illust,rate with sev,eral,exam,ples. In part,"icular, ou",r,framewor,k gi,ve,s succinct pro,ofs of cons,istenc,y,or incons,istency f,or v,arious poly,hedr,al s,urrog,ates in th,e li,"terature, an",d for i,nconsis,tent,surroga,"tes,",it,furt,her reveals,the d,isc,rete losses,fo,r whi,ch these su,rrog,ates are,consiste,nt. We,go on to,show a,ddition,al s,truc,ture of em,bed,"dings, such","as the equivalence of embedding and matching Bayes risks, and the equivalence of various notions of non-redudancy. Using these results, we establish that indirect elicitation, a necessary condition for consistency, is also sufficient when working with polyhedral surrogates."",,"
"A Three-Layered Multifactorial Evolutionary Algorithm with Parallelization for Large-Scale Engraving Path Planning,The proposed algorithm can reduce the computational burden and improve engraving efficiency in engraving path planning.,""Antian Liang, Hanshi Yang, Liming Sun, Meng Sun"",Electronics,,0.159 (20634),10.3390/electronics11111712,https://www.mdpi.com/2079-9292/11/11/1712/pdf?version=1653873978,2022,1,https://doi.org/10.3390/electronics11111712,https://semanticscholar.org/paper/4",0cdb63,"354263567c66069c4dcfff7b28be12257,""Today, although laser engraving t",echnology is w,"idely used in 2D image engraving, when t",he image,is l,arger,"and more complicated, most existin",g algorithm,s for engraving path planning have a huge,computational burden and,red,uced eng,ra,vin,g ef,fic,iency.,A,ccord,in,"gly,",thi,s article,addresse,s the trajec,tory optimizat,ion pro,blem,in,la,rge,#NAME?,le image,engraving. First,", w",e f,ormulate th,e probl,em as,an imp,ro,ve,d mode,l b,ased,on the,larg,e-scale traveling sa,lesman prob,lem (,TSP).,"Then, we pro",po,se a three,#NAME?,ay,ered algorithm,called 3L-,MFE,A-M,"P, str",ucture,d as follow,s: a,n uppe,r laye,"r,",the,genetic,algorith,m (GA); a mid,dle l,ayer,", the GA; and",a bottom,la,"yer, the",par,al,lel multifacto,rial evolut,ionary,a,lgorithm.,Experime,nts,on four cla,ssic,lar,ge-sc,ale TSP da,tase,ts show that,our al,gorithm,exh,ibits su,peri,or p,erfo,rmance in te,rms o,f t,he path len,gth,and,engraving t,ime,compared,with oth,er algo,rithms. I,n part,"icular,",com,pare,d with the,si,ngle-thread,"algorithm, the proposed parallel algorithm reduced the engraving time by 80%. Moreover, the engraving machine experiment demonstrated that the engraving time of our algorithm on mona-lisa 100K, vangogh 120K, and venus 140K was approximately one tenth that of the traditional dot engraving method. The results indicate that the proposed algorithm can reduce the computational burden and improve engraving efficiency in engraving path planning."",,"
"Manifold-aligned Neighbor Embedding,A manifold-aligned version of the uniform manifold approximation and projection algorithm can learn an aligned manifold that is visually competitive to embedding of the whole dataset.,""Mohammad Tariqul Islam, J. Fleischer"",ArXiv,,,10.48550/arXiv.2205.11257,,2022,1,https://doi.org/10.48550/arXiv.2205.11257,https://semanticscholar.org/paper/ab5b02e7d1d38b03165b38d36d861e1ff91d4d72,""In this paper, we introduce a neighbor embedding framework for manifold",alignm,ent. We demonstrate the ef?cacy of the framework using a manifold-al,igned version,of the uniform manifold approximation an,d project,ion,algori,thm. We show that our algorithm ca,n learn an,aligned manifold that is visually competi,tive to embedding of the,whol,e datase,t.,""",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Two New Characterizations of Path Graphs,Path graphs are intersection graphs of paths in a tree.,""N. Apollonio, Lorenzo Balzotti"",ArXiv,,,10.48550/arXiv.2208.01001,,2022,,https://doi.org/10.48550/arXiv.2208.01001,https://semanticscholar.org/paper/b9f718eb2a8aaa864d8b17b4b6752598486d4667,""Path graphs are intersection graphs of paths in a tree. We start from the characterization of path graphs by Monma and Wei [C.L. Monma, and V.K. Wei, Intersection Graphs of Paths in a Tree, J. Combin. T",heory,"Ser. B, 41:2 (1986) 141–181] and we reduce it to some 2-colorings su","bproblems, obt",aining the ?rst characterization that di,rectly le,ads,to a p,olynomial recognition algorithm. T,hen we intr,oduce the collection of the attachedness,graphs of a graph and we,exhi,bit a li,st,of,min,ima,l forb,id,den 2,#NAME?,dge,colo,red subgra,phs in e,ach of the a,ttachedness gr,"aph ."",",",",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Topology-Preserving Dimensionality Reduction via Interleaving Optimization,The interleaving distance between the persistent homology of Vietoris-Rips filtrations can be used to identify a scale at which topological features in an embedding and original data set are in correspondence.,""Bradley J. Nelson, Yuan Luo"",ArXiv,,,,,2022,2,,https://semanticscholar.org/paper/b718e00ec33422108ea9ce5379e12d75c60ce2b4,""Dimensionality reduction techniques are powerful tools for data preprocessing and",visual,ization which typically come with few guarantees concerning the topo,logical correc,tness of an embedding. The interleaving,distance,betw,een th,e persistent homology of Vietoris-,Rips ?ltrat,ions can be used to identify a scale at w,hich topological features,suc,h as clu,st,ers,or,hol,es in,an,embe,dd,ing,and,original d,ata set,are in corre,spondence. We,show ho,w op,timi,za,tio,n se,eking to,minimize the int,erl,eav,ing distanc,e can b,e inco,rporat,ed,i,nto di,men,sion,ality re,duct,"ion algorithms, and",explicitly,demon,strate,its use in,?n,ding an op,ti,ma,l linear proje,ction. We d,emo,nst,rate t,he uti,lity of thi,s fr,amewor,k to d,ata,vi,sualizati,"on."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Algebraic connectivity of layered path graphs under node deletion,The existence of at least one neighbor in the upper layer is crucial for algebraic connectivity not to deteriorate by node deletion.,""Ryusei Yoshise, Kaoru Yamamoto"",ArXiv,,,10.48550/arXiv.2204.00356,,2022,1,https://doi.org/10.48550/arXiv.2204.00356,https://semanticscholar.org/paper/82e438076ccc380d999bb8d45fba954a3100cb62,""—This paper studies the relation between node dele- tion and the algebraic connectivity for a graph",with,a hierarchical structure represented by layers. The problem is motiv,ated by a mobi,le robot formation control guided by a l,eader. In,par,ticula,"r, we consider a scenario in which",robots may,leave the network resulting in the remov,al of the nodes and the a,ssoc,iated ed,ge,s.,We s,how,that,th,e exi,st,ence,of,at least o,ne neigh,bor in the u,pper layer is,crucial,for,the,a,lge,brai,c connec,tivity not to det,eri,ora,te by node,deletio,"n."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"A genetic algorithm for straight-line embedding of a cycle onto a given set of points inside the general simple polygons,The results of the algorithm that uses this mutation operation are much more efficient than the version that uses only the usual two-point mutation operation.,""Maryam Fadavian, Heidar Fadavian"",ArXiv,,,10.48550/arXiv.2203.00453,,2022,1,https://doi.org/10.48550/arXiv.2203.00453,https://semanticscholar.org/paper/0bbfb5dad515ca8079f6e733ffb91455d9de03e7,"": In this paper,",we ha,ve examined the problem of embedding a cycle of n vertices onto a gi,ven set of n p,oints inside a simple polygon. The goal,of the pr,oble,m is t,hat the cycle must be embedded wit,hout bends,and does not intersect itself and the pol,ygon. This problem is a s,peci,al case,of,th,e pr,obl,em of,fi,nding,a,"(s,","X,",t) - path,inside a,simple poly,gon with the m,inimum,numb,er o,f,ben,ds a,nd inter,sections. The com,ple,xit,y of the pr,oblem i,s exam,ined i,n,th,is pap,er,is o,"pen, but",it,has been proved that,similar pr,oblem,s are,NP-complete.,W,e have pre,se,nt,ed a metaheuri,stic algori,thm,ba,sed on,a gen,etic algori,thm,for st,raight,#NAME?,ne,embedding,of a cy,cle with the,minim,um n,umbers of int,ersections,",",onto a g,iven,s,et of points i,nside the g,eneral,s,imple pol,ygons. Th,e ef,ficiency of,the,pro,posed,genetic a,lgor,ithm is due,to the,definit,ion,of the m,utat,ion,oper,"ation, which",remo,ves,it if ther,e i,s an,intersectio,n be,tween th,e embedde,d edges,of the c,ycle.,The exp,erim,enta,l results,sho,w that the,"results of the version of the algorithm that uses this mutation operation are much more efficient than the version that uses only the usual two-points mutation operation."",,"
"A genetic algorithm for straight-line embedding of a cycle onto a given set of points inside simple polygons,The results of the algorithm that uses mutation operation are much more efficient than the version that uses only the usual two-point mutation.,""Maryam Fadavian, Heidar Fadavian"",,,,,,2022,1,,https://semanticscholar.org/paper/28590ec22f6ca695de8526d2e66d2cdae609a3a0,""Iran Abstract: In this paper, we have examined the problem of embedding a cycle of n vertices onto a given set of",n poin,ts inside a simple polygon. The goal of the problem is that the cycl,e must be embe,dded without bends and does not intersec,t itself,and,the po,lygon. This problem is a special c,ase of the,"open problem of finding a (s, X, t) - sim",ple Hamiltonian path insi,de a,simple,po,lyg,on t,hat,does,no,t int,er,sect,its,elf and th,e sides,of the polyg,on. The comple,xity of,the,pro,bl,em,is e,xamined,in this paper is,ope,"n,",but it has,been pr,oved t,hat si,mi,la,r prob,lem,s ar,e NP-com,plet,e. We have presented,a metaheur,istic,algor,ithm based o,n,a genetic,al,go,rithm for stra,ight-line e,mbe,ddi,ng of,a cycl,e with the,mini,mum nu,mbers,of,int,ersection,"s, onto",a given set o,f poi,nts,inside simple,polygons.,T,he effic,ienc,y,of the propose,d genetic a,lgorit,hm,is due t,o the def,init,ion of the,muta,tion,oper,"ation, whi",ch r,emoves it if,there,is an i,nter,section,betw,een,the,embedded edg,es of,th,e cycle. Th,e e,xperi,mental resu,lts,show tha,t the res,ults of,the vers,ion of,the al,gori,thm,that uses,thi,s mutation,"operation are much more efficient than the version that uses only the usual two-points mutation"",,"
"Hierarchies over Vector Space: Orienting Word and Graph Embeddings,A directed rooted tree is constructed by inserting nodes in descending order of entity power.,""Xingzhi Guo, S. Skiena"",ArXiv,,,10.48550/arXiv.2211.01430,,2022,,https://doi.org/10.48550/arXiv.2211.01430,https://semanticscholar.org/paper/1b2e7e8d6fe3e5f4428dadc05ca9756812933f23,""Word and graph embeddings are widely used in deep learning applications. We present a data structure that captures inherent hierarchical propertie",s from,"an unordered ?at embedding space, particularly a sense of direction",between pairs,of entities. Inspired by the notion of,distribut,iona,l gene,"rality (Weeds et al., 2004), our a",lgorithm co,nstructs an arborescence (a directed root,ed tree) by inserting nod,es i,n descen,di,ng,orde,r o,f enti,ty,powe,r,(e.g,"., w",ord freque,"ncy), po",inting each,entity to the,closest,mor,e po,we,rfu,l no,de as it,s parent. We eval,uat,e t,he performa,nce of,the re,sultin,g,tr,ee str,uct,ures,on thre,e ta,sks: hypernym relati,on discover,"y, le",ast-co,mmon-ancesto,r,(LCA) disc,ov,er,"y among words,",and Wikipe,dia,pa,ge lin,k reco,very. We ac,hiev,e aver,age 8.,98%,an,d 2.70% f,or hyper,nym and LCA d,iscov,ery,across ?ve la,nguages an,d,62.76% a,ccur,ac,y on directed,Wiki-page l,ink re,co,"very, wit",h both su,bsta,ntially abo,ve b,asel,ines.,"Finally,",we i,nvestigate t,he effe,ct of i,nser,tion ord,"er,",the,powe,r/similarity,trad,e-o,ff and vari,ous,powe,r sources t,o op,timize p,arent sel,ection.,""",,",,,,,,,,
"Automatic Datapath Optimization using E-Graphs,Modern rewriting frameworks can adequately capture a wide variety of complex optimizations performed by human designers on bit-vector manipulating code.,""Samuel Coward, G. Constantinides, Theo Drane"",ArXiv,,,10.48550/arXiv.2204.11478,,2022,1,https://doi.org/10.48550/arXiv.2204.11478,https://semanticscholar.org/paper/9a3ba2b66dd91a6fd0a7277a8b4dd5dafac18eb7,""—Manual optimization of Register Transfer Level (RTL) datapath is commonplace in ind",ustry,but holds back development as it can be very time consuming. We util,ize the fact t,hat a complex transformation of one RTL,into anot,her,equiva,lent RTL can be broken down into a,sequence o,"f smaller, localized transformations. By",representing RTL as a gra,ph a,nd deplo,yi,ng,mode,rn,graph,re,writi,ng,tec,hniq,ues we can,automat,e the circui,t design space,explor,atio,"n, a",ll,owi,ng u,s to dis,cover functionall,y e,qui,valent but,optimiz,ed arc,hitect,ur,es,. We d,emo,nstr,ate that,mod,ern rewriting framew,orks can ad,equat,ely ca,pture a wide,v,ariety of,co,mp,lex optimizati,ons perform,ed,by,human,design,ers on bit-,vect,or man,ipulat,ing,co,"de, inclu",ding sig,ni?cant error,#NAME?,e su,btleties rega,rding the,va,lidity o,f tr,an,sformations un,der complex,inter,ac,tions of,bitwidths,. Th,e proposed,auto,mate,d opt,imization,appr,oach is able,to rep,roduce,the,results,of t,ypic,al i,ndustrial ma,nual,opt,"imization,",res,ultin,g in a redu,ctio,n in cir,cuit area,by up,to 71%. N,ot onl,y does,our,tool,discover,opt,"imized RTL,","but also correctly identi?es that the optimal architecture to implement a given arithmetic expression can depend on the width of the operands, thus producing a library of optimized designs rather than the single design point typically generated by manual optimization. In addition, we demonstrate that prior academic work on maximally exploiting carry-save representation and on multiple constant multiplication are both generalized and extended, falling out as special cases of this paper."",,"
"Algebraic connectivity of layered path graphs under node deletion,The existence of at least one neighbor in the upper layer is crucial for algebraic connectivity not to deteriorate by node deletion.,""Ryusei Yoshise, Kaoru Yamamoto"",IEEE Conference on Decision and Control,,,10.1109/CDC51059.2022.9992940,http://arxiv.org/pdf/2204.00356,2022,1,https://doi.org/10.1109/CDC51059.2022.9992940,https://semanticscholar.org/paper/73ba62457b2b816b79e64dfb5c52549be7cdefa8,""This paper studies the rel",ation,between node deletion and algebraic connectivity for graphs with a h,ierarchical st,ructure represented by layers. To captur,e this st,ruct,"ure, t",he concepts of layered path graph,and its (su,b)graph cone are introduced. The problem,is motivated by a mobile,robo,t format,io,n c,ontr,ol,guided,b,y a l,ea,der.,In,particular,", we con",sider a scen,ario in which,robots,may,leav,e,the,net,work res,ulting in the rem,ova,l o,f the nodes,and th,e asso,ciated,e,dg,es. We,sh,ow t,hat the,exis,tence of at least on,e neighbor,in th,e uppe,r layer is c,ru,cial for t,he,a,lgebraic conne,ctivity not,to,de,terior,ate by,node delet,ion.,""",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Runtime Composition Of Systems of Interacting Cyber-Physical Components,A transition system algebra is implemented in the Maude rewriting logic system.,""Benjamin Lion, F. Arbab, C. Talcott"",ArXiv,,,10.48550/arXiv.2205.13008,,2022,2,https://doi.org/10.48550/arXiv.2205.13008,https://semanticscholar.org/paper/5acc695a4ed24304ef4f7a15059f7cd5b9461c3f,"". We introduce a transition system based speci?cation of cyber-physical systems whose semantics is compositional with respect to a family of",algebr,aic products. We give su?cient conditions for execution of a product,to be correct,ly implemented by a lazy expansion of th,e product,con,struct,ion. The transition system algebra,is impleme,"nted in the Maude rewriting logic system,",and we report a simple c,ase,study il,lu,s-t,rati,ng,compos,it,ional,s,peci,?cat,"ion."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Adaptively Informed Trees (AIT*) and Effort Informed Trees (EIT*): Asymmetric bidirectional sampling-based path planning,AIT and EIT outperform other algorithms on problems optimizing obstacle clearance.,""Marlin P. Strub, J. Gammell"",Int. J. Robotics Res.,,,10.1177/02783649211069572,http://arxiv.org/pdf/2111.01877,2022,3,https://doi.org/10.1177/02783649211069572,https://semanticscholar.org/paper/2ff27c035f3b4e3c3a0c3e3b75526db223608dd4,""Optimal path planning is the problem of finding a",valid,sequence of states between a start and goal that optimizes an object,ive. Informed,path planning algorithms order their sea,rch with,prob,lem-sp,ecific knowledge expressed as heur,istics and,can be orders of magnitude more efficient,than uninformed algorith,ms.,Heuristi,cs,ar,e mo,st,effect,iv,e whe,n,they,are,both accu,rate and,computation,ally inexpensi,ve to e,valu,"ate,",b,ut,thes,e are of,ten conflicting c,har,act,eristics. T,his mak,es the,selec,ti,on,of ap,pro,pria,te heuri,stic,s difficult for many,problems.,This,paper,presents two,a,lmost-sure,ly,a,symptotically,optimal sam,pli,ng-,based,path p,lanning alg,orit,hms to,addre,ss,thi,s challen,"ge, Adap",tively Inform,ed Tr,ees,(AIT*) and Ef,fort Infor,me,d Trees,(EIT,*),. These algori,thms use an,asymm,et,ric bidir,ectional,sear,ch in which,bot,h se,arche,s continuo,usly,inform each,other.,This a,llow,s AIT* a,nd E,IT*,to i,mprove plann,ing p,erf,ormance by,sim,ultan,eously calc,ulat,ing and,exploitin,g incre,asingly a,ccurat,"e, prob",lem-,spec,ific heuri,sti,cs. The ben,"efits of AIT* and EIT* relative to other sampling-based algorithms are demonstrated on 12 problems in abstract, robotic, and biomedical domains optimizing path length and obstacle clearance. The experiments show that AIT* and EIT* outperform other algorithms on problems optimizing obstacle clearance, where a priori cost heuristics are often ineffective, and still perform well on problems minimizing path length, where such heuristics are often effective."",,"
"Paper title,Abstract summary,Authors,Journal,Influential citations,Scimago Journal Rank,DOI,PDF,Year,Citations,DOI URL,Semantic Scholar URL,Abstract,Takeaway suggests yes/no,Study type",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Structural Quality Metrics to Evaluate Knowledge Graphs,A knowledge graph that could not be known only by scale-related indicators such as the number of classes and properties.,""Sumin Seo, Heeseon Cheon, Hyunho Kim, Dongseok Hyun"",ArXiv,,,10.48550/arXiv.2211.10011,,2022,,https://doi.org/10.48550/arXiv.2211.10011,https://semanticscholar.org/paper/d7993e014f232a851dc46feb45ec454afe3faa5a,""This work presents six structural quality metrics that can measure the quality of knowledge graphs and analyzes ?ve cross-domain knowledge graphs on the web (Wikidata, DBpedia, YAGO, Google Knowledge Graph, Freebase) as well as ’Raftel’, Naver’s integrated knowledge graph. The ’Good Knowledge Graph’ should de?ne detailed classes and properties in its ontology so that knowledge in the real world can be expressed abundantly. Also, instances and RDF triples should use the classes and properties actively. Therefore, we tried to examine the internal quality of knowledge graphs numerically by focusing on the structure of the ontology, which is the schema of knowledge graphs, and the degree of use thereof. As a result of the analysis, it was possible to ?nd the characteristics of a knowledge graph that could not be known only by scale-related indicators such as the number of classes and properties."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"A Unified Framework for Rank-based Evaluation Metrics for Link Prediction in Knowledge Graphs,The link prediction task on knowledge graphs without explicit negative triples in the training data motivates the use of rank-based metrics.,""Charles Tapley Hoyt, M. Berrendorf, Mikhail Galkin, Volker Tresp, Benjamin M. Gyori"",ArXiv,,,10.48550/arXiv.2203.07544,,2022,2,https://doi.org/10.48550/arXiv.2203.07544,https://semanticscholar.org/paper/d10428bd18aa86c7f5007a27158dd07c0c55afa4,""The link prediction task on knowledge graphs without explicit negative triples in the training data motivates the usage of rank-based metrics. Here, we review existing rank-based metrics and propose desiderata for improved metrics to address lack of interpretability and comparability of existing metrics to datasets of different sizes and properties. We introduce a simple theoretical framework for rank-based metrics upon which we investigate two avenues for improvements to existing metrics via alternative aggregation functions and concepts from probability theory. We finally propose several new rank-based metrics that are more easily interpreted and compared accompanied by a demonstration of their usage in a benchmarking of knowledge graph embedding models."",,Review",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"KGxBoard: Explainable and Interactive Leaderboard for Evaluation of Knowledge Graph Completion Models,Averaged single-score metrics cannot reveal what exactly a model has learned.,""Haris Widjaja, Kiril Gashteovski, Wiem Ben Rim, Pengfei Liu, Christopher Malon, Daniel Ruffinelli, Carolin (Haas) Lawrence, Graham Neubig"",ArXiv,,,10.48550/arXiv.2208.11024,,2022,,https://doi.org/10.48550/arXiv.2208.11024,https://semanticscholar.org/paper/c33e99e90d066319866de9e0768e01b83360d1ab,""Knowledge Graphs (KGs) store information in the form of (head, predicate, tail)- triples. To augment KGs with new knowledge, researchers proposed models for KG Completion (KGC) tasks such as link prediction; i.e., answering (h; p; ?) or (?; p; t) queries. Such models are usually evaluated with averaged metrics on a held-out test set. While useful for tracking progress, averaged single-score metrics cannot reveal what exactly a model has learned—or failed to learn. To address this issue, we propose KGxBoard 1 : an interactive framework for performing ?ne-grained evaluation on meaningful subsets of the data, each of which tests individual and interpretable capabilities of a KGC model. In our experiments, we highlight the ?ndings that we discovered with the use of KGxBoard, which would have been impossible to detect with standard averaged single-score metrics."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Re-thinking Knowledge Graph Completion Evaluation from an Information Retrieval Perspective,The IR-like macro metrics are more stable and discriminative under different settings.,""Ying Zhou, Xuanang Chen, Ben He, Zheng Ye, Le Sun"",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,,,10.1145/3477495.3532052,https://dl.acm.org/doi/pdf/10.1145/3477495.3532052,2022,1,https://doi.org/10.1145/3477495.3532052,https://semanticscholar.org/paper/953f92e7279ec0f6802afaaf836f5cdc73c01f3b,""Knowledge graph completion (KGC) aims to infer missing knowledge triples based on known facts in a knowledge graph. Current KGC research mostly follows an entity ranking protocol, wherein the effectiveness is measured by the predicted rank of a masked entity in a test triple. The overall performance is then given by a micro(-average) metric over all individual answer entities. Due to the incomplete nature of the large-scale knowledge bases, such an entity ranking setting is likely affected by unlabelled top-ranked positive examples, raising questions on whether the current evaluation protocol is sufficient to guarantee a fair comparison of KGC systems. To this end, this paper presents a systematic study on whether and how the label sparsity affects the current KGC evaluation with the popular micro metrics. Specifically, inspired by the TREC paradigm for large-scale information retrieval (IR) experimentation, we create a relatively """"complete"""" judgment set based on a sample from the popular FB15k-237 dataset following the TREC pooling method. According to our analysis, it comes as a surprise that switching from the original labels to our """"complete"""" labels results in a drastic change of system ranking of a variety of 13 popular KGC models in terms of micro metrics. Further investigation indicates that the IR-like macro(-average) metrics are more stable and discriminative under different settings, meanwhile, less affected by label s",par,sit,y.,T,hus,", f",or,KGC,e,valu,at,"ion,",we,reco,mme,nd,con,ducting,TREC,#NAME?,e p,ool,ing,to,ba,lan,ce,be,tw,een,h,uman,eff,or,ts,an,d lab,el,comp,leten,es,"s,",an,d re,por,ti,ng,al,so,the,IR-like,m,acr,o m,etri,cs,to refle,ct,the,r,an,ki,ng,nat,ure,of,the,KG,C tas,k.,""",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Comprehensive Analysis of Knowledge Graph Embedding Techniques Benchmarked on Link Prediction,The new generation of translational models emerges as the most promising encoders for knowledge graph completion.,""Ilaria Ferrari, Giacomo Frisoni, Paolo Italiani, G. Moro, C. Sartori"",Electronics,,0.159 (20634),10.3390/electronics11233866,https://www.mdpi.com/2079-9292/11/23/3866/pdf?version=1669367554,2022,1,https://doi.org/10.3390/electronics11233866,https://semanticscholar.org/paper/b5167990eda7d48f1a70a1fcb900ed5d46c40985,""In knowledge graph representation learning, link prediction is among the most popular and influential tasks. Its surge in popularity has resulted in a panoply of orthogonal embedding-based methods projecting entities and relations into low-dimensional continuous vectors. To further enrich the research space, the community witnessed a prolific development of evaluation benchmarks with a variety of structures and domains. Therefore, researchers and practitioners face an unprecedented challenge in effectively identifying the best solution to their needs. To this end, we propose the most comprehensive and up-to-date study to systematically assess the effectiveness and efficiency of embedding models for knowledge graph completion. We compare 13 models on six datasets with different sizes, domains, and relational properties, covering translational, semantic matching, and neural network-based encoders. A fine-grained evaluation is conducted to compare each technique head-to-head in terms of standard metrics, training and evaluation times, memory consumption, carbon footprint, and space geometry. Our results demonstrate the high dependence between performance and graph types, identifying the best options for each scenario. Among all the encoding strategies, the new generation of translational models emerges as the most promising, bringing out the best and most consistent results across all the datasets and evaluation criteria."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Quality Evaluation of Triples in Knowledge Graph by Incorporating Internal With External Consistency.,Internal consistency evaluation is integrated with the external consistency evaluation to identify possible incorrect triples and reduce their influences on the KQ evaluation.,""Taiyu Ban, Xiangyu Wang, Lyuzhou Chen, Xingyu Wu, Qiuju Chen, Huanhuan Chen"",IEEE Transactions on Neural Networks and Learning Systems,,4.222 (355),10.1109/TNNLS.2022.3186033,,2022,1,https://doi.org/10.1109/TNNLS.2022.3186033,https://semanticscholar.org/paper/5b5fd098da83e35617cc2992600fbbb52bc7d9a3,""The evaluation of knowledge quality (KQ) in multisource knowledge graphs (KGs) is an essential step for many applications, such as fragmented knowledge fusion and knowledge base construction. Many existing quality evaluation methods for multisource knowledge are based on validation from high-quality knowledge bases or statistical analysis of knowledge related to a specific fact from multiple sources, named external consistency (EC)-based methods. However, high-quality KGs are difficult to obtain, and there might exist incorrect knowledge in multisource KGs interfering with KQ evaluation. To address the issue, this article refers to the internal structure of a KG to evaluate the degree to which the contained triples conform to the overall semantic pattern of the KG, such as KG embedding and logic inference-based approaches, defined as internal consistency (IC) evaluation. The IC is integrated with the EC to identify possible incorrect triples and reduce their influences on the KQ evaluation, thus alleviating the interference of incorrect knowledge. The proposed method is verified with multiple datasets, and the results demonstrate that the proposed method could significantly reduce wrong evaluations caused by incorrect knowledge and effectively improve the quality evaluation of triples."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"The DLCC Node Classification Benchmark for Analyzing Knowledge Graph Embeddings,Knowledge graph embeddings have gained a lot of uptake and have been heavily used in link prediction and other downstream prediction tasks.,""Jan Portisch, H. Paulheim"",International Workshop on the Semantic Web,,,10.48550/arXiv.2207.06014,,2022,1,https://doi.org/10.48550/arXiv.2207.06014,https://semanticscholar.org/paper/634cfec43844c73363e7d83e76335aa606cc9358,"". Knowledge graph embedding is a representation learning technique that projects entities and relations in a knowledge graph to continuous vector spaces. Embeddings have gained a lot of uptake and have been heavily used in link prediction and other downstream prediction tasks. Most approaches are evaluated on a single task or a single group of tasks to determine their overall performance. The evaluation is then assessed in terms of how well the embedding approach performs on the task at hand. Still, it is hardly evaluated (and often not even deeply under-stood) what information the embedding approaches are actually learning to represent. To?llthis gap, we present the DLCC (Description Logic Class Constructors) benchmark, a resource to analyze embedding approaches in terms of which kinds of classes they can represent. Two gold standards are presented, one based on the real-world knowledge graph DBpedia and one synthetic gold standard. In addition, an evaluation framework is provided that implements an experiment protocol so that researchers can directly use the gold standard. To demonstrate the use of DLCC, we compare multiple embedding approaches using the gold standards. We ?nd that many DL constructors on DBpedia are actually learned by recognizing di?erent correlated patterns rather than those de?ned in the gold standard; we further ?nd that speci?c DL constructors, such as cardinality constraints, are particularly hard to be learned for most embedding approaches."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Towards Formally Grounded Evaluation Measures for Semantic Parsing-based Knowledge Graph Question Answering,The absence of grounded alternative knowledge graph question answering measures is important.,""Trond Linjordet, K. Balog, Vinay Setty"",International Conference on the Theory of Information Retrieval,,,10.1145/3539813.3545146,,2022,,https://doi.org/10.1145/3539813.3545146,https://semanticscholar.org/paper/7ac96a8ecabd00f45782d2bb72c1715316213e31,""Knowledge graph question answering (KGQA) is important to make structured information accessible without formal query language expertise on the part of the users. The semantic parsing (SP) flavor of this task maps a natural language question to a formal query that is machine executable, such as SPARQL. The SP-KGQA task is currently evaluated by adopting measures from other tasks, such as information retrieval and machine translation. However, this adoption typically occurs without fully considering the desired behavior of SP-KGQA systems. To address this, we articulate task-specific desiderata, then develop novel SP-KGQA measures based on a probabilistic framework. We use the desiderata to formulate a set of axioms for SP-KGQA measures and conduct an axiomatic analysis that reveals insufficiencies of established measures previously used to report SP-KGQA performance. We also perform experimental evaluations, using synthetic and state-of-the-art neural machine translation approaches. The results highlight the importance of grounded alternative SP-KGQA measures."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Knowledge Graph Question Answering Datasets and Their Generalizability: Are They Enough for Future Research?,Existing approaches on Question Answering over Knowledge Graphs are weak generalizability.,""Longquan Jiang, Ricardo Usbeck"",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,,,10.1145/3477495.3531751,,2022,3,https://doi.org/10.1145/3477495.3531751,https://semanticscholar.org/paper/787a7e59c7aea516ad52696b6e7cd2f58d44fa77,""Existing approaches on Question Answering over Knowledge Graphs (KGQA) have weak generalizability. That is often due to the standard i.i.d. assumption on the underlying dataset. Recently, three levels of generalization for KGQA were defined, namely i.i.d., compositional, zero-shot. We analyze 25 well-known KGQA datasets for 5 different Knowledge Graphs (KGs). We show that according to this definition many existing and online available KGQA datasets are either not suited to train a generalizable KGQA system or that the datasets are based on discontinued and out-dated KGs. Generating new datasets is a costly process and, thus, is not an alternative to smaller research groups and companies. In this work, we propose a mitigation method for re-splitting available KGQA datasets to enable their applicability to evaluate generalization, without any cost and manual effort. We test our hypothesis on three KGQA datasets, i.e., LC-QuAD, LC-QuAD 2.0 and QALD-9). Experiments on re-splitted KGQA datasets demonstrate its effectiveness towards generalizability. The code and a unified way to access 18 available datasets is online at https://github.com/semantic-systems/KGQA-datasets as well as https://github.com/semantic-systems/KGQA-datasets-generalization."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"""Know, Know Where, Knowwheregraph: A Densely Connected, Cross-Domain Knowledge Graph and Geo-Enrichment Service Stack for Applications in Environmental Intelligence"",""Knowledge graphs are a novel paradigm for the representation, retrieval, and integration of data from highly heterogeneous sources."",""K. Janowicz, P. Hitzler, Wenwen Li, Dean Rehberger, M. Schildhauer, Rui Zhu, C. Shimizu, C. Fisher, Ling Cai, Gengchen Mai, Joseph Zalewski, Lu Zhou, Shirly Stephen, Seila Gonzalez, B. Mecum, Anna Carr, Andrew Schroeder, Dave Smith, D. Wright, Sizhe Wang, Yuanyuan Tian, Zilong Liu, Meilin Shi, Anthony M. D'Onofrio, Zhining Gu, Kitty Currier"",AI Mag.,,,10.1609/aimag.v43i1.19120,https://ojs.aaai.org/index.php/aimagazine/article/download/19120/18892,2022,4,https://doi.org/10.1609/aimag.v43i1.19120,https://semanticscholar.org/paper/6d1d06cd5c4346c3f2977a5292338ebfcae2cd53,""Knowledge graphs (KGs) are a novel paradigm for the representation, retrieval, and integration of data from highly heterogeneous sources. Within just a few years, KGs and their supporting technologies have become a core component of modern search engines, intelligent personal assistants, business intelligence, and so on. Interestingly, despite large-scale data availability, they have yet to be as successful in the realm of environmental data and environmental intelligence. In this paper, we will explain why spatial data require special treatment, and how and when to semantically lift environmental data to a KG. We will present our KnowWhereGraph that contains a wide range of integrated datasets at the human–environment interface, introduce our application areas, and discuss geospatial enrichment services on top of our graph. Jointly, the graph and services will provide answers to questions such as “what is here,” “what happened here before,” and “how does this region compare to …” for any region on earth within seconds."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Knowledge Graph Quality Evaluation under Incomplete Information,Knowledge graph quality evaluation under incomplete information.,""Xiaodong Li, Chenxin Zou, Yimeng Cai, Yuelong Zhu"",ArXiv,,,10.48550/arXiv.2212.00994,,2022,,https://doi.org/10.48550/arXiv.2212.00994,https://semanticscholar.org/paper/62e74be3dba081f0d9cf50a554f592f38c532f45,evaluators under incomplete information.,,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"""A Survey on Knowledge Graphs: Representation, Acquisition, and Applications"",""Knowledge graph embedding is organized from four aspects of representation space, scoring function, encoding models, and auxiliary information."",""Shaoxiong  Ji, Shirui  Pan, Erik  Cambria, Pekka  Marttinen, Philip S. Yu"",IEEE Transactions on Neural Networks and Learning Systems,,4.222 (355),10.1109/TNNLS.2021.3070843,https://research-repository.griffith.edu.au/bitstream/10072/416709/2/Pan2923674-Accepted.pdf,2022,340,https://doi.org/10.1109/TNNLS.2021.3070843,https://semanticscholar.org/paper/c9ec8cf5ce461647d0d1cf67093feeadea5d9957,""Human knowledge provides a formal understanding of the world. Knowledge graphs that represent structural relations between entities have become an increasingly popular research direction toward cognition and human-level intelligence. In this survey, we provide a comprehensive review of the knowledge graph covering overall research topics about: 1) knowledge graph representation learning; 2) knowledge acquisition and completion; 3) temporal knowledge graph; and 4) knowledge-aware applications and summarize recent breakthroughs and perspective directions to facilitate future research. We propose a full-view categorization and new taxonomies on these topics. Knowledge graph embedding is organized from four aspects of representation space, scoring function, encoding models, and auxiliary information. For knowledge acquisition, especially knowledge graph completion, embedding methods, path inference, and logical rule reasoning are reviewed. We further explore several emerging topics, including metarelational learning, commonsense reasoning, and temporal knowledge graphs. To facilitate future research on knowledge graphs, we also provide a curated collection of data sets and open-source libraries on different tasks. In the end, we have a thorough outlook on several promising research directions."",,Review",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"KGEA: A Knowledge Graph Enhanced Article Quality Identification Dataset,External knowledge can guide articles to a more competitive classification with the graph neural networks.,""Chunhui Ai, Derui Wang, Yang Xu, Wenrui Xie, Ziqiang Cao"",ArXiv,,,10.48550/arXiv.2206.07556,,2022,,https://doi.org/10.48550/arXiv.2206.07556,https://semanticscholar.org/paper/ae8a8ff9c8b24f96a0bd1e55f4c4e0cdbd8731e9,""With so many articles of varying quality being produced at every moment, it is a very urgent task to screen this data for quality articles and commit them out to social media. It is worth noting that high quality articles have many characteristics, such as relevance, text quality, straightforward, multi-sided, background, novelty and sentiment. Thus, it would be inadequate to purely use the content of an article to identify its quality. Therefore, we plan to use the external knowledge interaction to refine the performance and propose a Knowledge Graph Enhanced Article quality identification dataset (KGEA) based on Baidu Encyclopedia. We quantified the articles through 7 dimensions and use cooccurrence of the entities between the articles and the Baidu encyclopedia to construct the knowledge graph for every article. We also compared some text classification baselines and found that external knowledge can guide the articles to a more competitive classification with the graph neural networks."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Knowledge Graph Embedding Methods for Entity Alignment: An Experimental Review,Embedding methods have been used for entity alignment tasks.,""N. Fanourakis, Vasilis Efthymiou, D. Kotzinos, V. Christophides"",ArXiv,,,10.48550/arXiv.2203.09280,,2022,,https://doi.org/10.48550/arXiv.2203.09280,https://semanticscholar.org/paper/9f827aeea7fe134afa9fe4b36a68b0dd668bd142,""In recent years, we have witnessed the proliferation of knowledge graphs (KG) in various domains, aiming to support applications like question answering, recommendations, etc. A frequent task when integrating knowledge from different KGs is to find which subgraphs refer to the same real-world entity. Recently, embedding methods have been used for entity alignment tasks, that learn a vector-space representation of entities which preserves their similarity in the original KGs. A wide variety of supervised, unsupervised, and semi-supervised methods have been proposed that exploit both factual (attribute based) and structural information (relation based) of entities in the KGs. Still, a quantitative assessment of their strengths and weaknesses in real-world KGs according to different performance metrics and KG characteristics is missing from the literature. In this work, we conduct the first meta-level analysis of popular embedding methods for entity alignment, based on a statistically sound methodology. Our analysis reveals statistically significant correlations of different embedding methods with various meta-features extracted by KGs and rank them in a statistically significant way according to their effectiveness across all real-world KGs of our testbed. Finally, we study interesting trade-offs in terms of methods’ effectiveness and efficiency."",,Review",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Constructing a Knowledge Graph from Indian Legal Domain Corpus,The knowledge graph thus built has been quantitatively evaluated over a small random sample with reasonable results.,""Sarika Jain, Pooja Harde, Nandana Mihindukulasooriya, Sudipto Gosh, Ankush Bisht, A. Dubey"",TEXT2KG/MK@ESWC,,,,,2022,1,,https://semanticscholar.org/paper/ce39df2fe4326f5b5db05f60e8a0b3d18679f50f,""While being an important pillar of human society, legal domain consists of large corpora of complex documents about different aspects such as laws or court judgements. In recent years, knowledge graphs have become a prominent solution to represent such complex information in semantically rich machine readable manner allowing access to other AI powered downstream applications. In this work, we aim to construct a reliable knowledge graph from Legal domain corpus that may be utilized by researchers and the application developers working in legal domain.The source dataset chosen is the Indian Legal Court Judgements and NyOn 1 (Nyaya Ontology) has been utilized for conceptualization. A framework that consists of entity extraction, relation extraction, triple construction is used to convert the legal text into RDF triples. The knowledge graph thus built has been quantitatively evaluated over a small random sample with reasonable results."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Knowledge Graph Contrastive Learning for Recommendation,Knowledge graph-enhanced recommender systems are often noisy and contain topic-irrelevant connections between items and entities.,""Yuhao Yang, Chao Huang, Lianghao Xia, Chenliang Li"",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,,,10.1145/3477495.3532009,http://arxiv.org/pdf/2205.00976,2022,12,https://doi.org/10.1145/3477495.3532009,https://semanticscholar.org/paper/895396389a9fee1b607bf5141a6cc7925bb1e069,""Knowledge Graphs (KGs) have been utilized as useful side information to improve recommendation quality. In those recommender systems, knowledge graph information often contains fruitful facts and inherent semantic relatedness among items. However, the success of such methods relies on the high quality knowledge graphs, and may not learn quality representations with two challenges: i) The long-tail distribution of entities results in sparse supervision signals for KG-enhanced item representation; ii) Real-world knowledge graphs are often noisy and contain topic-irrelevant connections between items and entities. Such KG sparsity and noise make the item-entity dependent relations deviate from reflecting their true characteristics, which significantly amplifies the noise effect and hinders the accurate representation of user's preference. To fill this research gap, we design a general Knowledge Graph Contrastive Learning framework (KGCL) that alleviates the information noise for knowledge graph-enhanced recommender systems. Specifically, we propose a knowledge graph augmentation schema to suppress KG noise in information aggregation, and derive more robust knowledge-aware representations for items. In addition, we exploit additional supervision signals from the KG augmentation process to guide a cross-view contrastive learning paradigm, giving a greater role to unbiased user-item interactions in gradient descent and further suppressing the noise.",Ex,ten,si,ve,ex,per,im,ents,o,n th,re,e pu,bli,c dat,ase,ts,dem,onstrate,the,cons,ist,ent,su,per,ior,ity,o,f o,ur,KG,CL,ove,r st,at,e-,of-,the-a,rt,tech,nique,s.,K,GCL,als,o a,ch,ie,ves,st,rong,perfor,ma,nce,in,rec,omm,endation,s,cena,ri,os,w,it,h sp,arse,u,ser-,ite,m int,er,"actions, long-tail and noisy KG entities. Our implementation codes are available at https://github.com/yuh-yang/KGCL-SIGIR22."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Knowledge Graph Contrastive Learning for Recommendation,Knowledge graph-enhanced recommender systems are often noisy and contain topic-irrelevant connections between items and entities.,""Yuhao Yang, Chao Huang, Lianghao Xia, Chenliang Li"",SIGIR,,,10.1145/3477495.3532009,http://arxiv.org/pdf/2205.00976,2022,4,https://doi.org/10.1145/3477495.3532009,https://semanticscholar.org/paper/ed2226e222c68311d5c22c2eb6e5f35244232153,""Knowledge Graphs (KGs) have been utilized as useful side information to improve recommendation quality. In those recommender systems, knowledge graph information often contains fruitful facts and inherent semantic relatedness among items. However, the success of such methods relies on the high quality knowledge graphs, and may not learn quality representations with two challenges: i) The long-tail distribution of entities results in sparse supervision signals for KG-enhanced item representation; ii) Real-world knowledge graphs are often noisy and contain topic-irrelevant connections between items and entities. Such KG sparsity and noise make the item-entity dependent relations deviate from reflecting their true characteristics, which significantly amplifies the noise effect and hinders the accurate representation of user's preference. To fill this research gap, we design a general Knowledge Graph Contrastive Learning framework (KGCL) that alleviates the information noise for knowledge graph-enhanced recommender systems. Specifically, we propose a knowledge graph augmentation schema to suppress KG noise in information aggregation, and derive more robust knowledge-aware representations for items. In addition, we exploit additional supervision signals from the KG augmentation process to guide a cross-view contrastive learning paradigm, giving a greater role to unbiased user-item interactions in gradient descent and further suppressing the noise. Extensive experiments on three public datasets demonstrate the consistent superiority of",our,KG,CL,o,ver,st,at,e-of,#NAME?,he-a,rt,tec,hni,ques.,KG,CL,als,o achiev,es s,trong,pe,rfo,rma,nce,in,re,co,mme,nd,ati,on,sce,nari,os,w,ith,spar,se,user,#NAME?,i,nt,era,ctio,"ns,",l,on,g-t,ail,and,noisy,KG,en,tit,ies.,Ou,r implem,en,tati,on,c,od,es,are,ava,il,able,at,http,s:,"//github.com/yuh-yang/KGCL-SIGIR22."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"A Survey on Knowledge Graph Embedding,""Knowledge graph embedding improves computational efficiency by embedding entities and relations in the knowledge graph into a low-dimensional, dense and continuous vector space."",""Qi Yan, Jiaxin Fan, Mohan Li, Guanqun Qu, Yang Xiao"",International Conference on Data Science in Cyberspace,,,10.1109/DSC55868.2022.00086,,2022,2,https://doi.org/10.1109/DSC55868.2022.00086,https://semanticscholar.org/paper/f470e11faa6200026cf39e248510070c078e509a,""Knowledge graph (KG) is used to represent the relationships between different concepts in the real world. It is a special network in which nodes represent entities and edges represent relationships. KGs can intuitively model the connections between facts, but in many applications, there are certain limitations in directly using symbolic logic to represent knowledge in KGs and perform calculations, making it difficult to achieve expected results in downstream tasks. Meanwhile, with the explosive growth of Internet capacity, the traditional KG structure faces the problems of computational inefficiency and management difficulties. To alleviate these problems, Knowledge graph embedding (KGE) is proposed to improve the computational efficiency by embedding entities and relations in the KG into a low-dimensional, dense and continuous vector space, and thus the solution of some problems in the knowledge graph is transformed into vector operations. Moreover, KGE also can be used as a pre-trained model which is more beneficial to downstream applications, such as applications based on deep learning. In this paper, we classify KGE into three categories, namely translational distance models, semantic matching models and neural network based models. The advantages and disadvantages of different embedding methods are compared, while the main applications of KGE are summarized. Some current challenges of KGE are summarized, as well as some views on the future research directions of KGE.""",",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"A Comprehensive Survey of Graph Neural Networks for Knowledge Graphs,The knowledge graph has become one of the critical tools for knowledge management.,""Zi Ye, Y. J. Kumar, G. O. Sing, Fengyan Song, Junsong Wang"",IEEE Access,,0.927 (4581),10.1109/access.2022.3191784,https://ieeexplore.ieee.org/ielx7/6287639/6514899/09831453.pdf,2022,2,https://doi.org/10.1109/access.2022.3191784,https://semanticscholar.org/paper/60a6b17f28e88f17e58f60923d98674358dbd0e4,""The Knowledge graph, a multi-relational graph that represents rich factual information among entities of diverse classifications, has gradually become one of the critical tools for knowledge management. However, the existing knowledge graph still has some problems which form hot research topics in recent years. Numerous methods have been proposed based on various representation techniques. Graph Neural Network, a framework that uses deep learning to process graph-structured data directly, has significantly advanced the state-of-the-art in the past few years. This study firstly is aimed at providing a broad, complete as well as comprehensive overview of GNN-based technologies for solving four different KG tasks, including link prediction, knowledge graph alignment, knowledge graph reasoning, and node classification. Further, we also investigated the related artificial intelligence applications of knowledge graphs based on advanced GNN methods, such as recommender systems, question answering, and drug-drug interaction. This review will provide new insights for further study of KG and GNN."",,Review",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Building Semantic Knowledge Graphs from (Semi-)Structured Data: A Review,Knowledge graph creation from structured and semi-structured data sources using semantic web technologies is a hot topic in public and private domains.,""Vetle Ryen, A. Soylu, D. Roman"",Future Internet,,0.793 (5815),10.3390/fi14050129,https://www.mdpi.com/1999-5903/14/5/129/pdf?version=1650782411,2022,10,https://doi.org/10.3390/fi14050129,https://semanticscholar.org/paper/39345530afee65b6b945af5f837359b41a6584a9,""Knowledge graphs have, for the past decade, been a hot topic both in public and private domains, typically used for large-scale integration and analysis of data using graph-based data models. One of the central concepts in this area is the Semantic Web, with the vision of providing a well-defined meaning to information and services on the Web through a set of standards. Particularly, linked data and ontologies have been quite essential for data sharing, discovery, integration, and reuse. In this paper, we provide a systematic literature review on knowledge graph creation from structured and semi-structured data sources using Semantic Web technologies. The review takes into account four prominent publication venues, namely, Extended Semantic Web Conference, International Semantic Web Conference, Journal of Web Semantics, and Semantic Web Journal. The review highlights the tools, methods, types of data sources, ontologies, and publication methods, together with the challenges, limitations, and lessons learned in the knowledge graph creation processes."",,Review",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Knowledge Graph Completion by Jointly Learning Structural Features and Soft Logical Rules,A novel knowledge graph embedding model can learn more expressive embedding of entities and relations.,""Weidong Li, Rong Peng, Zhi Li"",IEEE Transactions on Knowledge and Data Engineering,,2.431 (883),10.1109/TKDE.2021.3108224,,2023,3,https://doi.org/10.1109/TKDE.2021.3108224,https://semanticscholar.org/paper/2acfa599b8f6d6a25d650fc3030f87004c9f7d99,""With the rapid development and widespread application of Knowledge graphs (KGs) in many artificial intelligence tasks, a large number of efforts have been made to refine them and increase their quality. Knowedge graph embedding (KGE) has become one of the main refinement tasks, which aims to predict missing facts based on existing ones in KGs. However, there are still mainly two difficult unresolved challenges: (i) how to leverage the local structural features of entities and the potential soft logical rules to learn more expressive embedding of entites and relations; and (ii) how to combine these two learning processes into one unified model. To conquer these problems, we propose a novel KGE model named JSSKGE, which can Jointly learn the local Structural features of entities and Soft logical rules. First, we employ graph attention networks which are specially designed for graph-structured data to aggregate the local structural information of nodes. Then, we utilize soft logical rules implicated in KGs as an expert to further rectify the embeddings of entities and relations. By jointly learning, we can obtain more informative embeddings to predict new facts. With experiments on four commonly used datasets, the JSSKGE obtains better performance than state-of-the-art approaches."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Knowledge Graph Question Answering Leaderboard: A Community Resource to Prevent a Replication Crisis,The lack of existing and curated leaderboards leads to a missing global view over the research field and could inject mistrust into the results.,""A. Perevalov, Xiongliang Yan, Liubov Kovriguina, Longquan Jiang, A. Both, Ricardo Usbeck"",International Conference on Language Resources and Evaluation,,,,,2022,3,,https://semanticscholar.org/paper/405277e9ed66ff916652f253f60fb28cf856b7bb,""Data-driven systems need to be evaluated to establish trust in the scientific approach and its applicability. In particular, this is true for Knowledge Graph (KG) Question Answering (QA), where complex data structures are made accessible via natural-language interfaces. Evaluating the capabilities of these systems has been a driver for the community for more than ten years while establishing different KGQA benchmark datasets. However, comparing different approaches is cumbersome. The lack of existing and curated leaderboards leads to a missing global view over the research field and could inject mistrust into the results. In particular, the latest and most-used datasets in the KGQA community, LC-QuAD and QALD, miss providing central and up-to-date points of trust. In this paper, we survey and analyze a wide range of evaluation results with significant coverage of 100 publications and 98 systems from the last decade. We provide a new central and open leaderboard for any KGQA benchmark dataset as a focal point for the community - https://kgqa.github.io/leaderboard/. Our analysis highlights existing problems during the evaluation of KGQA systems. Thus, we will point to possible improvements for future evaluations."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"A Survey on Visual Transfer Learning using Knowledge Graphs,Knowledge graphs are well suited to store and represent any kind of auxiliary knowledge.,""Sebastian Monka, Lavdim Halilaj, Achim Rettinger"",Semantic Web,,1.242 (2878),10.3233/sw-212959,https://content.iospress.com:443/download/semantic-web/sw212959?id=semantic-web%2Fsw212959,2022,6,https://doi.org/10.3233/sw-212959,https://semanticscholar.org/paper/e0ade6a261e6dd079e509c875901b40b53ec0b5d,""The information perceived via visual observations of real-world phenomena is unstructured and complex. Computer vision (CV) is the field of research that attempts to make use of that information. Recent approaches of CV utilize deep learning (DL) methods as they perform quite well if training and testing domains follow the same underlying data distribution. However, it has been shown that minor variations in the images that occur when these methods are used in the real world can lead to unpredictable and catastrophic errors. Transfer learning is the area of machine learning that tries to prevent these errors. Especially, approaches that augment image data using auxiliary knowledge encoded in language embeddings or knowledge graphs (KGs) have achieved promising results in recent years. This survey focuses on visual transfer learning approaches using KGs, as we believe that KGs are well suited to store and represent any kind of auxiliary knowledge. KGs can represent auxiliary knowledge either in an underlying graph-structured schema or in a vector-based knowledge graph embedding. Intending to enable the reader to solve visual transfer learning problems with the help of specific KG-DL configurations we start with a description of relevant modeling structures of a KG of various expressions, such as directed labeled graphs, hypergraphs, and hyper-relational graphs. We explain the notion of feature extractor, while specifically referring to visual and semantic features. We provide a broad overview of knowledge",gr,aph,e,mb,edd,ing,m,etho,ds,and,d,escr,ibe,seve,ral,j,oint,trainin,g ob,jecti,ves,su,ita,ble,to,co,mb,ine,t,hem,w,ith,high,d,im,ens,ional,v,isual,embe,dd,in,gs.,The,ma,in,s,ect,ion,int,roduces,f,our,di,ffer,ent,categor,ie,s on,h,ow,a,K,G ca,n be,c,ombi,ned,with,a,"DL pipeline: 1) Knowledge Graph as a Reviewer; 2) Knowledge Graph as a Trainee; 3) Knowledge Graph as a Trainer; and 4) Knowledge Graph as a Peer. To help researchers find meaningful evaluation benchmarks, we provide an overview of generic KGs and a set of image processing datasets and benchmarks that include various types of auxiliary knowledge. Last, we summarize related surveys and give an outlook about challenges and open issues for future research."",,Review",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"""Knowledge Graphs: Introduction, History and, Perspectives"",Knowledge graphs are beginning to play a central role in representing information extracted by AI systems.,""V. Chaudhri, C. Baru, Naren Chittar, Xin Dong, M. Genesereth, J. Hendler, Aditya Kalyanpur, D. Lenat, Juan Sequeda, Denny Vrande?i?, Kuansan Wang"",The AI Magazine,,,10.1609/aimag.v43i1.19119,https://ojs.aaai.org/index.php/aimagazine/article/download/19119/18891,2022,7,https://doi.org/10.1609/aimag.v43i1.19119,https://semanticscholar.org/paper/da6245620d3b68bdc2ad902e3d8dc1b5425b226f,""Knowledge graphs (KGs) have emerged as a compelling abstraction for organizing the world's structured knowledge and for integrating information extracted from multiple data sources. They are also beginning to play a central role in representing information extracted by AI systems, and for improving the predictions of AI systems by giving them knowledge expressed in KGs as input. The goals of this article are to (a) introduce KGs and discuss important areas of application that have gained recent prominence; (b) situate KGs in the context of the prior work in AI; and (c) present a few contrasting perspectives that help in better understanding KGs in relation to related technologies."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"BertNet: Harvesting Knowledge Graphs from Pretrained Language Models,""The knowledge harvested with our approach shows competitive quality, diversity, and novelty."",""Shibo Hao, Bowen Tan, Kaiwen Tang, Hengzhe Zhang, E. Xing, Zhiting Hu"",ArXiv,,,10.48550/arXiv.2206.14268,,2022,9,https://doi.org/10.48550/arXiv.2206.14268,https://semanticscholar.org/paper/a11fa157d6d80b57016f548dbdf5ca94a3cd5a36,""Symbolic knowledge graphs (KGs) have been constructed either by expensive human crowdsourcing or with complex text mining pipelines. The emerging large pretrained language models (LMs), such as B ERT , have shown to implicitly encode massive knowledge which can be queried with properly designed prompts. However, compared to the explicit KGs, the implict knowledge in the black-box LMs is often dif?cult to access or edit and lacks explainability. In this work, we aim at harvesting symbolic KGs from the LMs, and propose a new framework for automatic KG construction empowered by the neural LMs’ ?exibility and scalability. Compared to prior works that often rely on large human annotated data or existing massive KGs, our approach requires only the minimal de?nition of relations as inputs, and hence is suitable for extracting knowledge of rich new relations that are instantly assigned and not available before. The framework automatically generates diverse prompts, and performs ef?cient knowledge search within a given LM for consistent outputs. The knowledge harvested with our approach shows competitive quality, diversity, and novelty. As a result, we derive from diverse LMs a family of new KGs (e.g., B ERT N ET and R O BERT A N ET ) that contain a richer set of relations, including some complex ones (e.g., """"A is capable of but not good at B"""" ) that cannot be extracted with previous methods. Besides, the resulting KGs also serve as a vehicle to interpret the respective source LMs, leading to new insights into the varying knowledge capability of different LMs."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Knowledge Graph Exploration Systems: are we lost?,The requirements for effective knowledge graph exploration systems are unmet by existing knowledge graph data management systems.,""Matteo Lissandrini, D. Mottin, K. Hose, T. Pedersen"",Conference on Innovative Data Systems Research,,,,,2022,5,,https://semanticscholar.org/paper/11613de2ea5f94635383e7a4e4742758caf2d243,""Knowledge graphs (KGs) represent facts in the form of nodes and relationships and are widely used to represent and share knowledge in many different domains. However, their widespread adoption to integrate different data sources and their generation processes have made KGs very complicated and difficult to understand, leading to the advent of new knowledge graph exploration approaches to better understand their contents and extract relevant insights. Nevertheless, the needs of current KG exploration use cases are not met (even neglected) by existing KG data management systems. Hence, the question: are we lost? We hope not. Therefore, with the aim of fostering research on these open issues, in this position paper, we first present an overview of state-of-the-art approaches for KG exploration. Then, we identify the (currently unmet) requirements for effective KG exploration systems, and finally, we highlight promising research directions for the realization of a system able to fully support knowledge graph exploration."",,Review",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Construction and Applications of Billion-Scale Pre-trained Multimodal Business Knowledge Graph,OpenBG is an open business knowledge graph of unprecedented scale.,""Shumin Deng, Chengming Wang, Zhoubo Li, Ningyu Zhang, Zelin Dai, Hehong Chen, Feiyu Xiong, Ming Yan, Qiang Chen, Mosha Chen, Jiaoyan Chen, Jeff Z. Pan, Bryan Hooi, Huajun Chen"",ArXiv,,,10.48550/arXiv.2209.15214,,2022,2,https://doi.org/10.48550/arXiv.2209.15214,https://semanticscholar.org/paper/ee8e46eef3af7f1cacc7194f17856b76f88a863e,""Business Knowledge Graphs (KGs) are important to many enterprises today, providing factual knowledge and structured data that steer many products and make them more intelligent. Despite their promising benefits, building business KG necessitates solving prohibitive issues of deficient structure and multiple modalities. In this paper, we advance the understanding of the practical challenges related to building KG in non-trivial real-world systems. We introduce the process of building an open business knowledge graph (OpenBG) derived from a well-known enterprise, Alibaba Group. Specifically, we define a core ontology to cover various abstract products and consumption demands, with fine-grained taxonomy and multimodal facts in deployed applications. OpenBG is an open business KG of unprecedented scale: 2.6 billion triples with more than 88 million entities covering over 1 million core classes/concepts and 2,681 types of relations. We release all the open resources (OpenBG benchmarks) derived from it for the community and report experimental results of KG-centric tasks. We also run up an online competition based on OpenBG benchmarks, and has attracted thousands of teams. We further pre-train OpenBG and apply it to many KG- enhanced downstream tasks in business scenarios, demonstrating the effectiveness of billion-scale multimodal knowledge for e-commerce. All the resources with codes have been released at \url{https://github.com/OpenBGBenchmark/OpenBG}."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"An Overview of Knowledge Graph Reasoning: Key Technologies and Applications,Knowledge graph-oriented knowledge reasoning aims to deduce new knowledge or identify wrong knowledge from existing knowledge.,""Yonghong Chen, Hao Li, Han Li, Wenhao Liu, Yirui Wu, Qian Huang, Shaohua Wan"",J. Sens. Actuator Networks,,,10.3390/jsan11040078,https://www.mdpi.com/2224-2708/11/4/78/pdf?version=1669276833,2022,1,https://doi.org/10.3390/jsan11040078,https://semanticscholar.org/paper/f80ee5510c9b8259250013887e141b0556bb5464,""In recent years, with the rapid development of Internet technology and applications, the scale of Internet data has exploded, which contains a significant amount of valuable knowledge. The best methods for the organization, expression, calculation, and deep analysis of this knowledge have attracted a great deal of attention. The knowledge graph has emerged as a rich and intuitive way to express knowledge. Knowledge reasoning based on knowledge graphs is one of the current research hot spots in knowledge graphs and has played an important role in wireless communication networks, intelligent question answering, and other applications. Knowledge graph-oriented knowledge reasoning aims to deduce new knowledge or identify wrong knowledge from existing knowledge. Different from traditional knowledge reasoning, knowledge reasoning methods oriented to knowledge graphs are more diversified due to the concise, intuitive, flexible, and rich knowledge expression forms in knowledge graphs. Based on the basic concepts of knowledge graphs and knowledge graph reasoning, this paper introduces the latest research progress in knowledge graph-oriented knowledge reasoning methods in recent years. Specifically, according to different reasoning methods, knowledge graph reasoning includes rule-based reasoning, distributed representation-based reasoning, neural network-based reasoning, and mixed reasoning. These methods are summarized in detail, and the future research",di,rec,ti,on,s a,nd,pr,ospe,ct,s of,k,nowl,edg,e rea,son,in,g ba,sed on k,nowl,edge,gra,phs,ar,e d,isc,uss,ed,an,d,pro,sp,ecte,"d."",",",R",ev,iew,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"An Open Challenge for Inductive Link Prediction on Knowledge Graphs,The ILPC 2022 challenge on knowledge graph inductive link prediction is a novel open challenge on knowledge graph inductive link prediction.,""Mikhail Galkin, M. Berrendorf, Charles Tapley Hoyt"",ArXiv,,,10.48550/arXiv.2203.01520,,2022,4,https://doi.org/10.48550/arXiv.2203.01520,https://semanticscholar.org/paper/afbb1e7a2583c2d009845cbc112f4028f7ec92a3,""An emerging trend in representation learning over knowledge graphs (KGs) moves beyond transductive link prediction tasks over a fixed set of known entities in favor of inductive tasks that imply training on one graph and performing inference over a new graph with unseen entities. In inductive setups, node features are often not available and training shallow entity embedding matrices is meaningless as they cannot be used at inference time with unseen entities. Despite the growing interest, there are not enough benchmarks for evaluating inductive representation learning methods. In this work, we introduce ILPC 2022 , a novel open challenge on KG inductive link prediction. To this end, we constructed two new datasets based on Wikidata with various sizes of training and inference graphs that are much larger than existing inductive benchmarks. We also provide two strong baselines leveraging recently proposed inductive methods. We hope this challenge helps to streamline community efforts in the inductive graph representation learning area. ILPC 2022 follows best practices on evaluation fairness and reproducibility, and is available at https://github.com/pykeen/ilpc2022."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"A review of knowledge graph application scenarios in cyber security,Knowledge graphs show great application potential in the cyber security area.,""Kai Liu, Fei Wang, Zhaoyun Ding, Sheng Liang, Zhengfei Yu, Yun Zhou"",ArXiv,,,10.48550/arXiv.2204.04769,,2022,1,https://doi.org/10.48550/arXiv.2204.04769,https://semanticscholar.org/paper/f9a7b62877f25316d64c234e95955c0d7d7b0785,""Facing the dynamic complex cyber environments, internal and external cyber threat intelligence, and the increasing risk of cyber-attack, knowledge graphs show great application potential in the cyber security area because of their capabilities in knowledge aggregation, representation, management, and reasoning. However, while most research has focused on how to develop a complete knowledge graph, it remains unclear how to apply the knowledge graph to solve industrial real challenges in cyber-attack and defense scenarios. In this review, we provide a brief overview of the basic concepts, schema, and construction approaches for the cyber security knowledge graph. To facilitate future research on cyber security knowledge graphs, we also present a curated collection of datasets and open-source libraries on the knowledge construction and information extraction task. In the major part of this article, we conduct a comparative review of the different works that elaborate on the recent progress in the application scenarios of cyber security knowledge graph. Furthermore, a novel comprehensive classification framework is created to describe the connected works from nine primary categories and eighteen subcategories. Finally, we have a thorough outlook on several promising research directions based on the discussion of existing research flaws. attack path analysis, attack attribution, consequence prediction, and attack analysis."",,Review",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Knowledge Graph Completion Based on GCN of Multi-Information Fusion and High-Dimensional Structure Analysis Weight,A knowledge graph completion model encodes and decodes the feature information is proposed.,""Niu Haoran, He Haitao, Feng Jianzhou, Nie Junlan, Zhang Yangsen, Ren Jiadong"",,,,10.1049/CJE.2021.00.080,https://onlinelibrary.wiley.com/doi/pdfdirect/10.1049/cje.2021.00.080,2022,2,https://doi.org/10.1049/CJE.2021.00.080,https://semanticscholar.org/paper/e0ba1a1513a9417e623dcbc51cc749e64bdf977d,""Knowledge graph completion (KGC) can solve the problem of data sparsity in the knowledge graph. A large number of models for the KGC task have been proposed in recent years. However, the underutilisation of the structure information around nodes is one of the main problems of the previous KGC model, which leads to relatively single encoding information. To this end, a new KGC model that encodes and decodes the feature information is proposed. First, we adopt the subgraph sampling method to extract node structure. Moreover, the Graph convolutional network (GCN) introduced the channel attention convolution encode node structure features and represent them in matrix form to fully mine the node feature information. Eventually, the high-dimensional structure analysis weight decodes the encoded matrix embeddings and then constructs the scoring function. The experimental results show that the model performs well on the datasets used."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Declarative Description of Knowledge Graphs Construction Automation: Status & Challenges,Automation of knowledge graph construction is a promising direction.,""David Chaves-Fraga, Anastasia Dimou"",KGCW@ESWC,,,,,2022,3,,https://semanticscholar.org/paper/1df5a9fcdcef9461abfdd5da2521331627edb6eb,""Nowadays, Knowledge Graphs (KG) are among the most powerful mechanisms to represent knowledge and integrate data from multiple domains. However, most of the available data sources are still described in heterogeneous data structures, schemes, and formats. The conversion of these sources into the desirable KG requires manual and time-consuming tasks, such as programming translation scripts, defining declarative mapping rules, etc. In this vision paper, we analyze the trends regarding the automation of KG construction but also the use of mapping languages for the same process, and align the two by analyzing their tasks and a few exemplary tools. Our aim is not to have a complete study but to investigate if there is potential in this direction and, if so, to discuss what challenges we need to address to guarantee the maintainability, explainability, and reproducibility of the KG construction."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"From Discrimination to Generation: Knowledge Graph Completion with Generative Transformer,Knowledge graph completion aims to address the problem of extending a KG with missing triples.,""Xin Xie, Ningyu Zhang, Zhoubo Li, Shumin Deng, Hui Chen, Feiyu Xiong, Mosha Chen, Huajun Chen"",WWW,,,10.1145/3487553.3524238,https://dl.acm.org/doi/pdf/10.1145/3487553.3524238,2022,4,https://doi.org/10.1145/3487553.3524238,https://semanticscholar.org/paper/a146bc7758cf9233971e5d695550a366ad5022ae,""Knowledge graph completion aims to address the problem of extending a KG with missing triples. In this paper, we provide an approach GenKGC, which converts knowledge graph completion to sequence-to-sequence generation task with the pre-trained language model. We further introduce relation-guided demonstration and entity-aware hierarchical decoding for better representation learning and fast inference. Experimental results on three datasets show that our approach can obtain better or comparable performance than baselines and achieve faster inference speed compared with previous methods with pre-trained language models. We also release a new large-scale Chinese knowledge graph dataset OpenBG500 for research purpose1."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Construction and Applications of Billion-Scale Pre-trained Multimodal Business Knowledge Graph,OpenBG is an open business knowledge graph of unprecedented scale.,""Shumin Deng, Chengming Wang, Zhoubo Li, Ningyu Zhang, Zelin Dai, Hehong Chen, Feiyu Xiong, Ming Yan, Qiang Chen, Mosha Chen, Jiaoyan Chen, Jeff Z. Pan, Bryan Hooi, Huajun Chen"",ArXiv,,,10.48550/arXiv.2209.15214,,2022,2,https://doi.org/10.48550/arXiv.2209.15214,https://semanticscholar.org/paper/7d297aa18cab515c8b4d028e9cb20b097921032c,""—Business Knowledge Graphs (KGs) are important to many enterprises today, providing factual knowledge and structured data that steer many products and make them more intelligent. Despite their promising bene?ts, building business KG necessitates solving prohibitive issues of de?cient structure and multiple modalities. In this paper, we advance the understanding of the practical challenges related to building KG in non-trivial real-world systems. We introduce the process of building an open business knowledge graph (OpenBG) derived from a well-known enterprise, Alibaba Group. Speci?cally, we de?ne a core ontology to cover various abstract products and consumption demands, with ?ne-grained taxonomy and multimodal facts in deployed applications. OpenBG is an open business KG of unprecedented scale: 2.6 billion triples with more than 88 million entities covering over 1 million core classes/concepts and 2,681 types of re- lations. We release all the open resources (OpenBG benchmarks) derived from it for the community and report experimental results of KG-centric tasks. We also run up an online competition based on OpenBG benchmarks, and has attracted thousands of teams. We further pre-train OpenBG and apply it to many KG-enhanced downstream tasks in business scenarios, demonstrating the effectiveness of billion-scale multimodal knowledge for ecommerce. All the resources with codes have been released at https://github.com/OpenBGBenchmark/OpenBG."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Augmenting Knowledge Graphs for Better Link Prediction,A knowledge graph augmentation method incorporates literals in an embedding model without modifying its loss function.,""Jiang Wang, Filip Ilievski, Pedro A. Szekely, Ke-Thia Yao"",International Joint Conference on Artificial Intelligence,,,10.48550/arXiv.2203.13965,,2022,2,https://doi.org/10.48550/arXiv.2203.13965,https://semanticscholar.org/paper/387a916fa4927a5998cbef2e0b7e1f5e6a2e9c3e,""Embedding methods have demonstrated robust performance on the task of link prediction in knowledge graphs, by mostly encoding entity relationships. Recent methods propose to enhance the loss function with a literal-aware term. In this paper, we propose KGA: a knowledge graph augmentation method that incorporates literals in an embedding model without modifying its loss function. KGA discretizes quantity and year values into bins, and chains these bins both horizontally, modeling neighboring values, and vertically, modeling multiple levels of granularity. KGA is scalable and can be used as a pre-processing step for any existing knowledge graph embedding model. Experiments on legacy benchmarks and a new large benchmark, DWD, show that augmenting the knowledge graph with quantities and years is beneficial for predicting both entities and numbers, as KGA outperforms the vanilla models and other relevant baselines. Our ablation studies confirm that both quantities and years contribute to KGA's performance, and that its performance depends on the discretization and binning settings. We make the code, models, and the DWD benchmark publicly available to facilitate reproducibility and future research."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"A Knowledge Graph Completion Method Based on Fusing Association Information,The AiTransE model for knowledge graph completion uses the frequency of each relationship in the multiple-step relation paths between head and tail entities to calculate the degree of association with the direct relations.,""Yuhao Wang, Erping Zhao, Wei Wang"",IEEE Access,,0.927 (4581),10.1109/ACCESS.2022.3174110,https://ieeexplore.ieee.org/ielx7/6287639/6514899/09771411.pdf,2022,,https://doi.org/10.1109/ACCESS.2022.3174110,https://semanticscholar.org/paper/57204fdc651c8d3d36c27fe90e80afd002ba5cd2,""Knowledge graph is a carrier of knowledge. The knowledge graph completion task is to predict the links between entities to make the knowledge graph more complete. Currently, some completion method based on knowledge representation learning do not fully consider the association information between each relationship in the multiple-step relation paths and the direct relations, and the association information between the head and tail entity types and direct relations. In this study, we extract and utilize these associated information, and propos AiTransE model for knowledge graph completion, which uses the frequency of each relationship in the multiple-step relation paths between head and tail entities to calculate the degree of association with the direct relations, and uses head and tail entity types and direct relation types for matching to obtain the degree of association between them. Finally, the two association degrees are linearly weighted and merged and then introduced into the objective function, so that the model can give different degrees of attention to different triples, and improve model knowledge representation learning performance. Th",e experiment with link prediction was carried,out,on,the,Tibet,A,nimal,Husbandry,Dat,ase,t and,t,he,WN18,dat,aset,", a",nd,com,pa,red w,ith,the,Tran,"sE,",TransH,", Tr","ansR,",an,d ot,her,mod,els.,The,"experimental results show that this model has a significant improvement over other models in the indicators Hits@10 and Mean Rank."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Knowledge Graph Completion based on Hyperbolic Graph Contrastive Attention Network,The proposed method can improve the performance of link prediction for knowledge graphs completion significantly.,""Xirui Xiong, Bingqing Shen, Hongming Cai, Lihong Jiang, Pan Hu, Yuxiao Wang"",IEEE International Conference on e-Business Engineering,,,10.1109/ICEBE55470.2022.00015,,2022,,https://doi.org/10.1109/ICEBE55470.2022.00015,https://semanticscholar.org/paper/595e4ae2bada7b1b183771a575fdd5365af8c5d9,""Knowledge graph completion technology is important for the integrity of knowledge graph. However, the feature mining of knowledge graph is not sufficient due to the lack of hierarchical and neighborhood information. To solve such issues, this paper proposes a knowledge graph completion method based on the Hyperbolic Graph Contrastive ATtention network(HyGCAT). HyGCAT embedded the knowledge graph into the hyperbolic space with constant negative curvature to capture the complex hierarchical relations between entities with less memory. Meanwhile, HyGCAT uses the attention mechanism to learn the latent representations of neighborhood entities. Furthermore, HyGCAT strengthens the correlation between representations of entities and neighbor subgraphs through contrastive learning. The proposed method can improve the performance of link prediction for knowledge graphs completion significantly."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Knowledge Graph Completion Based on Graph Attention Networks and Text Information,The model combined with multi-source information has better representation ability for entities.,""Shen Hong, Heng Qian, Yongchao Gao, Hongli Lyu"",2022 IEEE 5th International Conference on Computer and Communication Engineering Technology (CCET),,,10.1109/CCET55412.2022.9906358,,2022,,https://doi.org/10.1109/CCET55412.2022.9906358,https://semanticscholar.org/paper/da6364941b799376c9c4ea1e6c4b2e6f6174500a,""In knowledge graphs (KGs), there exist some unsolved problems such as incomplete data, hidden information with incomplete mining and so on. In the most completion models, the information of the triples in the KG is generally utilized, but the neighborhood information and rich entity description information are not included in the triples. In this paper, the knowledge graph completion (KGC) method is improved based on graph attention networks (GATs) with text information by using the neighborhood information of aggregated triples and entity description information. And the embedding capability of semantic information is enhanced in KGs. First, the feature vector of entity description information is extracted by the Bi-LSTM model and concatenated with the entity embedding in the triples. Then the joint vectors are trained by GATs to aggregate the neighborhood information. Next, the KGC task is realized by a decoder. Finally, the effectiveness of the proposed method is verified by the link prediction experiments in the public datasets FB15K-237 and WNISRR and comparison is investigated with several other existing methods. The test results show that most of the indicators in the two datasets are improved. Furthermore, it is proved that the",model combined with multi-source information,has,be,tter,repre,se,ntati,on ability,for,en,titie,"s,",w,hich c,an,furt,her,i,mpro,ve,the,acc,urac,y and,com,prehen,sive,perf,orm,ance,of,KGC,tas,"ks.""",",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Temporal Knowledge Graph Completion: A Survey,Knowledge graph completion can predict missing links and is crucial for real-world knowledge graphs which widely suffer from incompleteness.,""Borui Cai, Yong Xiang, Longxiang Gao, Heng Zhang, Yunfeng Li, Jianxin Li"",ArXiv,,,,,2022,8,,https://semanticscholar.org/paper/ec61bc70c26436eeac63637b75ce4ab0127561aa,""Knowledge graph completion (KGC) can predict missing links and is crucial for real-world knowledge graphs, which widely suffer from incompleteness. KGC methods assume a knowledge graph is static, but that may lead to inaccurate prediction results because many facts in the knowledge graphs change over time. Recently, emerging methods have shown improved predictive results by further incorporating the timestamps of facts; namely, temporal knowledge graph completion (TKGC). With this temporal information, TKGC methods can learn the dynamic evolution of the knowledge graph that KGC methods fail to capture. In this paper, for the first time, we summarize the recent advances in TKGC research. First, we detail the background of TKGC, including the problem definition, benchmark datasets, and evaluation metrics. Then, we summarize existing TKGC methods based on how timestamps of facts are used to capture the temporal dynamics. Finally, we conclude the paper and present future research directions of TKGC."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"CAKE: A Scalable Commonsense-Aware Framework For Multi-View Knowledge Graph Completion,The proposed commonsense-aware negative sampling module is superior to other NS techniques.,""Guanglin Niu, Bo Li, Yongfei Zhang, Shi Pu"",Annual Meeting of the Association for Computational Linguistics,,,10.18653/v1/2022.acl-long.205,https://aclanthology.org/2022.acl-long.205.pdf,2022,8,https://doi.org/10.18653/v1/2022.acl-long.205,https://semanticscholar.org/paper/009263dec4026507d5809b14881f833c80b74cbc,""Knowledge graphs store a large number of factual triples while they are still incomplete, inevitably. The previous knowledge graph completion (KGC) models predict missing links between entities merely relying on fact-view data, ignoring the valuable commonsense knowledge. The previous knowledge graph embedding (KGE) techniques suffer from invalid negative sampling and the uncertainty of fact-view link prediction, limiting KGC’s performance. To address the above challenges, we propose a novel and scalable Commonsense-Aware Knowledge Embedding (CAKE) framework to automatically extract commonsense from factual triples with entity concepts. The generated commonsense augments effective self-supervision to facilitate both high-quality negative sampling (NS) and joint commonsense and fact-view link prediction. Experimental results on the KGC task demonstrate that assembling our framework could enhance the performance of the original KGE models, and the proposed commonsense-aware NS module is superior to other NS techniques. Besides, our proposed framework could be easily adaptive to various KGE models and explain the predicted results."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"A Dynamic Convolutional Network-Based Model for Knowledge Graph Completion,A new test method for knowledge graph completion is better than several benchmark algorithms for knowledge graph completion.,""Haoliang Peng, Yue Wu"",Inf.,,,10.3390/info13030133,https://www.mdpi.com/2078-2489/13/3/133/pdf?version=1646620346,2022,,https://doi.org/10.3390/info13030133,https://semanticscholar.org/paper/dd5523a1724d7aaf3a4e54545a15e80666b67e62,""Knowledge graph embedding can learn low-rank vector representations for knowledge graph entities and relations, and has been a main research topic for knowledge graph completion. Several recent works suggest that convolutional neural network (CNN)-based models can capture interactions between head and relation embeddings, and hence perform well on knowledge graph completion. However, previous convolutional network models have ignored the different contributions of different interaction features to the experimental results. In this paper, we propose a novel embedding model named DyConvNE for knowledge base completion. Our model DyConvNE uses a dynamic convolution kernel because the dynamic convolutional kernel can assign weights of varying importance to interaction features. We also propose a new method of negative sampling, which mines hard negative samples as additional negative samples for training. We have performed experiments on the data sets WN18RR and FB15k-237, and the results show that our method is better than several other benchmark algorithms for knowledge graph completion. In addition, we used a new test method when predicting the Hits@1 values of WN18RR and FB15k-237, named specific-relationship testing. This method gives about a 2% relative improvement over models that do not","use this method in terms of Hits@1."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Global Relation Auxiliary Graph Attention Network for Knowledge Graph Completion,A global relationship-assisted graph attention network performs well on knowledge graph completion tasks.,""Ruotian Hou, Wenjun Zhu, Cui Zhu"",2022 5th International Conference on Artificial Intelligence and Big Data (ICAIBD),,,10.1109/icaibd55127.2022.9820227,,2022,1,https://doi.org/10.1109/icaibd55127.2022.9820227,https://semanticscholar.org/paper/2f9a3eddec028a671406848e899e3a0405cfdb60,""Knowledge Graph Completion (KGC) has been an active research topic in recent years, which is the task of predicting missing links based on known triples of knowledge graphs. Some recent work has shown that graph neural networks (GNNs) using graph structure can perform well on KGC. These models learn information from entities and relations within the subject’s neighborhood and update the representation through a message passing mechanism. However, existing GNN models rarely include the modeling of relational information, and they tend to represent and learn nodes through complex networks, ignoring the underlying semantic information between relations. In this work, we propose a global relationship-assisted graph attention network. It not only models entities but also builds directed graph structures and updates the representation of relations between different relations. Specifically, the strongly correlated neighboring relations are identified for aggregation by an attention function based on the information and spatial domains. We also use a learnable nonlinear function to activate the attention values, allowing the model to adaptively aggregate information. Experiments show that GRA-GAT has a very advanced performance on link prediction tasks."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Knowledge Graph Completion with Pre-trained Multimodal Transformer and Twins Negative Sampling,Knowledge graph completion is of great importance to predict the missing triples in the existing knowledge graphs.,""Yichi Zhang, Wen Zhang"",ArXiv,,,10.48550/arXiv.2209.07084,,2022,,https://doi.org/10.48550/arXiv.2209.07084,https://semanticscholar.org/paper/0bc258895dcd06c224d770139e872249c25374fd,""Knowledge graphs (KGs) that modeling the world knowledge as structural triples are inevitably incomplete. Such problems still exist for multimodal knowledge graphs (MMKGs). Thus, knowledge graph completion (KGC) is of great importance to predict the missing triples in the existing KGs. As for the existing KGC methods, embedding-based methods rely on manual design to leverage multimodal information while finetune-based approaches are not superior to embedding-based methods in link prediction. To address these problems, we propose a V isual B ERT-enhanced K nowledge G raph C ompletion model (VBKGC for short). VBKGC could capture deeply fused multimodal information for entities and integrate them into the KGC model. Besides, we achieve the co-design of the KGC model and negative sampling by designing a new negative sampling strategy called twins negative sampling. Twins negative sampling is suitable for multimodal scenarios and could align different embeddings for entities. We conduct extensive experiments to show the outstanding performance of VBKGC on the link prediction task and make further exploration of VBKGC."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Explaining Link Prediction Systems based on Knowledge Graph Embeddings,Link prediction models can outperform traditional approaches and can be employed in multiple downstream tasks.,""Andrea Rossi, D. Firmani, P. Merialdo, Tommaso Teofili"",SIGMOD Conference,,,10.1145/3514221.3517887,https://iris.uniroma3.it/bitstream/11590/410639/3/2022-sigmod.pdf,2022,5,https://doi.org/10.1145/3514221.3517887,https://semanticscholar.org/paper/2ae37d50e80ec53320b71768a3c85750827799fd,""Link Prediction (LP) aims at tackling Knowledge Graph incompleteness by inferring new, missing facts from the already known ones. The rise of novel Machine Learning techniques has led researchers to develop LP models that represent Knowledge Graph elements as vectors in an embedding space. These models can outperform traditional approaches and they can be employed in multiple downstream tasks; nonetheless, they tend to be opaque, and are mostly regarded as black boxes. Their lack of interpretability limits our understanding of their inner mechanisms, and undermines the trust that users can place in them. In this paper, we propose the novel Kelpie explainability framework. Kelpie can be applied to any embedding-based LP models independently from their architecture, and it explains predictions by identifying the combinations of training facts that have enabled them. Kelpie can extract two complementary types of explanations, that we dub necessary and sufficient. We describe in detail both the structure and the implementation details of Kelpie, and thoroughly analyze its performance through extensive experiments. Our results show that Kelpie significantly outperforms baselines across almost all scenarios."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Knowledge Graph Embedding for Link Prediction Models,""Link prediction is a popular research area for disciplines like biological science, security, and the medical field."",""Ehtisham Ur Rehman, Aamir Saeed, N. Minallah, A. Hafeez"",,,,10.20944/preprints202202.0212.v1,https://www.preprints.org/manuscript/202202.0212/v1/download,2022,1,https://doi.org/10.20944/preprints202202.0212.v1,https://semanticscholar.org/paper/589ed6c533507591064ed003ebacf16f7a64cd5b,""For disciplines like biological science, security, and the medical field, link prediction is a popular research area. To demonstrate the link prediction many methods have been proposed. Some of them that have been demonstrated through this review paper are TransE, Complex, DistMult, and DensE models. Each model defines link prediction with different perceptions. We argue that the practical performance potential of these methods, having similar parameter values, using the fine-tuning technique to evaluate their reliability and reproducibility of results. We describe those methods and experiments; provide theoretical proofs and experimental examples, demonstrating how current link prediction methods work in such settings. We use the standard evaluation metrics for testing the model's ability."",,Review",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Tucker decomposition-based Temporal Knowledge Graph Completion,A tensor decomposition model for temporal knowledge graphs completion is an increasingly important task.,""Pengpeng  Shao, Guohua  Yang, Dawei  Zhang, Jianhua  Tao, Feihu  Che, Tong  Liu"",Knowl. Based Syst.,,,10.1016/j.knosys.2021.107841,http://arxiv.org/pdf/2011.07751,2022,2,https://doi.org/10.1016/j.knosys.2021.107841,https://semanticscholar.org/paper/b6374540edc2510db74346f28b34f81d472fd98c,""Knowledge graphs have been demonstrated to be an effective tool for numerous intelligent applications. However, a large amount of valuable knowledge still exists implicitly in the knowledge graphs. To enrich the existing knowledge graphs, recent years witness that many algorithms for link prediction and knowledge graphs embedding have been designed to infer new facts. But most of these studies focus on the static knowledge graphs and ignore the temporal information that reflects the validity of knowledge. Developing the model for temporal knowledge graphs completion is an increasingly important task. In this paper, we build a new tensor decomposition model for temporal knowledge graphs completion inspired by the Tucker decomposition of order 4 tensor. We demonstrate that the proposed model is fully expressive and report state-of-the-art results for several public benchmarks. Additionally, we present several regularization schemes to improve the strategy and study their impact on the proposed model. Experimental studies on three temporal datasets (i.e. ICEWS2014, ICEWS2005-15, GDELT) justify our design and demonstrate that our model outperforms baselines with an explicit margin on link prediction task."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"ComDensE : Combined Dense Embedding of Relation-aware and Common Features for Knowledge Graph Completion,The combined dense architecture as implemented in ComDensE achieves the best performance.,""Min-Sung Kim, Seungjun Baek"",International Conference on Pattern Recognition,,,10.1109/ICPR56361.2022.9956509,http://arxiv.org/pdf/2206.14925,2022,,https://doi.org/10.1109/ICPR56361.2022.9956509,https://semanticscholar.org/paper/402bed9904d8e033cc3f4fa38ed66e4a3db251ec,""Real-world knowledge graphs (KG) are mostly incomplete. The problem of recovering missing relations, called KG completion, has recently become an active research area. Knowledge graph (KG) embedding, a low-dimensional representation of entities and relations, is the crucial technique for KG completion. Convolutional neural networks in models such as ConvE, SACN, InteractE, and RGCN achieve recent successes. This paper takes a different architectural view and proposes ComDensE which combines relation-aware and common features using dense neural networks. In the relation-aware feature extraction, we attempt to create relational inductive bias by applying an encoding function specific to each relation. In the common feature extraction, we apply the common encoding function to all input embeddings. These encoding functions are implemented using dense layers in ComDensE. ComDensE achieves the state-of-the-art performance in the link prediction in terms of MRR, HIT@1 on FB15k-237 and HIT@1 on WN18RR compared to the previous baseline approaches. We conduct an extensive ablation study to examine the effects of the relation-aware layer and the common layer of the ComDensE. Experimental results illustrate that the combined dense architecture as implemented in ComDensE","achieves the best performance."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"HRER: A New Bottom-Up Rule Learning for Knowledge Graph Completion,HRER achieves the state-of-the-art across the standard link prediction datasets.,""Zongwei Liang, Jun-an Yang, Hui Liu, Keju Huang, Lin Cui, Ling-Zhi Qu, Xiang Li"",Electronics,,0.159 (20634),10.3390/electronics11060908,https://www.mdpi.com/2079-9292/11/6/908/pdf?version=1647339795,2022,1,https://doi.org/10.3390/electronics11060908,https://semanticscholar.org/paper/fcecda032b8692766cc5f083b3da5780b0e8c673,""Knowledge graphs (KGs) are collections of structured facts, which have recently attracted growing attention. Although there are billions of triples in KGs, they are still incomplete. These incomplete knowledge bases will bring limitations to practical applications. Predicting new facts from the given knowledge graphs is an increasingly important area. We investigate the models based on logic rules in this paper. This paper proposes HRER, a new bottom-up rule learning for knowledge graph completion. First of all, inspired by the observation that the known information of KGs is incomplete and unbalanced, HRER modifies the indicators for screening based on the existing relation rule mining methods. The new metric HRR is more effective than traditional confidences in filtering Horn rules. Besides, motivated by the differences between the embedding-based methods and the methods based on logic rules, HRER proposes entity rules. The entity rules make up for the limited expression of Horn rules to some extent. HRER needs a few parameters to control the number of rules and can provide the explanation for prediction. Experiments show that HRER achieves the state-of-the-art across the standard link prediction datasets."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Knowledge Graph Completion by Jointly Learning Structural Features and Soft Logical Rules,A novel knowledge graph embedding model can learn more expressive embedding of entities and relations.,""Weidong Li, Rong Peng, Zhi Li"",IEEE Transactions on Knowledge and Data Engineering,,2.431 (883),10.1109/TKDE.2021.3108224,,2023,3,https://doi.org/10.1109/TKDE.2021.3108224,https://semanticscholar.org/paper/2acfa599b8f6d6a25d650fc3030f87004c9f7d99,""With the rapid development and widespread application of Knowledge graphs (KGs) in many artificial intelligence tasks, a large number of efforts have been made to refine them and increase their quality. Knowedge graph embedding (KGE) has become one of the main refinement tasks, which aims to predict missing facts based on existing ones in KGs. However, there are still mainly two difficult unresolved challenges: (i) how to leverage the local structural features of entities and the potential soft logical rules to learn more expressive embedding of entites and relations; and (ii) how to combine these two learning processes into one unified model. To conquer these problems, we propose a novel KGE model named JSSKGE, which can Jointly learn the local Structural features of entities and Soft logical rules. First, we employ graph attention networks which are specially designed for graph-structured data to aggregate the local structural information of nodes. Then, we utilize soft logical rules implicated in KGs as an expert to further rectify the embeddings of entities and relations. By jointly learning, we can obtain more informative embeddings to predict new facts. With experiments on four commonly used datasets, the JSSKGE obtains better performance than state-of-the-art approaches."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Convolutional 3D Embedding for Knowledge Graph Completion,A neural network model for link prediction that uses 3D convolution is proposed.,""Wen-Hao Feng, Daren Zha, Lei Wang, Xiaobo Guo"",International Conference on Computer Supported Cooperative Work in Design,,,10.1109/CSCWD54268.2022.9776151,,2022,,https://doi.org/10.1109/CSCWD54268.2022.9776151,https://semanticscholar.org/paper/f3ccd30c83a5358d33be22eb1e5bc6f168c70667,""Link prediction is to predict missing relations between entities for Knowledge Graph Completion (KGC). Convolution neural network has been used in much previous work on link prediction to capture fundamental data pattern of knowledge graph. However, because these models use low-dimensional convolution operation, which limits their performance, they learn fewer expressive features. Further more, they do not have the the capability of keeping the translation property of knowledge triplet, which is an important property for knowledge reasoning. Focusing on these problems, we propose Conv3D (3D Convolution Embedding), a neural network model for link prediction that uses 3D convolution. To capture deeper feature interactions in the knowledge graph, we employ 3D convolution instead of shallow 1D or 2D convolution for generating triplet scores. We conduct link prediction experiments on four general datasets (WN18, WN18RR, FB15k, FB15k-237) and get state-of-the-art (SOTA) results on WN18 and WN18RR. We also explore the influence of convolution parameters (reshaping dimension, number of filters, kernel size) on FB15k-237 and obtain quantitative analytical findings."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Comprehensive Analysis of Knowledge Graph Embedding Techniques Benchmarked on Link Prediction,The new generation of translational models emerges as the most promising encoders for knowledge graph completion.,""Ilaria Ferrari, Giacomo Frisoni, Paolo Italiani, G. Moro, C. Sartori"",Electronics,,0.159 (20634),10.3390/electronics11233866,https://www.mdpi.com/2079-9292/11/23/3866/pdf?version=1669367554,2022,1,https://doi.org/10.3390/electronics11233866,https://semanticscholar.org/paper/b5167990eda7d48f1a70a1fcb900ed5d46c40985,""In knowledge graph representation learning, link prediction is among the most popular and influential tasks. Its surge in popularity has resulted in a panoply of orthogonal embedding-based methods projecting entities and relations into low-dimensional continuous vectors. To further enrich the research space, the community witnessed a prolific development of evaluation benchmarks with a variety of structures and domains. Therefore, researchers and practitioners face an unprecedented challenge in effectively identifying the best solution to their needs. To this end, we propose the most comprehensive and up-to-date study to systematically assess the effectiveness and efficiency of embedding models for knowledge graph completion. We compare 13 models on six datasets with different sizes, domains, and relational properties, covering translational, semantic matching, and neural network-based encoders. A fine-grained evaluation is conducted to compare each technique head-to-head in terms of standard metrics, training and evaluation times, memory consumption, carbon footprint, and space geometry. Our results demonstrate the high dependence between performance and graph types, identifying the best options for",each scenario. Among all the encoding strate,gies,", t",he n,ew gen,er,ation,of transl,atio,nal,mode,ls,e,merges,as,the,mo,st,pro,mi,"sing,",br,ingi,ng ou,t th,e best,and,most,co,nsis,ten,t re,sult,s ac,"ross all the datasets and evaluation criteria."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Knowledge Graph Completion based on Multi-task Learning and Extractive Text Summarization,The proposed method can improve the MeanRank index by 31 and 2.,""Hao Tian, Xiaoxiong Zhang, Liu Liu, Shanshan Liu, Kun Ding"",""International Conference on Control, Robotics and Intelligent System"",,,10.1145/3562007.3562036,,2022,,https://doi.org/10.1145/3562007.3562036,https://semanticscholar.org/paper/8ab1ddeaf4034940a296d5b0c2ee0f3b49ffa93c,""Knowledge completion graph is an important technology to supplement knowledge graph and improve data quality. However, existing knowledge graph completion methods ignored the characteristics of triple's relation and introduced redundant entity description information. In order to improve the above problems, this paper proposed an ALBERT-KGC model. The key contexts were extracted from redundant entity descriptions by the extraction summarization technology. Then ALBERT was used as an encoder to reduce the number of model parameters, and the multi-task learning method was applied to fine-tune the model, effectively integrating entity and relation features. The results of linking prediction experiments on data sets WN18RR and FB15k-237 showed that the proposed method can improve the MeanRank (MR) index by 31 and 2, and the top 10 hit ratio (Hit@10) index by 1.2% and 5.8% compared with the traditional methods, verifying the validity of the model."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"ProtoE: Enhancing Knowledge Graph Completion Models with Unsupervised Type Representation Learning,Unsupervised type representation learning methods can capture multiple type constraints in relations.,""Yuxun Lu, R. Ichise"",Inf.,,,10.3390/info13080354,https://www.mdpi.com/2078-2489/13/8/354/pdf?version=1660265554,2022,,https://doi.org/10.3390/info13080354,https://semanticscholar.org/paper/a6aaf11d05ea0733a90cde80ec8c905158462453,""Knowledge graph completion (KGC) models are a feasible approach for manipulating facts in knowledge graphs. However, the lack of entity types in current KGC models results in inaccurate link prediction results. Most existing type-aware KGC models require entity type annotations, which are not always available and expensive to obtain. We propose ProtoE, an unsupervised method for learning implicit type and type constraint representations. ProtoE enhances type-agnostic KGC models by relation-specific prototype embeddings. Our method does not rely on entity type annotations to capture the type and type constraints of entities. Unlike existing unsupervised type representation learning methods, which have only a single representation for entity-type and relation-type constraints, our method can capture multiple type constraints in relations. Experimental results show that our method can improve the performance of both bilinear and translational KGC models in the link prediction task."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"A knowledge graph completion model integrating entity description and network structure,The integration of entity description and network structure can significantly increase the effect of the knowledge graph completion task.,""Chuanming Yu, Zhen Zhang"",Aslib Journal of Information Management,,0.535 (9348),10.1108/ajim-01-2022-0031,,2022,,https://doi.org/10.1108/ajim-01-2022-0031,https://semanticscholar.org/paper/52cd4731e907204ee028cbd9ccd7ecd332b249d9,""PurposeIn recent years, knowledge graph completion has gained increasing research focus and shown significant improvements. However, most existing models only use the structures of knowledge graph triples when obtaining the entity and relationship representations. In contrast, the integration of the entity description and the knowledge graph network structure has been ignored. This paper aims to investigate how to leverage both the entity description and the network structure to enhance the knowledge graph completion with a high generalization ability among different datasets.Design/methodology/approachThe authors propose an entity-description augmented knowledge graph completion model (EDA-KGC), which incorporates the entity description and network structure. It consists of three modules, i.e. representation initialization, deep interaction and reasoning. The representation initialization module utilizes entity descriptions to obtain the pre-trained representation of entities. The deep interaction module acquires the features of the deep interaction between entities and relationships. The reasoning component performs matrix manipulations with the deep interaction feature vector and entity representation matrix, thus obtaining the probability distribution of target e",ntities. The authors conduct intensive experi,ment,s o,n th,e FB15,"K,",WN18,", FB15K-23",7 an,d W,N18RR,d,at,a sets,to,val,ida,te,the,e,ffect,of,the,prop,osed,model,.Fin,dings,The,exp,eri,ment,s de,mons,"trate that the proposed model outperforms the traditional structure-based knowledge graph completion model and the entity-description-enhanced knowledge graph completion model. The experiments also suggest that the model has greater feasibility in different scenarios such as sparse data, dynamic entities and limited training epochs. The study shows that the integration of entity description and network structure can significantly increase the effect of the knowledge graph completion task.Originality/valueThe research has a significant reference for completing the missing information in the knowledge graph and improving the application effect of the knowledge graph in information retrieval, question answering and other fields."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"A Pre-training Framework for Knowledge Graph Completion,Knowledge graph completion methods trend to be trained based on independent triples.,""Kuan Xu, Kuo Yang, Hanyang Dong, Xinyan Wang, Xuezhong Zhou"",ArXiv,,,10.48550/arXiv.2302.02614,,2023,,https://doi.org/10.48550/arXiv.2302.02614,https://semanticscholar.org/paper/eb3c745ce61226bdba8a7a60cc7b6326c43ebac4,""Knowledge graph completion (KGC) is one of the effective methods to identify new facts in knowledge graph. Except for a few methods based on graph network, most of KGC methods trend to be trained based on independent triples, while are difficult to take a full account of the information of global network connection contained in knowledge network. To address these issues, in this study, we propose a simple and effective Network-based Pre-training framework for knowledge graph completion (termed NetPeace), which takes into account the information of global network connection and local triple relationships in knowledge graph. Experiments show that in NetPeace framework, multiple KGC models yields consistent and significant improvements on benchmarks (e.g., 36.45% Hits@1 and 27.40% MRR improvements for TuckER on FB15k-237), especially dense knowledge graph. On the challenging low-resource task, NetPeace that benefits from the global features of KG achieves higher performance (104.03% MRR and 143.89% Hit@1 improvements at most) than original models."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"GreenKGC: A Lightweight Knowledge Graph Completion Method,A lightweight modularized knowledge graph completion solution is proposed to address this issue.,""Yun Cheng Wang, Xiou Ge, Bin Wang, C.-C. Jay Kuo"",ArXiv,,,10.48550/arXiv.2208.09137,,2022,1,https://doi.org/10.48550/arXiv.2208.09137,https://semanticscholar.org/paper/eb49e1012423a4c571286d1e3128bc0e2d02a75a,""Knowledge graph completion (KGC) aims to discover missing relationships between entities in knowledge graphs (KGs). Most prior KGC work focuses on learning representations for entities and relations. Yet, a higher-dimensional embedding space is usually required for a better reasoning capability, which leads to a larger model size and hinders applicability to real-world problems (e.g., large-scale KGs or mobile/edge computing). A lightweight modularized KGC solution, called GreenKGC, is proposed in this work to address this issue. GreenKGC consists of three modules: 1) representation learning, 2) feature pruning, and 3) decision learning. In Module 1, we leverage existing KG embedding models to learn high-dimensional representations for entities and relations. In Module 2, the KG is partitioned into several relation groups followed by a feature pruning process to find the most discriminant features for each relation group. Finally, a classifier is assigned to each relation group to cope with low-dimensional triple features for KGC tasks in Module 3. We evaluate the performance of GreenKGC on four widely used link prediction datasets and observe that GreenKGC can achieve comparable or even better performance against original high-dimensional embeddings with a much smaller model size. Furthermore, we experiment on two triple classification datasets to demonstr",ate that the same methodology can generalize,to m,ore,tas,"ks."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"NNKGC: Improving Knowledge Graph Completion with Node Neighborhoods,Current text-based models infer the tail entity given the head entity and a certain relation.,""Zihui Li, Boming Yang, T. Suzumura"",,,,,,2023,,,https://semanticscholar.org/paper/1f1d4da3a13269ef970f2cdb19763a0d634aaf97,""Knowledge graph completion (KGC) aims to discover missing relations of query entities. Current text-based models utilize the entity name and description to infer the tail entity given the head entity and a certain relation. Existing approaches also consider the neighborhood of the head entity. However, these methods tend to model the neighborhood using a flat structure and are only restricted to 1-hop neighbors. In this work, we propose a node neighborhood-enhanced framework for knowledge graph completion. It models the head entity neighborhood from multiple hops using graph neural networks to enrich the head node information. Moreover, we introduce an additional edge link prediction task to improve KGC. Evaluation on two public datasets shows that this framework is simple yet effective. The case study also shows that the model is able to predict explainable predictions."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Learning Framework of Entity and Entity Type Composition Representation for Knowledge Graph Completion,A proposed Knowledge Graph Embedding framework finds appropriate representations of entities and relations by learning structured information in triples and uses these representations to predict the missing links in a knowledge graph.,""Runyu Ni, H. Shibata, Y. Takama"",2022 IEEE International Conference on Big Data (Big Data),,,10.1109/BigData55660.2022.10020261,,2022,,https://doi.org/10.1109/BigData55660.2022.10020261,https://semanticscholar.org/paper/4ac1c46d07c67ce01b304d6a4fde578205f8f498,""This paper proposes a simple Knowledge Graph Embedding (KGE) framework that considers the entity types. The KGE finds appropriate representations of entities and relations by learning structured information in triples and uses these representations to predict the missing links in a knowledge graph (KG). The entity types are included in many KGs, but most of the existing methods ignored its potential for the link prediction task. The proposed framework, which is called EETCRL (Entity and Entity Type Composition Representation Learning), learns representations for entities and entity types in a simple way. Those combined representations are used for link prediction. The proposed framework is evaluated on three datasets and the results show that while the overall performance was comparable to baseline methods, its performance depends on the entity type. This paper also discusses how the information about entity types affects the link prediction through analysis of the fine-grained results."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Sequence Encoder-based Spatiotemporal Knowledge Graph Completion,Knowledge graph completion aims to infer new facts from incomplete knowledge graphs.,""Wei Jia, Xuan Wang, Jing Shan, Li Yan, Weinan Niu, Z. Ma"",Journal of Web Engineering,,0.255 (16279),10.13052/jwe1540-9589.2166,,2022,,https://doi.org/10.13052/jwe1540-9589.2166,https://semanticscholar.org/paper/072091bce76c2c8d7dd1e8cdf5b94e3e78051a32,""Knowledge graph (KG) completion aims to infer new facts from incomplete knowledge graphs. Most existing solutions focus on learning from time-aware fact triples and ignore the spatial information. In reality, knowledge graphs can evolve with time as well as the changing locations, such as the flight domain. Therefore, integrating spatiotemporal information into knowledge graph representation is important for the knowledge graph completion. To address this problem, this paper proposes two Spatio Temporal-aware knowledge graph completion models based on the Sequence Encoder, namely STSE and S-TSE, which incorporate the spatial and temporal information into relations. Specifically, the model consists of two steps: spatiotemporal-aware relation encoding and final scoring function evaluation. The first stage composes the spatiotemporal information into different tokens. Then two methods are proposed to obtain the embedding of spatiotemporal-aware relation by utilizing the Recursive Neural Network. The second stage proposes different scoring functions for two models. Empirically evaluation of the proposed models is conducted on spatiotemporal-aware KG completion task on two public datasets. Experimental results demonstrate the effectiveness of the proposal for spatiotemporal knowledge graph completion."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"StATIK: Structure and Text for Inductive Knowledge Graph Completion,StATIK achieves state-of-the-art results on three challenging inductive baselines.,""Elan Markowitz, Keshav Balasubramanian, Mehrnoosh Mirtaheri, M. Annavaram, A. Galstyan, G. V. Steeg"",NAACL-HLT,,,10.18653/v1/2022.findings-naacl.46,https://aclanthology.org/2022.findings-naacl.46.pdf,2022,3,https://doi.org/10.18653/v1/2022.findings-naacl.46,https://semanticscholar.org/paper/2f0385407e599219ae4568afd132307a30287cce,""Knowledge graphs (KGs) often represent knowledge bases that are incomplete. Machine learning models can alleviate this by helping automate graph completion. Recently, there has been growing interest in completing knowledge bases that are dynamic, where pre-viously unseen entities may be added to the KG with many missing links. In this paper, we present StATIK – St ructure A nd T ext for I nductive K nowledge Completion. StATIK uses Language Models to extract the semantic information from text descriptions, while using Message Passing Neural Networks to capture the structural information. StATIK achieves state of the art results on three challenging inductive baselines. We further analyze our hybrid model through detailed ablation studies."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"A Review of Knowledge Graph Completion,Knowledge graph representation learning is divided into conventional and graph neural network representation learning.,""Mohamad Zamini, H. Reza, M. Rabiei"",Inf.,,,10.3390/info13080396,https://www.mdpi.com/2078-2489/13/8/396/pdf?version=1661395650,2022,6,https://doi.org/10.3390/info13080396,https://semanticscholar.org/paper/15bcddf2d3ac05f54879e7153c434a532ec13c64,""Information extraction methods proved to be effective at triple extraction from structured or unstructured data. The organization of such triples in the form of (head entity, relation, tail entity) is called the construction of Knowledge Graphs (KGs). Most of the current knowledge graphs are incomplete. In order to use KGs in downstream tasks, it is desirable to predict missing links in KGs. Different approaches have been recently proposed for representation learning of KGs by embedding both entities and relations into a low-dimensional vector space aiming to predict unknown triples based on previously visited triples. According to how the triples will be treated independently or dependently, we divided the task of knowledge graph completion into conventional and graph neural network representation learning and we discuss them in more detail. In conventional approaches, each triple will be processed independently and in GNN-based approaches, triples also consider their local neighborhood."",,Review",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"From Discrimination to Generation: Knowledge Graph Completion with Generative Transformer,Knowledge graph completion aims to address the problem of extending a KG with missing triples.,""Xin Xie, Ningyu Zhang, Zhoubo Li, Shumin Deng, Hui Chen, Feiyu Xiong, Mosha Chen, Huajun Chen"",WWW,,,10.1145/3487553.3524238,https://dl.acm.org/doi/pdf/10.1145/3487553.3524238,2022,4,https://doi.org/10.1145/3487553.3524238,https://semanticscholar.org/paper/a146bc7758cf9233971e5d695550a366ad5022ae,""Knowledge graph completion aims to address the problem of extending a KG with missing triples. In this paper, we provide an approach GenKGC, which converts knowledge graph completion to sequence-to-sequence generation task with the pre-trained language model. We further introduce relation-guided demonstration and entity-aware hierarchical decoding for better representation learning and fast inference. Experimental results on three datasets show that our approach can obtain better or comparable performance than baselines and achieve faster inference speed compared with previous methods with pre-trained language models. We also release a new large-scale Chinese knowledge graph dataset OpenBG500 for research purpose1."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"A Neighborhood Re-Ranking Model With Relation Constraint for Knowledge Graph Completion,The relation constraint and structured information located in triples can boost the model performance.,""Yu Li, Bojie Hu, Jian Liu, Yufeng Chen, Jinan Xu"",IEEE/ACM Transactions on Audio Speech and Language Processing,,1.591 (1902),10.1109/TASLP.2022.3225537,,2023,,https://doi.org/10.1109/TASLP.2022.3225537,https://semanticscholar.org/paper/de6e5ec8a071dee57e7fa4d462d1f29f11a695d3,""Knowledge graph completion (KGC) aims to predict missing links based on observed triples. However, current KGC models are still limited by the following two aspects. (1) the entity semantics is implicitly learned by neural network and merely depends on existing facts, which mostly suffers from less additional specific knowledge. Although previous studies have noticed that entity type information can effectively improve KGC task, most of them rely on labeled type-specific data. (2) the recent graph-based models mainly concentrate on Graph Neural Network (GNN) to update source entity representation, regardless of the separate role that neighborhood information plays and may mix noisy neighbor features for target prediction. To address the above two issues, we propose a neighborhood re-ranking model with relation constraint for KGC task. We suggest that both relation constraint and structured information located in triples can boost the model performance. More importantly, we automatically generate explicit constraints as additional type feature to enrich entity representation instead of depending on human annotated labels. Meanwhile, we construct a neighborhood completion module to re-rank candidate entities for full use of the neighbor structure rather th",an traditional GNN updating manner. Extensive,exp,eri,ment,s on s,ev,en be,nchmarks d,emon,str,ate t,ha,t,our mo,del,ach,iev,es,the,c,ompet,iti,ve r,esult,s in,compa,riso,n to,the,rec,ent,adv,ance,d ba,"selines."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Augmenting Knowledge Graphs for Better Link Prediction,A knowledge graph augmentation method incorporates literals in an embedding model without modifying its loss function.,""Jiang Wang, Filip Ilievski, Pedro A. Szekely, Ke-Thia Yao"",International Joint Conference on Artificial Intelligence,,,10.48550/arXiv.2203.13965,,2022,2,https://doi.org/10.48550/arXiv.2203.13965,https://semanticscholar.org/paper/387a916fa4927a5998cbef2e0b7e1f5e6a2e9c3e,""Embedding methods have demonstrated robust performance on the task of link prediction in knowledge graphs, by mostly encoding entity relationships. Recent methods propose to enhance the loss function with a literal-aware term. In this paper, we propose KGA: a knowledge graph augmentation method that incorporates literals in an embedding model without modifying its loss function. KGA discretizes quantity and year values into bins, and chains these bins both horizontally, modeling neighboring values, and vertically, modeling multiple levels of granularity. KGA is scalable and can be used as a pre-processing step for any existing knowledge graph embedding model. Experiments on legacy benchmarks and a new large benchmark, DWD, show that augmenting the knowledge graph with quantities and years is beneficial for predicting both entities and numbers, as KGA outperforms the vanilla models and other relevant baselines. Our ablation studies confirm that both quantities and years contribute to KGA's performance, and that its performance depends on the discretization and binning settings. We make the code, models, and the DWD benchmark publicly available to facilitate reproducibility and future research."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"LP-BERT: Multi-task Pre-training Knowledge Graph BERT for Link Prediction,Link prediction plays an important role in knowledge graph.,""Da Li, Ming Yi, Yu Q. He"",ArXiv,,,,,2022,10,,https://semanticscholar.org/paper/0cd4ac8890c4d5c652552ca5ec15123fa0de67d5,""Link prediction plays an significant role in knowledge graph, which is an important resource for many artificial intelligence tasks, but it is often limited by incompleteness. In this paper, we propose knowledge graph BERT for link prediction, named LP-BERT, which contains two training stages: multi-task pre-training and knowledge graph fine-tuning. The pre-training strategy not only uses Mask Language Model (MLM) to learn the knowledge of context corpus, but also introduces Mask Entity Model (MEM) and Mask Relation Model (MRM), which can learn the relationship information from triples by predicting semantic based entity and relation elements. Structured triple relation information can be transformed into unstructured semantic information, which can be integrated into the pre-training model together with context corpus information. In the finetuning phase, inspired by contrastive learning, we carry out a triple-style negative sampling in sample batch, which greatly increased the proportion of negative sampling while keeping the training time almost unchanged. Furthermore, we propose a data augmentation method based on the inverse relationship of triples to further increase the sample diversity. We achieve state-of-the-art results on WN18RR and UMLS datasets, especially the Hits@10 indicator improved by 5% from the previous state-of-the-art result on WN18RR dataset."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Geometric Algebra based Embeddings for Static and Temporal Knowledge Graph Completion,GeomE is able to model diverse relations patterns.,""Chengjin Xu, M. Nayyeri, Yung-Yu Chen, Jens Lehmann"",IEEE Transactions on Knowledge and Data Engineering,,2.431 (883),10.1109/tkde.2022.3151435,,2022,,https://doi.org/10.1109/tkde.2022.3151435,https://semanticscholar.org/paper/81c420b949103b2c433dfa4671e87a2f6b5008e0,""Recent years, Knowledge Graph Embeddings (KGEs) have shown promising performance on link prediction tasks by mapping the entities and relations from a Knowledge Graph (KG) into a geometric space and thus have gained increasing attentions. In addition, many recent Knowledge Graphs involve evolving data, e.g., the fact (Obama, PresidentOf, USA) is valid only from 2009 to 2017. This introduces important challenges for knowledge representation learning since such temporal KGs change over time. In this work, we strive to move beyond the complex or hypercomplex space for KGE and propose a novel geometric algebra based embedding approach, GeomE, which uses multivector representations and the geometric product to model entities and relations. GeomE subsumes several state-of-the-art KGE models and is able to model diverse relations patterns. On top of this, we extend GeomE to TGeomE for temporal KGE, which performs 4th-order tensor factorization of a temporal KG and devises a new linear temporal regularization for time representation learning. Moreover, we study the effect of time granularity on the performance of TGeomE models. Experimental results show that our proposed models achieve the state-of-the-art performances on link prediction over four commonly-used static KG datasets and four well-established temporal KG dataset","s across various metrics."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"RLPath: a knowledge graph link prediction method using reinforcement learning based attentive relation path searching and representation learning,""A new link prediction method RLPath alternately trains a reinforcement learning model to search high-quality relation paths, and a translation-based model to realize link prediction."",""Ling  Chen, Jun  Cui, Xing  Tang, Yuntao  Qian, Yansheng  Li, Yongjun  Zhang"",Appl. Intell.,,,10.1007/s10489-021-02672-0,,2022,4,https://doi.org/10.1007/s10489-021-02672-0,https://semanticscholar.org/paper/89873dae883caaac56ff653f22fd13b067d11133,""Due to containing rich patterns between entities, relation paths have been widely used in knowledge graph link prediction. The state-of-the-art link prediction methods considering relation paths obtain relation paths by reinforcement learning with an untrainable reward setting, and realize link prediction by path-ranking algorithm (PRA), which ignores information in entities. In this paper, we propose a new link prediction method RLPath to employ information in both relation paths and entities, which alternately trains a reinforcement learning model with a trainable reward setting to search high-quality relation paths, and a translation-based model to realize link prediction. Simultaneously, we propose a novel reward setting for the reinforcement learning model, which shares the parameters with the attention of the translation-based model, so that these parameters can not only measure the contributions of relation paths, but also guide agents to search relation paths that have high contributions for link prediction, forming mutual promotion. In experiments, we compare RLPath with the state-of-the-art link prediction methods. The results show that","RLPath has competitive performance."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"An Open Challenge for Inductive Link Prediction on Knowledge Graphs,The ILPC 2022 challenge on knowledge graph inductive link prediction is a novel open challenge on knowledge graphs.,""Mikhail Galkin, M. Berrendorf, Charles Tapley Hoyt"",ArXiv,,,10.48550/arXiv.2203.01520,,2022,4,https://doi.org/10.48550/arXiv.2203.01520,https://semanticscholar.org/paper/afbb1e7a2583c2d009845cbc112f4028f7ec92a3,""An emerging trend in representation learning over knowledge graphs (KGs) moves beyond transductive link prediction tasks over a fixed set of known entities in favor of inductive tasks that imply training on one graph and performing inference over a new graph with unseen entities. In inductive setups, node features are often not available and training shallow entity embedding matrices is meaningless as they cannot be used at inference time with unseen entities. Despite the growing interest, there are not enough benchmarks for evaluating inductive representation learning methods. In this work, we introduce ILPC 2022 , a novel open challenge on KG inductive link prediction. To this end, we constructed two new datasets based on Wikidata with various sizes of training and inference graphs that are much larger than existing inductive benchmarks. We also provide two strong baselines leveraging recently proposed inductive methods. We hope this challenge helps to streamline community efforts in the inductive graph representation learning area. ILPC 2022 follows best practices on evaluation fairness and reproducibility, and is available at https://github.com/pykeen/ilpc2022."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Evaluating Explanations of Relational Graph Convolutional Network Link Predictions on Knowledge Graphs,Evaluating explanation quality is difficult without ground truth explanations.,Nicholas Halliwell,AAAI Conference on Artificial Intelligence,,,10.1609/aaai.v36i11.21577,https://ojs.aaai.org/index.php/AAAI/article/download/21577/21326,2022,2,https://doi.org/10.1609/aaai.v36i11.21577,https://semanticscholar.org/paper/4d6823c69a44d7c6cdaa65bc4115799e714d9c29,""Recently, explanation methods have been proposed to evaluate the predictions of Graph Neural Networks on the task of link prediction. Evaluating explanation quality is difficult without ground truth explanations. This thesis is focused on providing a method, including datasets and scoring metrics, to quantitatively evaluate explanation methods on link prediction on Knowledge Graphs."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Knowledge Graph Completion Based on Multi-Relation Graph Attention Network,A multi-relational graph attention network embeds each triple and its reverse one respectively.,Qiang Wei,International Conference on Big Data and Education,,,10.1145/3524383.3524429,,2022,,https://doi.org/10.1145/3524383.3524429,https://semanticscholar.org/paper/7c63aa210e7e7ccac1aa5faccf32fb3229e3b1d8,""Knowledge Graph Completion (KGC), can be performed mainly by inferring missing facts from entities and relations already in the knowledge graphs. However, most methods for KGC only focus on modeling undirected or single relational graph data, ignoring semantic information of multiple relations. We argue that information in the directed edge flows bi-directionally and there exists a latent reverse relation for each relation. These latent reverse relations contain additional information for completing knowledge graphs. Thus, in this paper, we propose a novel method called Knowledge Graph Completion based on Multi-relation Graph Attention neTwork (KGC-MGAT) for more accurate knowledge graph completion. We propose a multi-relational graph attention network to embed each triple and its reverse one respectively. Finally, we design a novel optimal objective for training. We conduct extensive experiments, and the results show the superiority of our method."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"A Novel Deep Learning Model for Link Prediction of Knowledge Graph,The TMPAN can effectively deal with the heterogeneous neighborhood information by introducing TransGCN's transformation assumptions into DPMPN.,""Shuai Ding, Qinghan Lai, Zihan Zhou, J. Gong, Jin'an Cui, Song Liu"",International Symposium on Circuits and Systems,,,10.1109/ISCAS48785.2022.9937699,,2022,,https://doi.org/10.1109/ISCAS48785.2022.9937699,https://semanticscholar.org/paper/9ea0feca8177cf10fe265eaaea5de946bbfbd25d,""Link prediction of knowledge graph is a relatively widely studied task in knowledge graph completion, the purpose of which is to complete the incomplete triples according to the original knowledge triples of the knowledge graph. To solve the problem of handling the heterogeneous neighborhood and the injective problem in the link prediction of knowledge graph, we propose a novel deep learning model called Transformation Assumptions with Message Passing Aggregation Network (TMPAN). TMPAN can effectively deal with the heterogeneous neighborhood information by introducing TransGCN’s transformation assumptions into DPMPN, which transforms head entities to tail entities using relationships as transformation operators. TMPAN also solves the injective problem caused by the single-aggregation operation by employing the multiple aggregators of the Principal Neighborhood Aggregation network (PNA) model. We comprehensively evaluate our model compared to typical baseline models by conducting experiments on two public datasets, FB15K-237 and YAGO3-10. The experimental results show the effectiveness of our model in the link prediction task."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"RDF* Knowledge Graph Completion by Translation,Link prediction techniques for inferring missing triples have been presented.,""Linda Kwan, Pouya Ghiasnezhad Omran, A. Haller"",International Workshop on the Semantic Web,,,,,2022,,,https://semanticscholar.org/paper/6257647ceb04a5248f501962a162fb4290ebffc3,""Knowledge graphs (KGs) are valuable for many applications, but they are incomplete due to their construction process or available information in a corresponding domain. Thus, Link Prediction (LP) techniques for inferring missing triples have been presented. Usually, such LP methods work on plain RDF triples, while more complex KGs like RDF*, where each fact can be qualified with another fact, are emerging. In this paper, we propose a translation-based method that can translate RDF* graphs to RDF graphs while the translation does not harm the performance of LP, whence we query the core facts (not qualifiers). We demonstrate that our translation-based method can help the link predictors that can handle RDF* directly like StarE to handle this specific kind of query more accurately. We also demonstrated that the extra complexity we create by translating could be manageable using more efficient link predictors like AnyBURL."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Subgraph Neighboring Relations Infomax for Inductive Link Prediction on Knowledge Graphs,The Subgraph Neighboring Relations Infomax outperforms existing state-of-art methods on inductive link prediction task.,""Xiaohan Xu, Peng Zhang, Yongquan He, Chengpeng Chao, Chaoyang Yan"",International Joint Conference on Artificial Intelligence,,,10.24963/ijcai.2022/325,https://www.ijcai.org/proceedings/2022/0325.pdf,2022,3,https://doi.org/10.24963/ijcai.2022/325,https://semanticscholar.org/paper/09a0a76c197bf254bc717be3b57ed6317ac7c589,""Inductive link prediction for knowledge graph aims at predicting missing links between unseen entities, those not shown in training stage. Most previous works learn entity-specific embeddings of entities, which cannot handle unseen entities. Recent several methods utilize enclosing subgraph to obtain inductive ability. However, all these works only consider the enclosing part of subgraph without complete neighboring relations, which leads to the issue that partial neighboring relations are neglected, and sparse subgraphs are hard to be handled. To address that, we propose Subgraph Neighboring Relations Infomax, SNRI, which sufficiently exploits complete neighboring relations from two aspects: neighboring relational feature for node feature and neighboring relational path for sparse subgraph. To further model neighboring relations in a global way, we innovatively apply mutual information (MI) maximization for knowledge graph. Experiments show that SNRI outperforms existing state-of-art methods by a large margin on inductive link prediction task, and verify the effectiveness of exploring complete neighboring relations in a global way to characterize node features and reason on sparse subgraphs."",",",",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Along the Time: Timeline-traced Embedding for Temporal Knowledge Graph Completion,The proposed method can not only distinguish the independence of semantic and temporal information.,""Fuwei Zhang, Zhao Zhang, Xiang Ao, Fuzhen Zhuang, Yongjun Xu, Qing He"",International Conference on Information and Knowledge Management,,,10.1145/3511808.3557233,https://dl.acm.org/doi/pdf/10.1145/3511808.3557233,2022,1,https://doi.org/10.1145/3511808.3557233,https://semanticscholar.org/paper/8250dd64e808b8912e91e239f669eed92d2e5452,""Recent years have witnessed remarkable progress on knowledge graph embedding (KGE) methods to learn the representations of entities and relations in static knowledge graphs (SKGs). However, knowledge changes over time. In order to represent the facts happening in a specific time, temporal knowledge graph (TKG) embedding approaches are put forward. While most existing models ignore the independence of semantic and temporal information. We empirically find that current models have difficulty distinguishing representations of the same entity or relation at different timestamps. In this regard, we propose a TimeLine-Traced Knowledge Graph Embedding method (TLT-KGE) for temporal knowledge graph completion. TLT-KGE aims to embed the entities and relations with timestamps as a complex vector or a quaternion vector. Specifically, TLT-KGE models semantic information and temporal information as different axes of complex number space or quaternion space. Meanwhile, two specific components carving the relationship between semantic and temporal information are devised to buoy the modeling. In this way, the proposed method can not only distinguish the independence of the semantic and temporal information, but also establ",ish a connection between them. Experimental r,esul,ts,on t,he lin,k,predi,ction task,dem,ons,trate,t,ha,t TLT-,KGE,ach,iev,es,sub,st,antia,l i,mpro,vemen,ts o,ver st,ate-,of-th,e-a,rt c,omp,etit,ors.,The,"source code will be available on https://github.com/zhangfw123/TLT-KGE."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"ABM: Attention-based Message Passing Network for Knowledge Graph Completion,A proposed knowledge graph completion method focuses on predicting the relation between any two entities in a knowledge graph.,""Weikai Xu, Lihui Liu, Hanghang Tong"",2022 IEEE International Conference on Big Data (Big Data),,,10.1109/BigData55660.2022.10021003,,2022,,https://doi.org/10.1109/BigData55660.2022.10021003,https://semanticscholar.org/paper/a3661df666f20043b6f08c1c1cd5ba2eb2ff17da,""Knowledge graph is ubiquitous and plays an important role in many real-world applications, including recommender systems, question answering, fact-checking, and so on. However, most of the knowledge graphs are incomplete which can hamper their practical usage. Fortunately, knowledge graph completion (KGC) can mitigate this problem by inferring missing edges in the knowledge graph according to the existing information. In this paper, we propose a novel KGC method named ABM (Attention-Based Message passing) which focuses on predicting the relation between any two entities in a knowledge graph. The proposed ABM consists of three integral parts, including (1) context embedding, (2) structure embedding, and (3) path embedding. In the context embedding, the proposed ABM generalizes the existing message passing neural network to update the node embedding and the edge embedding to assimilate the knowledge of nodes' neighbors, which captures the relative role information of the edge that we want to predict. In the structure embedding, the proposed method overcomes the shortcomings of the existing GNN method (i.e., most methods ignore the structural similarity between nodes.) by assigning different attention weights to different nodes while doing the aggregation. P",ath embedding generates paths between any two,ent,iti,es a,nd tre,at,s the,se paths a,s se,que,nces.,T,he,"n, the",se,quen,ce,ca,n be,u,sed a,s t,he i,nput,of t,he Tra,nsfo,rmer,to,upda,te,the,embe,ddin,"g of the knowledge graph to gather the global role of the missing edges. By utilizing these three mutually complementary strategies, the proposed ABM is able to capture both the local and global information which in turn leads to a superb performance. Experiment results show that ABM outperforms baseline methods on a wide range of datasets."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"An Extensible Approach for Query-Driven Multimodal Knowledge Graph Completion,The output of user-defined functions triggered by rules is used to decide the materialization of new links completing the original graph.,""Marcelo de Oliveira Costa Machado, Guilherme Lima, E. Soares, Vitor Nascimento, R. Brandão, M. Moreno"",International Workshop on the Semantic Web,,,,,2022,,,https://semanticscholar.org/paper/45f9f17eb55c89dc80dfacc99e3328eb3e5e20b7,""The knowledge graph completion task has gained a lot of attention in recent years, especially with the use of machine learning (ML). However, most of the work has focused on the structure of the graph while ignoring the data it describes. In this demo, we present an approach that does the opposite: it leverages the multimodal data described by a knowledge graph for its completion. We use IBM’s Hyperlinked Knowledge Graph framework, which allows nodes of the graph to carry arbitrary data content. This content is processed at query time by user-defined functions which are triggered by rules and whose output is used to decide the materialization of new links, completing the original graph. To demonstrate the approach, we use ML models to classify images of paintings and decide the materialization of links describing their semantics."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"ProjB: An Improved Bilinear Biased ProjE model for Knowledge Graph Completion,The proposed approach outperforms the state-of-the-art models in entity prediction task using linear and bilinear methods and other recent powerful ones.,""Mojtaba Moattari, S. Vahdati, F. Zulkernine"",ArXiv,,,10.48550/arXiv.2209.02390,,2022,,https://doi.org/10.48550/arXiv.2209.02390,https://semanticscholar.org/paper/e651f800b0a213ed7eda880e3ff90d7a0ad5f20e,""Knowledge Graph Embedding (KGE) methods have gained enormous attention from a wide range of AI communities including Natural Language Processing (NLP) for text generation, classification and context induction. Embedding a huge number of inter-relationships in terms of a small number of dimensions, require proper modeling in both cognitive and computational aspects. Recently, numerous objective functions regarding cognitive and computational aspects of natural languages are developed. Among which are the state-of-the-art methods of linearity, bilinearity, manifold-preserving kernels, projection-subspace, and analogical inference. However, the major challenge of such models lies in their loss functions that associate the dimension of relation embeddings to corresponding entity dimension. This leads to inaccurate prediction of corresponding relations among entities when counterparts are estimated wrongly. ProjE KGE, published by Bordes et al., due to low computational complexity and high potential for model improvement, is improved in this work regarding all translative and bilinear interactions while capturing entity nonlinearity. Experimental results on benchmark Knowledge Graphs (KGs) such as FB15K and WN18 show that the proposed approach outperforms the state-of-the-art models in entity",prediction task using linear and bilinear me,thod,s a,nd o,ther r,ec,ent p,owerful on,es.,In,addit,io,"n,",a par,all,el p,roc,es,sing,s,truct,ure,is,propo,sed,for th,e mo,del i,n o,rder,to,imp,rove,the,"scalability on large KGs. The effects of different adaptive clustering and newly proposed sampling approaches are also explained which prove to be effective in improving the accuracy of knowledge graph completion. handling greater number of interactions between entities and relations. attention mechanism, and consider both translational and bilinear aspects by adding relation and entity cluster-specific embedding vectors. Results from experimental evaluations show that our model outperforms the state-of-the-art translational and bilinear models in Knowledge Graph Completion task. In addition to the main KGE model, a tensor based model for speed improvement is formulated and implemented in the proposed approach and the speed results are provided. Finally, the new sampling and simplistic feature reduction approaches have been introduced as helpful tools for the researchers. The complexity and number of problems are relatively close to the baseline ProjE model."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"KGLM: Integrating Knowledge Graph Structure in Language Models for Link Prediction,Pre-training language models with this additional embedding layer using the triples extracted from the knowledge graph sets a new state-of-the-art performance for the link prediction task on the benchmark datasets.,""Jason Youn, I. Tagkopoulos"",ArXiv,,,10.48550/arXiv.2211.02744,,2022,1,https://doi.org/10.48550/arXiv.2211.02744,https://semanticscholar.org/paper/90d6047155977b674080a734ba1fa5c13161a2b9,""The ability of knowledge graphs to represent complex relationships at scale has led to their adoption for various needs including knowledge representation, question-answering, fraud detection, and recommendation systems. Knowledge graphs are often incomplete in the information they represent, necessitating the need for knowledge graph completion tasks, such as link and relation prediction. Pre-trained and fine-tuned language models have shown promise in these tasks although these models ignore the intrinsic information encoded in the knowledge graph, namely the entity and relation types. In this work, we propose the Knowledge Graph Language Model (KGLM) architecture, where we introduce a new entity/relation embedding layer that learns to differentiate distinctive entity and relation types, therefore allowing the model to learn the structure of the knowledge graph. In this work, we show that further pre-training the language models with this additional embedding layer using the triples extracted from the knowledge graph, followed by the standard fine-tuning phase sets a new state-of-the-art performance for the link prediction task on the benchmark datasets."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Study and analysis of various link predictions in knowledge graph: A challenging overview,Knowledge graph completion is the same as the link prediction concepts in the knowledge graphs.,""A. Khobragade, S. Ghumbre"",International Journal of Intelligent Decision Technologies,,,10.3233/idt-210103,,2022,,https://doi.org/10.3233/idt-210103,https://semanticscholar.org/paper/ce2f15287d8b0f48e263f4f4942bb842f37d5b24,""Knowledge Graph (KG) is the network which contains some topic-based entities, called nodes, and the associated information among the entities. Here, the concept in the knowledge graph is denoted by the tuple relationship, such that the ?entity1, predicate, entity2?. The entity in the knowledge graph is the abstract concepts based on the particular object, namely the organization, dataset, people, and some associated documentation. The big issue in the KG is that it consists of some incomplete information. The missing details can be identified by employing the knowledge graph completion (KGC) solution. KGC is the same as the link prediction concepts in the knowledge graphs. However, this concept is more complex that it does not predict the link relationship among the nodes but also the diversified information from the link relations. Hence this survey analyzes different methods of link prediction techniques, and this review provides a detailed review of 50 research papers concentrating on various methods, like embedding-based methods, deep learning methods, knowledge acquisition methods, ranking methods, and representation learning methods. The analysis is carried out with respect to the survey based on the publication year, research techniques, performance measures, dataset, toolset and achievement of the resear","ch methodologies. Also, the problems in the m",etho,ds,are,explai,ne,d in,the resear,ch g,aps,and,is,su,es. Fu,rth,ermo,"re,",t,he f,ut,ure e,xte,nt o,f the,se r,esearc,h wo,rks i,s d,one,bas,ed o,n th,e li,"mitations identified from the existing research methods."",,Review",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Novel translation knowledge graph completion model based on 2D convolution,A translation knowledge graph completion model based on 2D convolution achieves state-of-the-art results compared with the baseline.,""Jianzhou  Feng, Qikai  Wei, Jinman  Cui, Jing  Chen"",Appl. Intell.,,,10.1007/S10489-021-02438-8,,2022,,https://doi.org/10.1007/S10489-021-02438-8,https://semanticscholar.org/paper/9d06bf0ea4286000f75b02f6c236d9b52961602e,""The knowledge graph completion task involves predicting missing entities and relations in a knowledge graph. Many models have achieved good results, but they have become increasingly complex. In this study, we propose a simple translation-based model that relies on the fact that the multiplication of subjects and relations is approximately equal to the object. First, we utilize embeddings to represent entities and relations. Second, we perform vector multiplication on subject embedding and relation embedding to generate a 2D matrix and achieve full fusion of embedding at the element level. Third, we adopt a convolutional neural network on the 2D matrix. Thereafter, we can generate feature maps, which are then spliced into a 1D feature vector. The feature vector is transformed into predicted object embedding through a fully connected operation. Finally, we use the scoring function to score the candidate triples. Experimental results strongly demonstrate that the translation knowledge graph completion model based on 2D convolution achieves state-of-the-art results compared with the baseline."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Convolutional Neural Network Knowledge Graph Link Prediction Model Based on Relational Memory,A knowledge graph embedding model based on a relational memory network and convolutional neural network outperforms existing models and methods on several metrics.,""Ming Shi, Jing Zhao, Donglin Wu"",Computational Intelligence and Neuroscience,,0.863 (5106),10.1155/2023/3909697,https://downloads.hindawi.com/journals/cin/2023/3909697.pdf,2023,,https://doi.org/10.1155/2023/3909697,https://semanticscholar.org/paper/0fd42d5142da516fc1efc4772cfefaeaeffe7b80,""A knowledge graph is a collection of fact triples, a semantic network composed of nodes and edges. Link prediction from knowledge graphs is used to reason about missing parts of triples. Common knowledge graph link prediction models include translation models, semantics matching models, and neural network models. However, the translation models and semantic matching models have relatively simple structures and poor expressiveness. The neural network model can easily ignore the overall structural characteristics of triples and cannot capture the links between entities and relations in low-dimensional space. In response to the above problems, we propose a knowledge graph embedding model based on a relational memory network and convolutional neural network (RMCNN). We encode triple embedding vectors using a relational memory network and decode using a convolutional neural network. First, we will obtain entity and relation vectors by encoding the latent dependencies between entities and relations and some critical information and keeping the translation properties of triples. Then, we compose a matrix of head entity encoding embedding vector, relation encoding embedding vector, an",d tail entity embedding encoding vector as th,e in,put,of,the co,nv,oluti,onal neura,l ne,two,rk. F,in,al,"ly, we",us,e a,con,vo,luti,on,al ne,ura,l ne,twork,as,the de,code,r and,a,dime,nsi,on c,onve,rsio,"n strategy to improve the information interaction capability of entities and relations in more dimensions. Experiments show that our model achieves significant progress and outperforms existing models and methods on several metrics."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"A Simplified Benchmark for Ambiguous Explanations of Knowledge Graph Link Prediction Using Relational Graph Convolutional Networks (Student Abstract),Evaluating performance of explanation methods for link prediction is difficult without ground truth explanations.,""Nicholas Halliwell, Fabien L. Gandon, F. Lécué"",AAAI Conference on Artificial Intelligence,,,10.1609/aaai.v36i11.21618,https://ojs.aaai.org/index.php/AAAI/article/download/21618/21367,2022,,https://doi.org/10.1609/aaai.v36i11.21618,https://semanticscholar.org/paper/b0e051e0eaf89a069d5477f8d4d502ee788ba602,""Relational Graph Convolutional Networks (RGCNs) are commonly used on Knowledge Graphs (KGs) to perform black box link prediction. Several algorithms have been proposed to explain their predictions. Evaluating performance of explanation methods for link prediction is difficult without ground truth explanations. Furthermore, there can be multiple explanations for a given prediction in a KG. No dataset exists where observations have multiple ground truth explanations to compare against. Additionally, no standard scoring metrics exist to compare predicted explanations against multiple ground truth explanations. We propose and evaluate a method, including a dataset, to benchmark explanation methods on the task of explainable link prediction using RGCNs."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Research on Knowledge Graph Completion Model Combining Temporal Convolutional Network and Monte Carlo Tree Search,A deep agent network combines temporal convolutional network and Monte Carlo Tree Search solves the problem of sparse rewards and historical state encoding.,""Ying Wang, Mingchen Sun, Hongjiu Wang, Yudong Sun"",Mathematical Problems in Engineering,,0.327 (13984),10.1155/2022/2290540,https://downloads.hindawi.com/journals/mpe/2022/2290540.pdf,2022,,https://doi.org/10.1155/2022/2290540,https://semanticscholar.org/paper/20c10ccec1ce0be5f900d12899b4184c36ff0955,""In knowledge graph completion (KGC) and other applications, learning how to move from a source node to a target node with a given query is an important problem. It can be formulated as a reinforcement learning (RL) problem transition model under a given state. In order to overcome the challenges of sparse rewards and historical state encoding, we develop a deep agent network (graph-agent, GA), which combines temporal convolutional network (TCN) and Monte Carlo Tree Search (MCTS). Firstly, we combine MCTS with neural network to generate more positive reward trajectories, which can effectively solve the problem of sparse rewards. TCN is used to encode the history state, which is used for policy and Q-value respectively. Secondly, according to these trajectories, we use Q-Learning to improve the network and parameter sharing to enhance TCN strategy. We apply these steps repeatedly to learn the model. Thirdly, in the prediction stage of the model, Monte Carlo Tree Search combined with Q-value method is used to predict the target nodes. The experimental results on several graph-walking benchmarks show that GA is better than other RL methods based on-policy",gradient. The performance of GA is also bette,r th,an,the,tradit,io,nal K,GC baselin,"es.""",",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"From Discrimination to Generation: Knowledge Graph Completion with Generative Transformer,Knowledge graph completion aims to address the problem of extending a KG with missing triples.,""Xin  Xie, Ningyu  Zhang, Zhoubo  Li, Shumin  Deng, Hui  Chen, Feiyu  Xiong, Mosha  Chen, Huajun  Chen"",ArXiv,,,10.1145/3487553.3524238,https://dl.acm.org/doi/pdf/10.1145/3487553.3524238,2022,1,https://doi.org/10.1145/3487553.3524238,https://semanticscholar.org/paper/e2b6b918a0a0150c593eaf13c7be1919271ffdbf,""Knowledge graph completion aims to address the problem of ex-tending a KG with missing triples. In this paper, we provide an approach GenKGC , which converts knowledge graph completion to sequence-to-sequence generation task with the pre-trained language model. We further introduce relation-guided demonstration and entity-aware hierarchical decoding for better representation learning and fast inference. Experimental results on three datasets show that our approach can obtain better or comparable performance than baselines and achieve faster inference speed com-pared with previous methods with pre-trained language models. We also release a new large-scale Chinese knowledge graph dataset OpenBG500 for research purpose 1 ."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Scaling knowledge graph embedding models for link prediction,A scaling solution for GNN-based knowledge graph embedding models achieves a 16x speed up on benchmark datasets.,""Nasrullah Sheikh, Xiao Qin, B. Reinwald, Chuan Lei"",EuroMLSys@EuroSys,,,10.1145/3517207.3526974,,2022,,https://doi.org/10.1145/3517207.3526974,https://semanticscholar.org/paper/55b47247933874fce9166191485dde2dbf106fe0,""Developing scalable solutions for training Graph Neural Networks (GNNs) for link prediction tasks is challenging due to the inherent data dependencies which entail high computational costs and a huge memory footprint. We propose a new method for scaling training of knowledge graph embedding models for link prediction to address these challenges. Towards this end, we propose the following algorithmic strategies: self-sufficient partitions, constraint-based negative sampling, and edge mini-batch training. The experimental evaluation shows that our scaling solution for GNN-based knowledge graph embedding models achieves a 16x speed up on benchmark datasets while maintaining a comparable model performance to non-distributed methods on standard metrics."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Scaling knowledge graph embedding models for link prediction,A scaling solution for GNN-based knowledge graph embedding models achieves a 16x speed up on benchmark datasets.,""Nasrullah  Sheikh, Xiao  Qin, Berthold  Reinwald, Chuan  Lei"",EuroMLSys@EuroSys,,,10.1145/3517207.3526974,,2022,,https://doi.org/10.1145/3517207.3526974,https://semanticscholar.org/paper/cb46cfa3da47ab8e228c99e269a7be33dc407e6c,""Developing scalable solutions for training Graph Neural Networks (GNNs) for link prediction tasks is challenging due to the inherent data dependencies which entail high computational costs and a huge memory footprint. We propose a new method for scaling training of knowledge graph embedding models for link prediction to address these challenges. Towards this end, we propose the following algorithmic strategies: self-sufficient partitions, constraint-based negative sampling, and edge mini-batch training. The experimental evaluation shows that our scaling solution for GNN-based knowledge graph embedding models achieves a 16x speed up on benchmark datasets while maintaining a comparable model performance to non-distributed methods on standard metrics."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Explaining Link Predictions in Knowledge Graph Embedding Models with Influential Examples,The approach to generate explanations out-performs baselines on KGE models for two publicly available datasets.,""Adrianna Janik, Luca Costabello"",ArXiv,,,10.48550/arXiv.2212.02651,,2022,,https://doi.org/10.48550/arXiv.2212.02651,https://semanticscholar.org/paper/0cf48d13e5c96f32be4c97c60f6228aacc1d82a0,We study the problem of explaining link predictions in the Knowledge Graph Embedding (KGE) models. We propose an example-based approach that exploits the latent space rep- resentation of nodes and edges in a knowledge graph to explain predictions. We evaluated the importance of identi?ed triples by observing progressing degradation of model performance upon in?uential triples removal. Our experiments demonstrate that this approach to generate explanations out-performs baselines on KGE models for two publicly available datasets.,,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"A Retrieve-and-Read Framework for Knowledge Graph Link Prediction,A novel Transformer-based GNN reader enables the model to focus on salient context information relevant to the query.,""Vardaan Pahuja, Boshi Wang, Hugo Latapie, Jayanth Srinivasa, Yu Su"",ArXiv,,,10.48550/arXiv.2212.09724,,2022,,https://doi.org/10.48550/arXiv.2212.09724,https://semanticscholar.org/paper/600a11a9113e6d87c77c4d4d6ccd7008b6fa1a12,""Knowledge graph (KG) link prediction aims to infer new facts based on existing facts in the KG. Recent studies have shown that using the graph neighborhood of a node via graph neural networks (GNNs) provides more useful information compared to just using the query information. Conventional GNNs for KG link prediction follow the standard message-passing paradigm on the entire KG, which leads to over-smoothing of representations and also limits their scalability. On a large scale, it becomes computationally expensive to aggregate useful information from the entire KG for inference. To address the limitations of existing KG link prediction frameworks, we propose a novel retrieve-and-read framework, which ?rst retrieves a relevant subgraph context for the query and then jointly reasons over the context and the query with a high-capacity reader. As part of our exemplar instantiation for the new framework, we propose a novel Transformer-based GNN as the reader, which incorporates graph-based attention structure and cross-attention between query and context for deep fusion. This design enables the model to focus on salient context information relevant to the query. Empirical results on two standard KG link prediction datasets demonstrate the competitive performance of the proposed method. 1"",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"A Unified Framework for Rank-based Evaluation Metrics for Link Prediction in Knowledge Graphs,The link prediction task on knowledge graphs without explicit negative triples in the training data motivates the use of rank-based metrics.,""Charles Tapley Hoyt, M. Berrendorf, Mikhail Galkin, Volker Tresp, Benjamin M. Gyori"",ArXiv,,,10.48550/arXiv.2203.07544,,2022,2,https://doi.org/10.48550/arXiv.2203.07544,https://semanticscholar.org/paper/d10428bd18aa86c7f5007a27158dd07c0c55afa4,""The link prediction task on knowledge graphs without explicit negative triples in the training data motivates the usage of rank-based metrics. Here, we review existing rank-based metrics and propose desiderata for improved metrics to address lack of interpretability and comparability of existing metrics to datasets of different sizes and properties. We introduce a simple theoretical framework for rank-based metrics upon which we investigate two avenues for improvements to existing metrics via alternative aggregation functions and concepts from probability theory. We finally propose several new rank-based metrics that are more easily interpreted and compared accompanied by a demonstration of their usage in a benchmarking of knowledge graph embedding models."",,Review",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"A Cybersecurity Knowledge Graph Completion Method Based on Ensemble Learning and Adversarial Training,Existing knowledge graph completion methods do not perform well in domain knowledge.,""Peng Wang, Jingju Liu, Dongdong Hou, Shicheng Zhou"",Applied Sciences,,0.44 (11182),10.3390/app122412947,https://www.mdpi.com/2076-3417/12/24/12947/pdf?version=1671188243,2022,,https://doi.org/10.3390/app122412947,https://semanticscholar.org/paper/ce3eb8fbb84f4617a6a9fc5e53d7398255ff0986,""The application of cybersecurity knowledge graphs is attracting increasing attention. However, many cybersecurity knowledge graphs are incomplete due to the sparsity of cybersecurity knowledge. Existing knowledge graph completion methods do not perform well in domain knowledge, and they are not robust enough relative to noise data. To address these challenges, in this paper we develop a new knowledge graph completion method called CSEA based on ensemble learning and adversarial training. Specifically, we integrate a variety of projection and rotation operations to model the relationships between entities, and use angular information to distinguish entities. A cooperative adversarial training method is designed to enhance the generalization and robustness of the model. We combine the method of generating perturbations for the embedding layers with the self-adversarial training method. The UCB (upper confidence bound) multi-armed bandit method is used to select the perturbations of the embedding layer. This achieves a balance between perturbation diversity and maximum loss. To this end, we build a cybersecurity knowledge graph based on the CVE, CWE, and CAPEC cybersecurity databases. Our experimental results demonstrate the superiority of our propose",d model for completing cybersecurity knowledg,e gr,aph,"s."",",",",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Enhance Temporal Knowledge Graph Completion via Time-aware Attention Graph Convolutional Network,A graph convolutional network with a novel temporal attention layer outperforms the state-of-the-art baselines on entity prediction.,""HaoHui Wei, Hong Huang, Teng Zhang, Xuanhua Shi, Hai Jin"",,,,,,2022,,,https://semanticscholar.org/paper/43c3cd7131e31dea9c9ac02ab6bb942979d65787,"". Previous works on knowledge graph representation learning focus on static knowledge graph and get fully developed. However, task on temporal knowledge graph is far from consummation because of its late start. Recent researches have shifted to the temporal knowledge graph relying on the extension of static ones. Most of these methods seek approaches to incorporate temporal information but neglect the potential adjacent impact merged in temporal knowledge graphs. Meanwhile, di?erent temporal information of involved facts evoke impact with dif-ferent extent on the concerned entity, which is always overlooked in the previous works. In our paper, we propose a Time-aware Attention Graph Convolutional Network, named TAGCN , for temporal knowledge graph completion. Entity completion can be turned into interactions between entity and associated neighborhood. We utilize a graph convolutional network with a novel temporal attention layer to obtain neighboring information at all timestamps to avoid diachronic sparsity. We conduct extensive experiments on various datasets to evaluate our model performance. The results illustrate that our model outperforms the state-of-the-art baselines on entity prediction."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"SMiLE: Schema-augmented Multi-level Contrastive Learning for Knowledge Graph Link Prediction,Link prediction is the task of inferring missing links between entities in knowledge graphs.,""Miao Peng, Ben Liu, Qianqian Xie, Wenjie Xu, Hua Wang, Min Peng"",Conference on Empirical Methods in Natural Language Processing,,,10.48550/arXiv.2210.04870,,2022,,https://doi.org/10.48550/arXiv.2210.04870,https://semanticscholar.org/paper/722d1662f27ef33f7c5c3dfc9613f331e6e7e6d2,""Link prediction is the task of inferring missing links between entities in knowledge graphs. Embedding-based methods have shown effectiveness in addressing this problem by modeling relational patterns in triples. However, the link prediction task often requires contextual information in entity neighborhoods, while most existing embedding-based methods fail to capture it. Additionally, little attention is paid to the diversity of entity representations in different contexts, which often leads to false prediction results. In this situation, we consider that the schema of knowledge graph contains the specific contextual information, and it is beneficial for preserving the consistency of entities across contexts. In this paper, we propose a novel Schema-augmented Multi-level contrastive LEarning framework (SMiLE) to conduct knowledge graph link prediction. Specifically, we first exploit network schema as the prior constraint to sample negatives and pre-train our model by employing a multi-level contrastive learning method to yield both prior schema and contextual information. Then we fine-tune our model under the supervision of individual triples to learn subtler representations for link prediction. Extensive experimental results on four knowledge graph dataset",s with thorough analysis of each component de,mons,tra,te t,he eff,ec,tiven,ess of our,pro,pos,ed fr,am,ew,ork ag,ain,st s,tat,e-,of-t,he,#NAME?,bas,elin,es. T,he i,mpleme,ntat,ion o,f S,MiLE,is,ava,ilab,le a,"t https://github.com/GKNL/SMiLE."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Complex Embedding with Type Constraints for Link Prediction,The impartment of type constraints improved its performance on link prediction effectively.,""Xiaohui Li, Zhiliang Wang, Zhaohui Zhang"",Entropy,,0.553 (9039),10.3390/e24030330,https://www.mdpi.com/1099-4300/24/3/330/pdf?version=1646123052,2022,1,https://doi.org/10.3390/e24030330,https://semanticscholar.org/paper/2e07bf55e51bfaed9d5d29bddb27d7dcf89d0038,""Large-scale knowledge graphs not only store entities and relations but also provide ontology-based information about them. Type constraints that exist in this information are of great importance for link prediction. In this paper, we proposed a novel complex embedding method, CHolE, in which complex circular correlation was introduced to extend the classic real-valued compositional representation HolE to complex domains, and type constraints were integrated into complex representational embeddings for improving link prediction. The proposed model consisted of two functional components, the type constraint model and the relation learning model, to form type constraints such as modulus constraints and acquire the relatedness between entities accurately by capturing rich interactions in the modulus and phase angles of complex embeddings. Experimental results on benchmark datasets showed that CHolE outperformed previous state-of-the-art methods, and the impartment of type constraints improved its performance on link prediction effectively."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Link Prediction with Attention Applied on Multiple Knowledge Graph Embedding Models,Combining query representations from several models in a unified one can learn relational and structural patterns.,""Cosimo Gregucci, M. Nayyeri, D. Hern'andez, Steffen Staab"",,,,10.1145/3543507.3583358,https://eprints.soton.ac.uk/475536/1/Link_Prediction_Geometric_Query_Attention.pdf,2023,,https://doi.org/10.1145/3543507.3583358,https://semanticscholar.org/paper/d9802a67b326fe89bbd761c261937ee1e4d4d674,""Predicting missing links between entities in a knowledge graph is a fundamental task to deal with the incompleteness of data on the Web. Knowledge graph embeddings map nodes into a vector space to predict new links, scoring them according to geometric criteria. Relations in the graph may follow patterns that can be learned, e.g., some relations might be symmetric and others might be hierarchical. However, the learning capability of different embedding models varies for each pattern and, so far, no single model can learn all patterns equally well. In this paper, we combine the query representations from several models in a unified one to incorporate patterns that are independently captured by each model. Our combination uses attention to select the most suitable model to answer each query. The models are also mapped onto a non-Euclidean manifold, the Poincar\'e ball, to capture structural patterns, such as hierarchies, besides relational patterns, such as symmetry. We prove that our combination provides a higher expressiveness and inference power than each model on its own. As a result, the combined model can learn relational and structural patterns. We conduct extensive experimental analysis with various link prediction benchmarks sho",wing that the combined model outperforms indi,vidu,al,mode,"ls, in",cl,uding,state-of-,the-,art,appr,oa,ch,"es."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Knowledge Graph Completion Based on GCN of Multi-Information Fusion and High-Dimensional Structure Analysis Weight,A knowledge graph completion model encodes and decodes the feature information is proposed.,""Niu Haoran, He Haitao, Feng Jianzhou, Nie Junlan, Zhang Yangsen, Ren Jiadong"",,,,10.1049/CJE.2021.00.080,https://onlinelibrary.wiley.com/doi/pdfdirect/10.1049/cje.2021.00.080,2022,2,https://doi.org/10.1049/CJE.2021.00.080,https://semanticscholar.org/paper/e0ba1a1513a9417e623dcbc51cc749e64bdf977d,""Knowledge graph completion (KGC) can solve the problem of data sparsity in the knowledge graph. A large number of models for the KGC task have been proposed in recent years. However, the underutilisation of the structure information around nodes is one of the main problems of the previous KGC model, which leads to relatively single encoding information. To this end, a new KGC model that encodes and decodes the feature information is proposed. First, we adopt the subgraph sampling method to extract node structure. Moreover, the Graph convolutional network (GCN) introduced the channel attention convolution encode node structure features and represent them in matrix form to fully mine the node feature information. Eventually, the high-dimensional structure analysis weight decodes the encoded matrix embeddings and then constructs the scoring function. The experimental results show that the model performs well on the datasets used."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Improving knowledge graph completion via increasing embedding interactions,The proposed InterERP matches or outperforms the state-of-the-art approaches on four commonly used datasets.,""Weidong  Li, Rong  Peng, Zhi  Li"",Applied Intelligence,,1.211 (3015),10.1007/s10489-021-02947-6,,2022,,https://doi.org/10.1007/s10489-021-02947-6,https://semanticscholar.org/paper/b1464e3f0c82e21e23dfd9bc28e423856754b3d6,""Knowledge graphs usually consist of billions of triplet facts describing the real world. Although most of the existing knowledge graphs are huge in scale, they are still far from completion. As a result, varieties of knowledge graph embedding approaches have emerged, which have been proven to be an effective and efficient solution for knowledge graph completion. In this paper, we devise a novel knowledge graph embedding model named InterERP , which aims to improve model performance by increasing Inter actions between the embeddings of E ntities, R elations and relation P aths. Specifically, we first introduce the interaction matrix to obtain the interaction embeddings of entities and relations. Then, we employ the Inception network to learn the query embedding, which can further increase the interactions between entities and relations. Furthermore, we resort to logical rules to construct semantic relation paths and are committed to modeling the interactions between different relations in a relation path. The experimental results on four commonly used datasets, demonstrate that the proposed InterERP matches or outperforms the state-of-the-art approaches."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Knowledge Graph Completion Algorithm Based on Probabilistic Fuzzy Information Aggregation and Natural Language Processing Technology,The accuracy of the algorithm improves as the proportion of data in the experiment increases.,""Canlin Zhang, Kai Lu"",Mathematics,,0.538 (9300),10.3390/math10234578,https://www.mdpi.com/2227-7390/10/23/4578/pdf?version=1670406840,2022,,https://doi.org/10.3390/math10234578,https://semanticscholar.org/paper/8a96226800adf2eb8740fce8c819b7e182526664,""The knowledge graph was first used in the information search of the Internet as a way to improve the quality of the search because it contains a huge amount of structured knowledge data. In this paper, the knowledge map algorithm is studied through natural language processing technology and probabilistic fuzzy information aggregation, and the knowledge map completion algorithm is cognitive-fitted. NLP is natural language processing. Based on the experiments in this paper, it can be seen that, after combining the algorithm, the behavior data set of 1000 Amazon users was analyzed, and it can be found that the accuracy of the algorithm improves as the proportion of data in the experiment increases. Among them, the 10% dataset has a correct rate of 0.66; the 30% dataset has a final accuracy rate of 0.68; and the 50% dataset has a final accuracy rate of 0.70. The experimental results of this paper show that using probabilistic fuzzy information aggregation and natural language processing technology as a way to complete the knowledge graph can improve the accuracy of the operation. It plays an important role in the development of intelligent cognition and search engines."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Multi-Task Learning and Improved TextRank for Knowledge Graph Completion,""The mean rank, top 10 hit ratio, and top three hit ratio were enhanced by 38, 1,3, and 1.9% on WN18RR."",""Hao Tian, Xiaoxiong Zhang, Yuhan Wang, Daojian Zeng"",Entropy,,0.553 (9039),10.3390/e24101495,https://www.mdpi.com/1099-4300/24/10/1495/pdf?version=1666254073,2022,,https://doi.org/10.3390/e24101495,https://semanticscholar.org/paper/f99c4b49f09f78a3d1ad74552946a36e6cc75eec,""Knowledge graph completion is an important technology for supplementing knowledge graphs and improving data quality. However, the existing knowledge graph completion methods ignore the features of triple relations, and the introduced entity description texts are long and redundant. To address these problems, this study proposes a multi-task learning and improved TextRank for knowledge graph completion (MIT-KGC) model. The key contexts are first extracted from redundant entity descriptions using the improved TextRank algorithm. Then, a lite bidirectional encoder representations from transformers (ALBERT) is used as the text encoder to reduce the parameters of the model. Subsequently, the multi-task learning method is utilized to fine-tune the model by effectively integrating the entity and relation features. Based on the datasets of WN18RR, FB15k-237, and DBpedia50k, experiments were conducted with the proposed model and the results showed that, compared with traditional methods, the mean rank (MR), top 10 hit ratio (Hit@10), and top three hit ratio (Hit@3) were enhanced by 38, 1.3%, and 1.9%, respectively, on WN18RR. Additionally, the MR and Hit@10 were increased by 23 and 0.7%, respectively, on FB15k-237. The model also improved the Hit@3 and the top one hit ratio (Hit@1",") by 3.1% and 1.5% on the dataset DBpedia50k,",res,pec,tive,"ly, ve",ri,fying,the valid,ity,of,the m,od,el,"."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Open Knowledge Graph Link Prediction with Segmented Embedding,The OpenKG Segmented Embedding method can achieve state-of-the-art performance as well as effectively capture the unique semantics of each NP.,""Tingyu Xie, Peng Peng, Hongwei Wang, Yusheng Liu"",IEEE International Joint Conference on Neural Network,,,10.1109/IJCNN55064.2022.9891940,,2022,,https://doi.org/10.1109/IJCNN55064.2022.9891940,https://semanticscholar.org/paper/d5ba987ad36623777b7a9749db6e7655d912ecbf,""Open Knowledge Graph (OpenKG) link prediction is important for using OpenKGs in applications such as question answering and text comprehension. The noun phrases (NPs) and relation phrases in OpenKGs are not canonicalized, making OpenKG link prediction highly challenging. Existing methods addressing this problem infuse canonicalization information into knowledge graph embedding models. However, they still fail to fully exploit the semantics of NPs. First, two different NPs, even referring to the same entity, can carry different versions of information, which has been ignored by previous methods. Second, neighborhood information of NPs in OpenKGs has not been utilized, which contains abundant information for link prediction. Based on these observations, we propose the OpenKG Segmented Embedding (OKGSE) method. Specifically, to fully capture the dissimilarity of NPs belonging to the same cluster, we learn separate parts of embedding for both the NP cluster and NP. Meanwhile, we exploit neighborhood information by integrating graph context into the semantic matching score function. Extensive experiments across four benchmarks show that OKGSE can achieve state-of-the-art performance as well as effectively capture the unique semantics of each NP."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Supply Chain Link Prediction on Uncertain Knowledge Graph,The first graph neural network approach to model uncertainty in supply chain knowledge graph reasoning is shown.,""Nils Brockmann, E. Kosasih, A. Brintrup"",SIGKDD Explorations,,,10.1145/3575637.3575655,,2022,2,https://doi.org/10.1145/3575637.3575655,https://semanticscholar.org/paper/b249198cf6e3c63a1d25bce5ba7661f6d5ac78e8,""With manufacturing companies outsourcing to each other, multi-echelon supply chain networks emerge in which risks can propagate over multiple entities. Considerable structural and organizational barriers hamper obtaining the supply chain visibility that would be required for a company to monitor and mitigate these risks. Our work proposes to combine the automated extraction of supply chain relations from web data using NLP with augmenting the results using link prediction. For this, the first graph neural network based approach to model uncertainty in supply chain knowledge graph reasoning is shown. We illustrate our approach on a novel dataset and manage to improve the state-of-the-art performance by 60% in uncertainty link prediction. Generated confidence scores support real-world decision-making."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Reasoning Through Memorization: Nearest Neighbor Knowledge Graph Embeddings,A knowledge graph embedding approach with pre-trained language models can allow rare or emerging entities to be memorized explicitly rather than implicitly in model parameters.,""Ningyu Zhang, Xin Xie, Xiang Chen, Shumin Deng, Chuanqi Tan, Fei Huang, Xu Cheng, Huajun Chen"",ArXiv,,,,,2022,7,,https://semanticscholar.org/paper/072f7b3b68c930c4e01fc2ed1c54fcdc5e916a04,""Previous knowledge graph embedding approaches usually map entities to representations and utilize score functions to predict the target entities, yet they typically struggle to reason rare or emerging unseen entities. In this paper, we propose kNN-KGE, a new knowledge graph embedding approach with pre-trained language models, by linearly interpolating its entity distribution with k-nearest neighbors. We compute the nearest neighbors based on the distance in the entity embedding space from the knowledge store. Our approach can allow rare or emerging entities to be memorized explicitly rather than implicitly in model parameters. Experimental results demonstrate that our approach can improve inductive and transductive link prediction results and yield better performance for low-resource settings with only a few triples, which might be easier to reason via explicit memory. Code is available at https://github.com/zjunlp/KNN-KG."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Step out of KG: Knowledge Graph Completion via Knowledgeable Retrieval and Reading Comprehension,A knowledge-based information retrieval module can retrieve documents related to the triples to be completed.,""Xin Lv, Yankai Lin, Zijun Yao, Kaisheng Zeng, Jiajie Zhang, Lei Hou, Juanzi Li"",ArXiv,,,10.48550/arXiv.2210.05921,,2022,,https://doi.org/10.48550/arXiv.2210.05921,https://semanticscholar.org/paper/c30e0c008997925710eb63f413c57653c333e7ab,""Knowledge graphs, as the cornerstone of many AI applications, usually face serious incompleteness problems. In recent years, there have been many efforts to study automatic knowledge graph completion (KGC), most of which use existing knowledge to infer new knowledge. However, in our experiments, we ?nd that not all relations can be obtained by inference, which constrains the performance of existing models. To alleviate this prob-lem, we propose a new model based on information retrieval and reading comprehension, namely IR4KGC. Speci?cally, we pre-train a knowledge-based information retrieval module that can retrieve documents related to the triples to be completed. Then, the retrieved documents are handed over to the reading comprehension module to generate the predicted answers. In experiments, we ?nd that our model can well solve relations that cannot be inferred from existing knowledge, and achieve good results on KGC datasets."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Reasoning Through Memorization: Nearest Neighbor Knowledge Graph Embeddings,A knowledge graph embedding approach can allow rare or emerging entities to be memorized explicitly rather than implicitly in model parameters.,""Ningyu Zhang, Xin Xie, Xiang Chen, Shumin Deng, Chuanqi Tan, Fei Huang, Xu Cheng, Huajun Chen"",ArXiv,,,,,2022,5,,https://semanticscholar.org/paper/5a61585cea70ad0ec228d47acddc623103efca1b,""Previous knowledge graph embedding approaches usually map entities to representations and utilize score functions to predict the target entities, yet they struggle to reason rare or emerging unseen entities. In this paper, we propose kNN-KGE, a new knowledge graph embedding approach, by linearly interpolating its entity distribution with knearest neighbors. We compute the nearest neighbors based on the distance in the entity embedding space from the knowledge store. Our approach can allow rare or emerging entities to be memorized explicitly rather than implicitly in model parameters. Experimental results demonstrate that our approach can improve inductive and transductive link prediction results and yield better performance for low-resource settings with only a few triples, which might be easier to reason via explicit memory1."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"InterHT: Knowledge Graph Embeddings by Interaction between Head and Tail Entities,Distance-based methods show promising performance on link prediction task.,""Baoxin Wang, Qingye Meng, Ziyue Wang, Dayong Wu, Wanxiang Che, Shijin Wang, Zhigang Chen, Cong Liu"",ArXiv,,,,,2022,7,,https://semanticscholar.org/paper/39acaf86de56a9054ccab9af1594395e2991c9ac,""Knowledge graph embedding (KGE) models learn the representation of entities and relations in knowledge graphs. Distance-based methods show promising performance on link prediction task, which predicts the result by the distance between two entity representations. However, most of these methods represent the head entity and tail entity separately, which limits the model capacity. We propose two novel distance-based methods named InterHT and InterHT+ that allow the head and tail entities to interact better and get better entity representation. Experimental results show that our proposed method achieves the best results on ogbl-wikikg2 dataset."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Reasoning Through Memorization: Nearest Neighbor Knowledge Graph Embeddings,A knowledge graph embedding approach with pre-trained language models can allow rare or emerging entities to be memorized explicitly rather than implicitly in model parameters.,""Ningyu Zhang, Xin Xie, Xiang Chen, Shumin Deng, Chuanqi Tan, Fei Huang, Xu Cheng, Huajun Chen"",ArXiv,,,,,2022,7,,https://semanticscholar.org/paper/b30759d87369a5fadd7d252ec8514abfba68ca10,""Previous knowledge graph embedding approaches usually map entities to representations and utilize score functions to predict the target entities, yet they struggle to reason rare or emerging unseen entities. In this paper, we propose kNN-KGE, a new knowledge graph embedding approach with pre-trained language models, by linearly interpolating its entity distribution with k-nearest neighbors.We compute the nearest neighbors based on the distance in the entity embedding space from the knowledge store. Our approach can allow rare or emerging entities to be memorized explicitly rather than implicitly in model parameters. Experimental results demonstrate that our approach can improve inductive and transductive link prediction results and yield better performance for low-resource settings with only a few triples, which might be easier to reason via explicit memory1."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Multi-task Pre-training Language Model for Semantic Network Completion,A triple-style negative sampling in a batch of data can significantly increase the proportion of negative sampling while keeping the training time almost unchanged.,""Da Li, Sen Yang, Kele Xu, Ming Yi, Yukai He, Huaimin Wang"",,,,,,2022,3,,https://semanticscholar.org/paper/2924d471e3478380d4afac2940d45ea437a9c230,""—Semantic networks, such as the knowledge graph, can represent the knowledge leveraging the graph structure. Although the knowledge graph shows promising values in natural language processing, it suffers from incompleteness. This paper focuses on knowledge graph completion by predicting linkage be- tween entities, which is a fundamental yet critical task. Semantic matching is a potential solution for link prediction as it can deal with unseen entities, while the translational distance based methods struggle with the unseen entities. However, to achieve competitive performance as translational distance based methods, semantic matching based methods require large-scale datasets for the training purpose, which are typically unavailable in practical settings. Therefore, we employ the language model and introduce a novel knowledge graph architecture named LP-BERT, which contains two main stages: multi-task pre-training and knowledge graph ?ne-tuning. In the pre-training phase, three tasks are taken to drive the model to learn the relationship information from triples by predicting either entities or relations. While in the ?ne-tuning phase, inspired by contrastive learning, we design a triple-style negative sampling in a batch, which greatly increases the proportion of negative sampling while keeping the training time almost unchanged. Further","more, we propose a new data augmentation meth",od u,til,izin,g the,in,verse,relations,hip,of,tripl,es,t,o impr,ove,the,pe,rf,orma,nc,e and,ro,bust,ness,of t,he mod,el.,To de,mon,stra,te,the,effe,ctiv,"eness of our proposed framework, we conduct extensive experiments on three widely-used knowledge graph datasets, WN18RR, FB15k-237, and UMLS. The experi- mental results demonstrate the superiority of our methods, and our approach achieves state-of-the-art results on the WN18RR and FB15k-237 datasets. Signi?cantly, the Hits@10 indicator is improved by 5% from the previous state-of-the-art result on the WN18RR dataset while reaching 100% on the UMLS dataset. (MRM). Three tasks are trained in parallel, using the multi-task manner. In the ?ne-tuning stage, we design a triple-style negative sampling in a batch of data, which can signi?cantly increase the proportion of negative sampling while retaining the training time almost unchanged."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Scaling Knowledge Graph Embedding Models,A scaling solution for GNN-based knowledge graph embedding models achieves a 16x speed up on benchmark datasets.,""Nasrullah Sheikh, Xiao Qin, B. Reinwald, Chuan Lei"",,,,,,2022,1,,https://semanticscholar.org/paper/b3cbbc1f34a20c22853f3dd347fd635b2e414fd5,""Developing scalable solutions for training Graph Neural Networks (GNNs) for link prediction tasks is challenging due to the high data dependencies which entail high computational cost and huge memory footprint. We propose a new method for scaling training of knowledge graph embedding models for link prediction to address these challenges. Towards this end, we propose the following algorithmic strategies: self-sufficient partitions, constraint-based negative sampling, and edge mini-batch training. Both, partitioning strategy and constraint-based negative sampling, avoid cross partition data transfer during training. In our experimental evaluation, we show that our scaling solution for GNN-based knowledge graph embedding models achieves a 16x speed up on benchmark datasets while maintaining a comparable model performance as non-distributed methods on standard metrics."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"An Open Challenge for Inductive Link Prediction on Knowledge Graphs,The ILPC 2022 challenge on knowledge graph inductive link prediction is a novel open challenge on knowledge graphs.,""Mikhail  Galkin, Max  Berrendorf, Charles Tapley Hoyt"",ArXiv,,,10.48550/arXiv.2203.01520,,2022,,https://doi.org/10.48550/arXiv.2203.01520,https://semanticscholar.org/paper/b3698a557f8bf354a62b4f75799724d090b54876,""An emerging trend in representation learning over knowledge graphs (KGs) moves beyond transductive link prediction tasks over a fixed set of known entities in favor of inductive tasks that imply training on one graph and performing inference over a new graph with unseen entities. In inductive setups, node features are often not available and training shallow entity embedding matrices is meaningless as they cannot be used at inference time with unseen entities. Despite the growing interest, there are not enough benchmarks for evaluating inductive representation learning methods. In this work, we introduce ILPC 2022 , a novel open challenge on KG inductive link prediction. To this end, we constructed two new datasets based on Wikidata with various sizes of training and inference graphs that are much larger than existing inductive benchmarks. We also provide two strong baselines leveraging recently proposed inductive methods. We hope this challenge helps to streamline community efforts in the inductive graph representation learning area. ILPC 2022 follows best practices on evaluation fairness and reproducibility, and is available at https://github.com/pykeen/ilpc2022."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Ontology Completion with Graph-Based Machine Learning: A Comprehensive Evaluation,A structure-only link analysis can offer a scalable and computationally efficient ontology completion approach for a subset of analyzed data sets.,""Sebastian Mežnar, Matej Bevec, N. Lavra?, Blaž Škrlj"",Machine Learning and Knowledge Extraction,,,10.3390/make4040056,https://www.mdpi.com/2504-4990/4/4/56/pdf?version=1669882603,2022,,https://doi.org/10.3390/make4040056,https://semanticscholar.org/paper/159ccc3e08a62b2a9cf5aed911de237c174c8f34,""Increasing quantities of semantic resources offer a wealth of human knowledge, but their growth also increases the probability of wrong knowledge base entries. The development of approaches that identify potentially spurious parts of a given knowledge base is therefore highly relevant. We propose an approach for ontology completion that transforms an ontology into a graph and recommends missing edges using structure-only link analysis methods. By systematically evaluating thirteen methods (some for knowledge graphs) on eight different semantic resources, including Gene Ontology, Food Ontology, Marine Ontology, and similar ontologies, we demonstrate that a structure-only link analysis can offer a scalable and computationally efficient ontology completion approach for a subset of analyzed data sets. To the best of our knowledge, this is currently the most extensive systematic study of the applicability of different types of link analysis methods across semantic resources from different domains. It demonstrates that by considering symbolic node embeddings, explanations of the predictions (links) can be obtained, making this branch of methods potentially more valuable than black-box methods."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"InterHT: Knowledge Graph Embeddings by Interaction between Head and Tail Entities,Distance-based methods show promising performance on link prediction task.,""Baoxin Wang, Qingye Meng, Ziyue Wang, Dayong Wu, Wanxiang Che, Shijin Wang, Zhigang Chen, Cong Liu"",ArXiv,,,,,2022,3,,https://semanticscholar.org/paper/d0ec391c56b4d1593f8e305d49f5a409a94b1d4a,""Knowledge graph embedding (KGE) models learn the representation of entities and relations in knowledge graphs. Distance-based methods show promising performance on link prediction task, which predicts the result by the distance between two entity representations. However, most of these methods represent the head entity and tail entity separately, which limits the model capacity. We propose a novel distance-based method named InterHT that allows the head and tail entities to interact better and get better entity representation. Experimental results show that our proposed method achieves the best results on ogblwikikg2 dataset."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Joint Language Semantic and Structure Embedding for Knowledge Graph Completion,The semantics in the natural language description of the knowledge triplets with their structure information play an important role in knowledge graph completion.,""Jianhao Shen, Chenguang Wang, Linyuan Gong, Dawn Song"",International Conference on Computational Linguistics,,,10.48550/arXiv.2209.08721,,2022,4,https://doi.org/10.48550/arXiv.2209.08721,https://semanticscholar.org/paper/933cb8bf1cd50d6d5833a627683327b15db28836,""The task of completing knowledge triplets has broad downstream applications. Both structural and semantic information plays an important role in knowledge graph completion. Unlike previous approaches that rely on either the structures or semantics of the knowledge graphs, we propose to jointly embed the semantics in the natural language description of the knowledge triplets with their structure information. Our method embeds knowledge graphs for the completion task via fine-tuning pre-trained language models with respect to a probabilistic structured loss, where the forward pass of the language models captures semantics and the loss reconstructs structures. Our extensive experiments on a variety of knowledge graph benchmarks have demonstrated the state-of-the-art performance of our method. We also show that our method can significantly improve the performance in a low-resource regime, thanks to the better use of semantics. The code and datasets are available at https://github.com/pkusjh/LASS."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"A Framework for Adapting Pre-Trained Language Models to Knowledge Graph Completion,Entity representations can be extracted from pre-trained language models to develop knowledge graph completion models that are more robust to the naturally occurring sparsity found in knowledge graphs.,""Justin Lovelace, C. Rosé"",Conference on Empirical Methods in Natural Language Processing,,,,,2022,,,https://semanticscholar.org/paper/9dfe43db470ad2ac0ee8444a7605f28fecb2c661,""Recent work has demonstrated that entity representations can be extracted from pre-trained language models to develop knowledge graph completion models that are more robust to the naturally occurring sparsity found in knowledge graphs. In this work, we conduct a comprehensive exploration of how to best extract and incorporate those embeddings into knowledge graph completion models. We explore the suitability of the extracted embeddings for direct use in entity ranking and introduce both unsupervised and supervised processing methods that can lead to improved downstream performance. We then introduce supervised embedding extraction methods that can extract more informative representations. We then synthesize our findings and develop a knowledge graph completion model that significantly outperforms recent neural models."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"MADLINK: Attentive multihop and entity descriptions for link prediction in knowledge graphs,The proposed approach outperforms most of the state-of-the-art models.,""Russa Biswas, Harald Sack, Mehwish Alam"",Semantic Web,,1.242 (2878),10.3233/sw-222960,https://content.iospress.com:443/download/semantic-web/sw222960?id=semantic-web%2Fsw222960,2022,1,https://doi.org/10.3233/sw-222960,https://semanticscholar.org/paper/f899e1c18b0eaf4614d0e675023031e9b253c01b,""Knowledge Graphs (KGs) comprise of interlinked information in the form of entities and relations between them in a particular domain and provide the backbone for many applications. However, the KGs are often incomplete as the links between the entities are missing. Link Prediction is the task of predicting these missing links in a KG based on the existing links. Recent years have witnessed many studies on link prediction using KG embeddings which is one of the mainstream tasks in KG completion. To do so, most of the existing methods learn the latent representation of the entities and relations whereas only a few of them consider contextual information as well as the textual descriptions of the entities. This paper introduces an attentive encoder-decoder based link prediction approach considering both structural information of the KG and the textual entity descriptions. Random walk based path selection method is used to encapsulate the contextual information of an entity in a KG. The model explores a bidirectional Gated Recurrent Unit (GRU) based encoder-decoder to learn the representation of the paths whereas SBERT is used to generate the representation of the entity descriptions. The proposed approach outperforms most of the state-of-the-art models and achieves comp",arable results with the rest when evaluated w,ith,FB1,"5K,",FB15K-,23,"7, WN","18, WN18RR",", an",d Y,AGO3-,10,d,ataset,"s.""",",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"A Few-Shot Inductive Link Prediction Model in Knowledge Graphs,A graph neural network can effectively make predictions on a knowledge graph composed of unknown entities.,""Ruiting Yang, Zhongcheng Wei, Yongjian Fan, Jijun Zhao"",IEEE Access,,0.927 (4581),10.1109/ACCESS.2022.3206037,https://ieeexplore.ieee.org/ielx7/6287639/6514899/09887936.pdf,2022,,https://doi.org/10.1109/ACCESS.2022.3206037,https://semanticscholar.org/paper/0b8432a878fcc8dc6f7255521ef1b101489f1119,""Link prediction aims to predict the missing facts in knowledge graphs. Most previous work focuses on the transductive link prediction, which cannot predict unknown entities. However, knowledge graphs are evolving in practical scenarios and new entities are constantly added. A graph neural network based on subgraph structure can effectively make predictions on a knowledge graph composed of unknown entities. Based on this method, we propose a new inductive link prediction model MILP, which uses meta-learning to predict unseen entities on few-shot data. Specifically, MILP divides the training data into four tasks according to the relation types and constructs a subgraph structure of each triplet, and then trains each task sequentially through the meta-learning framework which uses graph neural network to score the triplets. Experiments are carried out on the benchmark inductive link prediction datasets, and the results show that in most cases the proposed model achieves better results than the baseline models, proving the effectiveness of MILP."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Influence Functions for Interpretable link prediction in Knowledge Graphs for Intelligent Environments,Influence functions do not scale well to large knowledge graphs.,""Unai Zulaika, Aitor Almeida, D. López-de-Ipiña"",2022 7th International Conference on Smart and Sustainable Technologies (SpliTech),,,10.23919/SpliTech55088.2022.9854264,,2022,,https://doi.org/10.23919/SpliTech55088.2022.9854264,https://semanticscholar.org/paper/43603e9d3c31985f0e72b5a123694abd53502fa6,""Knowledge graphs are large, graph-structured databases used in many use-case scenarios such as Intelligent Environments. Many Artificial Intelligent latent feature models are used to infer new facts in Knowledge Graphs. Despite their success, the lack of interpretability remains a challenge to overcome. This paper applies influence functions to obtain the most significant facts when predicting new knowledge and allows users to understand these models. However, Influence Functions do not scale well. We present an efficient method to scale up influence functions to large Knowledge Graphs to overcome such an issue. It drastically reduces the number of training samples when computing influences and uses fast curvature matrix-vector products to linearize the computation steps required for the inverse Hessian. We conduct experiments on different sized Knowledge Graphs demonstrating the scalability of our approach and its effectiveness in measuring the most influential facts. Our method provides an intuitive understanding of link prediction behaviour in Knowledge Graphs and Intelligent Environments."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"""The Largest Knowledge Graph in Materials Science Entities, Relations, and Link Prediction through Graph Representation Learning"",MatKG allows the rapid dissemination and assimilation of data when used as a knowledge base.,""John Dagdelen, Alex Dunn, O. Kononova, Mary Brady, C. Campbell, Arthur P Ramirez, Lars PE Yunker"",,,,,,2022,,,https://semanticscholar.org/paper/4538fd99ea0fce7bc255985046a9890312d6d1ed,""This paper introduces MatKG, a novel graph database of key concepts in material 1 science spanning the traditional material-structure-property-processing paradigm. 2 MatKG is autonomously generated through transformer-based, large language 3 models and generates pseudo ontological schema through statistical co-occurrence 4 mapping. At present, MatKG contains over 2 million unique relationship triples 5 derived from 80,000 entities. This allows the curated analysis, querying, and 6 visualization of materials knowledge at unique resolution and scale. Further, 7 Knowledge Graph Embedding models are used to learn embedding representations 8 of nodes in the graph which are used for downstream tasks such as link prediction 9 and entity disambiguation. MatKG allows the rapid dissemination and assimilation 10 of data when used as a knowledge base, while enabling the discovery of new 11 relations when trained as an embedding model."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Complex Query Answering with Neural Link Predictors (Extended Abstract),Neural link predictors are useful for identifying missing edges in large scale Knowledge Graphs.,""Pasquale Minervini, Erik Arakelyan, Daniel Daza, M. Cochez"",International Joint Conference on Artificial Intelligence,,,10.24963/ijcai.2022/741,https://www.ijcai.org/proceedings/2022/0741.pdf,2022,1,https://doi.org/10.24963/ijcai.2022/741,https://semanticscholar.org/paper/e97560b9a11ac927c9001d510ccc713d62b307b7,""Neural link predictors are useful for identifying missing edges in large scale Knowledge Graphs. However, it is still not clear how to use these models for answering more complex queries containing logical conjunctions (?), disjunctions (?), and existential quantifiers (?). We propose a framework for efficiently answering complex queries on in- complete Knowledge Graphs. We translate each query into an end-to-end differentiable objective, where the truth value of each atom is computed by a pre-trained neural link predictor. We then analyse two solutions to the optimisation problem, including gradient-based and combinatorial search. In our experiments, the proposed approach produces more accurate results than state-of-the-art methods — black-box models trained on millions of generated queries — without the need for training on a large and diverse set of complex queries. Using orders of magnitude less training data, we obtain relative improvements ranging from 8% up to 40% in Hits@3 across multiple knowledge graphs. We find that it is possible to explain the outcome of our model in terms of the intermediate solutions identified for each of the complex query atoms. All our source code and datasets are available online (https://github.com/uclnl","p/cqd)."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"DiriE: Knowledge Graph Embedding with Dirichlet Distribution,""Existing methods are subject to at least one of the following limitations: 1) ignoring the uncertainty, 2) incapability of complex relation patterns."",""Feiyang Wang, Zhongbao Zhang, Li Sun, Junda Ye, Yang Yan"",The Web Conference,,,10.1145/3485447.3512028,,2022,4,https://doi.org/10.1145/3485447.3512028,https://semanticscholar.org/paper/621dd7026238c6f6df01f54f4371bf342ec94d91,""Knowledge graph embedding aims to learn representations of entities and relations in low-dimensional space. Recently, extensive studies combine the characteristics of knowledge graphs with different geometric spaces, including Euclidean space, complex space, hyperbolic space and others, which achieves significant progress in representation learning. However, existing methods are subject to at least one of the following limitations: 1) ignoring the uncertainty, 2) incapability of complex relation patterns. To address the above issues simultaneously, we propose a novel model named DiriE, which embeds entities as Dirichlet distributions and relations as multinomial distributions. DiriE employs Bayesian inference to measure the relations between entities and learns binary embeddings of knowledge graphs for modeling complex relation patterns. Additionally, we propose a two-step negative triple generation method that generates negative triples of both entities and relations. We conduct a solid theoretical analysis to demonstrate the effectiveness and robustness of our method, including the expressiveness of complex relation patterns and the ability to model uncertainty. Furthermore, extensive experiments show that our method outperforms state-of-the-art methods in link prediction on benchm","ark datasets."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Sampling Enclosing Subgraphs for Link Prediction,A scalable link prediction solution is ScaLed.,""Paul Louis, Shweta Ann Jacob, Amirali Salehi-Abari"",International Conference on Information and Knowledge Management,,,10.1145/3511808.3557688,http://arxiv.org/pdf/2206.12004,2022,2,https://doi.org/10.1145/3511808.3557688,https://semanticscholar.org/paper/274f65f0f48a6e84e0af4c53a613dcf64efe4178,""Link prediction is a fundamental problem for graph-structured data (e.g., social networks, drug side-effect networks, etc.). Graph neural networks have offered robust solutions for this problem, specifically by learning the representation of the subgraph enclosing the target link (i.e., pair of nodes). However, these solutions do not scale well to large graphs as extraction and operation on enclosing subgraphs are computationally expensive. This paper presents a scalable link prediction solution, that we call ScaLed, which utilizes sparse enclosing subgraphs to make predictions. To extract sparse enclosing subgraphs, ScaLed takes multiple random walks from a target pair of nodes, then operates on the sampled enclosing subgraph induced by all visited nodes. By leveraging the smaller sampled enclosing subgraph, ScaLed can scale to larger graphs with much less overhead while maintaining high accuracy. Through comprehensive experiments, we have shown that ScaLed can produce comparable accuracy to those reported by the existing subgraph representation learning frameworks while being less computationally demanding."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Introducing RezoJDM16k: a French KnowledgeGraph DataSet for Link Prediction,""RezoJDM16k can be employed in many NLP downstream tasks for the French language such as machine translation, question-answering, and recommendation systems."",""M. Mirzapour, Waleed Ragheb, Mohammad Javad Saeedizade, Kévin Cousot, Hélène Jacquenet, Lawrence Carbon, Mathieu Lafourcade"",International Conference on Language Resources and Evaluation,,,,,2022,,,https://semanticscholar.org/paper/fb0754a875a3e001f57420295482d4c68a31eeea,""Knowledge graphs applications, in industry and academia, motivate substantial research directions towards large-scale information extraction from various types of resources. Nowadays, most of the available knowledge graphs are either in English or multilingual. In this paper, we introduce RezoJDM16k, a French knowledge graph dataset based on RezoJDM. With 16k nodes, 832k triplets, and 53 relation types, RezoJDM16k can be employed in many NLP downstream tasks for the French language such as machine translation, question-answering, and recommendation systems. Moreover, we provide strong knowledge graph embedding baselines that are used in link prediction tasks for future benchmarking. Compared to the state-of-the-art English knowledge graph datasets used in link prediction, RezoJDM16k shows a similar promising predictive behavior."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Knowledge Graph Entity Type Prediction with Relational Aggregation Graph Attention Network,The encoder relational aggregation graph attention network performs entity type prediction in the knowledge graph.,""Changlong Zou, Jingmin An, Guan-yu Li"",Extended Semantic Web Conference,,,,,2022,1,,https://semanticscholar.org/paper/8b54381a46e329571b5d144a4d65f7b8b1f6313e,""Most of the knowledge graph completion methods focus on inferring missing entities or relations between entities in the knowledge graphs. However, many knowledge graphs are missing entity types. The goal of entity type prediction in the knowledge graph is to infer the missing entity types that belong to entities in the knowledge graph, that is, (entity, entity type=?). At present, most knowledge graph entity type prediction models tend to model entities and entity types, which will cause the relations between entities to not be effectively used, and the relations often contain rich semantic information. To utilize the information contained in the relation when performing entity type prediction, we propose a method for entity type prediction based on relational aggregation graph attention network (RACE2T), which consists of an encoder relational aggregation graph attention network (FRGAT) and a decoder (CE2T). The encoder FRGAT uses the scoring function of the knowledge graph completion method to calculate the attention coefficient between entities. This attention coefficient will be used to aggregate the information of relations and entities in the neighborhood of the entity to utilize the information of the relations. The decoder CE2T is designed based on convolutional neural network, which models the entity embeddings output by FRGAT and entity type embe","ddings, and performs entity type prediction.",The,exp,erim,ental,re,sults,demonstra,te t,hat,the,me,th,od pro,pos,ed i,n t,hi,s pa,pe,r out,per,form,s exi,stin,g meth,ods.,The,sou,rce,cod,e an,d da,tase,"t for RACE2T can be downloaded from: https://github.com/GentlebreezeZ/RACE2T."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Graph Embedding Method Based on Biased Walking for Link Prediction,Existing graph representation learning methods based on random walks are uncontrolled.,""Mingshuo Nie, Dongming Chen, Dongqi Wang"",Mathematics,,0.538 (9300),10.3390/math10203778,https://www.mdpi.com/2227-7390/10/20/3778/pdf?version=1666686726,2022,1,https://doi.org/10.3390/math10203778,https://semanticscholar.org/paper/17a54acbb7c53a2500ae043dcb4ea490265092ce,""Link prediction is an essential and challenging problem in research on complex networks, which can provide research tools and theoretical supports for the formation and evolutionary mechanisms of networks. Existing graph representation learning methods based on random walks usually ignore the influence of local network topology on the transition probability of walking nodes when predicting the existence of links, and the sampling strategy of walking nodes during random walks is uncontrolled, which leads to the inability of these methods to effectively learn high-quality node vectors to solve the link prediction problem. To address the above challenges, we propose a novel graph embedding method for link prediction. Specifically, we analyze the evolution mechanism of links based on triadic closure theory and use the network clustering coefficient to represent the aggregation ability of the network’s local structure, and this adaptive definition of the aggregation ability of the local structure enables control of the walking strategy of nodes in the random walking process. Finally, node embedding generated based on biased walking paths is employed to solve the link prediction problem. Extensive experiments and analyses show that the TCW algorithm provides high accuracy across a diverse set of datas","ets."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Link prediction with Simple Graph Convolution and regularized Simple Graph Convolution,Imposing regularization improves model performance.,""Patrick Pho, Alexander V. Mantzaris"",International Conference on Information System and Data Mining,,,10.1145/3546157.3546163,,2022,1,https://doi.org/10.1145/3546157.3546163,https://semanticscholar.org/paper/83eded75bb11ea5f742c3cce195396ab300fcece,""Attributed graphs are used to model real-life systems in many domains such as social science, biology, etc. Link prediction is an important task on attributed graph with a wide range of useful applications. Simple link prediction approaches have limitation in their capability to capture network topology and node attributes. Graph Neural Networks (GNNs) provide an efficient framework incorporating node attributes and connectivity to produce informative embeddings for many downstream tasks including link prediction. In this work, we study two variants of GNNs, namely Simple Graph Convolution (SGC) and its extension for link prediction on three citation datasets. While it is fast and efficient, our model is insufficient to capture the complex node connectivities. On the other hand, imposing regularization reduces overfitting and improves model performance."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"""A Survey on Knowledge Graphs: Representation, Acquisition, and Applications"",""Knowledge graph embedding is organized from four aspects of representation space, scoring function, encoding models, and auxiliary information."",""Shaoxiong  Ji, Shirui  Pan, Erik  Cambria, Pekka  Marttinen, Philip S. Yu"",IEEE Transactions on Neural Networks and Learning Systems,,4.222 (355),10.1109/TNNLS.2021.3070843,https://research-repository.griffith.edu.au/bitstream/10072/416709/2/Pan2923674-Accepted.pdf,2022,340,https://doi.org/10.1109/TNNLS.2021.3070843,https://semanticscholar.org/paper/c9ec8cf5ce461647d0d1cf67093feeadea5d9957,""Human knowledge provides a formal understanding of the world. Knowledge graphs that represent structural relations between entities have become an increasingly popular research direction toward cognition and human-level intelligence. In this survey, we provide a comprehensive review of the knowledge graph covering overall research topics about: 1) knowledge graph representation learning; 2) knowledge acquisition and completion; 3) temporal knowledge graph; and 4) knowledge-aware applications and summarize recent breakthroughs and perspective directions to facilitate future research. We propose a full-view categorization and new taxonomies on these topics. Knowledge graph embedding is organized from four aspects of representation space, scoring function, encoding models, and auxiliary information. For knowledge acquisition, especially knowledge graph completion, embedding methods, path inference, and logical rule reasoning are reviewed. We further explore several emerging topics, including metarelational learning, commonsense reasoning, and temporal knowledge graphs. To facilitate future research on knowledge","graphs, we also provide a curated collection",of d,ata,set,s and,op,en-so,urce libra,ries,on,diff,er,en,t task,s.,In t,he,en,"d, w",e,have,a t,horo,ugh o,utlo,ok on,seve,ral p,rom,isin,g r,esea,rch,dire,"ctions."",,Review",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Learning Relation-Specific Representations for Few-shot Knowledge Graph Completion,The embeddings of two entities are insufficient to represent the semantic information of their relationship.,""Yuling Li, Kui Yu, Yuhong Zhang, Xindong Wu"",ArXiv,,,10.48550/arXiv.2203.11639,,2022,1,https://doi.org/10.48550/arXiv.2203.11639,https://semanticscholar.org/paper/cffe596ef04dc60604b9977ddfe0a791d057c0e4,""Recent years have witnessed increasing interest in few-shot knowledge graph completion (FKGC), which aims to infer unseen query triples for a few-shot relation using a handful of reference triples of the relation. The primary focus of existing FKGC methods lies in learning the relation representations that can reflect the common information shared by the query and reference triples. To this end, these methods learn the embeddings of entities with their direct neighbors, and use the concatenation of the entity embeddings as the relation representations. However, the entity embeddings learned only from direct neighborhoods may have low expressiveness when the entity has sparse neighbors or shares a common local neighborhood with other entities. Moreover, the embeddings of two entities are insufficient to represent the semantic information of their relationship, especially when they have multiple relations. To address these issues, we propose a Relation-Specific Context Learning (RSCL) framework, which exploits graph contexts of triples to capture the semantic information of relations and entities simultaneously. Specifically, we first extract graph contexts for each triple, which can provide long-term entity-relation dependencies. To model the graph contexts, we then develop a hierarchical relation-specific learner to learn glo",bal and local relation-specific representatio,ns f,or,rela,tions,by,capt,uring cont,extu,ali,zed i,nf,or,mation,of,tri,ple,s,and,in,corpo,rat,ing,local,inf,ormati,on o,f ent,iti,es.,Fin,ally,", we",uti,"lize the learned representations to predict the likelihood of the query triples. Experimental results on two public datasets demonstrate that RSCL outperforms state-of-the-art FKGC methods."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"A Weighted Symmetric Graph Embedding Approach for Link Prediction in Undirected Graphs.,The appropriate aggregating weight assignment and the bidirectional concatenation enable us to learn more accurate and symmetric edge representations for link prediction.,""Zhixiao Wang, Yahui Chai, Chengcheng Sun, Xiaobin Rui, Hao Mi, Xinyu Zhang, Philip S. Yu"",IEEE Transactions on Cybernetics,,4.506 (325),10.1109/TCYB.2022.3181810,,2022,2,https://doi.org/10.1109/TCYB.2022.3181810,https://semanticscholar.org/paper/8fa8120119da0ab7417595d87714c5d48677ff59,""Link prediction is an important task in social network analysis and mining because of its various applications. A large number of link prediction methods have been proposed. Among them, the deep learning-based embedding methods exhibit excellent performance, which encodes each node and edge as an embedding vector, enabling easy integration with traditional machine learning algorithms. However, there still remain some unsolved problems for this kind of methods, especially in the steps of node embedding and edge embedding. First, they either share exactly the same weight among all neighbors or assign a completely different weight to each node to obtain the node embedding. Second, they can hardly keep the symmetry of edge embeddings obtained from node representations by direct concatenation or other binary operations such as averaging and Hadamard product. In order to solve these problems, we propose a weighted symmetric graph embedding approach for link prediction. In node embedding, the proposed approach aggregates neighbors in different orders with different aggregating weights. In edge embedding, the proposed approach bidirectionally concatenates node pairs both forwardly and b",ackwardly to guarantee the symmetry of edge r,epre,sen,tati,ons wh,il,e pre,serving lo,cal,str,uctur,al,i,nforma,tio,n. T,he,ex,peri,me,ntal,res,ults,show,tha,t our,prop,osed,app,roac,h c,an b,ette,r pr,"edict network links, outperforming the state-of-the-art methods. The appropriate aggregating weight assignment and the bidirectional concatenation enable us to learn more accurate and symmetric edge representations for link prediction."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Towards Loosely-Coupling Knowledge Graph Embeddings and Ontology-based Reasoning,The prediction accuracy of knowledge graph embeddings is enhanced by domain knowledge that may not be included in the input knowledge graph.,""Zoi Kaoudi, Abelardo Carlos Mart??nez Lorenzo, V. Markl"",ArXiv,,,,,2022,2,,https://semanticscholar.org/paper/8ef2e6b11b519b609bfaa7ed056f621cee15d552,""Knowledge graph completion (a.k.a. link prediction), i.e., the task of inferring missing information from knowledge graphs, is a widely used task in many applications, such as product recommendation and question answering. The state-of-the-art approaches of knowledge graph embeddings and/or rule mining and reasoning are data-driven and, thus, solely based on the information the input knowledge graph contains. This leads to unsatisfactory prediction results which make such solutions inapplicable to crucial domains such as healthcare. To further enhance the accuracy of knowledge graph completion we propose to loosely-couple the data-driven power of knowledge graph embeddings with domain-specific reasoning stem-ming from experts or entailment regimes (e.g., OWL2). In this way, we not only enhance the prediction accuracy with domain knowledge that may not be included in the input knowledge graph but also allow users to plugin their own knowledge graph embedding and reasoning method. Our initial results show that we enhance the MRR accuracy of vanilla knowledge graph embeddings by up to 3x and outperform hybrid solutions that combine knowledge graph embeddings with rule mining and reasoning up to 3.5x MRR."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Linkless Link Prediction via Relational Distillation,Link prediction performance of MLPs is boosted by relational knowledge distillation to student MLPs.,""Zhichun Guo, William Shiao, Shichang Zhang, Yozen Liu, N. Chawla, Neil Shah, Tong Zhao"",ArXiv,,,10.48550/arXiv.2210.05801,,2022,2,https://doi.org/10.48550/arXiv.2210.05801,https://semanticscholar.org/paper/2be6804469b99d9c336ef0fe146f9a9ffaa75282,""Graph Neural Networks (GNNs) have been widely used on graph data and have shown exceptional performance in the task of link prediction. Despite their effectiveness, GNNs often suffer from high latency due to non-trivial neighborhood data dependency in practical deployments. To address this issue, researchers have proposed methods based on knowledge distillation (KD) to transfer the knowledge from teacher GNNs to student MLPs, which are known to be efficient even with industrial scale data, and have shown promising results on node classification. Nonetheless, using KD to accelerate link prediction is still unexplored. In this work, we start with exploring two direct analogs of traditional KD for link prediction, i.e., predicted logit-based matching and node representation-based matching. Upon observing direct KD analogs do not perform well for link prediction, we propose a relational KD framework, Linkless Link Prediction (LLP). Unlike simple KD methods that match independent link logits or node representations, LLP distills relational knowledge that is centered around each (anchor) node to the student MLP. Specifically, we propose two matching strategies that complement each other: rank-based matching and distribution-based matching. Extensive experiments demonstrate that LLP boosts the link prediction performance of MLP","s with significant margins, and even outperfo",rms,the,tea,cher G,NN,s on,6 out of 9,ben,chm,arks.,L,LP,also,ach,ieve,s a,7,76.3,7×,spee,dup,in,link,pred,iction,inf,erenc,e c,ompa,red,to,GNNs,on,"the large scale OGB-Citation2 dataset."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Geometry Interaction Knowledge Graph Embeddings,Knowledge graph embeddings can capture a richer set of relational information.,""Zongsheng Cao, Qianqian Xu, Zhiyong Yang, Xiaochun Cao, Qingming Huang"",AAAI,,,10.48550/arXiv.2206.12418,,2022,3,https://doi.org/10.48550/arXiv.2206.12418,https://semanticscholar.org/paper/3f6861639551b33da7276b6e27a9933c467e9d3b,""Knowledge graph (KG) embeddings have shown great power in learning representations of entities and relations for link prediction tasks. Previous work usually embeds KGs into a single geometric space such as Euclidean space (zero curved), hyperbolic space (negatively curved) or hyperspherical space (positively curved) to maintain their specific geometric structures (e.g., chain, hierarchy and ring structures). However, the topological structure of KGs appears to be complicated, since it may contain multiple types of geometric structures simultaneously. Therefore, embedding KGs in a single space, no matter the Euclidean space, hyperbolic space or hyperspheric space, cannot capture the complex structures of KGs accurately. To overcome this challenge, we propose Geometry Interaction knowledge graph Embeddings (GIE), which learns spatial structures interactively between the Euclidean, hyperbolic and hyperspherical spaces. Theoretically, our proposed GIE can capture a richer set of relational information, model key inference patterns, and enable expressive semantic matching across entities. Experimental results on three well-established knowledge graph completion benchmarks show that our GIE achieves the state-of-the-art performance with fewer parameters."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Incorporating Context Graph with Logical Reasoning for Inductive Relation Prediction,The context graph is introduced to process the subgraph and context graph respectively.,""Qika Lin, Jun Liu, Fangzhi Xu, Yudai Pan, Yifan Zhu, Lingling Zhang, Tianzhe Zhao"",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,,,10.1145/3477495.3531996,,2022,5,https://doi.org/10.1145/3477495.3531996,https://semanticscholar.org/paper/8c720eb939259971bcb87f46c92ebb0d2d5497c7,""Relation prediction on knowledge graphs (KGs) aims to infer missing valid triples from observed ones. Although this task has been deeply studied, most previous studies are limited to the transductive setting and cannot handle emerging entities. Actually, the inductive setting is closer to real-life scenarios because it allows entities in the testing phase to be unseen during training. However, it is challenging to precisely conduct inductive relation prediction as there exists requirements of entity-independent relation modeling and discrete logical reasoning for interoperability. To this end, we propose a novel model ConGLR to incorporate context graph with logical reasoning. Firstly, the enclosing subgraph w.r.t. target head and tail entities are extracted and initialized by the double radius labeling. And then the context graph involving relational paths, relations and entities is introduced. Secondly, two graph convolutional networks (GCNs) with the information interaction of entities and relations are carried out to process the subgraph and context graph respectively. Considering the influence of different edges and target relations, we introduce edge-aware and relation-aware attention mechanisms for the subgraph GCN.","Finally, by treating the relational path as r",ule,bod,y an,d targ,et,rela,tion as ru,le h,ead,", we",in,te,grate,neu,ral,cal,cu,lati,ng,and,log,ical,reas,onin,g to o,btai,n ind,uct,ive,sco,res.,And,to,"focus on the specific modeling goals of each module, the stop-gradient is utilized in the information interaction between context graph and subgraph GCNs in the training process. In this way, ConGLR satisfies two inductive requirements at the same time. Extensive experiments demonstrate that ConGLR obtains outstanding performance against state-of-the-art baselines on twelve inductive dataset versions of three common KGs."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"A Comprehensive Survey of Graph Neural Networks for Knowledge Graphs,Graph neural network-based technologies for solving four different knowledge graph tasks are hot research topics in recent years.,""Zi Ye, Y. J. Kumar, G. O. Sing, Fengyan Song, Junsong Wang"",IEEE Access,,0.927 (4581),10.1109/access.2022.3191784,https://ieeexplore.ieee.org/ielx7/6287639/6514899/09831453.pdf,2022,2,https://doi.org/10.1109/access.2022.3191784,https://semanticscholar.org/paper/60a6b17f28e88f17e58f60923d98674358dbd0e4,""The Knowledge graph, a multi-relational graph that represents rich factual information among entities of diverse classifications, has gradually become one of the critical tools for knowledge management. However, the existing knowledge graph still has some problems which form hot research topics in recent years. Numerous methods have been proposed based on various representation techniques. Graph Neural Network, a framework that uses deep learning to process graph-structured data directly, has significantly advanced the state-of-the-art in the past few years. This study firstly is aimed at providing a broad, complete as well as comprehensive overview of GNN-based technologies for solving four different KG tasks, including link prediction, knowledge graph alignment, knowledge graph reasoning, and node classification. Further, we also investigated the related artificial intelligence applications of knowledge graphs based on advanced GNN methods, such as recommender systems, question answering, and drug-drug interaction. This review will provide new insights for further study of KG and GNN."",,Review",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Meta-Learning Based Knowledge Extrapolation for Knowledge Graphs in the Federated Setting,A model trained on an existing knowledge graph needs to embed an emerging knowledge graph with unseen entities and relations.,""Mingyang Chen, Wen Zhang, Zhen Yao, Xian-gan Chen, Mengxiao Ding, Fei Huang, Huajun Chen"",International Joint Conference on Artificial Intelligence,,,10.48550/arXiv.2205.04692,,2022,5,https://doi.org/10.48550/arXiv.2205.04692,https://semanticscholar.org/paper/c943efc1e766a08f67b1364c13292092b17592b1,""We study the knowledge extrapolation problem to embed new components (i.e., entities and relations) that come with emerging knowledge graphs (KGs) in the federated setting. In this problem, a model trained on an existing KG needs to embed an emerging KG with unseen entities and relations. To solve this problem, we introduce the meta-learning setting, where a set of tasks are sampled on the existing KG to mimic the link prediction task on the emerging KG. Based on sampled tasks, we meta-train a graph neural network framework that can construct features for unseen components based on structural information and output embeddings for them. Experimental results show that our proposed method can effectively embed unseen components and outperforms models that consider inductive settings for KGs and baselines that directly use conventional KG embedding methods."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"The DLCC Node Classification Benchmark for Analyzing Knowledge Graph Embeddings,Knowledge graph embeddings have gained a lot of uptake and have been heavily used in link prediction and other downstream prediction tasks.,""Jan Portisch, H. Paulheim"",International Workshop on the Semantic Web,,,10.48550/arXiv.2207.06014,,2022,1,https://doi.org/10.48550/arXiv.2207.06014,https://semanticscholar.org/paper/634cfec43844c73363e7d83e76335aa606cc9358,"". Knowledge graph embedding is a representation learning technique that projects entities and relations in a knowledge graph to continuous vector spaces. Embeddings have gained a lot of uptake and have been heavily used in link prediction and other downstream prediction tasks. Most approaches are evaluated on a single task or a single group of tasks to determine their overall performance. The evaluation is then assessed in terms of how well the embedding approach performs on the task at hand. Still, it is hardly evaluated (and often not even deeply under-stood) what information the embedding approaches are actually learning to represent. To?llthis gap, we present the DLCC (Description Logic Class Constructors) benchmark, a resource to analyze embedding approaches in terms of which kinds of classes they can represent. Two gold standards are presented, one based on the real-world knowledge graph DBpedia and one synthetic gold standard. In addition, an evaluation framework is provided that implements an experiment protocol so that researchers can directly use the gold standard. To demonstrate the use of DLCC, we compare multiple embedding approaches using the gold standards. We ?nd that many DL constructors on DBpedia are actually learned by recognizing di?erent correlated patterns",rather than those de?ned in the gold standard,; we,fu,rthe,r ?nd,th,at sp,eci?c DL c,onst,ruc,"tors,",s,uc,h as c,ard,inal,ity,c,onst,ra,"ints,",ar,e pa,rticu,larl,y hard,to,be le,arn,ed f,or,most,emb,eddi,"ng approaches."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Few-Shot Inductive Learning on Temporal Knowledge Graphs using Concept-Aware Information,A model that mines concept-aware information among entities achieves superior performance on all three datasets.,""Zifeng Ding, Jingpei Wu, Bailan He, Yunpu Ma, Zhen Han, Volker Tresp"",ArXiv,,,10.48550/arXiv.2211.08169,,2022,2,https://doi.org/10.48550/arXiv.2211.08169,https://semanticscholar.org/paper/576a7f578c56626f5e764096e65848c98a25e24d,""Knowledge graph completion (KGC) aims to predict the missing links among knowledge graph (KG) entities. Though various methods have been developed for KGC, most of them can only deal with the KG entities seen in the training set and cannot perform well in predicting links concerning novel entities in the test set. Similar problem exists in temporal knowledge graphs (TKGs), and no previous temporal knowledge graph completion (TKGC) method is developed for modeling newly-emerged entities. Compared to KGs, TKGs require temporal reasoning techniques for modeling, which naturally increases the dif?culty in dealing with novel, yet unseen entities. In this work, we focus on the inductive learning of unseen entities’ representations on TKGs. We propose a few-shot out-of-graph (OOG) link prediction task for TKGs, where we predict the missing entities from the links concerning unseen entities by employing a meta-learning framework and utilizing the meta-information provided by only few edges associated with each unseen entity. We construct three new datasets for TKG few-shot OOG link prediction, and we propose a model that mines the concept-aware information among entities. Experimental results show that our model achieves superior performance on all three datasets and our concept-aware modeling compo","nent demonstrates a strong effect."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Structure Enhanced Graph Neural Networks for Link Prediction,The neglected topological information is shown to be valuable for link prediction tasks.,""Baole Ai, Zhou Qin, Wen Shen, Yong Li"",,,,,,2022,1,,https://semanticscholar.org/paper/c4cf8d9ef8c1a5b40df4cd515054fd3eb85bbb24,""Graph Neural Networks (GNNs) have shown promising results in various tasks, among which link prediction is an important one. GNN models usually follow a node-centric message passing procedure that aggregates the neighborhood information to the central node recursively. Following this paradigm, features of nodes are passed through edges without caring about where the nodes are located and which role they played. However, the neglected topological information is shown to be valuable for link prediction tasks. In this paper, we propose Structure Enhanced Graph neural network (SEG) for link prediction. SEG introduces the path labeling method to capture surrounding topological information of target nodes and then incorporates the structure into an ordinary GNN model. By jointly training the structure encoder and deep GNN model, SEG fuses topological structures and node features to take full advantage of graph information. Experiments on the OGB link prediction datasets demonstrate that SEG achieves state-of-the-art results among all three public datasets."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"OAG$_{\mathrm {know}}$ know : Self-Supervised Learning for Linking Knowledge Graphs,Self-supervised embedding learning framework can achieve competitive performance against its supervised counterpart.,""Xiao Liu, Li Mian, Yuxiao Dong, Fanjin Zhang, Jing Zhang, Jie Tang, Peng Zhang, Jibing Gong, Kuansan Wang"",IEEE Transactions on Knowledge and Data Engineering,,2.431 (883),10.1109/tkde.2021.3090830,,2023,3,https://doi.org/10.1109/tkde.2021.3090830,https://semanticscholar.org/paper/6bd730b2b37d83d2b6b887aa5d07e941b3c3bdb3,""— We propose a self-supervised embedding learning framework—SelfLinKG—to link concepts in heterogeneous knowledge graphs. Without any labeled data, SelfLinKG can achieve competitive performance against its supervised counterpart, and signi?cantly outperforms state-of-the-art unsupervised methods by 26%-50% under linear classi?cation protocol. The essential components of SelfLinKG are local attention-based encoding and momentum contrastive learning. The former aims to learn the graph representation using an attention network, while the latter is to learn a self-supervised model across knowledge graphs using contrastive learning. SelfLinKG has been deployed to build the the new version, called OAG know of Open Academic Graph (OAG). All data and codes are publicly available."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Inductive Logical Query Answering in Knowledge Graphs,Inductive models are able to perform logical reasoning at inference time over unseen nodes generalizing to graphs up to 500% larger than training ones.,""Mikhail Galkin, Zhaocheng Zhu, Hongyu Ren, Jian Tang"",ArXiv,,,10.48550/arXiv.2210.08008,,2022,3,https://doi.org/10.48550/arXiv.2210.08008,https://semanticscholar.org/paper/d2c177f6386e7b88b406e2f741ed5387e4ced3b0,""Formulating and answering logical queries is a standard communication interface for knowledge graphs (KGs). Alleviating the notorious incompleteness of real-world KGs, neural methods achieved impressive results in link prediction and complex query answering tasks by learning representations of entities, relations, and queries. Still, most existing query answering methods rely on transductive entity embeddings and cannot generalize to KGs containing new entities without retraining the entity embeddings. In this work, we study the inductive query answering task where inference is performed on a graph containing new entities with queries over both seen and unseen entities. To this end, we devise two mechanisms lever-aging inductive node and relational structure representations powered by graph neural networks (GNNs). Experimentally, we show that inductive models are able to perform logical reasoning at inference time over unseen nodes generalizing to graphs up to 500% larger than training ones. Exploring the ef?ciency–effectiveness trade-off, we ?nd the inductive relational structure representation method generally achieves higher performance, while the inductive node representation method is able to answer complex queries in the inference-only regime without any training on queries and scales to graphs of",millions of nodes. Code is available at http,s://,git,hub.,com/De,ep,Graph,Learning/I,nduc,tiv,eQE .,""",",",",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Future Event Prediction Based on Temporal Knowledge Graph Embedding,A novel historical and concurrent events attention-aware mechanism by modeling the event knowledge graph sequence recurrently is proposed.,""Zhipeng Li, Shanshan Feng, Jun Shi, Yang Zhou, Yong Liao, Yangzhao Yang, Yangyang Li, Nenghai Yu, Xun Shao"",Computer systems science and engineering,,0.316 (14303),10.32604/csse.2023.026823,https://file.techscience.com/ueditor/files/csse/TSP_CSSE-44-3/TSP_CSSE_26823/TSP_CSSE_26823.pdf,2022,1,https://doi.org/10.32604/csse.2023.026823,https://semanticscholar.org/paper/c620d157f5f999d698f0da86fb91d267ad8ded5c,""Accurate prediction of future events brings great benefits and reduces losses for society in many domains, such as civil unrest, pandemics, and crimes. Knowledge graph is a general language for describing and modeling complex systems. Different types of events continually occur, which are often related to historical and concurrent events. In this paper, we formalize the future event prediction as a temporal knowledge graph reasoning problem. Most existing studies either conduct reasoning on static knowledge graphs or assume knowledges graphs of all timestamps are available during the training process. As a result, they cannot effectively reason over temporal knowledge graphs and predict events happening in the future. To address this problem, some recent works learn to infer future events based on historical event-based temporal knowledge graphs. However, these methods do not comprehensively consider the latent patterns and influences behind historical events and concurrent events simultaneously. This paper proposes a new graph representation learning model, namely Recurrent Event Graph ATtention Network (RE-","GAT), based on a novel historical and concurr",ent,eve,nts,attent,io,n-awa,re mechani,sm b,y m,odeli,ng,t,he eve,nt,know,led,ge,gra,ph,sequ,enc,e re,curre,ntly,. More,spe,cific,all,"y, o",ur,RE-G,AT u,ses,"an attention-based historical events embedding module to encode past events, and employs an attentionbased concurrent events embedding module to model the associations of events at the same timestamp. A translation-based decoder module and a learning objective are developed to optimize the embeddings of entities and relations. We evaluate our proposed method on four benchmark datasets. Extensive experimental results demonstrate the superiority of our RE-GAT model comparing to various baselines, which proves that our method can more accurately predict what events are going to happen."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"A Semantic Mapping Method of Relation Representation Enhancement for Few-Shot Knowledge Graph Completion,The structure around the triple is helpful to understand the relation semantics implicated in the triple.,""Haitao He, Haoran Niu, Jianzhou Feng"",Electronics,,0.159 (20634),10.3390/electronics11223783,https://www.mdpi.com/2079-9292/11/22/3783/pdf?version=1669118183,2022,,https://doi.org/10.3390/electronics11223783,https://semanticscholar.org/paper/d3406cef6c8ce2953f4f7076f92ea7ee674ee8ea,""Few-shot knowledge graph completion (FKGC) tasks involve determining the authenticity of triple candidates using a small number of reference triples with a given relation. Intuitively, the expression of relation features contributes to the close correlation among the triples with the same relation. Therefore, the relation features are not comprehensive enough, leading to the fact that the triples cannot learn sufficient association information for the FKGC task. In this paper, an enhanced relation semantic representation model is constructed for associative reference triples from both aspects of external structure and internal semantics. On the one hand, as the structure around the triple is helpful to understand the relation semantics implicated in the triple, a graph convolution network with attention and relation features is proposed to obtain the graph structure features. Furthermore, the local structure information of triples can be used to learn the deep relation semantics. On the other hand, entity information can enhance the perception of the relation semantics in the triple. Afterward, in order to associate the triples with the same relation by enhanced relation semantics, a semantic mapping method is proposed, which use",s shared merged variables to map the relation,", en",tit,"y, a",nd gra,ph,stru,cture feat,ures,in,to th,e,sa,me emb,edd,ing,spa,ce,. Fi,na,"lly,",a p,roto,type,netw,ork ba,sed,on at,ten,tion,co,nvol,utio,n is,"established to extract the relation prototype representation, and then classify query triples to achieve the purpose of completing the knowledge graph. Through experimental verification, the proposed model achieves excellent performance on two datasets commonly used in the FKGC."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Similarity-Based Graph Enhanced Text Representation Learning for Electronic Component Knowledge Graph Completion,A hybrid encoding approach SiGeTR achieves state-of-the-art performance on the electronic components knowledge graph benchmark dataset.,""Yuxin Liu, Junyu Lu, Pingjian Zhang"",2022 4th World Symposium on Artificial Intelligence (WSAI),,,10.1109/wsai55384.2022.9836400,,2022,,https://doi.org/10.1109/wsai55384.2022.9836400,https://semanticscholar.org/paper/63be9ac5eb9d7d453d1f78dea142b0effa197e91,""In the electronic component supply chain system, manually built knowledge graph usually lacks the alternative relations among the electronic components. Prevalent graph embedding approaches exhibit strong capability in representing graph elements. However, it's difficult to generalize to never-seen elements due to the graph incompleteness, and the Laplacian-based convolution of GCN limits the information propagation to immediate neighbors. In contrast, the pre-trained encoder have stronger ability to extract semantic information. In this paper, we propose a hybrid encoding approach SiGeTR: Similarity-based Graph Enhanced Text Representation. Based on the approach of structural encoding, it incorporates the textual encoding which employs the text of triples in the graph and contextualized repre-sentations. Meanwhile, we propose to use node similarity based convolution matrices in the GCN to compute node embeddings. In experiments, our methods obtain state-of-the-art performance on the electronic components knowledge graph benchmark dataset and achieve significant results with low resources."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"A Co-Embedding Model with Variational Auto-Encoder for Knowledge Graphs,""Traditional knowledge graph embedding techniques usually represent entities/relations as vectors or tensors, mapping them in different semantic spaces and ignoring the uncertainties."",""Lu-Yao Xie, Huimin Huang, Qing Du"",Applied Sciences,,0.44 (11182),10.3390/app12020715,https://www.mdpi.com/2076-3417/12/2/715/pdf?version=1641971281,2022,2,https://doi.org/10.3390/app12020715,https://semanticscholar.org/paper/a1533862421b709c193d6b62390b78cd10c80c3c,""Knowledge graph (KG) embedding has been widely studied to obtain low-dimensional representations for entities and relations. It serves as the basis for downstream tasks, such as KG completion and relation extraction. Traditional KG embedding techniques usually represent entities/relations as vectors or tensors, mapping them in different semantic spaces and ignoring the uncertainties. The affinities between entities and relations are ambiguous when they are not embedded in the same latent spaces. In this paper, we incorporate a co-embedding model for KG embedding, which learns low-dimensional representations of both entities and relations in the same semantic space. To address the issue of neglecting uncertainty for KG components, we propose a variational auto-encoder that represents KG components as Gaussian distributions. In addition, compared with previous methods, our method has the advantages of high quality and interpretability. Our experimental results on several benchmark datasets demonstrate our model’s superiority over the state-of-the-art baselines."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Language Models as Knowledge Embeddings,Structure-based methods leverage textual information and language models.,""Xintao Wang, Qi He, Jiaqing Liang, Yanghua Xiao"",International Joint Conference on Artificial Intelligence,,,10.48550/arXiv.2206.12617,,2022,3,https://doi.org/10.48550/arXiv.2206.12617,https://semanticscholar.org/paper/008caa0a964c9df6b10d2cc3b699981029f83124,""Knowledge embeddings (KE) represent a knowledge graph (KG) by embedding entities and relations into continuous vector spaces. Existing methods are mainly structure-based or description-based. Structure-based methods learn representations that preserve the inherent structure of KGs. They cannot well represent abundant long-tail entities in real-world KGs with limited structural information. Description-based methods leverage textual information and language models. Prior approaches in this direction barely outperform structure-based ones, and suffer from problems like expensive negative sampling and restrictive description demand. In this paper, we propose LMKE, which adopts Language Models to derive Knowledge Embeddings, aiming at both enriching representations of long-tail entities and solving problems of prior description-based methods. We formulate description-based KE learning with a contrastive learning framework to improve efficiency in training and evaluation. Experimental results show that LMKE achieves state-of-the-art performance on KE benchmarks of link prediction and triple classification, especially for long-tail entities."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Kelpie: an Explainability Framework for Embedding-based Link Prediction Models,Link prediction models rely on embeddings to tackle incompleteness in Knowledge Graphs.,""Andrea Rossi, D. Firmani, P. Merialdo, Tommaso Teofili"",Proceedings of the VLDB Endowment,,2.376 (927),,,2022,,,https://semanticscholar.org/paper/055122ac08ae0c6a66e4cfba779002271fb7a9d5,""The latest generations of Link Prediction (LP) models rely on embeddings to tackle incompleteness in Knowledge Graphs, achieving great performance at the cost of interpretability. Their opaqueness limits the trust that users can place in them, hindering their adoption in real-world applications. We have recently introduced Kelpie, an explainability framework tailored specifically for embedding-based LP models. Kelpie can be applied to any embedding-based LP model, and supports two explanation scenarios that we have called necessary and sufficient . In this demonstration we showcase Kelpie’s capability to explain the predictions of models based on vastly different architectures on the 5 major datasets in literature."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Explaining automatic answers generated from knowledge base embedding models.,Advanced question-answering devices are typically produced with the help of large-scale knowledge bases such as DBpedia or Freebase.,Andrey Ruschel,,,,10.11606/d.3.2022.tde-07072022-084934,http://www.teses.usp.br/teses/disponiveis/3/3141/tde-07072022-084934/publico/AndreyRuschelCorr22.pdf,2022,,https://doi.org/10.11606/d.3.2022.tde-07072022-084934,https://semanticscholar.org/paper/5409f6d5b89a757c97f37dec173fc77cf352493a,""While many chatbot systems rely on templates and shallow semantic analysis, advanced question-answering devices are typically produced with the help of largescale knowledge bases such as DBpedia or Freebase. Information extraction is often based on embedding models that map semantically rich information into low-dimensional vectors, allowing computationally efficient calculations. When producing new facts about the world, embeddings often provide correct answers that are very hard to explain from a human perspective as they are based on operations performed in the low-dimensional vector space, thus bearing no meaning to human users. Although interpretability has become a central concern in machine learning, the literature so far has focused on non-relational classifiers (such as deep neural networks); embeddings, however, require a whole range of different approaches. In this work we improve an existing method designed to provide explanations for predictions made by embedding models."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Concept Embedding Models,""Existing concept bottleneck models are unable to find optimal compromises between high task accuracy, robust concept-based explanations, and effective interventions on concepts."",""M. Zarlenga, Pietro Barbiero, Gabriele Ciravegna, G. Marra, Francesco Giannini, M. Diligenti, Z. Shams, F. Precioso, S. Melacci, Adrian Weller, Pietro Lio', M. Jamnik"",ArXiv,,,10.48550/arXiv.2209.09056,,2022,2,https://doi.org/10.48550/arXiv.2209.09056,https://semanticscholar.org/paper/540bb63289636fea28172604881994f7bc41c896,""Deploying AI-powered systems requires trustworthy models supporting effective human interactions, going beyond raw prediction accuracy. Concept bottleneck models promote trustworthiness by conditioning classi?cation tasks on an intermediate level of human-like concepts. This enables human interventions which can correct mispredicted concepts to improve the model’s performance. However, existing concept bottleneck models are unable to ?nd optimal compromises between high task accuracy, robust concept-based explanations, and effective interventions on concepts—particularly in real-world conditions where complete and accurate concept supervisions are scarce. To address this, we propose Concept Embedding Models, a novel family of concept bottleneck models which goes beyond the current accuracy-vs-interpretability trade-off by learning interpretable high-dimensional concept representations. Our experiments demonstrate that Concept Embedding Models (1) attain better or competitive task accuracy w.r.t. standard neural models without"",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Context-Dependent Anomaly Detection with Knowledge Graph Embedding Models,A knowledge graph embedding model can detect context-dependent anomalies with a high degree of accuracy.,""Nathan Vaska, Kevin J. Leahy, Victoria Helus"",2022 IEEE 18th International Conference on Automation Science and Engineering (CASE),,,10.1109/CASE49997.2022.9926631,http://arxiv.org/pdf/2203.09354,2022,,https://doi.org/10.1109/CASE49997.2022.9926631,https://semanticscholar.org/paper/0b96f94cc6bfc7664678908bbe09214f7f45fbca,""Increasing the semantic understanding and contextual awareness of machine learning models is important for improving robustness and reducing susceptibility to data shifts. In this work, we leverage contextual awareness for the anomaly detection problem. Although graphed-based anomaly detection has been widely studied, context-dependent anomaly detection is an open problem and without much current research. We develop a general framework for converting a context-dependent anomaly detection problem to a link prediction problem, allowing well-established techniques from this domain to be applied. We implement a system based on our framework that utilizes knowledge graph embedding models and demonstrates the ability to detect outliers using context provided by a semantic knowledge base. We show that our method can detect context-dependent anomalies with a high degree of accuracy and show that current object detectors can detect enough classes to provide the needed context to show good performance within our example domain."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Knowledge Graph Embedding Methods for Entity Alignment: An Experimental Review,Embedding methods have been used for entity alignment tasks.,""N. Fanourakis, Vasilis Efthymiou, D. Kotzinos, V. Christophides"",ArXiv,,,10.48550/arXiv.2203.09280,,2022,,https://doi.org/10.48550/arXiv.2203.09280,https://semanticscholar.org/paper/9f827aeea7fe134afa9fe4b36a68b0dd668bd142,""In recent years, we have witnessed the proliferation of knowledge graphs (KG) in various domains, aiming to support applications like question answering, recommendations, etc. A frequent task when integrating knowledge from different KGs is to find which subgraphs refer to the same real-world entity. Recently, embedding methods have been used for entity alignment tasks, that learn a vector-space representation of entities which preserves their similarity in the original KGs. A wide variety of supervised, unsupervised, and semi-supervised methods have been proposed that exploit both factual (attribute based) and structural information (relation based) of entities in the KGs. Still, a quantitative assessment of their strengths and weaknesses in real-world KGs according to different performance metrics and KG characteristics is missing from the literature. In this work, we conduct the first meta-level analysis of popular embedding methods for entity alignment, based on a statistically sound methodology. Our analysis reveals statistically significant correlations of different embedding methods with various meta-features extracted by KGs and rank them in a statistically significant way according to their effectiveness across all real-world KGs of our testbed. Finally, we study interesting trade-offs in terms of methods’ effectiveness and efficiency."",,Review",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Using Context-to-Vector with Graph Retrofitting to Improve Word Embeddings,Traditional static embeddings play an important role in low-resource and lightweight settings.,""Jiangbin Zheng, Yile Wang, Ge Wang, Jun Xia, Yufei Huang, Guojiang Zhao, Yue Zhang, Stan Y. Li"",Annual Meeting of the Association for Computational Linguistics,,,10.18653/v1/2022.acl-long.561,https://aclanthology.org/2022.acl-long.561.pdf,2022,3,https://doi.org/10.18653/v1/2022.acl-long.561,https://semanticscholar.org/paper/fe13d9a9c481efcf5591fd0a57c058d0c0088c43,""Although contextualized embeddings generated from large-scale pre-trained models perform well in many tasks, traditional static embeddings (e.g., Skip-gram, Word2Vec) still play an important role in low-resource and lightweight settings due to their low computational cost, ease of deployment, and stability. In this paper, we aim to improve word embeddings by 1) incorporating more contextual information from existing pre-trained models into the Skip-gram framework, which we call Context-to-Vec; 2) proposing a post-processing retrofitting method for static embeddings independent of training by employing priori synonym knowledge and weighted vector distribution. Through extrinsic and intrinsic tasks, our methods are well proven to outperform the baselines by a large margin."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Shoring Up the Foundations: Fusing Model Embeddings and Weak Supervision,L IGER outperforms vanilla weak supervision on six benchmark NLP and video tasks.,""Mayee F. Chen, Daniel Y. Fu, Dyah Adila, Michael Zhang, Frederic Sala, K. Fatahalian, Christopher R'e"",Conference on Uncertainty in Artificial Intelligence,,,10.48550/arXiv.2203.13270,,2022,8,https://doi.org/10.48550/arXiv.2203.13270,https://semanticscholar.org/paper/44e71c0d98f10521bf64b7e743068e8fda640a36,""Foundation models offer an exciting new paradigm for constructing models with out-of-the-box embeddings and a few labeled examples. However, it is not clear how to best apply foundation models without labeled data. A potential approach is to fuse foundation models with weak supervision frameworks, which use weak label sources—pre-trained models, heuristics, crowd-workers—to construct pseudolabels. The challenge is building a combination that best exploits the signal available in both foundation models and weak sources. We propose L IGER , a combination that uses foundation model embeddings to improve two crucial elements of existing weak supervision techniques. First, we produce finer estimates of weak source quality by partitioning the embedding space and learning per-part source accuracies. Second, we improve source coverage by extending source votes in embedding space. Despite the black-box nature of foundation models, we prove results characteriz-ing how our approach improves performance and show that lift scales with the smoothness of label distributions in embedding space. On six benchmark NLP and video tasks, L IGER outperforms vanilla weak supervision by 14.1 points, weakly-supervised kNN and adapters by 11.8 points, and kNN and adapters supervised by traditional hand labels by 7.2 points. powerful"",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"On Embeddings for Numerical Features in Tabular Deep Learning,Embedding numerical features is beneficial for many backbones.,""Yura Gorishniy, Ivan Rubachev, Artem Babenko"",ArXiv,,,10.48550/arXiv.2203.05556,,2022,10,https://doi.org/10.48550/arXiv.2203.05556,https://semanticscholar.org/paper/dba4c862dbaa9b7187ade4ae54dc7e9e425ad4e1,""Recently, Transformer-like deep architectures have shown strong performance on tabular data problems. Unlike traditional models, e.g., MLP, these architectures map scalar values of numerical features to high-dimensional embeddings before mixing them in the main backbone. In this work, we argue that embeddings for numerical features are an underexplored degree of freedom in tabular DL, which allows constructing more powerful DL models and competing with GBDT on some traditionally GBDT-friendly benchmarks. We start by describing two conceptually different approaches to building embedding modules: the first one is based on a piecewise linear encoding of scalar values, and the second one utilizes periodic activations. Then, we empirically demonstrate that these two approaches can lead to significant performance boosts compared to the embeddings based on conventional blocks such as linear layers and ReLU activations. Importantly, we also show that embedding numerical features is beneficial for many backbones, not only for Transformers. Specifically, after proper embeddings, simple MLP-like models can perform on par with the attention-based architectures. Overall, we highlight embeddings for numerical features as an important design aspect with good potential for further improvements in tabular DL."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Emb-GAM: an Interpretable and Efficient Predictor using Pre-trained Language Models,The final model is a transparent linear function of its input features and feature interactions.,""Chandan Singh, Jianfeng Gao"",ArXiv,,,10.48550/arXiv.2209.11799,,2022,2,https://doi.org/10.48550/arXiv.2209.11799,https://semanticscholar.org/paper/f10d1eaf5758244e238a1aa9a79c2f33fa607aec,""Deep learning models have achieved impressive prediction performance but often sacrifice interpretability and speed, critical considerations in high-stakes domains and compute-limited settings. In contrast, generalized additive models (GAMs) can maintain interpretability and speed but often suffer from poor prediction performance due to their inability to effectively capture feature interactions. This work aims to bridge this gap by using pre-trained neural language models to extract embeddings from each input before aggregating them and learning a linear model in the embedding space. The final model (which we call Emb-GAM) is a transparent, linear function of its input features and feature interactions. Leveraging the language model allows Emb-GAM to learn far fewer linear coefficients, model larger interactions, dramatically speed up inference, and generalize well to novel inputs (e.g. unseen ngrams in text). Across a variety of natural-languageprocessing datasets, Emb-GAM achieves strong prediction performance without sacrificing interpretability or speed. All code is made available on Github.1"",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Concept Embedding Models: Beyond the Accuracy-Explainability Trade-Off,""Existing concept bottleneck models are unable to find optimal compromises between high task accuracy, robust concept-based explanations."",""M. Zarlenga, Pietro Barbiero, Gabriele Ciravegna, G. Marra, Francesco Giannini, M. Diligenti, Z. Shams, F. Precioso, S. Melacci, Adrian Weller, Pietro Lio', M. Jamnik"",,,,,,2022,1,,https://semanticscholar.org/paper/ce3036fadfa9692867532fe472ea40b4b81a6dc3,""Deploying AI-powered systems requires trustworthy models supporting effective human interactions, going beyond raw prediction accuracy. Concept bottleneck models promote trustworthiness by conditioning classi?cation tasks on an intermediate level of human-like concepts. This enables human interventions which can correct mispredicted concepts to improve the model’s performance. However, existing concept bottleneck models are unable to ?nd optimal compromises between high task accuracy, robust concept-based explanations"",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Learning Backward Compatible Embeddings,The best method maintains backward compatibility with existing unintended tasks even after multiple model version updates.,""Weihua Hu, Rajas Bansal, Kaidi Cao, Nikhil S. Rao, Karthik Subbian, J. Leskovec"",Knowledge Discovery and Data Mining,,,10.1145/3534678.3539194,http://arxiv.org/pdf/2206.03040,2022,3,https://doi.org/10.1145/3534678.3539194,https://semanticscholar.org/paper/acc682841729ec95416aa61589d7e1a91d2c2b77,""Embeddings, low-dimensional vector representation of objects, are fundamental in building modern machine learning systems. In industrial settings, there is usually an embedding team that trains an embedding model to solve intended tasks (e.g., product recommendation). The produced embeddings are then widely consumed by consumer teams to solve their unintended tasks (e.g., fraud detection). However, as the embedding model gets updated and retrained to improve performance on the intended task, the newly-generated embeddings are no longer compatible with the existing consumer models. This means that historical versions of the embeddings can never be retired or all consumer teams have to retrain their models to make them compatible with the latest version of the embeddings, both of which are extremely costly in practice. Here we study the problem of embedding version updates and their backward compatibility. We formalize the problem where the goal is for the embedding team to keep updating the embedding version, while the consumer teams do not have to retrain their models. We develop a solution based on learning backward compatible embeddings, which allows the embedding model version to be updated frequently, while also allowing the latest version of the embedding to be quickly transformed into any backward compatible historical v",ersion of,"it, so",that consumer team,s do not have to retrain,their,mo,dels. Our,key ide,a is that,whenever,a ne,w,embedding,model is tra,"ined,",we lea,rn,it,t,oge,ther,with,a l,ig,ht-w,eigh,t ba,ckward,com,patibi,lity,tran,sfo,rmat,ion,tha,t al,ign,s the,new,e,mbed,ding,to,the,pr,ev,ious,vers,ion,of,i,"t. Our learned backward transformations can then be composed to produce any historical version of embedding. Under our framework, we explore six methods and systematically evaluate them on a real-world recommender system application. We show that the best method, which we call BC-Aligner, maintains backward compatibility with existing unintended tasks even after multiple model version updates. Simultaneously, BC-Aligner achieves the intended task performance similar to the embedding model that is solely optimized for the intended task. Code is publicly available at https://github.com/snap-stanford/bc-emb"",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"LMFingerprints: Visual Explanations of Language Model Embedding Spaces through Layerwise Contextualization Scores,Stopwords are unexpectedly high contextualized in the models' upper layers.,""R. Sevastjanova, A. Kalouli, C. Beck, H. Hauptmann, Mennatallah El-Assady"",Computer graphics forum (Print),,,10.1111/cgf.14541,https://dspace.library.uu.nl/bitstream/handle/1874/423131/Computer_Graphics_Forum_2022_Sevastjanova_LMFingerprints_Visual_Explanations_of_Language_Model_Embedding_Spaces.pdf?sequence=1&isAllowed=y,2022,3,https://doi.org/10.1111/cgf.14541,https://semanticscholar.org/paper/98795a8c6af73a370f985ce59ea0f095e66b5858,""Language models, such as BERT, construct multiple, contextualized embeddings for each word occurrence in a corpus. Understanding how the contextualization propagates through the model's layers is crucial for deciding which layers to use for a specific analysis task. Currently, most embedding spaces are explained by probing classifiers; however, some findings remain inconclusive. In this paper, we present LMFingerprints, a novel scoring?based technique for the explanation of contextualized word embeddings. We introduce two categories of scoring functions, which measure (1) the degree of contextualization, i.e., the layerwise changes in the embedding vectors, and (2) the type of contextualization, i.e., the captured context information. We integrate these scores into an interactive explanation workspace. By combining visual and verbal elements, we provide an overview of contextualization in six popular transformer?based language models. We evaluate hypotheses from the domain of computational linguistics, and our results not only confirm findings from related work but also reveal new aspects about the information captured in the embedding spaces. For instance, we",show tha,t while,numbers are poorly,"contextualized, stopwor",ds have,a,n unexpec,ted high,contextu,alization,in t,he,models',"upper layers,",wher,e their,n,eig,hb,orh,oods,shif,t fr,om,sim,ilar,fun,ctiona,lity,token,s to,toke,ns,that,co,ntri,bute,to,the,mean,in,g of,the,su,rrou,ndi,ng,sen,tence,"s.""",",,R",ev,iew,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Incremental User Embedding Modeling for Personalized Text Classification,The incremental user embedding modeling approach allows us to create generalized user representations in a consecutive manner.,""Ruixue Lian, Chengyu Huang, Y. Tang, Qi Gu, Chengyuan Ma, Chenlei Guo"",""IEEE International Conference on Acoustics, Speech, and Signal Processing"",,,10.1109/ICASSP43922.2022.9747689,http://arxiv.org/pdf/2202.06369,2022,,https://doi.org/10.1109/ICASSP43922.2022.9747689,https://semanticscholar.org/paper/61807003003aac096de4b539834680ebdc1af185,""Individual user profiles and interaction histories play a significant role in providing customized experiences in real-world applications such as chatbots, social media, retail, and education. Adaptive user representation learning by utilizing user personalized information has be-come increasingly challenging due to ever-growing his-tory data. In this work, we propose an incremental user embedding modeling approach, in which embeddings of user’s recent interaction histories are dynamically integrated into the accumulated history vectors via a trans-former encoder. This modeling paradigm allows us to create generalized user representations in a consecutive manner and also alleviate the challenges of data management. We demonstrate the effectiveness of this approach by applying it to a personalized multi-class classification task based on the Reddit dataset, and achieve 9% and 30% relative improvement on prediction accuracy over a baseline system for two experiment settings through appropriate comment history encoding and task modeling."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Cosine-Based Embedding for Completing Lightweight Schematic Knowledge in DL-Litecore,Existing embedding methods for completing schematic knowledge are far from complete.,""Weizhuo Li, Xianda Zheng, Huan Gao, Qiu Ji, G. Qi"",Applied Sciences,,0.44 (11182),10.3390/app122010690,https://www.mdpi.com/2076-3417/12/20/10690/pdf?version=1666689902,2022,,https://doi.org/10.3390/app122010690,https://semanticscholar.org/paper/7c80af3931a711eeb6413ed9a02dbcd603f23652,""Schematic knowledge, an important component of knowledge graphs (KGs), defines a rich set of logical axioms based on concepts and relations to support knowledge integration, reasoning, and heterogeneity elimination over KGs. Although several KGs consist of lots of factual knowledge, their schematic knowledge (e.g., subclassOf axioms, disjointWith axioms) is far from complete. Currently, existing KG embedding methods for completing schematic knowledge still suffer from two limitations. Firstly, existing embedding methods designed to encode factual knowledge pay little attention to the completion of schematic knowledge (e.g., axioms). Secondly, several methods try to preserve logical properties of relations for completing schematic knowledge, but they cannot simultaneously preserve the transitivity (e.g., subclassOf) and symmetry (e.g., disjointWith) of axioms well. To solve these issues, we propose a cosine-based embedding method named CosE tailored for completing lightweight schematic knowledge in DL-Litecore. Precisely, the concepts in axioms will be encoded into two semantic spaces defined in CosE. One is called angle-based semantic space, which is employed to preserve the transitivity or symmetry of relations in axioms. The other one is defined as translation-based semantic space that is used to measure the confidence of each",axiom. We,design,two types of score,functions for these two,semant,ic,"spaces,",so as to,sufficie,ntly lear,n the,v,ector rep,resentations,of co,ncepts.,M,ore,ov,"er,",we,propo,se a,n,ovel,neg,ativ,e samp,ling,strat,egy,based,on,the,mu,tual,exc,lus,ion b,etwe,en,sub,clas,sOf,and,di,sj,oint,With.,In,th,is,"way, concepts can obtain better vector representations for schematic knowledge completion. We implement our method and verify it on four standard datasets generated by real ontologies. Experiments show that CosE can obtain better results than existing models and keep the logical properties of relations for transitivity and symmetry simultaneously."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"A Functional Contextual Account of Background Knowledge in Categorization: Implications for Artificial General Intelligence and Cognitive Accounts of General Knowledge,The Relational Frame Theory may be able to offer a novel explanation of how background knowledge arises.,""D. Edwards, Ciara McEnteggart, Y. Barnes-Holmes"",Frontiers in Psychology,,0.873 (5025),10.3389/fpsyg.2022.745306,https://www.frontiersin.org/articles/10.3389/fpsyg.2022.745306/pdf,2022,3,https://doi.org/10.3389/fpsyg.2022.745306,https://semanticscholar.org/paper/e635f0b92128f477f079e40f585cded89972cf79,""Psychology has benefited from an enormous wealth of knowledge about processes of cognition in relation to how the brain organizes information. Within the categorization literature, this behavior is often explained through theories of memory construction called exemplar theory and prototype theory which are typically based on similarity or rule functions as explanations of how categories emerge. Although these theories work well at modeling highly controlled stimuli in laboratory settings, they often perform less well outside of these settings, such as explaining the emergence of background knowledge processes. In order to explain background knowledge, we present a non-similarity-based post-Skinnerian theory of human language called Relational Frame Theory (RFT) which is rooted in a philosophical world view called functional contextualism (FC). This theory offers a very different interpretation of how categories emerge through the functions of behavior and through contextual cues, which may be of some benefit to existing categorization theories. Specifically, RFT may be able to offer a novel explanation of how background knowledge arises, and we provide some mathematical considerations in order to identify a form",al model.,Finall,"y, we discuss much",of this work within the,broader,c,ontext of,general,semantic,knowledg,e and,a,rtificial,intelligence,rese,"arch."",",",",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Incorporating Background Knowledge in Symbolic Regression using a Computer Algebra System,Soft constraints can lead to improved performance both in terms of search effectiveness and model meaningfulness.,""Charles Fox, Neil Tran, Nikki Nacion, Samiha Sharlin, Tyler R. Josephson"",ArXiv,,,10.48550/arXiv.2301.11919,,2023,,https://doi.org/10.48550/arXiv.2301.11919,https://semanticscholar.org/paper/cfb6987b93a60b21946515548a5553fbeb2ffe7b,""Symbolic Regression (SR) can generate interpretable, concise expressions that fit a given dataset, allowing for more human understanding of the structure than black-box approaches. The addition of background knowledge (in the form of symbolic mathematical constraints) allows for the generation of expressions that are meaningful with respect to theory while also being consistent with data. We specifically examine the addition of constraints to traditional genetic algorithm (GA) based SR (PySR) as well as a Markov-chain Monte Carlo (MCMC) based Bayesian SR architecture (Bayesian Machine Scientist), and apply these to rediscovering adsorption equations from experimental, historical datasets. We find that, while hard constraints prevent GA and MCMC SR from searching, soft constraints can lead to improved performance both in terms of search effectiveness and model meaningfulness, with computational costs increasing by about an order-of-magnitude. If the constraints do not correlate well with the dataset or expected models, they can hinder the search of expressions. We find Bayesian SR is better these constraints (as the Bayesian prior) than by modifying the fitness function in the GA."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Emblaze: Illuminating Machine Learning Representations through Interactive Comparison of Embedding Spaces,Emblaze integrates embedding space comparison within a computational notebook environment.,""Venkatesh Sivaraman, Yiwei Wu, Adam Perer"",International Conference on Intelligent User Interfaces,,,10.1145/3490099.3511137,https://dl.acm.org/doi/pdf/10.1145/3490099.3511137,2022,3,https://doi.org/10.1145/3490099.3511137,https://semanticscholar.org/paper/372f46308d131674c3f140b49db1fbe3dd7dfe79,""Modern machine learning techniques commonly rely on complex, high-dimensional embedding representations to capture underlying structure in the data and improve performance. In order to characterize model flaws and choose a desirable representation, model builders often need to compare across multiple embedding spaces, a challenging analytical task supported by few existing tools. We first interviewed nine embedding experts in a variety of fields to characterize the diverse challenges they face and techniques they use when analyzing embedding spaces. Informed by these perspectives, we developed a novel system called Emblaze that integrates embedding space comparison within a computational notebook environment. Emblaze uses an animated, interactive scatter plot with a novel Star Trail augmentation to enable visual comparison. It also employs novel neighborhood analysis and clustering procedures to dynamically suggest groups of points with interesting changes between spaces. Through a series of case studies with ML experts, we demonstrate how interactive comparison with Emblaze can help gain new insights into embedding space structure."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Leveraging Three Types of Embeddings from Masked Language Models in Idiom Token Classification,Contextualized word embeddings derived from masked language models can give promising results for idiom token classification.,""Ryosuke Takahashi, Ryohei Sasano, Koichi Takeda"",STARSEM,,,10.18653/v1/2022.starsem-1.21,https://aclanthology.org/2022.starsem-1.21.pdf,2022,,https://doi.org/10.18653/v1/2022.starsem-1.21,https://semanticscholar.org/paper/2626681008130b33f951e551a391adfaa827d9ce,""Many linguistic expressions have idiomatic and literal interpretations, and the automatic distinction of these two interpretations has been studied for decades. Recent research has shown that contextualized word embeddings derived from masked language models (MLMs) can give promising results for idiom token classification. This indicates that contextualized word embedding alone contains information about whether the word is being used in a literal sense or not. However, we believe that more types of information can be derived from MLMs and that leveraging such information can improve idiom token classification. In this paper, we leverage three types of embeddings from MLMs; uncontextualized token embeddings and masked token embeddings in addition to the standard contextualized word embeddings and show that the newly added embeddings significantly improve idiom token classification for both English and Japanese datasets."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Local Semantic Correlation Modeling Over Graph Neural Networks for Deep Feature Embedding and Image Retrieval,Deep feature embedding aims to learn discriminative features for image samples which can minimize their intra-class distance while maximizing their inter-class distance.,""Shichao Kan, Yigang Cen, Yang Li, Mladenovic Vladimir, Zhihai He"",IEEE Transactions on Image Processing,,4.03 (383),10.1109/TIP.2022.3163571,,2022,5,https://doi.org/10.1109/TIP.2022.3163571,https://semanticscholar.org/paper/f374c34fa95d7e09f0b1e4aa9ad94e56a7a3c213,""Deep feature embedding aims to learn discriminative features or feature embeddings for image samples which can minimize their intra-class distance while maximizing their inter-class distance. Recent state-of-the-art methods have been focusing on learning deep neural networks with carefully designed loss functions. In this work, we propose to explore a new approach to deep feature embedding. We learn a graph neural network to characterize and predict the local correlation structure of images in the feature space. Based on this correlation structure, neighboring images collaborate with each other to generate and refine their embedded features based on local linear combination. Graph edges learn a correlation prediction network to predict the correlation scores between neighboring images. Graph nodes learn a feature embedding network to generate the embedded feature for a given image based on a weighted summation of neighboring image features with the correlation scores as weights. Our extensive experimental results under the image retrieval settings demonstrate that our proposed method outperforms the state-of-the-art methods by a large margin, especially for top-1 recalls."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Embedding for Evaluation of Topic Modeling Unsupervised Algorithms,""The Word Embedding Topic Evaluation methodology outperforms existing document models that are generally used in measuring topic evaluation such as coherence score, perplexity, etc. in terms of topic quality and predictive performance."",""Ananya Srivastava, Ms. Lavanya Gunasekar, M. Bagyalakshmi"",,,,,,2022,,,https://semanticscholar.org/paper/bfcbc71781a1058b6072aeea0f5c33092247ea34,"": Topic Modeling is one of the most popular techniques used for text mining in Natural Language Processing. Topic modeling refers to the task of identifying topics that best describes a set of documents. It will classify data based on a particular topic and determine the relationship between tokens. This is done by extracting the patterns of word clusters and frequencies of words in the document. It has enjoyed success in various applications in machine learning, natural language processing (NLP), and data mining for almost two decades. There are several algorithms for implementing topic modeling. Most common techniques are LDA – Latent Dirichlet Allocation, LSA or LSI – Latent Semantic Analysis or Latent Semantic Indexing. In this paper, we have proposed the Word Embedding Topic Evaluation methodology which will help in identifying the efficient outcomes with better accuracy. It outperforms existing document models that are generally used in measuring topic evaluation such as coherence score, perplexity etc., in terms of topic quality and predictive performance."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Explaining Link Predictions in Knowledge Graph Embedding Models with Influential Examples,The approach to generate explanations out-performs baselines on KGE models for two publicly available datasets.,""Adrianna Janik, Luca Costabello"",ArXiv,,,10.48550/arXiv.2212.02651,,2022,,https://doi.org/10.48550/arXiv.2212.02651,https://semanticscholar.org/paper/0cf48d13e5c96f32be4c97c60f6228aacc1d82a0,We study the problem of explaining link predictions in the Knowledge Graph Embedding (KGE) models. We propose an example-based approach that exploits the latent space rep- resentation of nodes and edges in a knowledge graph to explain predictions. We evaluated the importance of identi?ed triples by observing progressing degradation of model performance upon in?uential triples removal. Our experiments demonstrate that this approach to generate explanations out-performs baselines on KGE models for two publicly available datasets.,,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Semantics Driven Embedding Learning for Effective Entity Alignment,The attribute embedding and relation embedding are driven by semantics building bridges between entities.,""Ziyue Zhong, Meihui Zhang, Ju Fan, Chenxiao Dou"",IEEE International Conference on Data Engineering,,,10.1109/icde53745.2022.00205,,2022,1,https://doi.org/10.1109/icde53745.2022.00205,https://semanticscholar.org/paper/f7e8f369ae12bdcc76eaab4e42839fd36406abc0,""Knowledge-based data service has become an emerging form of service in the world wide web (WWW). To ensure the service quality, a comprehensive knowledge base has to be constructed. Knowledge base integration is often a primary way to improve the completeness. In this paper, we focus on the fundamental problem in knowledge base integration, i.e., entity alignment (EA). EA has been studied for years. Traditional approaches focus on the symbolic features of entities and propose various similarity measures to identify equivalent entities. With recent development in knowledge graph representation learning, embedding-based entity alignment has emerged, which encodes the entities into vectors according to the semantic or structural information and computes the relatedness of entities based on the vector representation. While embedding-based approaches achieve promising results, we identify some important information that are not well exploited in existing works: 1) The neighboring entities contribute differently in the EA process, and should be carefully assigned the importance in learning the relatedness of entities; 2) The attribute values (especially the long texts) contain rich semantics that can build supplementary associations between entities. To this end, we propose SDEA - a Semantics Driven entity embedding method for Entity Alignment. SDEA consists of",two modu,"les, na",mely attribute embe,dding and relation embed,ding. T,he,attribut,e embedd,ing captu,res the s,emant,ic,informat,ion from attr,ibute,values,w,ith,a,pr,e-tr,ained,tra,ns,form,er-b,ased,langu,age,model.,The,rela,tio,n em,bed,ding,sel,ect,ively,agg,re,gate,s th,e s,eman,tic,i,nfor,matio,n f,rom,n,"eighbors using a GRU model equipped with an attention mechanism. Both attribute embedding and relation embedding are driven by semantics, building bridges between entities. Experimental results show that our method significantly outperforms the state-of-the-art approaches on three benchmarks."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Context-aware Embeddings for Stock Prediction with Visual Clues,A core-tensor parameter is able to thoroughly fuse different factors and preserve their interactions.,""Jinghua Tan, Tonglei Guo, Jun-Yu Chen, Tao Shu"",2022 5th International Conference on Information and Communications Technology (ICOIACT),,,10.1109/ICOIACT55506.2022.9972118,,2022,,https://doi.org/10.1109/ICOIACT55506.2022.9972118,https://semanticscholar.org/paper/0ccb8191a487400035f2ab857fbccf608af2f420,""The stock market is a complex dynamic system, and its fluctuation must be the result of the joint influence of various market factors. Most previous studies usually attempt to predict stock movements more accurately by involving more market information regarded as a forecast indicator vector, which inevitably ignores feature interactions and causes significant gaps between the real-world deployment and such accuracy breakthrough. In this study, we propose a dynamic fusion framework to learn the interactions according to the prediction tasks, and innovatively interpret predictive models with visual clues from both the input perspective and the output perspective. Specifically, a core-tensor parameter is utilized to bridge the representations learning and model predicting, which is able to thoroughly fuse different factors and preserve their interactions. An interpretation design is further adopted to identify the key factors, the synergistic effects, and the profitable outputs. In addition, for the unstructured input, a context-aware hierarchy-attention interpretation is proposed to gain insight into the multi-granularity textual contents. Experiments performed on the real datasets demonstrate the superiority of the proposed approach over several strong baselines. A case study is further conducted to explain what can",be inter,preted,out of the proposed,"fusion framework."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Disentangling Embedding Spaces with Minimal Distributional Assumptions,Disjoint attributions concept discovery method is applicable to a broader class of problems than current approaches.,""Tobias Leemann, M. Kirchhof, Yao Rong, Enkelejda Kasneci, G. Kasneci"",ArXiv,,,10.48550/arXiv.2206.13872,,2022,2,https://doi.org/10.48550/arXiv.2206.13872,https://semanticscholar.org/paper/cde6b04e48a01509ab8f59ac3284e7f00fec3a1d,""Interest in understanding and factorizing learned embedding spaces is growing. For instance, recent concept-based explanation techniques analyze a machine learning model in terms of interpretable latent components. Such components have to be discovered in the model’s embedding space, e.g., through independent component analysis (ICA) or modern disentanglement learning techniques. While these unsupervised approaches offer a sound formal framework, they either require access to a data generating function or impose rigid assumptions on the data distribution, such as independence of components, that are often violated in practice. In this work, we link conceptual explainability for vision models with disentanglement learning and ICA. This enables us to provide first theoretical results on how components can be identified without requiring any distributional assumptions. From these insights, we derive the disjoint attributions (DA) concept discovery method that is applicable to a broader class of problems than current approaches, but yet possesses a formal identifiability guarantee. In an extensive comparison against component analysis and over 300 state-of-the-art disentanglement models, DA stably maintains superior performance, even under varying distributions and correlation strengths."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Background knowledge in ontology matching: A survey,External background knowledge plays a major role in the task of semi-automated ontology and schema matching.,""Jan Portisch, M. Hladik, H. Paulheim"",Semantic Web,,1.242 (2878),10.3233/sw-223085,https://content.iospress.com:443/download/semantic-web/sw223085?id=semantic-web%2Fsw223085,2022,3,https://doi.org/10.3233/sw-223085,https://semanticscholar.org/paper/45c9883d51cda85ed44502fa174bd42f6315d36b,""Ontology matching is an integral part for establishing semantic interoperability. One of the main challenges within the ontology matching operation is semantic heterogeneity, i.e. modeling differences between the two ontologies that are to be integrated. The semantics within most ontologies or schemas are, however, typically incomplete because they are designed within a certain context which is not explicitly modeled. Therefore, external background knowledge plays a major role in the task of (semi-) automated ontology and schema matching. In this survey, we introduce the reader to the general ontology matching problem. We review the background knowledge sources as well as the approaches applied to make use of external knowledge. Our survey covers all ontology matching systems that have been presented within the years 2004–2021 at a well-known ontology matching competition together with systematically selected publications in the research field. We present a classification system for external background knowledge, concept linking strategies, as well as for background knowledge exploitation approaches. We provide extensive examples and classify all ontology matching systems under review in a resource/strategy matrix obtained by coalescing the two classification systems. Lastly, we outline interesting and yet underexplored research direct",ions of a,pplying,external knowledge,within the ontology mat,ching p,ro,"cess."",,R",eview,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Concept Embedding Analysis: A Review,""Concept analysis aims to find global, assessable associations of human interpretable semantic concepts with internal representations of a DNN."",Gesina Schwalbe,ArXiv,,,10.48550/arXiv.2203.13909,,2022,2,https://doi.org/10.48550/arXiv.2203.13909,https://semanticscholar.org/paper/f57dc8023c36e8df77994f842fb7e68b76b35b9a,""Deep neural networks (DNNs) have found their way into many applications with potential impact on the safety, security, and fairness of human-machine-systems. Such require basic understanding and sufficient trust by the users. This motivated the research field of explainable artificial intelligence (XAI), i.e. finding methods for opening the “black-boxes” DNNs represent. For the computer vision domain in specific, practical assessment of DNNs requires a globally valid association of human interpretable concepts with internals of the model. The research field of concept (embedding) analysis (CA) tackles this problem: CA aims to find global, assessable associations of humanly interpretable semantic concepts (e.g., eye, bearded) with internal representations of a DNN. This work establishes a general definition of CA and a taxonomy for CA methods, uniting several ideas from literature. That allows to easy position and compare CA approaches. Guided by the defined notions, the current state-of-the-art research regarding CA methods and interesting applications are reviewed. More than thirty relevant methods are discussed, compared, and categorized. Finally, for practitioners, a survey of fifteen datasets is provided that have been used for supervised concept analysis. Open challenges and research directions are pointed out at the end. Acknowledgments. The research leading to these results was partly funded by by the German Federal Minis",try for E,conomic,Affairs and Energy,within the projects “KI,Wissen,–,Automoti,ve AI po,wered by,Knowledge,” and,“,KI Absich,erung – Safe,AI fo,r autom,at,ed,dr,ivi,ng”.,Than,ks t,o,the,cons,orti,a for,the,succes,sful,coop,era,tion,. 1,ar,X iv,:2,20 3,. 13,9,0 9v,1 [,cs,.L,G ],2,5 M,ar 2,2,2,Sp,"ringer Nature 2021 LTEX template 2 Concept Embedding Analysis"",,Review",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"""A Survey on Knowledge Graphs: Representation, Acquisition, and Applications"",""Knowledge graph embedding is organized from four aspects of representation space, scoring function, encoding models, and auxiliary information."",""Shaoxiong  Ji, Shirui  Pan, Erik  Cambria, Pekka  Marttinen, Philip S. Yu"",IEEE Transactions on Neural Networks and Learning Systems,,4.222 (355),10.1109/TNNLS.2021.3070843,https://research-repository.griffith.edu.au/bitstream/10072/416709/2/Pan2923674-Accepted.pdf,2022,340,https://doi.org/10.1109/TNNLS.2021.3070843,https://semanticscholar.org/paper/c9ec8cf5ce461647d0d1cf67093feeadea5d9957,""Human knowledge provides a formal understanding of the world. Knowledge graphs that represent structural relations between entities have become an increasingly popular research direction toward cognition and human-level intelligence. In this survey, we provide a comprehensive review of the knowledge graph covering overall research topics about: 1) knowledge graph representation learning; 2) knowledge acquisition and completion; 3) temporal knowledge graph; and 4) knowledge-aware applications and summarize recent breakthroughs and perspective directions to facilitate future research. We propose a full-view categorization and new taxonomies on these topics. Knowledge graph embedding is organized from four aspects of representation space, scoring function, encoding models, and auxiliary information. For knowledge acquisition, especially knowledge graph completion, embedding methods, path inference, and logical rule reasoning are reviewed. We further explore several emerging topics, including metarelational learning, commonsense reasoning, and temporal knowledge graphs. To facilitate future research on knowledge graphs, we also provide a curated collection of data sets and ope",n-source,librari,es on different tas,"ks. In the end, we have",a thoro,ug,h outlook,on seve,ral promi,sing rese,arch,di,rections.,""",,Review",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Predicting Embedding Reliability in Low-Resource Settings Using Corpus Similarity Measures,It is possible to estimate the reliability of low-resource embeddings using corpus similarity measures that remain robust on small amounts of data.,""Jonathan Dunn, Haipeng Li, Damian Sastre"",International Conference on Language Resources and Evaluation,,,10.48550/arXiv.2206.04330,,2022,2,https://doi.org/10.48550/arXiv.2206.04330,https://semanticscholar.org/paper/c74d3f3cdb924b3950fdd7889b65004eeaba1c12,""This paper simulates a low-resource setting across 17 languages in order to evaluate embedding similarity, stability, and reliability under different conditions. The goal is to use corpus similarity measures before training to predict properties of embeddings after training. The main contribution of the paper is to show that it is possible to predict downstream embedding similarity using upstream corpus similarity measures. This finding is then applied to low-resource settings by modelling the reliability of embeddings created from very limited training data. Results show that it is possible to estimate the reliability of low-resource embeddings using corpus similarity measures that remain robust on small amounts of data. These findings have significant implications for the evaluation of truly low-resource languages in which such systematic downstream validation methods are not possible because of data limitations."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Depth Completion Using Geometry-Aware Embedding,The proposed method outperforms previous works.,""Wenchao Du, Hu Chen, Hong-ling Yang, Yan Zhang"",IEEE International Conference on Robotics and Automation,,,10.48550/arXiv.2203.10912,,2022,4,https://doi.org/10.48550/arXiv.2203.10912,https://semanticscholar.org/paper/bba225bd34e145fdeadbf20c389b3ac63f25ae89,""Exploiting internal spatial geometric constraints of sparse LiDARs is beneficial to depth completion, however, has been not explored well. This paper proposes an efficient method to learn geometry-aware embedding, which encodes the local and global geometric structure information from 3D points, e.g., scene layout, object's sizes and shapes, to guide dense depth estimation. Specifically, we utilize the dynamic graph representation to model generalized geometric relationship from irregular point clouds in a flexible and efficient manner. Further, we joint this embedding and corresponded RGB appearance information to infer missing depths of the scene with well structure-preserved details. The key to our method is to integrate implicit 3D geometric representation into a 2D learning architecture, which leads to a better trade-off between the performance and efficiency. Extensive experiments demonstrate that the proposed method outperforms previous works and could reconstruct fine depths with crisp boundaries in regions that are over-smoothed by them. The ablation study gives more insights into our method that could achieve significant gains with a simple design, while having better generalization capability and stability. The code is available at https://github.com/Wenchao-Du/GAENet."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Disentangling Visual Embeddings for Attributes and Objects,A novel architecture can disentangle attribute and object features in the visual space.,""Nirat Saini, Khoi Pham, Abhinav Shrivastava"",Computer Vision and Pattern Recognition,,,10.1109/CVPR52688.2022.01329,http://arxiv.org/pdf/2205.08536,2022,6,https://doi.org/10.1109/CVPR52688.2022.01329,https://semanticscholar.org/paper/b3c514de08f3953e00464f63464e1241396b54b8,""We study the problem of compositional zero-shot learning for object-attribute recognition. Prior works use visual features extracted with a backbone network, pre-trained for object classification and thus do not capture the subtly distinct features associated with attributes. To overcome this challenge, these studies employ supervision from the linguistic space, and use pre-trained word embeddings to better separate and compose attribute-object pairs for recognition. Analogous to linguistic embedding space, which already has unique and agnostic embeddings for object and attribute, we shift the focus back to the visual space and propose a novel architecture that can disentangle attribute and object features in the visual space. We use visual decomposed features to hallucinate embeddings that are representative for the seen and novel compositions to better regularize the learning of our model. Extensive experiments show that our method outperforms existing work with significant margin on three datasets: MIT-States, UT-Zappos, and a new benchmark created based on VAW. The code, models, and dataset splits are publicly available at https://github.com/nirat1606/OADis."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Incremental Embedding Learning With Disentangled Representation Translation.,A mask-guided module enables us to effectively preserve the discriminative yet representative features in the disentangled translation process.,""Kun-Juan Wei, Da Chen, Yuhong Li, Xu Yang, Cheng Deng, Dacheng Tao"",IEEE Transactions on Neural Networks and Learning Systems,,4.222 (355),10.1109/TNNLS.2022.3199816,,2022,1,https://doi.org/10.1109/TNNLS.2022.3199816,https://semanticscholar.org/paper/9ce5a82907ce7fc3396db878a35b040b471fac1b,""Humans are capable of accumulating knowledge by sequentially learning different tasks, while neural networks fail to achieve this due to catastrophic forgetting problems. Most current incremental learning methods focus more on tackling catastrophic forgetting for traditional classification networks. Notably, however, embedding networks that are basic architectures for many metric learning applications also suffer from this problem. Moreover, the most significant difficulty for continual embedding networks is that the relationships between the latent features and prototypes of previous tasks will be destroyed once new tasks have been learned. Accordingly, we propose a novel incremental method for embedding networks, called the disentangled representation translation (DRT) method, to obtain the discriminative class-disentangled features without reusing any samples of previous tasks and while avoiding the perturbation of task-related information. Next, a mask-guided module is specifically explored to adaptively change or retain the valuable information of latent features. This module enables us to effectively preserve the discriminative yet representative features in the disentangled translation process. In addition, DRT can easily be equipped with a regularization item of incr",emental l,earning,to further improve,performance. We conduct,extens,iv,e experim,ents on,four popu,lar datas,ets;,as,the expe,rimental resu,lts c,learly,de,mon,st,rat,"e, o",ur me,thod,c,an e,ffec,tive,ly all,evia,te the,cat,astro,phi,c fo,rge,ttin,g pr,obl,em fo,r em,be,ddin,g ne,two,rks.,""",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Recurrent Dynamic Embedding for Video Object Segmentation Supplementary Material,The most similar embedding implemented by argmax is used when the pixel location is triggered.,""Mingxing Li, Liucheng Hu, Zhiwei Xiong, Bang Zhang, Pan Pan, Dong Liu"",,,,,,2022,,,https://semanticscholar.org/paper/db2df7a2a737d88711a1bdafd93e5e9426bc028f,""We summarize the EMA based methods first select proposal embeddings and then merge the proposal embeddings with the old memory bank in an EMA way. As shown in Eq. 1 (note Eq. 1 is the process to pixel level), GCNet [5] uses simple averaging (? = 0.5 in Eq. 1). AFB-URR [6] uses EMA (? = 0 ? 1 in Eq. 1) when the new feature is close to an existing one. And SwiftNet [9] uses the most similar embedding implemented by argmax (? = 0 in Eq. 1) when the pixel location is triggered."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Embed to Control Partially Observed Systems: Representation Learning with Provable Sample Efficiency,A reinforcement learning algorithm named Embed to Control learns the representation at two levels while optimizing the policy.,""Lingxiao Wang, Qi Cai, Zhuoran Yang, Zhaoran Wang"",ArXiv,,,10.48550/arXiv.2205.13476,,2022,3,https://doi.org/10.48550/arXiv.2205.13476,https://semanticscholar.org/paper/4a0e0d1cf992d014a802935206ebbcb795c14daf,""Reinforcement learning in partially observed Markov decision processes (POMDPs) faces two challenges. (i) It often takes the full history to predict the future, which induces a sample complexity that scales exponentially with the horizon. (ii) The observation and state spaces are often continuous, which induces a sample complexity that scales exponentially with the extrinsic dimension. Addressing such challenges requires learning a minimal but su?cient representation of the observation and state histories by exploiting the structure of the POMDP. To this end, we propose a reinforcement learning algorithm named Embed to Control (ETC), which learns the representation at two levels while optimizing the policy. (i) For each step, ETC learns to represent the state with a low-dimensional feature, which factorizes the transition kernel. (ii) Across multiple steps, ETC learns to represent the full history with a low-dimensional embedding, which assembles the per-step feature. We integrate (i) and (ii) in a uni?ed framework that allows a variety of estimators (including maximum likelihood estimators and generative adversarial networks). For a class of POMDPs with a low-rank structure in the transition kernel, ETC attains an O (1 /? 2 ) sample complexity that scales polynomially with the horizon and the intrinsic dimension (that is, the rank). Here ? is the",optimalit,y gap.,To our best knowled,"ge, ETC is the ?rst samp",le-e?ci,en,t algorit,hm that,bridges r,epresenta,tion,le,arning an,d policy opti,mizat,ion in,PO,MDP,s,wit,h in,?nite,obs,er,vati,on a,nd s,tate s,pace,"s."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"InterHT: Knowledge Graph Embeddings by Interaction between Head and Tail Entities,Distance-based methods show promising performance on link prediction task.,""Baoxin Wang, Qingye Meng, Ziyue Wang, Dayong Wu, Wanxiang Che, Shijin Wang, Zhigang Chen, Cong Liu"",ArXiv,,,,,2022,7,,https://semanticscholar.org/paper/39acaf86de56a9054ccab9af1594395e2991c9ac,""Knowledge graph embedding (KGE) models learn the representation of entities and relations in knowledge graphs. Distance-based methods show promising performance on link prediction task, which predicts the result by the distance between two entity representations. However, most of these methods represent the head entity and tail entity separately, which limits the model capacity. We propose two novel distance-based methods named InterHT and InterHT+ that allow the head and tail entities to interact better and get better entity representation. Experimental results show that our proposed method achieves the best results on ogbl-wikikg2 dataset."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"InterHT: Knowledge Graph Embeddings by Interaction between Head and Tail Entities,Distance-based methods show promising performance on link prediction task.,""Baoxin Wang, Qingye Meng, Ziyue Wang, Dayong Wu, Wanxiang Che, Shijin Wang, Zhigang Chen, Cong Liu"",ArXiv,,,,,2022,3,,https://semanticscholar.org/paper/d0ec391c56b4d1593f8e305d49f5a409a94b1d4a,""Knowledge graph embedding (KGE) models learn the representation of entities and relations in knowledge graphs. Distance-based methods show promising performance on link prediction task, which predicts the result by the distance between two entity representations. However, most of these methods represent the head entity and tail entity separately, which limits the model capacity. We propose a novel distance-based method named InterHT that allows the head and tail entities to interact better and get better entity representation. Experimental results show that our proposed method achieves the best results on ogblwikikg2 dataset."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Reasoning Through Memorization: Nearest Neighbor Knowledge Graph Embeddings,A knowledge graph embedding approach with pre-trained language models can allow rare or emerging entities to be memorized explicitly rather than implicitly in model parameters.,""Ningyu Zhang, Xin Xie, Xiang Chen, Shumin Deng, Chuanqi Tan, Fei Huang, Xu Cheng, Huajun Chen"",ArXiv,,,,,2022,7,,https://semanticscholar.org/paper/072f7b3b68c930c4e01fc2ed1c54fcdc5e916a04,""Previous knowledge graph embedding approaches usually map entities to representations and utilize score functions to predict the target entities, yet they typically struggle to reason rare or emerging unseen entities. In this paper, we propose kNN-KGE, a new knowledge graph embedding approach with pre-trained language models, by linearly interpolating its entity distribution with k-nearest neighbors. We compute the nearest neighbors based on the distance in the entity embedding space from the knowledge store. Our approach can allow rare or emerging entities to be memorized explicitly rather than implicitly in model parameters. Experimental results demonstrate that our approach can improve inductive and transductive link prediction results and yield better performance for low-resource settings with only a few triples, which might be easier to reason via explicit memory. Code is available at https://github.com/zjunlp/KNN-KG."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Reasoning Through Memorization: Nearest Neighbor Knowledge Graph Embeddings,A knowledge graph embedding approach with pre-trained language models can allow rare or emerging entities to be memorized explicitly rather than implicitly in model parameters.,""Ningyu Zhang, Xin Xie, Xiang Chen, Shumin Deng, Chuanqi Tan, Fei Huang, Xu Cheng, Huajun Chen"",ArXiv,,,,,2022,7,,https://semanticscholar.org/paper/b30759d87369a5fadd7d252ec8514abfba68ca10,""Previous knowledge graph embedding approaches usually map entities to representations and utilize score functions to predict the target entities, yet they struggle to reason rare or emerging unseen entities. In this paper, we propose kNN-KGE, a new knowledge graph embedding approach with pre-trained language models, by linearly interpolating its entity distribution with k-nearest neighbors.We compute the nearest neighbors based on the distance in the entity embedding space from the knowledge store. Our approach can allow rare or emerging entities to be memorized explicitly rather than implicitly in model parameters. Experimental results demonstrate that our approach can improve inductive and transductive link prediction results and yield better performance for low-resource settings with only a few triples, which might be easier to reason via explicit memory1."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"VGSE: Visually-Grounded Semantic Embeddings for Zero-Shot Learning,Visually-grounded semantic embeddings improve performance over word embeddings across various zero-shot learning models by a large margin.,""Wenjia Xu, Yongqin Xian, Jiuniu Wang, B. Schiele, Zeynep Akata"",Computer Vision and Pattern Recognition,,,10.1109/CVPR52688.2022.00910,http://arxiv.org/pdf/2203.10444,2022,6,https://doi.org/10.1109/CVPR52688.2022.00910,https://semanticscholar.org/paper/0760f775746059b7ca9318b09ac94e98915af2a3,""Human-annotated attributes serve as powerful semantic embeddings in zero-shot learning. However, their annotation process is labor-intensive and needs expert supervision. Current unsupervised semantic embeddings, i.e., word embeddings, enable knowledge transfer between classes. However, word embeddings do not always reflect visual similarities and result in inferior zero-shot performance. We propose to discover semantic embeddings containing discriminative visual properties for zero-shot learning, without requiring any human annotation. Our model visually divides a set of images from seen classes into clusters of local image regions according to their visual similarity, and further imposes their class discrimination and semantic relatedness. To associate these clusters with previously unseen classes, we use external knowledge, e.g., word embeddings and propose a novel class relation discovery module. Through quantitative and qualitative evaluation, we demonstrate that our model discovers semantic embeddings that model the visual properties of both seen and unseen classes. Furthermore, we demonstrate on three benchmarks that our visually-grounded semantic embeddings further improve performance over word embeddings across various ZSL models by a large margin. Code is available at https://g",ithub.com,/wenjia,"Xu/VGSE"",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Explaining Link Prediction Systems based on Knowledge Graph Embeddings,Link prediction models can outperform traditional approaches and can be employed in multiple downstream tasks.,""Andrea Rossi, D. Firmani, P. Merialdo, Tommaso Teofili"",SIGMOD Conference,,,10.1145/3514221.3517887,https://iris.uniroma3.it/bitstream/11590/410639/3/2022-sigmod.pdf,2022,5,https://doi.org/10.1145/3514221.3517887,https://semanticscholar.org/paper/2ae37d50e80ec53320b71768a3c85750827799fd,""Link Prediction (LP) aims at tackling Knowledge Graph incompleteness by inferring new, missing facts from the already known ones. The rise of novel Machine Learning techniques has led researchers to develop LP models that represent Knowledge Graph elements as vectors in an embedding space. These models can outperform traditional approaches and they can be employed in multiple downstream tasks; nonetheless, they tend to be opaque, and are mostly regarded as black boxes. Their lack of interpretability limits our understanding of their inner mechanisms, and undermines the trust that users can place in them. In this paper, we propose the novel Kelpie explainability framework. Kelpie can be applied to any embedding-based LP models independently from their architecture, and it explains predictions by identifying the combinations of training facts that have enabled them. Kelpie can extract two complementary types of explanations, that we dub necessary and sufficient. We describe in detail both the structure and the implementation details of Kelpie, and thoroughly analyze its performance through extensive experiments. Our results show that Kelpie significantly outperforms baselines across almost all scenarios."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Representing Mixtures of Word Embeddings with Mixtures of Topic Embeddings,A topic modeling framework embeds words and topics in the same vector space.,""Dongsheng Wang, D. Guo, He Zhao, Huangjie Zheng, Korawat Tanwisuth, Bo Chen, Mingyuan Zhou"",International Conference on Learning Representations,,,10.48550/arXiv.2203.01570,,2022,4,https://doi.org/10.48550/arXiv.2203.01570,https://semanticscholar.org/paper/4102043f373446a92b81c2e8c7e9e747e7f5d434,""A topic model is often formulated as a generative model that explains how each word of a document is generated given a set of topics and document-specific topic proportions. It is focused on capturing the word co-occurrences in a document and hence often suffers from poor performance in analyzing short documents. In addition, its parameter estimation often relies on approximate posterior inference that is either not scalable or suffers from large approximation error. This paper introduces a new topic-modeling framework where each document is viewed as a set of word embedding vectors and each topic is modeled as an embedding vector in the same embedding space. Embedding the words and topics in the same vector space, we define a method to measure the semantic difference between the embedding vectors of the words of a document and these of the topics, and optimize the topic embeddings to minimize the expected difference over all documents. Experiments on text analysis demonstrate that the proposed method, which is amenable to mini-batch stochastic gradient descent based optimization and hence scalable to big corpora, provides competitive performance in discovering more coherent and diverse topics and extracting better document representations. The code is available at https://github.com/BoChenGroup/WeTe."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Incremental Few-Shot Semantic Segmentation via Embedding Adaptive-Update and Hyper-class Representation,A hyper-class embedding is learned by clustering all category embeddings for initialization and aligned with category embedding of the new class for enhancement.,""Guangchen Shi, Yirui Wu, J. Liu, Shaohua Wan, Wenhai Wang, Tong Lu"",ACM Multimedia,,,10.1145/3503161.3548218,http://arxiv.org/pdf/2207.12964,2022,6,https://doi.org/10.1145/3503161.3548218,https://semanticscholar.org/paper/86a69a5f86b136041cd050aeb799efbaed42be9c,""Incremental few-shot semantic segmentation (IFSS) targets at incrementally expanding model's capacity to segment new class of images supervised by only a few samples. However, features learned on old classes could significantly drift, causing catastrophic forgetting. Moreover, few samples for pixel-level segmentation on new classes lead to notorious overfitting issues in each learning session. In this paper, we explicitly represent class-based knowledge for semantic segmentation as a category embedding and a hyper-class embedding, where the former describes exclusive semantical properties, and the latter expresses hyper-class knowledge as class-shared semantic properties. Aiming to solve IFSS problems, we present EHNet, i.e., Embedding adaptive-update and Hyper-class representation Network from two aspects. First, we propose an embedding adaptive-update strategy to avoid feature drift, which maintains old knowledge by hyper-class representation, and adaptively update category embeddings with a class-attention scheme to involve new classes learned in individual sessions. Second, to resist overfitting issues caused by few training samples, a hyper-class embedding is learned by clustering all category embeddings for initialization and aligned with category embed",ding of t,he new,class for enhanceme,"nt, where learned knowle",dge ass,is,ts to lea,rn new k,"nowledge,",thus all,eviat,in,g perform,ance dependen,ce on,traini,ng,da,ta,sc,ale.,Sign,ific,an,"tly,",the,se t,wo des,igns,provi,de r,epres,ent,atio,n c,apab,ilit,y f,or cl,asse,s,with,suf,fic,ient,se,ma,ntic,s and,li,mit,ed,"biases, enabling to perform segmentation tasks requiring high semantic dependence. Experiments on PASCAL-5i and COCO datasets show that EHNet achieves new state-of-the-art performance with remarkable advantages."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Reasoning Through Memorization: Nearest Neighbor Knowledge Graph Embeddings,A knowledge graph embedding approach can allow rare or emerging entities to be memorized explicitly rather than implicitly in model parameters.,""Ningyu Zhang, Xin Xie, Xiang Chen, Shumin Deng, Chuanqi Tan, Fei Huang, Xu Cheng, Huajun Chen"",ArXiv,,,,,2022,5,,https://semanticscholar.org/paper/5a61585cea70ad0ec228d47acddc623103efca1b,""Previous knowledge graph embedding approaches usually map entities to representations and utilize score functions to predict the target entities, yet they struggle to reason rare or emerging unseen entities. In this paper, we propose kNN-KGE, a new knowledge graph embedding approach, by linearly interpolating its entity distribution with knearest neighbors. We compute the nearest neighbors based on the distance in the entity embedding space from the knowledge store. Our approach can allow rare or emerging entities to be memorized explicitly rather than implicitly in model parameters. Experimental results demonstrate that our approach can improve inductive and transductive link prediction results and yield better performance for low-resource settings with only a few triples, which might be easier to reason via explicit memory1."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"A two-stage embedding model for recommendation with multimodal auxiliary information,A two-stage embedding model significantly outperforms the state-of-the-art baselines in terms of various evaluation metrics.,""Juan  Ni, Zhenhua  Huang, Yang  Hu, Chen  Lin"",Inf. Sci.,,,10.1016/j.ins.2021.09.006,,2022,2,https://doi.org/10.1016/j.ins.2021.09.006,https://semanticscholar.org/paper/b4c8c42d62c6185e151ecdf224d671b68cf2a559,""Abstract Recommender system has recently received a lot of attention in the information service community. In many application scenarios, such as Internet of Things (IoTs) environments, item multimodal auxiliary information (such as text and image) can be obtained to expand their feature representation and to increase user satisfaction with recommendations. Motivated by this fact, this paper introduces a novel two-stage embedding model (TSEM), which adequately leverage item multimodal auxiliary information to substantially improve recommendation performance. Specifically, it encompasses two sequential stages: graph convolutional embedding (GCE) and multimodal joint fuzzy embedding (MJFE). In the former, we first generate a bipartite graph for user-item interactions, and then utilize it to construct user and item backbone features via a spatial-based graph convolutional network (SGCN). While in the latter, by employing item multimodal auxiliary information, we integrate multi-task deep learning, deterministic Softmax, and fuzzy Softmax into a convolutional neural network (CNN)-based learning framework, which is optimized to obtain user backbone features and item semantic-enhanced fuzzy (SEF) features accurately. After TSEM converges, user backbone features and item SEF features can be utilized to calculate user preferences on items via Euclidean distance. Extensive e",xperiment,s over,two real-world data,sets show that the propo,sed TSE,M,model sig,nificant,ly outper,forms the,stat,e-,of-the-ar,t baselines i,n ter,ms of v,ar,iou,s,eva,luat,ion m,etri,cs,"."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Disentangled Ontology Embedding for Zero-shot Learning,Existing zero-shot learning methods that utilize knowledge graphs all neglect the intrinsic complexity of inter-class relationships represented in knowledge graphs.,""Yuxia Geng, Jiaoyan Chen, Wen Zhang, Yajing Xu, Zhuo Chen, Jeff Z. Pan, Yufen Huang, Feiyu Xiong, Hua-zeng Chen"",Knowledge Discovery and Data Mining,,,10.1145/3534678.3539453,https://arxiv.org/pdf/2206.03739,2022,6,https://doi.org/10.1145/3534678.3539453,https://semanticscholar.org/paper/94491abe7b0d2de9435eef7907c089af5d4fe575,""Knowledge Graph (KG) and its variant of ontology have been widely used for knowledge representation, and have shown to be quite effective in augmenting Zero-shot Learning (ZSL). However, existing ZSL methods that utilize KGs all neglect the intrinsic complexity of inter-class relationships represented in KGs. One typical feature is that a class is often related to other classes in different semantic aspects. In this paper, we focus on ontologies for augmenting ZSL, and propose to learn disentangled ontology embeddings guided by ontology properties to capture and utilize more fine-grained class relationships in different aspects. We also contribute a new ZSL framework named DOZSL, which contains two new ZSL solutions based on generative models and graph propagation models, respectively, for effectively utilizing the disentangled ontology embeddings. Extensive evaluations have been conducted on five benchmarks across zero-shot image classification (ZS-IMGC) and zero-shot KG completion (ZS-KGC). DOZSL often achieves better performance than the state-of-the-art, and its components have been verified by ablation studies and case studies. Our codes and datasets are available at https://github.com/zjukg/DOZSL."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Embedding Earth: Self-supervised contrastive pre-training for dense land cover classification,The proposed pre-training scheme can generalize between disparate regions for earth observation tasks.,""Michail Tarasiou, S. Zafeiriou"",ArXiv,,,10.48550/arXiv.2203.06041,,2022,2,https://doi.org/10.48550/arXiv.2203.06041,https://semanticscholar.org/paper/436a2dc4ff745f698eaa654262b1b66b51886e30,""In training machine learning models for land cover semantic segmentation there is a stark contrast between the availability of satellite imagery to be used as inputs and ground truth data to enable supervised learning. While thousands of new satellite images become freely available on a daily basis, getting ground truth data is still very challenging, time consuming and costly. In this paper we present Embedding Earth a selfsupervised contrastive pre-training method for leveraging the large availability of satellite imagery to improve performance on downstream dense land cover classification tasks. Performing an extensive experimental evaluation spanning four countries and two continents we use models pre-trained with our proposed method as initialization points for supervised land cover semantic segmentation and observe significant improvements up to 25% absolute mIoU. In every case tested we outperform random initialization, especially so when ground truth data are scarse. Through a series of ablation studies we explore the qualities of the proposed approach and find that learnt features can generalize between disparate regions opening up the possibility of using the proposed pre-training scheme as a replacement to random initialization for Earth observation tasks. Code will be uploaded soon at https://github.com/michaeltrs/DeepSatModels."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Combining Embeddings and Rules for Fact Prediction,Rule mining and knowledge graph embeddings are approaches to guess missing facts.,""Armand Boschin, Nitisha Jain, Gurami Keretchashvili, Fabian M. Suchanek"",,,,,,2022,2,,https://semanticscholar.org/paper/87852047f1b76c66038d383cb2ebbe99423bc970,""Knowledge bases are typically incomplete, meaning that they are missing information that we would expect to be there. Recent years have seen two main approaches to guess missing facts: Rule Mining and Knowledge Graph Embeddings. The first approach is symbolic, and finds rules such as “If two people are married, they most likely live in the same city”. These rules can then be used to predict missing statements. Knowledge Graph Embeddings, on the other hand, are trained to predict missing facts for a knowledge base by mapping entities to a vector space. Each of these approaches has their strengths and weaknesses, and this article provides a survey of neuro-symbolic works that combine embeddings and rule mining approaches for fact prediction."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Deep Learning with Logical Constraints,""There has been increasing interest in logically specified background knowledge in order to obtain neural models with better performance, able to learn from less data, and/or guaranteed to be compliant with the background knowledge itself for safety-critical applications."",""Eleonora Giunchiglia, Mihaela Catalina Stoian, Thomas Lukasiewicz"",International Joint Conference on Artificial Intelligence,,,10.48550/arXiv.2205.00523,,2022,8,https://doi.org/10.48550/arXiv.2205.00523,https://semanticscholar.org/paper/f674c7958b9e2402001557487968de155d18024b,""In recent years, there has been an increasing interest in exploiting logically specified background knowledge in order to obtain neural models (i) with a better performance, (ii) able to learn from less data, and/or (iii) guaranteed to be compliant with the background knowledge itself, e.g., for safety-critical applications. In this survey, we retrace such works and categorize them based on (i) the logical language that they use to express the background knowledge and (ii) the goals that they achieve."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Paper title,Abstract summary,Authors,Journal,Influential citations,Scimago Journal Rank,DOI,PDF,Year,Citations,DOI URL,Semantic Scholar URL,Abstract,Takeaway suggests yes/no,Study type",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Towards Loosely-Coupling Knowledge Graph Embeddings and Ontology-based Reasoning,The prediction accuracy of knowledge graph embeddings is enhanced by domain knowledge that may not be included in the input knowledge graph.,""Zoi Kaoudi, Abelardo Carlos Mart??nez Lorenzo, V. Markl"",ArXiv,,,,,2022,2,,https://semanticscholar.org/paper/8ef2e6b11b519b609bfaa7ed056f621cee15d552,""Knowledge graph completion (a.k.a. link prediction), i.e., the task of inferring missing information from knowledge graphs, is a widely used task in many applications, such as product recommendation and question answering. The state-of-the-art approaches of knowledge graph embeddings and/or rule mining and reasoning are data-driven and, thus, solely based on the information the input knowledge graph contains. This leads to unsatisfactory prediction results which make such solutions inapplicable to crucial domains such as healthcare. To further enhance the accuracy of knowledge graph completion we propose to loosely-couple the data-driven power of knowledge graph embeddings with domain-specific reasoning stem-ming from experts or entailment regimes (e.g., OWL2). In this way, we not only enhance the prediction accuracy with domain knowledge that may not be included in the input knowledge graph but also allow users to plugin their own knowledge graph embedding and reasoning method. Our initial results show that we enhance the MRR accuracy of vanilla knowledge graph embeddings by up to 3x and outperform hybrid solutions that combine knowledge graph embeddings with rule mining and reasoning up to 3.5x MRR."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Improving the portability of predicting students’ performance models by using ontologies,The ontological models obtained in one source course can be applied to other different target courses with similar usage levels without losing prediction accuracy.,""Javier  López-Zambrano, Juan Alfonso Lara, Cristóbal  Romero"",J. Comput. High. Educ.,,,10.1007/s12528-021-09273-3,,2022,3,https://doi.org/10.1007/s12528-021-09273-3,https://semanticscholar.org/paper/76c4f2cd48b00b692a56962aef9ba25b778ff0f0,""One of the main current challenges in Educational Data Mining and Learning Analytics is the portability or transferability of predictive models obtained for a particular course so that they can be applied to other different courses. To handle this challenge, one of the foremost problems is the models’ excessive dependence on the low-level attributes used to train them, which reduces the models’ portability. To solve this issue, the use of high-level attributes with more semantic meaning, such as ontologies, may be very useful. Along this line, we propose the utilization of an ontology that uses a taxonomy of actions that summarises students’ interactions with the Moodle learning management system. We compare the results of this proposed approach against our previous results when we used low-level raw attributes obtained directly from Moodle logs. The results indicate that the use of the proposed ontology improves the portability of the models in terms of predictive accuracy. The main contribution of this paper is to show that the ontological models obtained in one source course can be applied to other different target courses with similar usage levels without losing",predic,tio,n accu,"racy.""",",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"A Framework for Context-Dependent Augmented Reality Applications Using Machine Learning and Ontological Reasoning,The framework has been prototypically implemented using the Microsoft HoloLens2 AR device and applied to a use case in the domain of work safety measures.,""Fabian Muff, Hans-Georg Fill"",AAAI Spring Symposium: MAKE,,,,,2022,,,https://semanticscholar.org/paper/24395ad770064aaf3c189439fd16836e263dcd99,""The concept of augmented reality permits to embed virtual objects and information within the real context of a user. This is achieved using various sensors to assess the current state of the environment and thus derive the artificially generated information for the user through visual means. For determining the current situation of a user based on sensor data and deriving according actions for information display, we describe a framework that combines machine learning services for object recognition with ontological reasoning. For demonstrating its feasibility, the framework has been prototypically implemented using the Microsoft HoloLens2 AR device and applied to a use case in the domain of work safety measures. Thereby we revert to business process models that have been annotated with concepts from an ontology for letting users specify the situations and actions in work safety scenarios, which can subsequently be processed using objects identified in the real environment of the user and classified based on the concepts in the ontology."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"OntoSenticNet 2: Enhancing Reasoning Within Sentiment Analysis,Knowledge-based representations within sentiment analysis systems are promising directions to investigate.,""M. Dragoni, Fondazione Bruno Kessler, Ivan Donadello, E. Cambria"",IEEE Intelligent Systems,,1.572 (1933),10.1109/MIS.2021.3093659,,2022,22,https://doi.org/10.1109/MIS.2021.3093659,https://semanticscholar.org/paper/7b112773b691e5c2627ec991115c4bbfb397b8cc,""Sentiment analysis is a trending topic that has not yet exhausted its attractiveness, despite the huge research effort carried out in the last 15 years. One of the most promising directions to investigate is the integration of knowledge-based representations within sentiment analysis systems in order to enhance their expressiveness and, at the same time, to enable reasoning over the relevant information detected within opinion-based sources. In this article, we present an improved version of OntoSenticNet providing: i) an updated definition of concepts, properties, and individuals together with an improved hierarchical organization of such entities; ii) the modeling of the sentic algebra elements for supporting the execution of semantic sentiment operations at reasoning time; and iii) the conceptual model of sentiment dependencies and discovery paths. The process of building OntoSenticNet 2 is discussed and some examples are proposed in order to illustrate the conceptual model."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Description Logic EL++ Embeddings with Intersectional Closure,The intersection of boxes is a box.,""X. Peng, Zhenwei Tang, Maxat Kulmanov, Kexin Niu, R. Hoehndorf"",ArXiv,,,,,2022,3,,https://semanticscholar.org/paper/6a3eb23a94823b2dd745330270663079f8e15fd1,""Many ontologies, in particular in the biomedical domain, are based on the Description Logic EL. Several efforts have been made to interpret and exploit ELontologies by distributed representation learning. Specifically, concepts within ELtheories have been represented as n-balls within an n-dimensional embedding space. However, the intersectional closure is not satisfied when using n-balls to represent concepts because the intersection of two n-balls is not an n-ball. This leads to challenges when measuring the distance between concepts and inferring equivalence between concepts. To this end, we developed EL Box Embedding (ELBE) to learn Description Logic ELembeddings using axis-parallel boxes. We generate specially designed box-based geometric constraints from ELaxioms for model training. Since the intersection of boxes remains as a box, the intersectional closure is satisfied. We report extensive experimental results on three datasets and present a case study to demonstrate the effectiveness of the proposed method."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"On Embeddings for Numerical Features in Tabular Deep Learning,Embedding numerical features is beneficial for many backbones.,""Yura Gorishniy, Ivan Rubachev, Artem Babenko"",ArXiv,,,10.48550/arXiv.2203.05556,,2022,10,https://doi.org/10.48550/arXiv.2203.05556,https://semanticscholar.org/paper/dba4c862dbaa9b7187ade4ae54dc7e9e425ad4e1,""Recently, Transformer-like deep architectures have shown strong performance on tabular data problems. Unlike traditional models, e.g., MLP, these architectures map scalar values of numerical features to high-dimensional embeddings before mixing them in the main backbone. In this work, we argue that embeddings for numerical features are an underexplored degree of freedom in tabular DL, which allows constructing more powerful DL models and competing with GBDT on some traditionally GBDT-friendly benchmarks. We start by describing two conceptually different approaches to building embedding modules: the first one is based on a piecewise linear encoding of scalar values, and the second one utilizes periodic activations. Then, we empirically demonstrate that these two approaches can lead to significant performance boosts compared to the embeddings based on conventional blocks such as linear layers and ReLU activations. Importantly, we also show that embedding numerical features is beneficial for many backbones, not only for Transformers. Specifically, after proper embeddings, simple MLP-like models can perform on par with the attention-based architectures. Overall, we highlight embeddings for numerical features as an important design aspect with good potential for further improvements in tabular DL."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"A Co-Embedding Model with Variational Auto-Encoder for Knowledge Graphs,""Traditional knowledge graph embedding techniques usually represent entities/relations as vectors or tensors, mapping them in different semantic spaces and ignoring the uncertainties."",""Lu-Yao Xie, Huimin Huang, Qing Du"",Applied Sciences,,0.44 (11182),10.3390/app12020715,https://www.mdpi.com/2076-3417/12/2/715/pdf?version=1641971281,2022,2,https://doi.org/10.3390/app12020715,https://semanticscholar.org/paper/a1533862421b709c193d6b62390b78cd10c80c3c,""Knowledge graph (KG) embedding has been widely studied to obtain low-dimensional representations for entities and relations. It serves as the basis for downstream tasks, such as KG completion and relation extraction. Traditional KG embedding techniques usually represent entities/relations as vectors or tensors, mapping them in different semantic spaces and ignoring the uncertainties. The affinities between entities and relations are ambiguous when they are not embedded in the same latent spaces. In this paper, we incorporate a co-embedding model for KG embedding, which learns low-dimensional representations of both entities and relations in the same semantic space. To address the issue of neglecting uncertainty for KG components, we propose a variational auto-encoder that represents KG components as Gaussian distributions. In addition, compared with previous methods, our method has the advantages of high quality and interpretability. Our experimental results on several benchmark datasets demonstrate our model’s superiority over the state-of-the-art baselines."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Complex Embedding with Type Constraints for Link Prediction,The impartment of type constraints improved its performance on link prediction effectively.,""Xiaohui Li, Zhiliang Wang, Zhaohui Zhang"",Entropy,,0.553 (9039),10.3390/e24030330,https://www.mdpi.com/1099-4300/24/3/330/pdf?version=1646123052,2022,1,https://doi.org/10.3390/e24030330,https://semanticscholar.org/paper/2e07bf55e51bfaed9d5d29bddb27d7dcf89d0038,""Large-scale knowledge graphs not only store entities and relations but also provide ontology-based information about them. Type constraints that exist in this information are of great importance for link prediction. In this paper, we proposed a novel complex embedding method, CHolE, in which complex circular correlation was introduced to extend the classic real-valued compositional representation HolE to complex domains, and type constraints were integrated into complex representational embeddings for improving link prediction. The proposed model consisted of two functional components, the type constraint model and the relation learning model, to form type constraints such as modulus constraints and acquire the relatedness between entities accurately by capturing rich interactions in the modulus and phase angles of complex embeddings. Experimental results on benchmark datasets showed that CHolE outperformed previous state-of-the-art methods, and the impartment of type constraints improved its performance on link prediction effectively."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"PIE: a Parameter and Inference Efficient Solution for Large Scale Knowledge Graph Embedding Reasoning,The self-supervised auxiliary task can reduce more than half of the parameters while maintaining comparable performance.,""Linlin Chao, Taifeng Wang, Wei Chu"",ArXiv,,,10.48550/arXiv.2204.13957,,2022,3,https://doi.org/10.48550/arXiv.2204.13957,https://semanticscholar.org/paper/d67b20cc794c4ab5536fc665678f67042190f685,""Knowledge graph (KG) embedding methods which map entities and relations to unique embeddings in the KG have shown promising results on many reasoning tasks. However, the same embedding dimension for both dense entities and sparse entities will cause either over parameterization (sparse entities) or under ?tting (dense entities). Normally, a large dimension is set to get better performance. Meanwhile, the inference time grows log-linearly with the number of entities for all entities are traversed and compared. Both the parameter and inference become challenges when working with huge amounts of entities. Thus, we propose PIE, a p arameter and i nference e f?cient solution. Inspired from tensor decomposition methods, we ?nd that decompose entity embedding matrix into low rank matrices can reduce more than half of the parameters while maintaining comparable performance. To accelerate model inference, we propose a self-supervised auxiliary task, which can be seen as ?ne-grained entity typing. By randomly masking and recovering entities’ connected relations, the task learns the co-occurrence of entity and relations. Utilizing the ?ne grained typing, we can ?lter unrelated entities during inference and get targets with possibly sub-linear time re",quireme,nt.,Exper,iments,"on link prediction benchmarks demonstrate the proposed key capabilities. Moreover, we prove effectiveness of the proposed solution on the Open Graph Benchmark large scale challenge dataset WikiKG90Mv2 and achieve the state of the art performance."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Modular ontology modeling,Reusing ontologies for new purposes or adapting them to new use-cases is frequently difficult.,""C. Shimizu, K. Hammar, P. Hitzler"",Semantic Web,,1.242 (2878),10.3233/sw-222886,,2022,10,https://doi.org/10.3233/sw-222886,https://semanticscholar.org/paper/5029a31f0f39a7e0ee21109f67a7c5cc7132633f,""Reusing ontologies for new purposes, or adapting them to new use-cases, is frequently difficult. In our experiences, we have found this to be the case for several reasons: (i) differing representational granularity in ontologies and in use-cases, (ii) lacking conceptual clarity in potentially reusable ontologies, (iii) lack and difficulty of adherence to good modeling principles, and (iv) a lack of reuse emphasis and process support available in ontology engineering tooling. In order to address these concerns, we have developed the Modular Ontology Modeling (MOMo) methodology, and its supporting tooling infrastructure, CoModIDE (the Comprehensive Modular Ontology IDE – “commodity”). MOMo builds on the established eXtreme Design methodology, and like it emphasizes modular development and design pattern reuse; but crucially adds the extensive use of graphical schema diagrams, and tooling that support them, as vehicles for knowledge elicitation from experts. In this paper, we present the MOMo workflow in detail, and describe several useful resources for executing it. In particular, we provide a thorough and rigorous evaluation of CoModIDE in its role of supporting the MOMo methodology’s graphical modeling paradigm. We find that CoModIDE significantly improves approachability of such a paradigm, and that it displays a high usability."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Knowledge Graph Reasoning with Logics and Embeddings: Survey and Perspective,Logic-based and embedding-based methods are integrated in knowledge graph reasoning.,""Wen Zhang, Jiaoyan Chen, Juan Li, Zezhong Xu, Jeff Z. Pan, Huajun Chen"",ArXiv,,,,,2022,3,,https://semanticscholar.org/paper/4baf6f668b6b10a33a16f12aa51b0edef02b1c35,""Knowledge graph (KG) reasoning is becoming increasingly popular in both academia and industry. Conventional KG reasoning based on symbolic logic is deterministic, with reasoning results being explainable, while modern embedding-based reasoning can deal with uncertainty and predict plausible knowledge, often with high efficiency via vector computation. A promising direction is to integrate both logic-based and embedding-based methods, with the vision to have advantages of both. It has attracted wide research attention with more and more works published in recent years. In this paper, we comprehensively survey these works, focusing on how logics and embeddings are integrated. We first briefly introduce preliminaries, then systematically categorize and discuss works of logic and embedding-aware KG reasoning from different perspectives, and finally conclude and discuss the challenges and further directions."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Concept Embedding Models,""Existing concept bottleneck models are unable to find optimal compromises between high task accuracy, robust concept-based explanations, and effective interventions on concepts."",""M. Zarlenga, Pietro Barbiero, Gabriele Ciravegna, G. Marra, Francesco Giannini, M. Diligenti, Z. Shams, F. Precioso, S. Melacci, Adrian Weller, Pietro Lio', M. Jamnik"",ArXiv,,,10.48550/arXiv.2209.09056,,2022,2,https://doi.org/10.48550/arXiv.2209.09056,https://semanticscholar.org/paper/540bb63289636fea28172604881994f7bc41c896,""Deploying AI-powered systems requires trustworthy models supporting effective human interactions, going beyond raw prediction accuracy. Concept bottleneck models promote trustworthiness by conditioning classi?cation tasks on an intermediate level of human-like concepts. This enables human interventions which can correct mispredicted concepts to improve the model’s performance. However, existing concept bottleneck models are unable to ?nd optimal compromises between high task accuracy, robust concept-based explanations, and effective interventions on concepts—particularly in real-world conditions where complete and accurate concept supervisions are scarce. To address this, we propose Concept Embedding Models, a novel family of concept bottleneck models which goes beyond the current accuracy-vs-interpretability trade-off by learning interpretable high-dimensional concept representations. Our experiments demonstrate that Concept Embedding Models (1) attain better or competitive task accuracy w.r.t. standard neural models without"",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Emblaze: Illuminating Machine Learning Representations through Interactive Comparison of Embedding Spaces,Emblaze integrates embedding space comparison within a computational notebook environment.,""Venkatesh Sivaraman, Yiwei Wu, Adam Perer"",International Conference on Intelligent User Interfaces,,,10.1145/3490099.3511137,https://dl.acm.org/doi/pdf/10.1145/3490099.3511137,2022,3,https://doi.org/10.1145/3490099.3511137,https://semanticscholar.org/paper/372f46308d131674c3f140b49db1fbe3dd7dfe79,""Modern machine learning techniques commonly rely on complex, high-dimensional embedding representations to capture underlying structure in the data and improve performance. In order to characterize model flaws and choose a desirable representation, model builders often need to compare across multiple embedding spaces, a challenging analytical task supported by few existing tools. We first interviewed nine embedding experts in a variety of fields to characterize the diverse challenges they face and techniques they use when analyzing embedding spaces. Informed by these perspectives, we developed a novel system called Emblaze that integrates embedding space comparison within a computational notebook environment. Emblaze uses an animated, interactive scatter plot with a novel Star Trail augmentation to enable visual comparison. It also employs novel neighborhood analysis and clustering procedures to dynamically suggest groups of points with interesting changes between spaces. Through a series of case studies with ML experts, we demonstrate how interactive comparison with Emblaze can help gain new insights into embedding space structure."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Concept Embedding Models: Beyond the Accuracy-Explainability Trade-Off,""Existing concept bottleneck models are unable to find optimal compromises between high task accuracy, robust concept-based explanations."",""M. Zarlenga, Pietro Barbiero, Gabriele Ciravegna, G. Marra, Francesco Giannini, M. Diligenti, Z. Shams, F. Precioso, S. Melacci, Adrian Weller, Pietro Lio', M. Jamnik"",,,,,,2022,1,,https://semanticscholar.org/paper/ce3036fadfa9692867532fe472ea40b4b81a6dc3,""Deploying AI-powered systems requires trustworthy models supporting effective human interactions, going beyond raw prediction accuracy. Concept bottleneck models promote trustworthiness by conditioning classi?cation tasks on an intermediate level of human-like concepts. This enables human interventions which can correct mispredicted concepts to improve the model’s performance. However, existing concept bottleneck models are unable to ?nd optimal compromises between high task accuracy, robust concept-based explanations"",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Improving Transitive Embeddings in Neural Reasoning Tasks via Knowledge-Based Policy Networks (full paper),Knowledge graph embedding methods can achieve Hits@10 as high as %73 using samples generated by a policy network.,""Shervin Mehryar, R. Çelebi"",SemREC/SMART@ISWC,,,,,2022,,,https://semanticscholar.org/paper/eb6940bfb839e4f75136914a3f35adfee0a1f002,"". This paper proposes an approach to embed ontologies in order to deal with reasoning based on transitive relations, using the datasets provided for the SemRec Challenge at ISWC 2022. Knowledge Graph Embedding (KGE) methods provide a low-dimensional representation of the entities and relationships extracted from the knowledge graph and have been successfully used for a variety of applications such as question answering, reasoning, inference, and link prediction. However, most KGE methods cannot handle the underlying constraints and characteristics of ontologies, preventing them from performing important reasoning tasks such as subsumption and instance checking. We propose to extend translation-based embedding methods to include subsumption and instance checking reasoning by leveraging transitive relations. Ex-perimental results show that our approach can achieve Hits@10 as high as %73 using samples generated by a policy network."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Exploiting the Power of Equality-generating Dependencies in Ontological Reasoning,Equality-generating dependencies are at the core of many common reasoning tasks.,""Luigi Bellomarini, Davide Benedetto, M. Brandetti, Emanuel Sallinger"",Proceedings of the VLDB Endowment,,2.376 (927),10.14778/3565838.3565850,,2022,,https://doi.org/10.14778/3565838.3565850,https://semanticscholar.org/paper/885a27c73cf094c41647607fbf8ea1ae3eb89e1f,""Equality-generating dependencies (EGDs) allow to fully exploit the power of existential quantification in ontological reasoning settings modeled via Tuple-Generating Dependencies (TGDs), by enabling value-assignment or forcing the equivalence of fresh symbols. These capabilities are at the core of many common reasoning tasks, including graph traversals, clustering, data matching and data fusion, and many more related real-world scenarios.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Ontology Matching Through Absolute Orientation of Embedding Spaces,The approach works well on similarly structured graphs.,""Jan Portisch, Guilherme Costa, Karolin Stefani, K. Kreplin, M. Hladik, H. Paulheim"",Extended Semantic Web Conference,,,10.48550/arXiv.2204.04040,,2022,1,https://doi.org/10.48550/arXiv.2204.04040,https://semanticscholar.org/paper/573a7923883ae5f82776a0799947d5274fd6de2a,"". Ontology matching is a core task when creating interoperable and linked open datasets. In this paper, we explore a novel structure-based mapping approach which is based on knowledge graph embeddings: The ontologies to be matched are embedded, and an approach known as absolute orientation is used to align the two embedding spaces. Next to the approach, the paper presents a ?rst, preliminary evaluation using synthetic and real-world datasets. We ?nd in experiments with synthetic data, that the approach works very well on similarly structured graphs; it handles alignment noise better than size and structural di?erences in the ontologies."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Representing Mixtures of Word Embeddings with Mixtures of Topic Embeddings,A topic modeling framework embeds words and topics in the same vector space.,""Dongsheng Wang, D. Guo, He Zhao, Huangjie Zheng, Korawat Tanwisuth, Bo Chen, Mingyuan Zhou"",International Conference on Learning Representations,,,10.48550/arXiv.2203.01570,,2022,4,https://doi.org/10.48550/arXiv.2203.01570,https://semanticscholar.org/paper/4102043f373446a92b81c2e8c7e9e747e7f5d434,""A topic model is often formulated as a generative model that explains how each word of a document is generated given a set of topics and document-specific topic proportions. It is focused on capturing the word co-occurrences in a document and hence often suffers from poor performance in analyzing short documents. In addition, its parameter estimation often relies on approximate posterior inference that is either not scalable or suffers from large approximation error. This paper introduces a new topic-modeling framework where each document is viewed as a set of word embedding vectors and each topic is modeled as an embedding vector in the same embedding space. Embedding the words and topics in the same vector space, we define a method to measure the semantic difference between the embedding vectors of the words of a document and these of the topics, and optimize the topic embeddings to minimize the expected difference over all documents. Experiments on text analysis demonstrate that the proposed method, which is amenable to mini-batch stochastic gradient descent based optimization and hence scalable to big corpora, provides competitive performance in discovering more coherent and diverse topics and extracting",better,do,cument,repre,"sentations. The code is available at https://github.com/BoChenGroup/WeTe."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Embedding Regression: Models for Context-Specific Description and Inference,A fast and simple method produces valid vector representations of how words are used in different contexts.,""Pedro L. Rodriguez, A. Spirling, Brandon M Stewart"",American Political Science Review,,5.816 (201),10.1017/s0003055422001228,https://www.cambridge.org/core/services/aop-cambridge-core/content/view/4C90013E5C714C8483ED95CC699022FB/S0003055422001228a.pdf/div-class-title-embedding-regression-models-for-context-specific-description-and-inference-div.pdf,2023,3,https://doi.org/10.1017/s0003055422001228,https://semanticscholar.org/paper/761dc674ee0aa898043ead184a922f21731ff37a,""Social scientists commonly seek to make statements about how word use varies over circumstances—including time, partisan identity, or some other document-level covariate. For example, researchers might wish to know how Republicans and Democrats diverge in their understanding of the term “immigration.” Building on the success of pretrained language models, we introduce the à la carte on text (conText) embedding regression model for this purpose. This fast and simple method produces valid vector representations of how words are used—and thus what words “mean”—in different contexts. We show that it outperforms slower, more complicated alternatives and works well even with very few documents. The model also allows for hypothesis testing and statements about statistical significance. We demonstrate that it can be used for a broad range of important tasks, including understanding US polarization, historical legislative development, and sentiment detection. We provide open-source software for fitting the mode","l."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Ontology of Mathematical Modeling Based on Interval Data,Mathematical models built using interval data analysis are quite effective in many applications.,""M. Dyvak, A. Melnyk, Artur Rot, Marcin Hernes, A. Pukas"",Complex,,,10.1155/2022/8062969,,2022,6,https://doi.org/10.1155/2022/8062969,https://semanticscholar.org/paper/0ec9c5a5b60e592e7f369fe7dba67284ca4270d4,""An ontological approach as a tool for managing the processes of constructing mathematical models based on interval data and further use of these models for solving applied problems is proposed in this article. Mathematical models built using interval data analysis are quite effective in many applications, as they have “guaranteed” predictive properties, which are determined by the accuracy of experimental data. However, the application of mathematical modeling methods is complicated by the lack of software tools for the implementation of procedures for constructing this type of mathematical models, creating an ontological model that operates by the categories of the subject area of mathematical modeling, regardless of the modeling object proposed in this article. This approach has made it possible to generate tools for mathematical modeling of various objects based on the interval data analysis for any software development environment selected by the user. The technology of creating the software on the basis of the developed ontological superstructure for mathematical modeling using the interval data for different objects, as well as various forms of user interface implementation, is presented in this article. A number of schemes, which illustrate the technology of using the ontological approac",h of ma,the,matica,l mode,"ling based on interval data, are presented, and the features of its interpretation when solving environmental monitoring problems are described."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Ontology-Based Production Simulation with OntologySim,The ability to generate truly cyber physical systems interlocked with reality can help solving the challenge.,""M. May, Lars Kiefer, Andreas Kuhnle, G. Lanza"",Applied Sciences,,0.44 (11182),10.3390/app12031608,https://www.mdpi.com/2076-3417/12/3/1608/pdf?version=1644384411,2022,5,https://doi.org/10.3390/app12031608,https://semanticscholar.org/paper/ccec5459ae25a2242d6779fb161efc97cc8fb522,""Imagine the possibility to save a simulation at any time, modify or analyze it, and restart again with exactly the same state. The conceptualization and its concrete manifestation in the implementation OntologySim is demonstrated in this paper. The presented approach of a fully ontology-based simulation can solve current challenges in modeling and simulation in production science. Due to the individualization and customization of products and the resulting increase in complexity of production, a need for flexibly adaptable simulations arises. This need is exemplified in the trend towards Digital Twins and Digital Shadows. Their application to production systems, against the background of an ever increasing speed of change in such systems, is arduous. Moreover, missing understandability and human interpretability of current approaches hinders successful, goal oriented applications. The OntologySim can help solving this challenge by providing the ability to generate truly cyber physical systems, both interlocked with reality and providing a simulation framework. In a nutshell, this paper presents a discrete-event-based open-source simulation using multi-agency and ontology."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Query Embedding on Hyper-relational Knowledge Graphs,Existing approaches for approximate query answering cannot make use of qualifier pairs.,""Dimitrios Alivanistos, M. Berrendorf, Michael Cochez, Mikhail Galkin"",ICLR,,,,,2022,1,,https://semanticscholar.org/paper/fedbff3683daf4317f3c9521f190ffc410f91458,""Multi-hop logical reasoning is an established problem in the field of representation learning on knowledge graphs (KGs). It subsumes both one-hop link prediction as well as other more complex types of logical queries. Existing algorithms operate only on classical, triple-based graphs, whereas modern KGs often employ a hyperrelational modeling paradigm. In this paradigm, typed edges may have several key-value pairs known as qualifiers that provide fine-grained context for facts. In queries, this context modifies the meaning of relations, and usually reduces the answer set. Hyper-relational queries are often observed in real-world KG applications, and existing approaches for approximate query answering cannot make use of qualifier pairs. In this work, we bridge this gap and extend the multi-hop reasoning problem to hyper-relational KGs allowing to tackle this new type of complex queries. Building upon recent advancements in Graph Neural Networks and query embedding techniques, we study how to embed and answer hyper-relational conjunctive queries. Besides that, we propose a method to answer such queries and demonstrate in our experiments that qualifiers improve query answering on a diverse set of query patterns."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Amalgamation of Embeddings With Model Explainability for Sentiment Analysis,Combining context-free and context-dependent text representations potentially capture complementary features of word meaning.,""Shila Jawale, S.D. Sawarker"",International Journal of Applied Evolutionary Computation,,,10.4018/ijaec.315629,,2022,,https://doi.org/10.4018/ijaec.315629,https://semanticscholar.org/paper/38bdc360af744615b54841b988dfbfb3f92aabb0,""Regarding the ubiquity of digitalization and electronic processing, an automated review processing system, also known as sentiment analysis, is crucial. There were many architectures and word embeddings employed for effective sentiment analysis. Deep learning is now-a-days becoming prominent for solving these problems as huge amounts of data get generated per second. In deep learning, word embedding acts as a feature representative and plays an important role. This paper proposed a novel deep learning architecture which represents hybrid embedding techniques that address polysemy, semantic and syntactic issues of a language model, along with justifying the model prediction. The model is evaluated on sentiment identification tasks, obtaining the result as F1-score 0.9254 and F1-score 0.88, for MR and Kindle dataset respectively. The proposed model outperforms many current techniques for both tasks in experiments, suggesting that combining context-free and context-dependent text representations potentially capture complementary features of word meaning. The model decisions justified with the help of visualization techniques such as t-SNE."",,Review",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Kelpie: an Explainability Framework for Embedding-based Link Prediction Models,Link prediction models rely on embeddings to tackle incompleteness in Knowledge Graphs.,""Andrea Rossi, D. Firmani, P. Merialdo, Tommaso Teofili"",Proceedings of the VLDB Endowment,,2.376 (927),,,2022,,,https://semanticscholar.org/paper/055122ac08ae0c6a66e4cfba779002271fb7a9d5,""The latest generations of Link Prediction (LP) models rely on embeddings to tackle incompleteness in Knowledge Graphs, achieving great performance at the cost of interpretability. Their opaqueness limits the trust that users can place in them, hindering their adoption in real-world applications. We have recently introduced Kelpie, an explainability framework tailored specifically for embedding-based LP models. Kelpie can be applied to any embedding-based LP model, and supports two explanation scenarios that we have called necessary and sufficient . In this demonstration we showcase Kelpie’s capability to explain the predictions of models based on vastly different architectures on the 5 major datasets in literature."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Link Prediction with Attention Applied on Multiple Knowledge Graph Embedding Models,Combining query representations from several models in a unified one can learn relational and structural patterns.,""Cosimo Gregucci, M. Nayyeri, D. Hern'andez, Steffen Staab"",,,,10.1145/3543507.3583358,https://eprints.soton.ac.uk/475536/1/Link_Prediction_Geometric_Query_Attention.pdf,2023,,https://doi.org/10.1145/3543507.3583358,https://semanticscholar.org/paper/d9802a67b326fe89bbd761c261937ee1e4d4d674,""Predicting missing links between entities in a knowledge graph is a fundamental task to deal with the incompleteness of data on the Web. Knowledge graph embeddings map nodes into a vector space to predict new links, scoring them according to geometric criteria. Relations in the graph may follow patterns that can be learned, e.g., some relations might be symmetric and others might be hierarchical. However, the learning capability of different embedding models varies for each pattern and, so far, no single model can learn all patterns equally well. In this paper, we combine the query representations from several models in a unified one to incorporate patterns that are independently captured by each model. Our combination uses attention to select the most suitable model to answer each query. The models are also mapped onto a non-Euclidean manifold, the Poincar\'e ball, to capture structural patterns, such as hierarchies, besides relational patterns, such as symmetry. We prove that our combination provides a higher expressiveness and inference power than each model on its own. As a result, the combined model can learn relational and structural patterns. We conduct extensive",experi,men,tal an,alysis,"with various link prediction benchmarks showing that the combined model outperforms individual models, including state-of-the-art approaches."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Disentangling Embedding Spaces with Minimal Distributional Assumptions,Disjoint attributions concept discovery method is applicable to a broader class of problems than current approaches.,""Tobias Leemann, M. Kirchhof, Yao Rong, Enkelejda Kasneci, G. Kasneci"",ArXiv,,,10.48550/arXiv.2206.13872,,2022,2,https://doi.org/10.48550/arXiv.2206.13872,https://semanticscholar.org/paper/cde6b04e48a01509ab8f59ac3284e7f00fec3a1d,""Interest in understanding and factorizing learned embedding spaces is growing. For instance, recent concept-based explanation techniques analyze a machine learning model in terms of interpretable latent components. Such components have to be discovered in the model’s embedding space, e.g., through independent component analysis (ICA) or modern disentanglement learning techniques. While these unsupervised approaches offer a sound formal framework, they either require access to a data generating function or impose rigid assumptions on the data distribution, such as independence of components, that are often violated in practice. In this work, we link conceptual explainability for vision models with disentanglement learning and ICA. This enables us to provide first theoretical results on how components can be identified without requiring any distributional assumptions. From these insights, we derive the disjoint attributions (DA) concept discovery method that is applicable to a broader class of problems than current approaches, but yet possesses a formal identifiability guarantee. In an extensive comparison against component analysis and over 300 state-of-the-art disentanglement models, DA stably maintains superior performance, even under vary",ing dis,tri,bution,s and,"correlation strengths."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Mobile Devices Interface Adaptivity Using Ontologies,The semantic context model is focused to bring in the usage of adaptive environment.,""Muhammad Waseem Iqbal, Muhammad Raza Naqvi, Muhammad Adnan Khan, Faheem Khan, T. Whangbo"",Computers Materials & Continua,,,10.32604/cmc.2022.023239,https://www.techscience.com/cmc/v71n3/46496/pdf,2022,29,https://doi.org/10.32604/cmc.2022.023239,https://semanticscholar.org/paper/f8d5a4ea6242ab90c788e4c3963caf752f09e91b,""Currently, many mobile devices provide various interaction styles and modes which create complexity in the usage of interfaces. The context offers the information base for the development of Adaptive user interface (AUI) frameworks to overcome the heterogeneity. For this purpose, the ontological modeling has been made for specific context and environment. This type of philosophy states to the relationship among elements (e.g., classes, relations, or capacities etc.) with understandable satisfied representation. The context mechanisms can be examined and understood by any machine or computational framework with these formal definitions expressed in Web ontology language (WOL)/Resource description frame work (RDF). The Protégé is used to create taxonomy in which system is framed based on four contexts such as user, device, task and environment. Some competency questions and use-cases are utilized for knowledge obtaining while the information is refined through the instances of concerned parts of context tree. The consistency of the model has been verified through the reasoning software while SPARQL querying ensured the data availability in the models for defined use-cases. The semantic context model is",focuse,d t,o brin,g in t,"he usage of adaptive environment. This exploration has finished up with a versatile, scalable and semantically verified context learning system. This model can be mapped to individual User interface (UI) display through smart calculations for versatile UIs."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"""Establishing Meta-Decision-Making for AI: An Ontology of Relevance, Representation and Reasoning"",The ontology allows researchers that adopt it to frame their work in relation to one or more of these parts.,""C. Badea, Leilani H. Gilpin"",ArXiv,,,10.48550/arXiv.2210.00608,,2022,2,https://doi.org/10.48550/arXiv.2210.00608,https://semanticscholar.org/paper/b384a88daccffa86f4c9af5deee02719ce209ee8,""We propose an ontology of building decision-making sys- tems, with the aim of establishing Meta-Decision-Making for Arti?cial Intelligence (AI), improving autonomy, and creat- ing a framework to build metrics and benchmarks upon. To this end, we propose the three parts of Relevance, Representa- tion, and Reasoning, and discuss their value in ensuring safety and mitigating risk in the context of third wave cognitive sys- tems. Our nomenclature re?ects the literature on decision-making, and our ontology allows researchers that adopt it to frame their work in relation to one or more of these parts."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Contextual Semantic Embeddings for Ontology Subsumption Prediction,BERTSubs can predict multiple kinds of subsumers from the same ontology or another ontology.,""Jiaoyan Chen, Yuan He, E. Jiménez-Ruiz, Hang Dong, I. Horrocks"",ArXiv,,,,,2022,1,,https://semanticscholar.org/paper/5785c7ccf7691911cfb23f7d24d064a953e8cfef,""Automating ontology construction and curation is an important but challenging task in knowledge engineering and arti?cial intelligence. Prediction by machine learning techniques such as contextual semantic embedding is a promising direction, but the relevant research is still preliminary especially for expressive ontologies in Web Ontology Language (OWL). In this paper, we present a new subsumption prediction method named BERTSubs for classes of OWL ontology. It exploits the pre-trained language model BERT to compute contextual embeddings of a class, where customized templates are proposed to incorporate the class context (e.g., neighbouring classes) and the logical existential restriction. BERTSubs is quite general, being able to predict multiple kinds of subsumers including named classes and existential restrictions from the same ontology or another ontology. Extensive evaluation on ?ve real-world ontologies for three different subsumption tasks has shown the effectiveness of the templates and that BERTSubs can dramatically outperform the baselines that use (literal-aware) knowledge graph embeddings, non-contextual word embeddings and the state-of-the-art OWL ontology embeddings."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Contextual Semantic Embeddings for Ontology Subsumption Prediction,BERTSubs can predict multiple kinds of subsumers from the same ontology or another ontology.,""Jiaoyan Chen, Yuan He, E. Jiménez-Ruiz, Hang Dong, I. Horrocks"",ArXiv,,,,,2022,1,,https://semanticscholar.org/paper/44bfb8934cf5bf345903166f380dcc5ac159dd7a,""Automating ontology construction and curation is an important but challenging task in knowledge engineering and arti?cial intelligence. Prediction by machine learning techniques such as contextual semantic embedding is a promising direction, but the relevant research is still preliminary especially for expressive ontologies in Web Ontology Language (OWL). In this paper, we present a new subsumption prediction method named BERTSubs for classes of OWL ontology. It exploits the pre-trained language model BERT to compute contextual embeddings of a class, where customized templates are proposed to incorporate the class context (e.g., neighbouring classes) and the logical existential restriction. BERTSubs is quite general, being able to predict multiple kinds of subsumers including named classes and existential restrictions from the same ontology or another ontology. Extensive evaluation on ?ve real-world ontologies for three different subsumption tasks has shown the effectiveness of the templates and that BERTSubs can dramatically outperform the baselines that use (literal-aware) knowledge graph embeddings, non-contextual word embeddings and the state-of-the-art OWL ontology embeddings."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Using Ontologies for the Formalization and Recognition of Criticality for Automated Driving,Ontologies are a powerful tool for modeling and formalization of factors associated with criticality in the environment of automated vehicles.,""Lukas Westhofen, Christian Neurohr, Martin Butz, Maike Scholtes, Michael Schuldes"",IEEE Open Journal of Intelligent Transportation Systems,,,10.48550/arXiv.2205.01532,,2022,2,https://doi.org/10.48550/arXiv.2205.01532,https://semanticscholar.org/paper/0dc1b434caf405fdfeeb0ce5b8d37c09c2fadab2,""Knowledge representation and reasoning has a long history of examining how knowledge can be formalized, interpreted, and semantically analyzed by machines. In the area of automated vehicles, recent advances suggest the ability to formalize and leverage relevant knowledge as a key enabler in handling the inherently open and complex context of the traffic world. This paper demonstrates ontologies to be a powerful tool for a) modeling and formalization of and b) reasoning about factors associated with criticality in the environment of automated vehicles. For this, we leverage the well-known 6-Layer Model to create a formal representation of the environmental context. Within this representation, an ontology models domain knowledge as logical axioms, enabling deduction on the presence of critical factors within traffic scenarios. For executing automated analyses, a joint description logic and rule reasoner is used in combination with an a-priori predicate augmentation. We elaborate on the modular approach, present a publicly available implementation, and exemplarily evaluate the method by means of a large-scale drone data set of urban tr",affic s,cen,arios.,""",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Enhancing Cubes with Models to Describe Multidimensional Data,""The automatic tuning of models (e.g., the number of clusters) is a research challenge left open in IAM."",""Matteo  Francia, Patrick  Marcel, Verónika  Peralta, Stefano  Rizzi"",Inf. Syst. Frontiers,,,10.1007/s10796-021-10147-3,https://link.springer.com/content/pdf/10.1007/s10796-021-10147-3.pdf,2022,1,https://doi.org/10.1007/s10796-021-10147-3,https://semanticscholar.org/paper/27dcb435121227e2f507247a7421cf16aea115d0,""The Intentional Analytics Model (IAM) has been recently envisioned as a new paradigm to couple OLAP and analytics. It relies on two basic ideas: (i) letting the user explore data by expressing her analysis intentions rather than the data she needs, and (ii) returning enhanced cubes, i.e., multidimensional data annotated with knowledge insights in the form of interesting model components (e.g., clusters). In this paper we contribute to give a proof-of-concept for the IAM vision by delivering an end-to-end implementation of describe , one of the five intention operators introduced by IAM. Among the research challenges left open in IAM, those we address are (i) automatically tuning the size of models (e.g., the number of clusters), (ii) devising a measure to estimate the interestingness of model components, (iii) selecting the most effective chart or graph for visualizing each enhanced cube depending on its features, and (iv) devising a visual metaphor to display enhanced cubes and interact with them. We assess the validity of our approach in terms of user effort for formulating intentions, effectiveness, efficiency, and scalability."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Tsetlin Machine Embedding: Representing Words Using Logical Expressions,A Tsetlin Machine-based autoencoder learns logical clauses self-supervised.,""Bimal Bhattarai, Ole-Christoffer Granmo, Lei Jiao, Rohan Kumar Yadav, Jivitesh Sharma"",ArXiv,,,10.48550/arXiv.2301.00709,,2023,2,https://doi.org/10.48550/arXiv.2301.00709,https://semanticscholar.org/paper/78a1ac59ecdea71529a5ffa9bf73b2d1bf1247b8,""Embedding words in vector space is a fundamen-tal ?rst step in state-of-the-art natural language processing (NLP). Typical NLP solutions employ pre-de?ned vector representations to improve gener-alization by co-locating similar words in vector space. For instance, Word2Vec is a self-supervised predictive model that captures the context of words using a neural network. Similarly, GLoVe is a popular unsupervised model incorporating corpus-wide word co-occurrence statistics. Such word embedding has signi?cantly boosted important NLP tasks, including sentiment analysis, document classi?cation, and machine translation. However, the embeddings are dense ?oating-point vectors, making them expensive to compute and dif?cult to in-terpret. In this paper, we instead propose to represent the semantics of words with a few de?ning words that are related using propositional logic. To produce such logical embeddings, we introduce a Tsetlin Machine-based autoencoder that learns logical clauses self-supervised. The clauses con-sist of contextual words like “black,” “cup,” and “hot” to de?ne other words like “coffee,” thus being human-understandable. We evaluate our embedding approach on several intrinsic and extrinsic benchmarks, outperforming GLoVe on six classi?cation tasks. Fur",thermor,"e,",we inv,estiga,"te the interpretability of our embedding using the logical representations acquired during training. We also visualize word clusters in vector space, demonstrating how our logical embedding co-locate similar words. 1"",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Learning Backward Compatible Embeddings,The best method maintains backward compatibility with existing unintended tasks even after multiple model version updates.,""Weihua Hu, Rajas Bansal, Kaidi Cao, Nikhil S. Rao, Karthik Subbian, J. Leskovec"",Knowledge Discovery and Data Mining,,,10.1145/3534678.3539194,http://arxiv.org/pdf/2206.03040,2022,3,https://doi.org/10.1145/3534678.3539194,https://semanticscholar.org/paper/acc682841729ec95416aa61589d7e1a91d2c2b77,""Embeddings, low-dimensional vector representation of objects, are fundamental in building modern machine learning systems. In industrial settings, there is usually an embedding team that trains an embedding model to solve intended tasks (e.g., product recommendation). The produced embeddings are then widely consumed by consumer teams to solve their unintended tasks (e.g., fraud detection). However, as the embedding model gets updated and retrained to improve performance on the intended task, the newly-generated embeddings are no longer compatible with the existing consumer models. This means that historical versions of the embeddings can never be retired or all consumer teams have to retrain their models to make them compatible with the latest version of the embeddings, both of which are extremely costly in practice. Here we study the problem of embedding version updates and their backward compatibility. We formalize the problem where the goal is for the embedding team to keep updating the embedding version, while the consumer teams do not have to retrain their models. We develop a solution based on learning backward compatible embeddings, which allows the embedding model version to be updated freq","uently,",wh,ile al,so all,"owing the latest version of the embedding to be quickly transformed into any backward compatible historical version of it, so that consumer teams do not have to retrain their models. Our key idea is that whenever a new embedding model is trained, we learn it together with a light-weight backward compatibility transformation that aligns the new embedding to the previous version of it. Our learned backward transformations can then be composed to produce any historical version of embedding. Under our framework, we explore six methods and systematically evaluate them on a real-world recommender system application. We show that the best method, which we call BC-Aligner, maintains backward compatibility with existing unintended tasks even after multiple model version updates. Simultaneously, BC-Aligner achieves the intended task performance similar to the embedding model that is solely optimized for the intended task. Code is publicly available at https://github.com/snap-stanford/bc-emb"",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Explaining Ontology-Mediated Query Answers using Proofs over Universal Models (Technical Report),The complexity of determining the existence of a proof below a given quality threshold can be measured in different ways for several Horn DLs.,""Christian Alrabbaa, Stefan Borgwardt, P. Koopmann, Alisa Kovtunova"",RuleML+RR,,,10.48550/arXiv.2208.14381,,2022,1,https://doi.org/10.48550/arXiv.2208.14381,https://semanticscholar.org/paper/914a5b312a2bb6c886d35edc952d5e7b9419e2be,""In ontology-mediated query answering, access to incomplete data sources is mediated by a conceptual layer constituted by an ontology, which can be formulated in a description logic (DL) or using existential rules. In the literature, there exists a multitude of complex techniques for incorporat-ing ontological knowledge into queries. However, few of these approaches were designed for explainability of the query answers. We tackle this chal-lenge by adapting an existing proof framework toward conjunctive query answering, based on the notion of universal models. We investigate the data and combined complexity of determining the existence of a proof below a given quality threshold, which can be measured in di?erent ways. By distinguishing various parameters such as the shape of the query, we obtain an overview of the complexity of this problem for several Horn DLs."",,Review",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"FOG: A Generic Framework for Knowledge Graph Embedding with Ontology Guided Relational Constrains,Knowledge graph embedding models have limited capability for complex implicit information reasoning.,""Tengwei Song, Jie Luo, Xiang Chen"",,,,,,2022,,,https://semanticscholar.org/paper/b0bc749f8f669472a9719f512d4b997c5848a25b,"". Many knowledge graph (KG) embedding models have been proposed for knowledge acquisition tasks and have achieved high performance on common evaluation metrics. However, many current KG embedding models have only limited capability for complex implicit information reasoning and may derive results that contradict the ontology of the KG. To tackle this problem, we propose an ontology-guided joint embedding framework to incorporate the constraints speci?ed in the ontology into the representation learned by KG embedding models through a joint loss function, which is de?ned on positive and negative instances derived from two sets of ontology axioms. Furthermore, we propose two additional reasoning capability evaluation metrics for measuring the capability of models to correctly predict relations or links deduced from the KG and ontology, and avoid miss-predictions. The experimental results demonstrated that models with our framework performed better in most cases across tasks and datasets, and performed signi?cantly better for reasoning capability evaluation metrics in many cases."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Enriching Artificial Intelligence Explanations with Knowledge Fragments,""The explanations provided can be further improved with information regarding the purpose of potential actions that can be taken to influence demand and to provide """"what-if"""" analysis capabilities."",""Jože M. Rožanec, Elena Trajkova, I. Novalija, Patrik Zajec, K. Kenda, B. Fortuna, Dunja Mladeni'c"",Future Internet,,0.793 (5815),10.48550/arXiv.2204.05579,,2022,3,https://doi.org/10.48550/arXiv.2204.05579,https://semanticscholar.org/paper/1bc11e4e91941a6e5a7a78bf7a77b88397d0dd50,""Artificial intelligence models are increasingly used in manufacturing to inform decision making. Responsible decision making requires accurate forecasts and an understanding of the models’ behavior. Furthermore, the insights into the models’ rationale can be enriched with domain knowledge. This research builds explanations considering feature rankings for a particular forecast, enriching them with media news entries, datasets’ metadata, and entries from the Google knowledge graph. We compare two approaches (embeddings-based and semantic-based) on a real-world use case regarding demand forecasting. The embeddings-based approach measures the similarity between relevant concepts and retrieved media news entries and datasets’ metadata based on the word movers’ distance between embeddings. The semantic-based approach recourses to wikification and measures the Jaccard distance instead. The semantic-based approach leads to more diverse entries when displaying media events and more precise and diverse results regarding recommended datasets. We conclude that the explanations provided can be further improved with info",rmation,re,gardin,g the,"purpose of potential actions that can be taken to influence demand and to provide “what-if” analysis capabilities."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Incorporation of Human Knowledge into Data Embeddings to Improve Pattern Significance and Interpretability,Externalizing tacit human knowledge as explicit sample labels improves pattern significance and interpretability.,""Jie Li, Chunting Zhou"",IEEE Transactions on Visualization and Computer Graphics,,1.753 (1583),10.1109/TVCG.2022.3209382,,2022,1,https://doi.org/10.1109/TVCG.2022.3209382,https://semanticscholar.org/paper/c01225eee64252f5f1fc6937b6f943446412437c,""Embedding is a common technique for analyzing multi-dimensional data. However, the embedding projection cannot always form significant and interpretable visual structures that foreshadow underlying data patterns. We propose an approach that incorporates human knowledge into data embeddings to improve pattern significance and interpretability. The core idea is (1) externalizing tacit human knowledge as explicit sample labels and (2) adding a classification loss in the embedding network to encode samples' classes. The approach pulls samples of the same class with similar data features closer in the projection, leading to more compact (significant) and class-consistent (interpretable) visual structures. We give an embedding network with a customized classification loss to implement the idea and integrate the network into a visualization system to form a workflow that supports flexible class creation and pattern exploration. Patterns found on open datasets in case studies, subjects' performance in a user study, and quantitative experiment results illustrate the general usability and effectiveness of the approach."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"ExpressivE: A Spatio-Functional Embedding For Knowledge Graph Completion,The Expressive embedding model solves all these challenges simultaneously.,""Aleksandar Pavlovi'c, Emanuel Sallinger"",ArXiv,,,10.48550/arXiv.2206.04192,,2022,2,https://doi.org/10.48550/arXiv.2206.04192,https://semanticscholar.org/paper/4ce677706dd7be6c3678bfe4cd0e72af6274e660,""Knowledge graphs are inherently incomplete. Therefore substantial research has been directed towards knowledge graph completion (KGC), i.e., predicting missing triples from the information represented in the knowledge graph (KG). Embedding models have yielded promising results for KGC, yet any current KGC embedding model is incapable of: (1) fully capturing vital inference patterns (e.g., composition), (2) capturing prominent logical rules jointly (e.g., hierarchy and composition), and (3) providing an intuitive interpretation of captured patterns. In this work, we propose ExpressivE, a fully expressive spatio-functional embedding model that solves all these challenges simultaneously. ExpressivE embeds pairs of entities as points and relations as hyper-parallelograms in the virtual triple space R. This model design allows ExpressivE not only to capture a rich set of inference patterns jointly but additionally to display any supported inference pattern through the spatial relation of hyper-parallelograms, offering an intuitive and consistent geometric interpretation of ExpressivE embeddings and their captured patterns. Experimental results on standard KGC benchmarks reveal that ExpressivE is competitive with state-of-the-art models and even significantly outperforms them on WN18RR."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Off-Policy Meta-Reinforcement Learning with Belief-based Task Inference,The performance of the agent improves with a small amount of data.,""Takahisa Imagawa, Takuya Hiraoka, Yoshimasa Tsuruoka"",IEEE Access,,0.927 (4581),10.1109/access.2022.3170582,https://ieeexplore.ieee.org/ielx7/6287639/9668973/09763505.pdf,2022,2,https://doi.org/10.1109/access.2022.3170582,https://semanticscholar.org/paper/95a36bd64eab43b5b271d5bc55b5e57a53ef82ac,""Meta-reinforcement learning (RL) addresses the problem of sample inefficiency in deep RL by using experience obtained in past tasks for solving a new task. However, most existing meta-RL methods require partially or fully on-policy data, which hinders the improvement of sample efficiency. To alleviate this problem, we propose a novel off-policy meta-RL method, embedding learning and uncertainty evaluation (ELUE). An ELUE agent is characterized by the learning of what we call a task embedding space, an embedding space for representing the features of tasks. The agent learns a belief model over the task embedding space and trains a belief-conditional policy and Q-function. The belief model is designed to be agnostic to the order in which task information is obtained, thereby reducing the difficulty of task embedding learning. For a new task, the ELUE agent collects data by the pretrained policy, and updates its belief on the basis of the belief model. Thanks to the belief update, the performance of the agent improves with a small amount of data. In addition, the agent updates the parameters of its policy and Q-function so that it can adjust the pretrained relationships when there are enough data. We demonstrate that ELUE ou",tperfor,ms,state-,of-the,"-art meta RL methods through experiments on meta-RL benchmarks."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Semantics Driven Embedding Learning for Effective Entity Alignment,The attribute embedding and relation embedding are driven by semantics building bridges between entities.,""Ziyue Zhong, Meihui Zhang, Ju Fan, Chenxiao Dou"",IEEE International Conference on Data Engineering,,,10.1109/icde53745.2022.00205,,2022,1,https://doi.org/10.1109/icde53745.2022.00205,https://semanticscholar.org/paper/f7e8f369ae12bdcc76eaab4e42839fd36406abc0,""Knowledge-based data service has become an emerging form of service in the world wide web (WWW). To ensure the service quality, a comprehensive knowledge base has to be constructed. Knowledge base integration is often a primary way to improve the completeness. In this paper, we focus on the fundamental problem in knowledge base integration, i.e., entity alignment (EA). EA has been studied for years. Traditional approaches focus on the symbolic features of entities and propose various similarity measures to identify equivalent entities. With recent development in knowledge graph representation learning, embedding-based entity alignment has emerged, which encodes the entities into vectors according to the semantic or structural information and computes the relatedness of entities based on the vector representation. While embedding-based approaches achieve promising results, we identify some important information that are not well exploited in existing works: 1) The neighboring entities contribute differently in the EA process, and should be carefully assigned the importance in learning the relatedness of entities; 2) The attribute values (especially the long texts) contain rich semantics that can build supplementary associations",betwee,n e,ntitie,s. To,"this end, we propose SDEA - a Semantics Driven entity embedding method for Entity Alignment. SDEA consists of two modules, namely attribute embedding and relation embedding. The attribute embedding captures the semantic information from attribute values with a pre-trained transformer-based language model. The relation embedding selectively aggregates the semantic information from neighbors using a GRU model equipped with an attention mechanism. Both attribute embedding and relation embedding are driven by semantics, building bridges between entities. Experimental results show that our method significantly outperforms the state-of-the-art approaches on three benchmarks."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Exploration of Ontological Representations for Evolutionary Computation,Object-oriented representations aid research and development as naturally decoupled components can be more easily modified and extended.,""Hugo Alcaraz-Herrera, J. Cartlidge"",IEEE Congress on Evolutionary Computation,,,10.1109/CEC55065.2022.9870376,https://research-information.bris.ac.uk/ws/files/341170692/CEC.2022.AAM.pdf,2022,1,https://doi.org/10.1109/CEC55065.2022.9870376,https://semanticscholar.org/paper/ac3daca09eff5cc6df045dcf247205105bdf1bfb,""This research explores the utility of ontological representations using object-oriented (OO) design principles, such that characteristics of the problem domain are directly mapped onto the representation of individuals. A comparison against more traditional representations is performed in two problem domains of differing complexity: (i) Tangram, a simple geometric puzzle; and (ii) EvoRecSys, an evolutionary recommender system for health and well-being advice. We show that OO representations aid research and development as naturally decoupled components can be more easily modified and extended, which can in turn lead to the discovery of better solutions."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Towards Loosely-Coupling Knowledge Graph Embeddings and Ontology-based Reasoning,The prediction accuracy of knowledge graph embeddings is enhanced by domain knowledge that may not be included in the input knowledge graph.,""Zoi  Kaoudi, Abelardo Carlos Martinez Lorenzo, Volker  Markl"",ArXiv,,,,,2022,,,https://semanticscholar.org/paper/018f8e24b599de92272a0a42ed28ac262be726fd,""Knowledge graph completion (a.k.a. link prediction), i.e., the task of inferring missing information from knowledge graphs, is a widely used task in many applications, such as product recommendation and question answering. The state-of-the-art approaches of knowledge graph embeddings and/or rule mining and reasoning are datadriven and, thus, solely based on the information the input knowledge graph contains. This leads to unsatisfactory prediction results which make such solutions inapplicable to crucial domains such as healthcare. To further enhance the accuracy of knowledge graph completion we propose to loosely-couple the data-driven power of knowledge graph embeddings with domain-specific reasoning stemming from experts or entailment regimes (e.g., OWL2). In this way, we not only enhance the prediction accuracy with domain knowledge that may not be included in the input knowledge graph but also allow users to plugin their own knowledge graph embedding and reasoning method. Our initial results show that we enhance the MRR accuracy of vanilla knowledge graph embeddings by up to 3x and outperform hybrid solutions that combine knowledge graph embeddings with rule mining and reasoning up to 3.5x MRR."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Integrating Ontologies and Vector Space Embeddings Using Conceptual Spaces (Invited Paper),Vector space embeddings excel at modeling similarity and analogy.,""Zied Bouraoui, Víctor Gutiérrez-Basulto, S. Schockaert"",International Research School in Artificial Intelligence in Bergen,,,10.4230/OASIcs.AIB.2022.3,,2022,,https://doi.org/10.4230/OASIcs.AIB.2022.3,https://semanticscholar.org/paper/50689ff38f985e7105bce288936ba007fcdfe9ba,""Ontologies and vector space embeddings are among the most popular frameworks for encoding conceptual knowledge. Ontologies excel at capturing the logical dependencies between concepts in a precise and clearly defined way. Vector space embeddings excel at modelling similarity and analogy. Given these complementary strengths, there is a clear need for frameworks that can combine the best of both worlds. In this paper, we present an overview of our recent work in this area. We first discuss the theory of conceptual spaces, which was proposed in the 1990s by Gärdenfors as an intermediate representation layer in between embeddings and symbolic knowledge bases. We particularly focus on a number of recent strategies for learning conceptual space representations from data. Next, building on the idea of conceptual spaces, we discuss approaches where relational knowledge is modelled in terms of geometric constraints. Such approaches aim at a tight integration of symbolic and geometric representations, which unfortunately comes with a number of limitations. For this reason, we finally also discuss methods in which similarity, and other forms of conceptual relatedness, are derived from vector space embeddings and subsequently used to sup",port fl,exi,ble fo,rms of,"reasoning with ontologies, thus enabling a looser integration between embeddings and symbolic knowledge. 2012 ACM Subject Classification Computing methodologies ? Knowledge representation and reasoning"",,Review",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"An Adaptive Logical Rule Embedding Model for Inductive Reasoning over Temporal Knowledge Graphs,The proposed model has good zero-shot reasoning ability.,""Xin Mei, Libin Yang, Xiaoyan Cai, Zuowei Jiang"",Conference on Empirical Methods in Natural Language Processing,,,,,2022,,,https://semanticscholar.org/paper/f0004055579ad3c6be69eefa23938eaea2dc145e,""Temporal knowledge graphs (TKGs) extrapolation reasoning predicts future events based on historical information, which has great research significance and broad application value. Existing methods can be divided into embedding-based methods and logical rule-based methods. Embedding-based methods rely on learned entity and relation embeddings to make predictions and thus lack interpretability. Logical rule-based methods bring scalability problems due to being limited by the learned logical rules. We combine the two methods to capture deep causal logic by learning rule embeddings, and propose an interpretable model for temporal knowledge graph reasoning called adaptive logical rule embedding model for inductive reasoning (ALRE-IR). ALRE-IR can adaptively extract and assess reasons contained in historical events, and make predictions based on causal logic. Furthermore, we propose a one-class augmented matching loss for optimization. When evaluated on the ICEWS14, ICEWS0515 and ICEWS18 datasets, the performance of ALRE-IR outperforms other state-of-the-art baselines. The results also demonstrate that ALRE-IR still shows outstanding performance when transferred to related dataset with common relation vocabulary, indicating our proposed model has good zero-shot reasoning ability."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Flexible Model Exchange in Modelling Smart Mobility by Using Domain Ontologies,The application of the presented methodology facilitates and supports the decision-making for future mobility in general.,""Leonard Stepien, F. Köster"",IEEE Systems Conference,,,10.1109/syscon53536.2022.9773837,,2022,1,https://doi.org/10.1109/syscon53536.2022.9773837,https://semanticscholar.org/paper/5ddf8d627eef62215a5733eea04f08c0d021a699,""The development of smart mobility calls for the simultaneous consideration of multiple stakeholders’ perspectives while considering local circumstances. The analysis in simulation allows the efficient comparison of different scenarios and options to support the decision-making process. As diverse aspects call for different simulative implementations, the use of numerous modelling approaches reveals unsolved challenges in the integration process towards a comprehensive and consistent simulation. Taking the example of planning public charging infrastructure, three stakeholder groups as different component models with their interdependencies form the co-simulation framework. Facing the high adaptability required, the exchange of models and their integration come in focus, aiming for a mostly automated procedure to integrate a new model within an existing simulation framework. Domain ontologies enable the comparison of incorporated parameters and their transformation. Meta data allows to highly automate this process. The challenges to overcome are elaborated and the process of exchanging a component model is introduced. Thereby, this paper contributes to fill the gap between the standardization of model interfaces and the functionalities of",existin,g m,aster,algori,"thm for simulation execution in the mobility domain. The application of the here-presented methodology facilitates and supports the decision-making for future mobility in general. It enables an existing simulation framework’s adoption to spatial particularities and adjustments over time."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Explaining Link Predictions in Knowledge Graph Embedding Models with Influential Examples,The approach to generate explanations out-performs baselines on KGE models for two publicly available datasets.,""Adrianna Janik, Luca Costabello"",ArXiv,,,10.48550/arXiv.2212.02651,,2022,,https://doi.org/10.48550/arXiv.2212.02651,https://semanticscholar.org/paper/0cf48d13e5c96f32be4c97c60f6228aacc1d82a0,We study the problem of explaining link predictions in the Knowledge Graph Embedding (KGE) models. We propose an example-based approach that exploits the latent space rep- resentation of nodes and edges in a knowledge graph to explain predictions. We evaluated the importance of identi?ed triples by observing progressing degradation of model performance upon in?uential triples removal. Our experiments demonstrate that this approach to generate explanations out-performs baselines on KGE models for two publicly available datasets.,,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"An Embedding Framework for the Design and Analysis of Consistent Polyhedral Surrogates,Every discrete loss is embedded by some polyhedral loss.,""J. Finocchiaro, Rafael M. Frongillo, Bo Waggoner"",ArXiv,,,10.48550/arXiv.2206.14707,,2022,2,https://doi.org/10.48550/arXiv.2206.14707,https://semanticscholar.org/paper/93502133541f5e095b3facd33231d296d20bbb81,""We formalize and study the natural approach of designing convex surrogate loss functions via embeddings, for problems such as classification, ranking, or structured prediction. In this approach, one embeds each of the finitely many predictions (e.g. rankings) as a point in R, assigns the original loss values to these points, and “convexifies” the loss in some way to obtain a surrogate. We establish a strong connection between this approach and polyhedral (piecewise-linear convex) surrogate losses: every discrete loss is embedded by some polyhedral loss, and every polyhedral loss embeds some discrete loss. Moreover, an embedding gives rise to a consistent link function as well as linear surrogate regret bounds. Our results are constructive, as we illustrate with several examples. In particular, our framework gives succinct proofs of consistency or inconsistency for various polyhedral surrogates in the literature, and for inconsistent surrogates, it further reveals the discrete losses for which these surrogates are consistent. We go on to show additional structure of embeddings, such as the equivalence of embedding and matching Bayes risks, and the equivalence of various notions of non-redudancy. Using these results, we establish that indirect elicitation, a necessary condition for consistency, is also su",fficien,t w,hen wo,rking,"with polyhedral surrogates."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Using ontologies for dataset engineering in automotive AI applications,A methodology for domain analysis to build up an ontology for perception of autonomous vehicles is demonstrated by the creation of a synthetic test dataset for an Euro NCAP-like use case.,""Martin Herrmann, Christian Witt, Laureen Lake, Stefani Guneshka, Christian Heinzemann, Frank Bonarens, P. Feifel, Simon Funke"",""Design, Automation and Test in Europe"",,,10.23919/DATE54114.2022.9774675,,2022,6,https://doi.org/10.23919/DATE54114.2022.9774675,https://semanticscholar.org/paper/467411a8e3c3ab78732e7a486f39b12b09448994,""Basis of a robust safety strategy for an automated driving function based on neural networks is a detailed description of its input domain, i.e. a description of the environment, in which the function is used. This is required to describe its functional system boundaries and to perform a comprehensive safety analysis. Moreover, it allows to tailor datasets specifically designed for safety related validation tests. Ontologies fulfill the task to gather expert knowledge and model information to enable computer aided processing, while using a notion understandable for humans. In this contribution, we propose a methodology for domain analysis to build up an ontology for perception of autonomous vehicles including characteristic features that become important when dealing with neural networks. Additionally, the method is demonstrated by the creation of a synthetic test dataset for an Euro NCAP-like use case."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Improving Embeddings Representations for Comparing Higher Education Curricula: A Use Case in Computing,Pre-trained word embeddings are fine-tuned in a study program classification task.,""Jeffri Murrugarra-Llerena, Fernando Alva-Manchego, Nils Murrugarra-Llerena"",Conference on Empirical Methods in Natural Language Processing,,,,,2022,,,https://semanticscholar.org/paper/6c3582585dc69ce6f522a2f54700c4579dd8dd8f,""We propose an approach for comparing curricula of study programs in higher education. Pre-trained word embeddings are fine-tuned in a study program classification task, where each curriculum is represented by the names and content of its courses. By combining metric learning with a novel course-guided attention mechanism, our method obtains more accurate curriculum representations than strong baselines. Experiments on a new dataset with curricula of computing programs demonstrate the intuitive power of our approach via attention weights, topic modeling, and embeddings visualizations. We also present a use case comparing computing curricula from USA and Latin America to showcase the capabilities of our improved embeddings representations."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Faithiful Embeddings for EL++ Knowledge Bases,BoxEL models concepts in a KB as axis-parallel boxes that are suitable for modeling concept intersection.,""Bo Xiong, Nico Potyka, T. Tran, M. Nayyeri, Steffen Staab"",,,,,,2022,2,,https://semanticscholar.org/paper/3f449a28dce59a1906bd64a6be52440756b9e0e0,"". Recently, increasing efforts are put into learning continual representations for symbolic knowledge bases (KBs). However, these approaches either only embed the data-level knowledge (ABox) or suffer from inherent limitations when dealing with concept-level knowledge (TBox), i.e., they cannot faithfully model the logical structure present in the KBs. We present BoxEL, a geometric KB embedding approach that allows for better capturing the logical structure (i.e., ABox and TBox axioms) in the description logic EL ++ . BoxEL models concepts in a KB as axis-parallel boxes that are suitable for modeling concept intersection, entities as points inside boxes, and relations between concepts/entities as af?ne transformations . We show theoretical guarantees ( soundness ) of BoxEL for preserving logical structure. Namely, the learned model of BoxEL embedding with loss 0 is a (logical) model of the KB. Experimental results on (plausible) subsumption reasonings and a real-world application–protein-protein prediction show that BoxEL outperforms traditional knowledge graph embedding methods as well as state-of-the-art EL ++ embedding approaches."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Explaining automatic answers generated from knowledge base embedding models.,Advanced question-answering devices are typically produced with the help of large-scale knowledge bases such as DBpedia or Freebase.,Andrey Ruschel,,,,10.11606/d.3.2022.tde-07072022-084934,http://www.teses.usp.br/teses/disponiveis/3/3141/tde-07072022-084934/publico/AndreyRuschelCorr22.pdf,2022,,https://doi.org/10.11606/d.3.2022.tde-07072022-084934,https://semanticscholar.org/paper/5409f6d5b89a757c97f37dec173fc77cf352493a,""While many chatbot systems rely on templates and shallow semantic analysis, advanced question-answering devices are typically produced with the help of largescale knowledge bases such as DBpedia or Freebase. Information extraction is often based on embedding models that map semantically rich information into low-dimensional vectors, allowing computationally efficient calculations. When producing new facts about the world, embeddings often provide correct answers that are very hard to explain from a human perspective as they are based on operations performed in the low-dimensional vector space, thus bearing no meaning to human users. Although interpretability has become a central concern in machine learning, the literature so far has focused on non-relational classifiers (such as deep neural networks); embeddings, however, require a whole range of different approaches. In this work we improve an existing method designed to provide explanations for predictions made by embedding models."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Abstracting Ontology-Driven Conceptual Models,Ontology-driven conceptual models are widely used to capture information about complex and critical domains.,""E. Romanenko, D. Calvanese, G. Guizzardi"",,,,,,2022,,,https://semanticscholar.org/paper/f6ebbadd5f1e964cc5e331b25e9784c34789e21f,""ing Ontology-Driven Conceptual Models: Objects, Aspects, Events, and their Parts Elena Romanenko1[0000?0002?8139?5977], Diego Calvanese1,2[0000?0001?5174?9693], and Giancarlo Guizzardi1,3[0000?0002?3452?553X] 1 Free University of Bozen-Bolzano, 39100 Bolzano, Italy. eromanenko@unibz.it, calvanese@inf.unibz.it, giancarlo.guizzardi@unibz.it 2 Umeå University, 90187 Umeå, Sweden. 3 University of Twente, 7500 Enschede, The Netherlands. Abstract. Ontology-driven conceptual models are widely used to capture information about complex and critical domains. Therefore, it is essential for these models to be comprehensible and cognitively tractable. Over the years, different techniques for complexity management in conceptual models have been suggested. Among these, a prominent strategy is model abstraction. This work extends an existing strategy for model abstraction of OntoUML models that proposes a set of graph-rewriting rules leveraging on the ontological semantics of that language. That original work, however, only addresses a set of the ontological notions covered in that language. We review and extend that rule set to cover more generally types of objects, aspects, events, and their parts. Ontology-driven conceptual models are widely used to capture information about complex and critical domains. Therefore, it is essential for these models to be comprehensible and cognitively",tracta,ble,. Over,the y,"ears, different techniques for complexity management in conceptual models have been suggested. Among these, a prominent strategy is model abstraction. This work extends an existing strategy for model abstraction of OntoUML models that proposes a set of graph-rewriting rules leveraging on the ontological semantics of that language. That original work, however, only addresses a set of the ontological notions covered in that language. We review and extend that rule set to cover more generally types of objects, aspects, events, and their parts."",,Review",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"On the Eve of True Explainability for OWL Ontologies: Description Logic Proofs with Evee and Evonne (Extended Version),A Java library for computing proofs for DLs up to ALCH is introduced.,""Christian Alrabbaa, Stefan Borgwardt, Tom Friese, P. Koopmann, J. M'endez, Alexej Popovivc"",ArXiv,,,10.48550/arXiv.2206.07711,,2022,1,https://doi.org/10.48550/arXiv.2206.07711,https://semanticscholar.org/paper/1e6a5321d5b3245113ac0100487e86bc564a16c3,""When working with description logic ontologies, understanding entailments derived by a description logic reasoner is not always straightforward. So far, the standard ontology editor Protégé offers two services to help: (black-box) justifications for OWL 2 DL ontologies, and (glass-box) proofs for lightweight OWL EL ontologies, where the latter exploits the proof facilities of reasoner Elk. Since justifications are often insufficient in explaining inferences, there is thus only little tool support for explaining inferences in more expressive DLs. In this paper, we introduce Evee-libs, a Java library for computing proofs for DLs up to ?????? , and Evee-protege, a collection of Protégé plugins for displaying those proofs in Protégé. We also give a short glimpse of the latest version of Evonne, a more advanced standalone application for displaying and interacting with proofs computed with Evee-libs."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Analyzing Transformers in Embedding Space,Parameters of both pretrained and fine-tuned models can be interpreted in embedding space.,""Guy Dar, Mor Geva, Ankit Gupta, Jonathan Berant"",ArXiv,,,10.48550/arXiv.2209.02535,,2022,2,https://doi.org/10.48550/arXiv.2209.02535,https://semanticscholar.org/paper/c7fa5c2172a4624d6baa91e66344e4520d3028ad,""Understanding Transformer-based models has attracted signi?cant attention, as they lie at the heart of recent technological advances across machine learning. While most interpretability methods rely on running models over inputs, recent work has shown that an input-independent approach, where parameters are interpreted directly without a forward/back-ward pass is feasible for some Transformer parameters, and for two-layer attention networks. In this work, we present a conceptual framework where all parameters of a trained Transformer are interpreted by projecting them into the embedding space , that is, the space of vocabulary items they operate on. Focusing mostly on GPT-2 for this paper, we provide di-verse evidence to support our argument. First, an empirical analysis showing that parameters of both pretrained and ?ne-tuned models can be interpreted in embedding space. Second, we present two applications of our framework: (a) aligning the parameters of different models that share a vocabulary, and (b) construct-ing a classi?er without training by “translat-ing” the parameters of a ?ne-tuned classi?er to parameters of a different model that was only pretrained. Overall, our ?ndings show that at least in part, we can abstract away model speci?cs and understand Transformers in the embedding space."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Figure Descriptive Text Extraction Using Ontological Representation,Conceptual models bring an improvement in figure descriptive sentence classification over word-based approaches.,""Gilchan Park, Julia Taylor Rayz, Line C. Pouchard"",The Florida AI Research Society,,,10.48550/arXiv.2208.06040,,2022,4,https://doi.org/10.48550/arXiv.2208.06040,https://semanticscholar.org/paper/4f898d3542e4e54f38369a5680440634bccd6e0c,""Experimental research publications provide figure form resources including graphs, charts, and any type of images to effectively support and convey methods and results. To describe figures, authors add captions, which are often incomplete, and more descriptions reside in body text. This work presents a method to extract figure descriptive text from the body of scientific articles. We adopted ontological semantics to aid concept recognition of figure-related information, which generates humanand machine-readable knowledge representations from sentences. Our results show that conceptual models bring an improvement in figure descriptive sentence classification over word-based approaches."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Revisiting Negative Sampling VS. Non-Sampling in Implicit Recommendation,Negative sampling has been widely applied to recent recommendation models.,""C. Chen, Weizhi Ma, M. Zhang, Chenyang Wang, Yiqun Liu, Shaoping Ma"",ACM Transactions on Information Systems,,1.585 (1912),10.1145/3522672,,2022,2,https://doi.org/10.1145/3522672,https://semanticscholar.org/paper/e7a41093471e96a395b79afe2734f40ec4dff767,""Recommendation systems play an important role in alleviating information overload issue. Generally, a recommendation model is trained to discern between positive (liked) and negative (disliked) instances for each user. However, under the open-world assumption, there are only positive instances but no negative instances from users’ implicit feedback, which poses the imbalanced learning challenge of lacking negative samples. To address this, two types of learning strategies have been proposed before, which are negative sampling strategy and non-sampling strategy. The first strategy samples negative instances from missing data (i.e., unlabeled data), while non-sampling strategy regards all the missing data as negative. Although learning strategies are known to be essential for algorithm performance, the in-depth comparison of negative sampling and non-sampling has not been sufficiently explored by far. To bridge this gap, we systematically analyze the role of negative sampling and non-sampling for implicit recommendation in this work. Specifically, we first theoretically revisit the objection of negative sampling and non-sampling. Then, with a careful setup of various representative recommendation methods, we explore the performance of negative sampling and non-sampling in different scenarios. Our results empirically show that although negative sampling has been widely applied to recent recommendation models, it is non-trivial for uniform sampling methods to show comparable performance to non-sampling learning methods. Finally, we discuss the scalability",and comp,"lexity of negative sampling and non-sampling, and pres",ent some open,problems,and future,research topics that,worth to b,e furt,"her explored."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"A Gain-Tuning Dynamic Negative Sampler for Recommendation,The gain-tuning negative sampler can effectively identify the false negative samples and further diminish the risk of false negative instances.,""Qiannan Zhu, Haobo Zhang, Qing He, Zhicheng Dou"",The Web Conference,,,10.1145/3485447.3511956,,2022,2,https://doi.org/10.1145/3485447.3511956,https://semanticscholar.org/paper/111e22b143305698d21cc91add477e8bf49a4f86,""Selecting reliable negative training instances is the challenging task in the implicit feedback-based recommendation, which is optimized by pairwise learning on user feedback data. The existing methods usually exploit various negative samplers (i.e., heuristic-based or GAN-based sampling) on user feedback data to improve the quality of negative samples. However, these methods usually focused on maintaining the hard negative samples with a high gradient for training, causing the false negative samples to be selected preferentially. The limitation of the false negative noise amplification may lead to overfitting and further poor generalization of the model. To address this issue, we propose a Gain-Tuning Dynamic Negative Sampling GDNS to make the recommendation more robust and effective. Our proposed model designs an expectational gain sampler, concerning the expectation of user’ preference gap between the positive and negative samples in training, to guide the negative selection dynamically. This gain-tuning negative sampler can effectively identify the false negative samples and further diminish the risk of introducing false negative instances. Moreover, for improving the training efficiency, we construct positive and negative groups for each user in each iteration, and develop a group-wise optimizer to optimize them in a cross manner. Experiments on two real-world datasets show our approach significantly outperforms state-of-the-art negative sampling baselines."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Revisiting Negative Sampling VS. Non-Sampling in Implicit Recommendation,Negative sampling has been widely applied to recent recommendation models.,""C. Chen, Weizhi Ma, M. Zhang, Chenyang Wang, Yiqun Liu, Shaoping Ma"",ACM Transactions on Information Systems,,1.585 (1912),10.1145/3522672,,2022,1,https://doi.org/10.1145/3522672,https://semanticscholar.org/paper/83cde4e6a8a404daa53f2784aa7cbb578abb284e,""Recommendation systems play a vital role in alleviating information overload. Generally, a recommendation model is trained to discern between positive (liked) and negative (disliked) instances for each user. However, under the open-world assumption, there are only positive instances but no negative instances from users’ implicit feedback, which poses the imbalanced learning challenge of lacking negative samples. To address this, two types of training strategies have been proposed in previous studies, which are 1) negative sampling strategy and 2) non-sampling strategy. The first strategy samples negative instances from missing data (i.e., unlabeled data), while the second one regards all the missing data as negative. Although training strategies are known to be essential for algorithm performance, the in-depth comparison of negative sampling and non-sampling is still left insufficiently explored by far. To bridge this gap, in this paper we systematically analyze the role of negative sampling and non-sampling for implicit recommendation. Specifically, we first theoretically revisit the objection of negative sampling and non-sampling. Then, with a careful setup of various representative recommendation methods, we explore the performance of negative sampling and non-sampling in different scenarios. Our results empirically show that although negative sampling has been widely applied to recent recommendation models, it is non-trivial for uniform sampling methods to show comparable performance to non-sampling learning methods. Finally, we discuss the scalab",ility and,"complexity of negative sampling and non-sampling, and",present some,open pro,blems and f,uture research topics,that worth,to be,further explored,".""",",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Stay Positive: Knowledge Graph Embedding Without Negative Sampling,Negative examples are needed to train a classifier.,""Ainaz Hajimoradlou, Seyed Mehran Kazemi"",,,,,,2022,4,,https://semanticscholar.org/paper/49ea0366600f21dd12cf228c27849a88b7fe6e8a,""Knowledge graphs (KGs) are typically incomplete and we often wish to infer new facts given the existing ones. This can be thought of as a binary classification problem; we aim to predict if new facts are true or false. Unfortunately, we generally only have positive examples (the known facts) but we also need negative ones to train a classifier. To resolve this, it is usual to generate negative examples using a negative sampling strategy. However, this can produce false negatives which may reduce performance, is computationally expensive, and does not produce calibrated classification probabilities. In this paper, we propose a training procedure that obviates the need for negative sampling by adding a novel regularization term to the loss function. Our results for two relational embedding models (DistMult and SimplE) show the merit of our proposal both in terms of performance and speed."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Uncertainty-aware Prediction Validator in Deep Learning Models for Cyber-physical System Data,Uncertainty quantification is negatively correlated to prediction performance of a deep learning model of CPS data.,""Ferhat Ozgur Catak, T. Yue, Sajid Ali"",ACM Transactions on Software Engineering and Methodology,,1.7 (1681),10.1145/3527451,,2022,7,https://doi.org/10.1145/3527451,https://semanticscholar.org/paper/7f36cf7b7ed9bd80e3843d860b7044a5988b2742,""The use of Deep learning in Cyber-Physical Systems (CPSs) is gaining popularity due to its ability to bring intelligence to CPS behaviors. However, both CPSs and deep learning have inherent uncertainty. Such uncertainty, if not handled adequately, can lead to unsafe CPS behavior. The first step toward addressing such uncertainty in deep learning is to quantify uncertainty. Hence, we propose a novel method called NIRVANA (uNcertaInty pRediction ValidAtor iN Ai) for prediction validation based on uncertainty metrics. To this end, we first employ prediction-time Dropout-based Neural Networks to quantify uncertainty in deep learning models applied to CPS data. Second, such quantified uncertainty is taken as the input to predict wrong labels using a support vector machine, with the aim of building a highly discriminating prediction validator model with uncertainty values. In addition, we investigated the relationship between uncertainty quantification and prediction performance and conducted experiments to obtain optimal dropout ratios. We conducted all the experiments with four real-world CPS datasets. Results show that uncertainty quantification is negatively correlated to prediction performance of a deep learning model of CPS data. Also, our dropout ratio adjustment approach is effective in reducing uncertainty of correct predictions while increasing uncertainty of wrong predictions."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Region or Global A Principle for Negative Sampling in Graph-based Recommendation,Negative sampling is a vital technique to solve the one-class problem in graph-based recommendation methods.,""Z. Yang, Ming Ding, Xu Zou, Jie Tang, Bin Xu, Chang Zhou, Hongxia Yang"",IEEE Transactions on Knowledge and Data Engineering,,2.431 (883),10.1109/tkde.2022.3155155,,2022,2,https://doi.org/10.1109/tkde.2022.3155155,https://semanticscholar.org/paper/1c99281bda08ab51efd95d4d6f48b2f83a5d8716,""Graph-based recommendation systems are blossoming recently, which models user-item interactions as a user-item graph and utilizes graph neural networks (GNNs) to learn the embeddings for users and items. A fundamental challenge of graph-based recommendation is that there only exists observed positive user-item pairs in the user-item graph. Negative sampling is a vital technique to solve the one-class problem and is widely used in many recommendation methods. However, the previous works only focus on the design of negative sampling distribution but ignore the sampled region for negative sampling. In this work, we propose the Three-Region Principle to guide negative sampling, which suggests that we should negatively sample more items at an intermediate region and less adjacent and distant items. In light of this principle, we present the RecNS method, which is a general negative sampling method designed with two sampling strategies: positive-assisted sampling and exposure-augmented sampling. Instead of sampling existing negative items from graph data, we merge these two strategies in embedding space to generate negative item embeddings. Extensive experiments demonstrate that RecNS method significantly outperforms all negative sampling baselines, e.g., 10.47% for PinSage, 6.02% for NGCF, and 8.20% for LightGCN in terms of Recall@20 on the Alibaba dataset."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Uncertainty-Aware Learning against Label Noise on Imbalanced Datasets,Existing methods often perform class-agnostic noise modeling.,""Yingsong Huang, Bing Bai, Shengwei Zhao, Kun Bai, Fei Wang"",AAAI Conference on Artificial Intelligence,,,10.1609/aaai.v36i6.20654,,2022,4,https://doi.org/10.1609/aaai.v36i6.20654,https://semanticscholar.org/paper/6f963257c57065273e5a7b1723e1f1eb97d18b2c,""Learning against label noise is a vital topic to guarantee a reliable performance for deep neural networks.Recent research usually refers to dynamic noise modeling with model output probabilities and loss values, and then separates clean and noisy samples.These methods have gained notable success. However, unlike cherry-picked data, existing approaches often cannot perform well when facing imbalanced datasets, a common scenario in the real world.We thoroughly investigate this phenomenon and point out two major issues that hinder the performance, i.e., inter-class loss distribution discrepancy and misleading predictions due to uncertainty.The first issue is that existing methods often perform class-agnostic noise modeling. However, loss distributions show a significant discrepancy among classes under class imbalance, and class-agnostic noise modeling can easily get confused with noisy samples and samples in minority classes.The second issue refers to that models may output misleading predictions due to epistemic uncertainty and aleatoric uncertainty, thus existing methods that rely solely on the output probabilities may fail to distinguish confident samples. Inspired by our observations, we propose an Uncertainty-aware Label Correction framework(ULC) to handle label noise on imbalanced datasets. First, we perform epistemic uncertainty-aware class-specific noise modeling to identify trustworthy clean samples and refine/discard highly confident true/corrupted labels.Then, we introduce aleatoric uncertainty in the subsequent learning process to prevent noise accumulation",in the l,abel noise modeling process. We conduct experiments on,several synt,hetic and,real-world,datasets. The result,s demonstra,te the,effectiveness of,t,"he proposed method, especially on imbalanced datasets."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Balance-Subsampled Stable Prediction Across Unknown Test Data,The proposed method can reduce the confounding effects among predictors induced by the distribution shift.,""Kun Kuang, Hengtao Zhang, Runze Wu, Fei Wu, Y. Zhuang, Aijun Zhang"",ACM Transactions on Knowledge Discovery from Data,,1.566 (1946),10.1145/3477052,,2022,5,https://doi.org/10.1145/3477052,https://semanticscholar.org/paper/a151bc8efa4f0aa81f48c42ecae91e6f0ede5433,""In data mining and machine learning, it is commonly assumed that training and test data share the same population distribution. However, this assumption is often violated in practice because of the sample selection bias, which might induce the distribution shift from training data to test data. Such a model-agnostic distribution shift usually leads to prediction instability across unknown test data. This article proposes a novel balance-subsampled stable prediction (BSSP) algorithm based on the theory of fractional factorial design. It isolates the clear effect of each predictor from the confounding variables. A design-theoretic analysis shows that the proposed method can reduce the confounding effects among predictors induced by the distribution shift, improving both the accuracy of parameter estimation and the stability of prediction across unknown test data. Numerical experiments on synthetic and real-world datasets demonstrate that our BSSP algorithm can significantly outperform the baseline methods for stable prediction across unknown test data."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Sampling-Based Verification of CTMCs with Uncertain Rates,A principled solution to compute prediction regions on the reachability probabilities from a finite set of parameter samples and a user-specified confidence level.,""Thom S. Badings, N. Jansen, Sebastian Junges, M. Stoelinga, Matthias Volk"",CAV,,,10.48550/arXiv.2205.08300,,2022,2,https://doi.org/10.48550/arXiv.2205.08300,https://semanticscholar.org/paper/394a4c23f4aa226a4eaa027bc8072b65d461b92e,"". We employ uncertain parametric CTMCs with parametric transition rates and a prior on the parameter values. The prior encodes uncertainty about the actual transition rates, while the parameters allow dependencies between transition rates. Sampling the parameter values from the prior distribution then yields a standard CTMC, for which we may compute relevant reachability probabilities. We provide a principled solution, based on a technique called scenario-optimization, to the following problem: From a ?nite set of parameter samples and a user-speci?ed con?dence level, compute prediction regions on the reachability probabilities. The prediction regions should (with high probability) contain the reachability probabilities of a CTMC induced by any additional sample. To boost the scalability of the approach, we employ standard abstraction techniques and adapt our methodology to support approximate reachability probabilities. Experiments with various well-known benchmarks show the applicability of the approach."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Conformal Prediction Sets with Limited False Positives,Conformal sets can become inundated with noisy candidates.,""Adam Fisch, Tal Schuster, T. Jaakkola, R. Barzilay"",International Conference on Machine Learning,,,,,2022,4,,https://semanticscholar.org/paper/a32d3ab3362ecdab71a040b731e9a4e2eafe2c8a,""We develop a new approach to multi-label conformal prediction in which we aim to output a precise set of promising prediction candidates with a bounded number of incorrect answers. Standard conformal prediction provides the ability to adapt to model uncertainty by constructing a calibrated candidate set in place of a single prediction, with guarantees that the set contains the correct answer with high probability. In order to obey this coverage property, however, conformal sets can become inundated with noisy candidates—which can render them unhelpful in practice. This is par-ticularly relevant to practical applications where there is a limited budget, and the cost (monetary or otherwise) associated with false positives is non-negligible. We propose to trade coverage for a notion of precision by enforcing that the presence of incorrect candidates in the predicted conformal sets (i.e., the total number of false positives) is bounded according to a user-speci?ed tolerance. Subject to this constraint, our algorithm then op-timizes for a generalized notion of set coverage (i.e., the true positive rate) that allows for any number of true answers for a given query (includ-ing zero). We demonstrate the effectiveness of this approach across a number of classi?cation tasks in natural language processing, computer vision, and computational chemistry. ChEMBL dataset. For k -FP validity, we report the empirical average of false positives in the prediction sets. For ( k, ? ) -FP validity we report the percentage of prediction sets with ? k false positives. TPR is expressed as a percent. Our FP-CP methods meet our target thresholds; using the Inner Sets approach does","too, but",is conservative (as expected). Applying FP-CP calibra,tion with our,DeepSets,model (NN),yields substantially,higher TPR,acros,s various toleran,ce,"levels compared to the other baseline scoring mechanisms."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Evaluating High-Order Predictive Distributions in Deep Learning,The predictive distribution order required for such differentiation increases greatly with input dimension.,""Ian Osband, Zheng Wen, S. Asghari, V. Dwaracherla, Xiuyuan Lu, Benjamin Van Roy"",Conference on Uncertainty in Artificial Intelligence,,,,,2022,7,,https://semanticscholar.org/paper/07fc96252cb70645252e071a843684cb9f4583ce,""Most work on supervised learning research has focused on marginal predictions. In decision problems, joint predictive distributions are essential for good performance. Previous work has developed methods for assessing low-order predictive distributions with inputs sampled i.i.d. from the testing distribution. With low-dimensional inputs, these methods distinguish agents that effectively estimate uncertainty from those that do not. We estab-lish that the predictive distribution order required for such differentiation increases greatly with input dimension, rendering these methods impractical. To accommodate high-dimensional inputs, we introduce dyadic sampling , which focuses on predictive distributions associated with random pairs of inputs. We demonstrate that this approach efficiently distinguishes agents in high-dimensional examples involving simple logistic regression as well as complex synthetic and empirical data."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Distribution-free Prediction Sets Adaptive to Unknown Covariate Shift,A novel flexible distribution-free method can efficiently adapt to unknown covariate shift.,""Hongxiang Qiu, E. Dobriban, E. T. Tchetgen"",,,,,,2022,5,,https://semanticscholar.org/paper/206bcb7e48c3b7d0f8d4079b88d5003fe3c105c2,""Predicting sets of outcomes—instead of unique outcomes—is a promising solution to uncertainty quanti?cation in statistical learning. Despite a rich literature on constructing prediction sets with statistical guarantees, adapting to unknown covariate shift—a prevalent issue in practice—poses a serious challenge and has yet to be fully solved. In this paper, we propose a novel ?exible distribution-free method, PredSet-1Step, to construct prediction sets that can e?ciently adapt to unknown covariate shift. We formally show that our method is asymptotically probably approximately correct , having well-calibrated coverage error with high con?dence for large samples. We illustrate that it achieves nominal coverage in a number of experiments and a data set concerning HIV risk prediction in a South African cohort study. Our theory hinges on a new bound for the convergence rate of the coverage of Wald con?dence intervals based on general asymptotically linear estimators. This is a technical tool of independent interest. Theoretical results for CV-TMLE"",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Distribution-Free Prediction Sets Adaptive to Unknown Covariate Shift,A novel flexible distribution-free method can efficiently adapt to unknown covariate shift.,""Hongxiang Qiu, Edgar Dobriban, E. T. Tchetgen"",,,,,,2022,7,,https://semanticscholar.org/paper/1527da2d4795be1299637a417d64f83964a21ac4,""Predicting sets of outcomes—instead of unique outcomes—is a promising solution to uncertainty quanti?cation in statistical learning. Despite a rich literature on constructing prediction sets with statistical guarantees, adapting to unknown covariate shift—a prevalent issue in practice—poses a serious challenge and has yet to be fully solved. In this paper, we propose a novel ?exible distribution-free method, PredSet-1Step, to construct prediction sets that can e?ciently adapt to unknown covariate shift. We formally show that our method is asymptotically probably approximately correct , having well-calibrated coverage error with high con?dence for large samples. We illustrate that it achieves nominal coverage in a number of experiments and a data set concerning HIV risk prediction in a South African cohort study. Our theory hinges on a new bound for the convergence rate of the coverage of Wald con?dence intervals based on general asymptotically linear estimators. This is a technical tool of independent interest. Theoretical results for CV-TMLE"",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Calibrated Predictive Distributions via Diagnostics for Conditional Coverage,Recalibration as well as validation are attainable goals in practice.,""Biprateep Dey, Dave Zhao, J. Newman, B. Andrews, Rafael Izbicki, Ann B. Lee"",ArXiv,,,10.48550/arXiv.2205.14568,,2022,2,https://doi.org/10.48550/arXiv.2205.14568,https://semanticscholar.org/paper/89f6fac4a70243aef979e707c6b078854b5dc5a1,""Uncertainty quantification is crucial for assessing the predictive ability of AI algorithms. A large body of work (including normalizing flows and Bayesian neural networks) has been devoted to describing the entire predictive distribution (PD) of a target variable Y given input features X. However, off-the-shelf PDs are usually far from being conditionally calibrated; i.e., the probability of occurrence of an event given input X can be significantly different from the predicted probability. Most current research on predictive inference (such as conformal prediction) concerns constructing prediction sets, that do not only provide correct uncertainties on average over the entire population (that is, averaging over X), but that are also approximately conditionally calibrated with accurate uncertainties for individual instances. It is often believed that the problem of obtaining and assessing entire conditionally calibrated PDs is too challenging to approach. In this work, we show that recalibration as well as validation are indeed attainable goals in practice. Our proposed method relies on the idea of regressing probability integral transform (PIT) scores against X. This regression gives full diagnostics of conditional coverage across the entire feature space and can be used to recalibrate misspecified PDs. We benchmark our corrected prediction bands against oracle bands and state-"",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Uncertainty-Aware Prediction Validator in Deep Learning Models for Cyber-Physical System Data,Uncertainty quantification is negatively correlated to prediction performance of a deep learning model of CPS data.,""Ferhat Ozgur Catak, T. Yue, Sajid Ali"",ACM Transactions on Software Engineering and Methodology,,1.7 (1681),10.1145/3527451,https://dl.acm.org/doi/pdf/10.1145/3527451,2022,2,https://doi.org/10.1145/3527451,https://semanticscholar.org/paper/e1b60c9189618c5b8d4224c1d8a6c8a016b249a7,""The use of Deep learning in Cyber-Physical Systems (CPSs) is gaining popularity due to its ability to bring intelligence to CPS behaviors. However, both CPSs and deep learning have inherent uncertainty. Such uncertainty, if not handled adequately, can lead to unsafe CPS behavior. The first step towards addressing such uncertainty in deep learning is to quantify uncertainty. Hence, we propose a novel method called NIRVANA (uNcertaInty pRediction ValidAtor iN Ai) for prediction validation based on uncertainty metrics. To this end, we first employ prediction-time Dropout-based Neural Networks to quantify uncertainty in deep learning models applied to CPS data. Second, such quantified uncertainty is taken as the input to predict wrong labels using a support vector machine, with the aim of building a highly discriminating prediction validator model with uncertainty values. In addition, we investigated the relationship between uncertainty quantification and prediction performance, and conducted experiments to obtain optimal dropout ratios. We conducted all the experiments with four real-world CPS datasets. Results show that uncertainty quantification is negatively correlated to prediction performance of a deep learning model of CPS data. Also, our dropout ratio adjustment approach is effective in reducing uncertainty of correct predictions while increasing uncertainty of wrong predictions."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Reinforced PU-learning with Hybrid Negative Sampling Strategies for Recommendation,Existing negative sampling strategies cannot automatically select suitable approaches for different data.,""Wun-Ting Yang, Chiao-Ting Chen, Chuan-Yun Sang, Szu-Hao Huang"",ACM Transactions on Intelligent Systems and Technology,,2.766 (687),10.1145/3582562,,2023,,https://doi.org/10.1145/3582562,https://semanticscholar.org/paper/1061235acb0800ffd445a50cee8b8fda82260537,""The data of recommendation systems typically only contain the purchased item as positive data and other un-purchased items as unlabeled data. In order to train a good recommendation model, in addition to the known positive information, we also need high-quality negative information. Capturing negative signals in positive and unlabeled data is challenging for recommendation systems. Most studies have used specific data and proposed negative sampling methods suitable to the data characteristics. Existing negative sampling strategies cannot automatically select suitable approaches for different data. However, this one-size-fits-all strategy often makes potential positive samples considered as negative, or truly negative samples considered as potential positive samples and recommend to users. In this way, it will not only turn down the recommendation result, but even also have an adverse effect. Accordingly, we propose a novel negative sampling model, Reinforced PU-learning with Hybrid Negative Sampling Strategies for Recommendation (RHNSR), which can combine multiple sampling strategies and dynamically adjust the proportions used by different sampling strategies. In addition, ensemble learning, which integrates various model sampling strategies for obtaining an improved solution, was applied to RHNSR. Extensive experiments were conducted on three real-world recommendation datasets, and the experimental results indicated that the proposed model significantly outperformed state-of-the-art baseline models, and",revealed,significant improvements in precision and hit ratio (,\(49.02\% \),and \(37,".41\% \) ,","respectively)."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Robust Prediction Error Estimation with Monte-Carlo Methodology,The bias due to using the empirical distribution captures the sensitivity of the estimator to the on hand input data.,""Kimia Vahdat, S. Shashaani"",,,,,,2022,1,,https://semanticscholar.org/paper/5b117671b839879a4cb9f877356996fb8f7e2143,""In this paper, we aim to estimate the prediction error of machine learning models under the true distribution of the data on hand. We consider the prediction model as a data-driven black-box function and quantify its statistical properties using non-parametric methods. We propose a novel sampling technique that takes advantage of the underlying probability distribution information embedded in the data. The proposed method combines two existing frameworks for estimating the prediction inaccuracy error; m out of n bootstrapping and iterative bootstrapping. m out of n bootstrapping is to maintain the consistency, and iterative bootstrapping is often used for bias correction of the prediction error estimation. Using Monte-Carlo uncertainty quanti?cation techniques, we disintegrate the total variance of the estimator so the user can make informed decisions regarding measures to overcome the preventable errors. In addition, via the same Monte-Carlo framework, we provide a way to estimate the bias due to using the empirical distribution. This bias captures the sensitivity of the estimator to the on hand input data and help with understanding the robustness of the estimator. The application of the proposed uncertainty quanti?cation is tested in a model selection case study using simulated and real datasets. We evaluate the performance of the proposed estimator in two frameworks; ?rst, directly applying is as an optimization model to ?nd the best model; second, ?xing an optimization engine and use the proposed estimator as a ?tness function withing the optimizer. Furthermore, we compare the asymptotic statistical properties and numerical results in a ?nite datas",et of the,proposed estimator with the existing state-of-the-art,"methods."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Improved estimation in negative binomial regression,The maximum likelihood estimator of the dispersion parameter may be subject to a significant bias with small to moderate sample sizes.,""E. K. Kenne Pagui, A. Salvan, N. Sartori"",Statistics in Medicine,,1.371 (2457),10.1002/sim.9361,,2022,1,https://doi.org/10.1002/sim.9361,https://semanticscholar.org/paper/34e127a0f1a5680da0a1e744ee8c64a6e4c9bda4,""Negative binomial regression is commonly employed to analyze overdispersed count data. With small to moderate sample sizes, the maximum likelihood estimator of the dispersion parameter may be subject to a significant bias, that in turn affects inference on mean parameters. This article proposes inference for negative binomial regression based on adjustments of the score function aimed at mean or median bias reduction. The resulting estimating equations generalize those available for improved inference in generalized linear models and can be solved using a suitable extension of iterative weighted least squares. Simulation studies confirm the good properties of the new methods, which are also found to solve in many cases numerical problems of maximum likelihood estimation. The methods are illustrated and evaluated using two case studies: an Ames salmonella assay data set and data on epileptic seizures. Inference based on adjusted scores turns out to generally improve on maximum likelihood, and even on explicit bias correction, with median bias reduction being overall preferable."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Optimizing Sampling for Data Freshness: Unreliable Transmissions with Random Two-way Delay,The optimal sampling strategy is also optimal for general non-decreasing functions of the AoI.,""Jiayu Pan, A. Bedewy, Yin Sun, N. Shroff"",IEEE Conference on Computer Communications,,,10.1109/INFOCOM48880.2022.9796895,,2022,4,https://doi.org/10.1109/INFOCOM48880.2022.9796895,https://semanticscholar.org/paper/8a51c9e458078b35d1e3785cdeec15a33f7b6690,""In this paper, we study a sampling problem in which fresh samples of a signal (source) are sent through an unreliable channel to a remote estimator, and acknowledgments are sent back over a feedback channel. Both the forward and feedback channels are subject to random transmission times. Motivated by distributed sensing, the estimator can estimate the real-time value of the source signal by combining the signal samples received through the channel and noisy signal observations collected from a local sensor. We prove that the estimation error is a non-decreasing function of the Age of Information (AoI) for received signal samples and design an optimal sampling strategy that minimizes the long-term average estimation error. The optimal sampler design follows a threshold strategy: If the last transmission was successful, the source waits until the expected estimation error upon delivery exceeds a threshold and then sends out a new sample. If the last transmission fails, the source immediately sends out a new sample without waiting. The threshold is the unique root of a fixed-point equation and can be solved with low complexity (e.g., by bisection search). In addition, the proposed sampling strategy is also optimal for minimizing the long-term average of general non-decreasing functions of the AoI. Its optimality holds for general transmission time distributions of the forward and feedback channels."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Nonstationary Bandit Learning via Predictive Sampling,Thompson sampling can perform poorly when applied to nonstationary environments.,""Yueyang Liu, B. V. Roy, Kuang Xu"",ArXiv,,,10.48550/arXiv.2205.01970,,2022,3,https://doi.org/10.48550/arXiv.2205.01970,https://semanticscholar.org/paper/8ff77b57e9382f4603fe473206975d6c12a7881f,""Thompson sampling has proven e?ective across a wide range of stationary bandit environments. However, as we demonstrate in this paper, it can perform poorly when applied to nonstationary environments. We show that such failures are attributed to the fact that, when exploring, the algorithm does not di?erentiate actions based on how quickly the information acquired loses its usefulness due to nonstationarity. Building upon this insight, we propose predictive sampling, which extends Thompson sampling to do this. We establish a Bayesian regret bound and establish that, in nonstationary bandit environments, the regret incurred by Thompson sampling can far exceed that of predictive sampling. We also present implementations of predictive sampling that scale to complex bandit environments of practical interest in a computationally tractable manner. Through simulations, we demonstrate that predictive sampling outperforms Thompson sampling and other state-of-the-art algorithms across a wide range of nonstationary bandit environments."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Non-Bayesian updating in a social learning experiment,The second subjects weigh their signal as a Bayesian agent would do when the signal confirms their first belief.,""Roberta De Filippis, Antonio  Guarino, Philippe  Jehiel, Toru  Kitagawa"",J. Econ. Theory,,,10.1016/J.JET.2021.105188,https://discovery.ucl.ac.uk/10067007/7/Guarino_CWP6020-Non-Bayesian-updating-in-a-social-learning-experiment.pdf,2022,9,https://doi.org/10.1016/J.JET.2021.105188,https://semanticscholar.org/paper/c4688194cd20dc6fb2adef7ca093da7b8c31acfa,""Abstract In our laboratory experiment, subjects, in sequence, have to predict the value of a good. The second subject in the sequence makes his prediction twice: first (“first belief”), after he observes his predecessor's prediction; second (“posterior belief”), after he observes his private signal. We find that the second subjects weigh their signal as a Bayesian agent would do when the signal confirms their first belief; they overweight the signal when it contradicts their first belief. This way of updating, incompatible with Bayesianism, can be explained by the Likelihood Ratio Test Updating (LRTU) model, a generalization of the Maximum Likelihood Updating rule. It is at odds with another family of updating, the Full Bayesian Updating. In another experiment, we directly test the LRTU model and find support for it."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Knowledge Graph Reasoning with Logics and Embeddings: Survey and Perspective,Logic-based and embedding-based methods are integrated in knowledge graph reasoning.,""Wen Zhang, Jiaoyan Chen, Juan Li, Zezhong Xu, Jeff Z. Pan, Huajun Chen"",ArXiv,,,,,2022,3,,https://semanticscholar.org/paper/4baf6f668b6b10a33a16f12aa51b0edef02b1c35,""Knowledge graph (KG) reasoning is becoming increasingly popular in both academia and industry. Conventional KG reasoning based on symbolic logic is deterministic, with reasoning results being explainable, while modern embedding-based reasoning can deal with uncertainty and predict plausible knowledge, often with high efficiency via vector computation. A promising direction is to integrate both logic-based and embedding-based methods, with the vision to have advantages of both. It has attracted wide research attention with more and more works published in recent years. In this paper, we comprehensively survey these works, focusing on how logics and embeddings are integrated. We first briefly introduce preliminaries, then systematically categorize and discuss works of logic and embedding-aware KG reasoning from different perspectives, and finally conclude and discuss the challenges and further directions."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Empowering Language Models with Knowledge Graph Reasoning for Open-Domain Question Answering,A knowledge-enabled language model can be plugged into existing Transformer-based language models to interact with a differentiable Knowledge Graph Reasoning module collaboratively.,""Ziniu Hu, Yichong Xu, W. Yu, Shuohang Wang, Ziyi Yang, Chenguang Zhu, Kai-Wei Chang, Yizhou Sun"",Conference on Empirical Methods in Natural Language Processing,,,10.48550/arXiv.2211.08380,,2022,1,https://doi.org/10.48550/arXiv.2211.08380,https://semanticscholar.org/paper/8806ba65f2a477fe685c250c1536d2e8ef450958,""Answering open-domain questions requires world knowledge about in-context entities. As pre-trained Language Models (LMs) lack the power to store all required knowledge, external knowledge sources, such as knowledge graphs, are often used to augment LMs. In this work, we propose knOwledge REasOning empowered Language Model(OREO-LM), which consists of a novel Knowledge Interaction Layer that can be flexibly plugged into existing Transformer-based LMs to interact with a differentiable Knowledge Graph Reasoning module collaboratively. In this way, LM guides KG to walk towards the desired answer, while the retrieved knowledge improves LM.By adopting OREO-LM to RoBERTa and T5, we show significant performance gain, achieving state-of-art results in the Closed-Book setting. The performance enhancement is mainly from the KG reasoning’s capacity to infer missing relational facts. In addition, OREO-LM provides reasoning paths as rationales to interpret the model’s decision."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Type-aware Embeddings for Multi-Hop Reasoning over Knowledge Graphs,A plug-and-play model can be easily incorporated into existing embedding-based models to improve their performance.,""Zhiwei Hu, V'ictor Guti'errez-Basulto, Zhiliang Xiang, Xiaoli Li, Rui Li, Jeff Z. Pan"",International Joint Conference on Artificial Intelligence,,,10.48550/arXiv.2205.00782,,2022,2,https://doi.org/10.48550/arXiv.2205.00782,https://semanticscholar.org/paper/4f210afb00371eb1dda1dd618335184857235c16,""Multi-hop reasoning over real-life knowledge graphs (KGs) is a highly challenging problem as traditional subgraph matching methods are not capable to deal with noise and missing information. Recently, to address this problem a promising approach based on jointly embedding logical queries and KGs into a low-dimensional space to identify answer entities has emerged. However, existing proposals ignore critical semantic knowledge inherently available in KGs, such as type information. To leverage type information, we propose a novel type-aware model, TypE-aware Message Passing (TEMP), which enhances the entity and relation representation in queries, and simultaneously improves generalization, and deductive and inductive reasoning. Remarkably, TEMP is a plug-and-play model that can be easily incorporated into existing embedding-based models to improve their performance. Extensive experiments on three real-world datasets demonstrate TEMP’s effectiveness."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Reasoning Through Memorization: Nearest Neighbor Knowledge Graph Embeddings,A knowledge graph embedding approach with pre-trained language models can allow rare or emerging entities to be memorized explicitly rather than implicitly in model parameters.,""Ningyu Zhang, Xin Xie, Xiang Chen, Shumin Deng, Chuanqi Tan, Fei Huang, Xu Cheng, Huajun Chen"",ArXiv,,,,,2022,7,,https://semanticscholar.org/paper/b30759d87369a5fadd7d252ec8514abfba68ca10,""Previous knowledge graph embedding approaches usually map entities to representations and utilize score functions to predict the target entities, yet they struggle to reason rare or emerging unseen entities. In this paper, we propose kNN-KGE, a new knowledge graph embedding approach with pre-trained language models, by linearly interpolating its entity distribution with k-nearest neighbors.We compute the nearest neighbors based on the distance in the entity embedding space from the knowledge store. Our approach can allow rare or emerging entities to be memorized explicitly rather than implicitly in model parameters. Experimental results demonstrate that our approach can improve inductive and transductive link prediction results and yield better performance for low-resource settings with only a few triples, which might be easier to reason via explicit memory1."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"FLEX: Feature-Logic Embedding Framework for CompleX Knowledge Graph Reasoning,The logic part of feature-logic framework naturally models all FOL operations.,""Xu Lin, E. Haihong, Gengxian Zhou, Tianyi Hu, Ningyuan Li, Ming-ming Sun, Haoran Luo"",ArXiv,,,10.48550/arXiv.2205.11039,,2022,,https://doi.org/10.48550/arXiv.2205.11039,https://semanticscholar.org/paper/2e2904ed97aa986b8dd4460bc0414d9cdd36b840,""Current best performing models for knowledge graph reasoning (KGR) are based on complex distribution or geometry objects to embed entities and ?rst-order logical (FOL) queries in low-dimensional spaces. They can be summarized as a center-size framework (point/box/cone, Beta/Gaussian distribution, etc.) whose logical reasoning ability is limited by the expressiveness of the relevant mathematical concepts. Because too deeply the center and the size depend on each other, it is dif?cult to integrate the logical reasoning ability with other models. To address these challenges, we instead propose a novel KGR framework named F eature-L ogic E mbedding framework, FLEX, which is the ?rst KGR framework that can not only TRULY handle all FOL operations including conjunction, disjunction, negation and so on, but also support various feature spaces allowing integration. Speci?cally, the logic part of feature-logic framework is based on vector logic, which naturally models all FOL operations. Experiments demonstrate that FLEX signi?cantly outperforms existing state-of-the-art methods on benchmark datasets."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"FLEX: Feature-Logic Embedding Framework for CompleX Knowledge Graph Reasoning,The logic part of feature-logic framework naturally models all FOL operations.,""Xu Lin, E. Haihong, Gengxian Zhou, Tianyi Hu, Ningyuan Li, Mingzhi Sun, Haoran Luo"",ArXiv,,,10.48550/arXiv.2205.11039,,2022,1,https://doi.org/10.48550/arXiv.2205.11039,https://semanticscholar.org/paper/1d6da6a536c6b5009d45f063c590420730c769db,""Current best performing models for knowledge graph reasoning (KGR) introduce geometry objects or probabilistic distributions to embed entities and ?rst-order logical (FOL) queries into low-dimensional vector spaces. They can be summarized as a center-size framework (point/box/cone, Beta/Gaussian distribution, etc.). However, they have limited logical reasoning ability. And it is dif?cult to generalize to various features, because the center and size are one-to-one constrained, unable to have multiple centers or sizes. To address these challenges, we instead propose a novel KGR framework named F eature- L ogic E mbedding framework, FLEX, which is the ?rst KGR framework that can not only TRULY handle all FOL operations including conjunction, disjunction, negation and so on, but also support various feature spaces. Speci?cally, the logic part of feature-logic framework is based on vector logic, which naturally models all FOL operations. Experiments demonstrate that FLEX signi?cantly outperforms existing state-of-the-art methods on benchmark datasets."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"RulE: Neural-Symbolic Knowledge Graph Reasoning with Rule Embedding,RulE can perform logical rule inference in a soft way.,""Xiaojuan Tang, Song-Chun Zhu, Yitao Liang, Muhan Zhang"",ArXiv,,,10.48550/arXiv.2210.14905,,2022,,https://doi.org/10.48550/arXiv.2210.14905,https://semanticscholar.org/paper/39ac055abc397ee31c51396c39c90510379fbb9b,""Knowledge graph (KG) reasoning is an important problem for knowledge graphs. It predicts missing links by reasoning on existing facts. Knowledge graph embedding (KGE) is one of the most popular methods to address this problem. It embeds entities and relations into low-dimensional vectors and uses the learned entity/relation embeddings to predict missing facts. However, KGE only uses zeroth-order (propositional) logic to encode existing triplets (e.g., “Alice is Bob’s wife.”); it is unable to leverage first-order (predicate) logic to represent generally applicable logical rules (e.g., “?x, y : x is y’s wife ? y is x’s husband”). On the other hand, traditional rule-based KG reasoning methods usually rely on hard logical rule inference, making it brittle and hardly competitive with KGE. In this paper, we propose RulE, a novel and principled framework to represent and model logical rules and triplets. RulE jointly represents entities, relations and logical rules in a unified embedding space. By learning an embedding for each logical rule, RulE can perform logical rule inference in a soft way and give a confidence score to each grounded rule, similar to how KGE gives each triplet a confidence score. Compared to KGE alone, RulE allows injecting prior logical rule information into the embedding space, which improves the generalization of knowledge graph embedding. Besides, the learned confidence scores of rules improve the logical rule inference process by softly controlling the contribution of each rule, which alleviates the brittleness of logic. We evaluate",our method with link predicti,on tasks. E,xper,imental,res,ult,s on,m,"ultiple benchmark KGs demonstrate the effectiveness of RulE. https://github.com/XiaojuanTang/RulE"",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Towards Hybrid Logic-based and Embedding-based Reasoning on Financial Knowledge Graphs,A framework that jointly uses logic-based reasoning and knowledge graph embeddings to provide a scalable alternative to basic isomorphism checks in ontological reasoning.,""A. Vlad, S. Vahdati, M. Nayyeri, Luigi Bellomarini, Emanuel Sallinger"",EDBT/ICDT Workshops,,,,,2022,,,https://semanticscholar.org/paper/54e41154a861067345343804cdc5d060f29ed145,""Warded Datalog+/- is a Datalog-based KRR language that guarantees decidability and tractability of the ontological reasoning task, thanks to its favourable theoretical properties. The Vadalog reasoning system exploits Warded Datalog+/- to provide a practical implementation of different reasoning tasks via basic isomorphism checks. However, these can be prohibitive in space and time complexity especially in the economic and financial context which is characterised by extreme-scale data stores and complex societal network dynamics. Recently, Knowledge Graph Embeddings (KGEs) have gained great interest in the scientific community and have extensively improved learning and knowledge discovery techniques. In this paper, we present and provide an experimental evaluation of Vada-ER, a framework that jointly uses logic-based reasoning and KGEs to provide a scalable alternative to basic isomorphism checks in ontological reasoning. With our work, we aim to improve the synergy between the reasoning and the embedding technologies and communities."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Comprehensive Analysis of Knowledge Graph Embedding Techniques Benchmarked on Link Prediction,The new generation of translational models emerges as the most promising encoders for knowledge graph completion.,""Ilaria Ferrari, Giacomo Frisoni, Paolo Italiani, G. Moro, C. Sartori"",Electronics,,0.159 (20634),10.3390/electronics11233866,https://www.mdpi.com/2079-9292/11/23/3866/pdf?version=1669367554,2022,1,https://doi.org/10.3390/electronics11233866,https://semanticscholar.org/paper/b5167990eda7d48f1a70a1fcb900ed5d46c40985,""In knowledge graph representation learning, link prediction is among the most popular and influential tasks. Its surge in popularity has resulted in a panoply of orthogonal embedding-based methods projecting entities and relations into low-dimensional continuous vectors. To further enrich the research space, the community witnessed a prolific development of evaluation benchmarks with a variety of structures and domains. Therefore, researchers and practitioners face an unprecedented challenge in effectively identifying the best solution to their needs. To this end, we propose the most comprehensive and up-to-date study to systematically assess the effectiveness and efficiency of embedding models for knowledge graph completion. We compare 13 models on six datasets with different sizes, domains, and relational properties, covering translational, semantic matching, and neural network-based encoders. A fine-grained evaluation is conducted to compare each technique head-to-head in terms of standard metrics, training and evaluation times, memory consumption, carbon footprint, and space geometry. Our results demonstrate the high dependence between performance and graph types, identifying the best options for each scenario. Among all the encoding strategies, the new generation of translational models emerges as the most promising, bringing out the best and most consistent resul",ts across all the datasets and,evaluation,cri,"teria.""",",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Reasoning Through Memorization: Nearest Neighbor Knowledge Graph Embeddings,A knowledge graph embedding approach with pre-trained language models can allow rare or emerging entities to be memorized explicitly rather than implicitly in model parameters.,""Ningyu Zhang, Xin Xie, Xiang Chen, Shumin Deng, Chuanqi Tan, Fei Huang, Xu Cheng, Huajun Chen"",ArXiv,,,,,2022,7,,https://semanticscholar.org/paper/072f7b3b68c930c4e01fc2ed1c54fcdc5e916a04,""Previous knowledge graph embedding approaches usually map entities to representations and utilize score functions to predict the target entities, yet they typically struggle to reason rare or emerging unseen entities. In this paper, we propose kNN-KGE, a new knowledge graph embedding approach with pre-trained language models, by linearly interpolating its entity distribution with k-nearest neighbors. We compute the nearest neighbors based on the distance in the entity embedding space from the knowledge store. Our approach can allow rare or emerging entities to be memorized explicitly rather than implicitly in model parameters. Experimental results demonstrate that our approach can improve inductive and transductive link prediction results and yield better performance for low-resource settings with only a few triples, which might be easier to reason via explicit memory. Code is available at https://github.com/zjunlp/KNN-KG."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"An Adaptive Logical Rule Embedding Model for Inductive Reasoning over Temporal Knowledge Graphs,The proposed model has good zero-shot reasoning ability.,""Xin Mei, Libin Yang, Xiaoyan Cai, Zuowei Jiang"",Conference on Empirical Methods in Natural Language Processing,,,,,2022,,,https://semanticscholar.org/paper/f0004055579ad3c6be69eefa23938eaea2dc145e,""Temporal knowledge graphs (TKGs) extrapolation reasoning predicts future events based on historical information, which has great research significance and broad application value. Existing methods can be divided into embedding-based methods and logical rule-based methods. Embedding-based methods rely on learned entity and relation embeddings to make predictions and thus lack interpretability. Logical rule-based methods bring scalability problems due to being limited by the learned logical rules. We combine the two methods to capture deep causal logic by learning rule embeddings, and propose an interpretable model for temporal knowledge graph reasoning called adaptive logical rule embedding model for inductive reasoning (ALRE-IR). ALRE-IR can adaptively extract and assess reasons contained in historical events, and make predictions based on causal logic. Furthermore, we propose a one-class augmented matching loss for optimization. When evaluated on the ICEWS14, ICEWS0515 and ICEWS18 datasets, the performance of ALRE-IR outperforms other state-of-the-art baselines. The results also demonstrate that ALRE-IR still shows outstanding performance when transferred to related dataset with common relation vocabulary, indicating our proposed model has good zero-shot reasoning ability."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Towards Large-Scale Interpretable Knowledge Graph Reasoning for Dialogue Systems,A single transformer model can generate responses by reasoning over differentiable knowledge graphs.,""Yi-Lin Tuan, Sajjad Beygi, M. Fazel-Zarandi, Qiaozi Gao, Alessandra Cervone, William Yang Wang"",Findings,,,10.48550/arXiv.2203.10610,,2022,1,https://doi.org/10.48550/arXiv.2203.10610,https://semanticscholar.org/paper/6abc706f116a4d64c2b39dfade3c5cd4cd744f4a,""Users interacting with voice assistants today need to phrase their requests in a very specific manner to elicit an appropriate response. This limits the user experience, and is partly due to the lack of reasoning capabilities of dialogue platforms and the hand-crafted rules that require extensive labor. One possible solution to improve user experience and relieve the manual efforts of designers is to build an end-to-end dialogue system that can do reasoning itself while perceiving user’s utterances. In this work, we propose a novel method to incorporate the knowledge reasoning capability into dialog systems in a more scalable and generalizable manner. Our proposed method allows a single transformer model to directly walk on a large-scale knowledge graph to generate responses. To the best of our knowledge, this is the first work to have transformer models generate responses by reasoning over differentiable knowledge graphs. We investigate the reasoning abilities of the proposed method on both task-oriented and domain-specific chit-chat dialogues. Empirical results show that this method can effectively and efficiently incorporate a knowledge graph into a dialogue system with fully-interpretable reasoning paths."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"""A Survey on Knowledge Graphs: Representation, Acquisition, and Applications"",""Knowledge graph embedding is organized from four aspects of representation space, scoring function, encoding models, and auxiliary information."",""Shaoxiong  Ji, Shirui  Pan, Erik  Cambria, Pekka  Marttinen, Philip S. Yu"",IEEE Transactions on Neural Networks and Learning Systems,,4.222 (355),10.1109/TNNLS.2021.3070843,https://research-repository.griffith.edu.au/bitstream/10072/416709/2/Pan2923674-Accepted.pdf,2022,340,https://doi.org/10.1109/TNNLS.2021.3070843,https://semanticscholar.org/paper/c9ec8cf5ce461647d0d1cf67093feeadea5d9957,""Human knowledge provides a formal understanding of the world. Knowledge graphs that represent structural relations between entities have become an increasingly popular research direction toward cognition and human-level intelligence. In this survey, we provide a comprehensive review of the knowledge graph covering overall research topics about: 1) knowledge graph representation learning; 2) knowledge acquisition and completion; 3) temporal knowledge graph; and 4) knowledge-aware applications and summarize recent breakthroughs and perspective directions to facilitate future research. We propose a full-view categorization and new taxonomies on these topics. Knowledge graph embedding is organized from four aspects of representation space, scoring function, encoding models, and auxiliary information. For knowledge acquisition, especially knowledge graph completion, embedding methods, path inference, and logical rule reasoning are reviewed. We further explore several emerging topics, including metarelational learning, commonsense reasoning, and temporal knowledge graphs. To facilitate future research on knowledge graphs, we also provide a curated collection of data sets and open-source libraries on different tasks. In the end, we have a thorough outlook on several promising research","directions."",,Review",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Neural Methods for Logical Reasoning over Knowledge Graphs,Neural network models achieve a 10% relative increase over the best performing state of the art.,""Alfonso Amayuelas, Shuai Zhang, Susie Xi Rao, Ce Zhang"",International Conference on Learning Representations,,,10.48550/arXiv.2209.14464,,2022,4,https://doi.org/10.48550/arXiv.2209.14464,https://semanticscholar.org/paper/2d80d0b053179988f2155ea9eaf57b60a7742c16,""Reasoning is a fundamental problem for computers and deeply studied in Arti?cial Intelligence. In this paper, we speci?cally focus on answering multi-hop logical queries on Knowledge Graphs (KGs). This is a complicated task because, in real-world scenarios, the graphs tend to be large and incomplete. Most previous works have been unable to create models that accept full First-Order Logical (FOL) queries, which include negative queries, and have only been able to process a limited set of query structures. Additionally, most methods present logic operators that can only perform the logical operation they are made for. We introduce a set of models that use Neural Networks to create one-point vector embeddings to answer the queries. The versatility of neural networks allows the framework to handle FOL queries with Conjunction ( ? ), Disjunction ( ? ) and Negation ( ¬ ) operators. We demonstrate experimentally the performance of our model through extensive experimentation on well-known benchmarking datasets. Besides having more versatile operators, the models achieve a 10% relative increase over the best performing state of the art and more than 30% over the original method based on single-point vector embeddings."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Reasoning Through Memorization: Nearest Neighbor Knowledge Graph Embeddings,A knowledge graph embedding approach can allow rare or emerging entities to be memorized explicitly rather than implicitly in model parameters.,""Ningyu Zhang, Xin Xie, Xiang Chen, Shumin Deng, Chuanqi Tan, Fei Huang, Xu Cheng, Huajun Chen"",ArXiv,,,,,2022,5,,https://semanticscholar.org/paper/5a61585cea70ad0ec228d47acddc623103efca1b,""Previous knowledge graph embedding approaches usually map entities to representations and utilize score functions to predict the target entities, yet they struggle to reason rare or emerging unseen entities. In this paper, we propose kNN-KGE, a new knowledge graph embedding approach, by linearly interpolating its entity distribution with knearest neighbors. We compute the nearest neighbors based on the distance in the entity embedding space from the knowledge store. Our approach can allow rare or emerging entities to be memorized explicitly rather than implicitly in model parameters. Experimental results demonstrate that our approach can improve inductive and transductive link prediction results and yield better performance for low-resource settings with only a few triples, which might be easier to reason via explicit memory1."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Explaining Link Prediction Systems based on Knowledge Graph Embeddings,Link prediction models can outperform traditional approaches and can be employed in multiple downstream tasks.,""Andrea Rossi, D. Firmani, P. Merialdo, Tommaso Teofili"",SIGMOD Conference,,,10.1145/3514221.3517887,https://iris.uniroma3.it/bitstream/11590/410639/3/2022-sigmod.pdf,2022,5,https://doi.org/10.1145/3514221.3517887,https://semanticscholar.org/paper/2ae37d50e80ec53320b71768a3c85750827799fd,""Link Prediction (LP) aims at tackling Knowledge Graph incompleteness by inferring new, missing facts from the already known ones. The rise of novel Machine Learning techniques has led researchers to develop LP models that represent Knowledge Graph elements as vectors in an embedding space. These models can outperform traditional approaches and they can be employed in multiple downstream tasks; nonetheless, they tend to be opaque, and are mostly regarded as black boxes. Their lack of interpretability limits our understanding of their inner mechanisms, and undermines the trust that users can place in them. In this paper, we propose the novel Kelpie explainability framework. Kelpie can be applied to any embedding-based LP models independently from their architecture, and it explains predictions by identifying the combinations of training facts that have enabled them. Kelpie can extract two complementary types of explanations, that we dub necessary and sufficient. We describe in detail both the structure and the implementation details of Kelpie, and thoroughly analyze its performance through extensive experiments. Our results show that Kelpie significantly outperforms baselines across almost all scenarios."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Query2Particles: Knowledge Graph Reasoning with Particle Embeddings,""Query2Particles achieves state-of-the-art performance on the complex query answering tasks on FB15k, FB15K-237, and NELL knowledge graphs."",""Jiaxin Bai, Zihao Wang, Hongming Zhang, Yangqiu Song"",NAACL-HLT,,,10.48550/arXiv.2204.12847,,2022,3,https://doi.org/10.48550/arXiv.2204.12847,https://semanticscholar.org/paper/b4ba06e178e3a56436d1253b794669d4831be328,""Answering complex logical queries on incomplete knowledge graphs (KGs) with missing edges is a fundamental and important task for knowledge graph reasoning. The query embedding method is proposed to answer these queries by jointly encoding queries and entities to the same embedding space. Then the answer entities are selected according to the similarities between the entity embeddings and the query embedding. As the answers to a complex query are obtained from a combination of logical operations over sub-queries, the embeddings of the answer entities may not always follow a uni-modal distribution in the embedding space. Thus, it is challenging to simultaneously retrieve a set of diverse answers from the embedding space using a single and con-centrated query representation such as a vector or a hyper-rectangle. To better cope with queries with diversi?ed answers, we propose Query2Particles (Q2P), a complex KG query answering method. Q2P encodes each query into multiple vectors, named particle embeddings. By doing so, the candidate answers can be retrieved from different areas over the embedding space using the maximal similarities between the entity embeddings and any of the particle embeddings. Meanwhile, the corresponding neural logic operations are de?ned to support its reasoning over arbitrary ?rst-order logic queries. The experiments show that Query2Particles achieves state-of-the-art performance on the complex query answering tasks on FB15k, FB15K-237, and NEL","L knowledge graphs."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"An Overview of Knowledge Graph Reasoning: Key Technologies and Applications,Knowledge graph-oriented knowledge reasoning aims to deduce new knowledge or identify wrong knowledge from existing knowledge.,""Yonghong Chen, Hao Li, Han Li, Wenhao Liu, Yirui Wu, Qian Huang, Shaohua Wan"",J. Sens. Actuator Networks,,,10.3390/jsan11040078,https://www.mdpi.com/2224-2708/11/4/78/pdf?version=1669276833,2022,1,https://doi.org/10.3390/jsan11040078,https://semanticscholar.org/paper/f80ee5510c9b8259250013887e141b0556bb5464,""In recent years, with the rapid development of Internet technology and applications, the scale of Internet data has exploded, which contains a significant amount of valuable knowledge. The best methods for the organization, expression, calculation, and deep analysis of this knowledge have attracted a great deal of attention. The knowledge graph has emerged as a rich and intuitive way to express knowledge. Knowledge reasoning based on knowledge graphs is one of the current research hot spots in knowledge graphs and has played an important role in wireless communication networks, intelligent question answering, and other applications. Knowledge graph-oriented knowledge reasoning aims to deduce new knowledge or identify wrong knowledge from existing knowledge. Different from traditional knowledge reasoning, knowledge reasoning methods oriented to knowledge graphs are more diversified due to the concise, intuitive, flexible, and rich knowledge expression forms in knowledge graphs. Based on the basic concepts of knowledge graphs and knowledge graph reasoning, this paper introduces the latest research progress in knowledge graph-oriented knowledge reasoning methods in recent years. Specifically, according to different reasoning methods, knowledge graph reasoning includes rule-based reasoning, distributed representation-based reasoning, neural network-based reasoning, and mixed reasoning",. These methods are summarized,"in detail,",and,the fu,ture,re,sear,ch,"directions and prospects of knowledge reasoning based on knowledge graphs are discussed and prospected."",,Review",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Inductive Knowledge Graph Reasoning for Multi-batch Emerging Entities,A graph convolutional network with adaptive relation aggregation is designed to encode and update entities using their neighboring relations.,""Yuanning Cui, Yuxin Wang, Zequn Sun, Wenqiang Liu, Yiqiao Jiang, Kexin Han, Wei Hu"",International Conference on Information and Knowledge Management,,,10.1145/3511808.3557361,http://arxiv.org/pdf/2208.10378,2022,2,https://doi.org/10.1145/3511808.3557361,https://semanticscholar.org/paper/80d3e96228da4309edc768145ceffdc841776d6a,""Over the years, reasoning over knowledge graphs (KGs), which aims to infer new conclusions from known facts, has mostly focused on static KGs. The unceasing growth of knowledge in real life raises the necessity to enable the inductive reasoning ability on expanding KGs. Existing inductive work assumes that new entities all emerge once in a batch, which oversimplifies the real scenario that new entities continually appear. This study dives into a more realistic and challenging setting where new entities emerge in multiple batches. We propose a walk-based inductive reasoning model to tackle the new setting. Specifically, a graph convolutional network with adaptive relation aggregation is designed to encode and update entities using their neighboring relations. To capture the varying neighbor importance, we employ a query-aware feedback attention mechanism during the aggregation. Furthermore, to alleviate the sparse link problem of new entities, we propose a link augmentation strategy to add trustworthy facts into KGs. We construct three new datasets for simulating this multi-batch emergence scenario. The experimental results show that our proposed model outperforms state-of-the-art embedding-based, walk-based and rule-based models on inductive KG reasoning."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Neural-Symbolic Models for Logical Queries on Knowledge Graphs,A neural-symbolic model can answer complex first-order logic queries on knowledge graphs.,""Zhaocheng Zhu, Mikhail Galkin, Zuobai Zhang, Jian Tang"",International Conference on Machine Learning,,,10.48550/arXiv.2205.10128,,2022,11,https://doi.org/10.48550/arXiv.2205.10128,https://semanticscholar.org/paper/53eecd3d126a11911b53c639a7a808cac4fbf127,""Answering complex ?rst-order logic (FOL) queries on knowledge graphs is a fundamental task for multi-hop reasoning. Traditional symbolic methods traverse a complete knowledge graph to extract the answers, which provides good interpretation for each step. Recent neural methods learn geometric embeddings for complex queries. These methods can generalize to incomplete knowledge graphs, but their reasoning process is hard to interpret. In this paper, we propose Graph Neural Network Query Executor (GNN-QE), a neural-symbolic model that enjoys the advantages of both worlds. GNN-QE decomposes a complex FOL query into relation projections and logical operations over fuzzy sets, which provides interpretability for intermediate variables. To reason about the missing links, GNN-QE adapts a graph neural network from knowledge graph completion to execute the relation projections, and models the logical operations with product fuzzy logic. Experiments on 3 datasets show that GNN-QE signi?cantly improves over previous state-of-the-art models in answering FOL queries. Mean-while, GNN-QE can predict the number of answers without explicit supervision, and provide visualizations for intermediate variables. 1"",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"PIE: a Parameter and Inference Efficient Solution for Large Scale Knowledge Graph Embedding Reasoning,The same embedding dimension for both dense entities and sparse entities will cause either over parameterization (sparse entities) or under fitting (dense entities).,""Linlin Chao, Taifeng Wang, Wei Chu"",ArXiv,,,10.48550/arXiv.2204.13957,,2022,3,https://doi.org/10.48550/arXiv.2204.13957,https://semanticscholar.org/paper/d67b20cc794c4ab5536fc665678f67042190f685,""Knowledge graph (KG) embedding methods which map entities and relations to unique embeddings in the KG have shown promising results on many reasoning tasks. However, the same embedding dimension for both dense entities and sparse entities will cause either over parameterization (sparse entities) or under ?tting (dense entities). Normally, a large dimension is set to get better performance. Meanwhile, the inference time grows log-linearly with the number of entities for all entities are traversed and compared. Both the parameter and inference become challenges when working with huge amounts of entities. Thus, we propose PIE, a p arameter and i nference e f?cient solution. Inspired from tensor decomposition methods, we ?nd that decompose entity embedding matrix into low rank matrices can reduce more than half of the parameters while maintaining comparable performance. To accelerate model inference, we propose a self-supervised auxiliary task, which can be seen as ?ne-grained entity typing. By randomly masking and recovering entities’ connected relations, the task learns the co-occurrence of entity and relations. Utilizing the ?ne grained typing, we can ?lter unrelated entities during inference and get targets with possibly sub-linear time requirement. Experiments on link prediction benchmarks demonstrate the proposed key capabilities. Moreover, we prove effectiveness of the proposed solution on the Open Graph Benchmark large scale",challenge dataset WikiKG90Mv2,and achiev,e th,e state,of,the,art,p,"erformance."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"DiriE: Knowledge Graph Embedding with Dirichlet Distribution,""Existing methods are subject to at least one of the following limitations: 1) ignoring the uncertainty, 2) incapability of complex relation patterns."",""Feiyang Wang, Zhongbao Zhang, Li Sun, Junda Ye, Yang Yan"",The Web Conference,,,10.1145/3485447.3512028,,2022,4,https://doi.org/10.1145/3485447.3512028,https://semanticscholar.org/paper/621dd7026238c6f6df01f54f4371bf342ec94d91,""Knowledge graph embedding aims to learn representations of entities and relations in low-dimensional space. Recently, extensive studies combine the characteristics of knowledge graphs with different geometric spaces, including Euclidean space, complex space, hyperbolic space and others, which achieves significant progress in representation learning. However, existing methods are subject to at least one of the following limitations: 1) ignoring the uncertainty, 2) incapability of complex relation patterns. To address the above issues simultaneously, we propose a novel model named DiriE, which embeds entities as Dirichlet distributions and relations as multinomial distributions. DiriE employs Bayesian inference to measure the relations between entities and learns binary embeddings of knowledge graphs for modeling complex relation patterns. Additionally, we propose a two-step negative triple generation method that generates negative triples of both entities and relations. We conduct a solid theoretical analysis to demonstrate the effectiveness and robustness of our method, including the expressiveness of complex relation patterns and the ability to model uncertainty. Furthermore, extensive experiments show that our method outperforms state-of-the-art methods in link prediction on benchmark datasets."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"A Survey on Knowledge Graph Embedding,""Knowledge graph embedding improves computational efficiency by embedding entities and relations in the knowledge graph into a low-dimensional, dense and continuous vector space."",""Qi Yan, Jiaxin Fan, Mohan Li, Guanqun Qu, Yang Xiao"",International Conference on Data Science in Cyberspace,,,10.1109/DSC55868.2022.00086,,2022,2,https://doi.org/10.1109/DSC55868.2022.00086,https://semanticscholar.org/paper/f470e11faa6200026cf39e248510070c078e509a,""Knowledge graph (KG) is used to represent the relationships between different concepts in the real world. It is a special network in which nodes represent entities and edges represent relationships. KGs can intuitively model the connections between facts, but in many applications, there are certain limitations in directly using symbolic logic to represent knowledge in KGs and perform calculations, making it difficult to achieve expected results in downstream tasks. Meanwhile, with the explosive growth of Internet capacity, the traditional KG structure faces the problems of computational inefficiency and management difficulties. To alleviate these problems, Knowledge graph embedding (KGE) is proposed to improve the computational efficiency by embedding entities and relations in the KG into a low-dimensional, dense and continuous vector space, and thus the solution of some problems in the knowledge graph is transformed into vector operations. Moreover, KGE also can be used as a pre-trained model which is more beneficial to downstream applications, such as applications based on deep learning. In this paper, we classify KGE into three categories, namely translational distance models, semantic matching models and neural network based models. The advantages and disadvantages of different embedding methods are compared, while the main applications of KGE are summarized. Some current challenges of KGE are summarized,",as well as some views on the,future rese,arch,direct,ions,of,KGE,".""",",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"""Reasoning over Different Types of Knowledge Graphs: Static, Temporal and Multi-Modal"",Knowledge graph reasoning is a fast-growing research direction.,""K. Liang, Lingyuan Meng, Meng Liu, Yue Liu, Wenxuan Tu, Siwei Wang, Sihang Zhou, Xinwang Liu, Fu Sun"",ArXiv,,,10.48550/arXiv.2212.05767,,2022,3,https://doi.org/10.48550/arXiv.2212.05767,https://semanticscholar.org/paper/4b963961f9990dea41133cd09109da1b3fed531f,""—Knowledge graph reasoning (KGR), aiming to deduce new facts from existing facts based on mined logic rules underlying knowledge graphs (KGs), has become a fast-growing research direction. It has been proven to signi?cantly bene?t the usage of KGs in many AI applications, such as question answering and recommendation systems, etc. According to the graph types, the existing KGR models can be roughly divided into three categories, i.e., static models, temporal models, and multi-modal models. The early works in this domain mainly focus on static KGR and tend to directly apply general knowledge graph embedding models to the reasoning task. However, these models are not suitable for more complex but practical tasks, such as inductive static KGR, temporal KGR, and multi-modal KGR. To this end, multiple works have been developed recently, but no survey papers and open-source repositories comprehensively summarize and discuss models in this important direction. To ?ll the gap, we conduct a survey for knowledge graph reasoning tracing from static to temporal and then to multi-modal KGs. Concretely, the preliminaries, summaries of KGR models, and typical datasets are introduced and discussed consequently. Moreover, we discuss the challenges and potential opportunities. The corresponding open-source repository is shared on GitHub: https://github.com/LIANGKE23/Awesome-Knowledge-Graph-Reasoning."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"""Reasoning over Different Types of Knowledge Graphs: Static, Temporal and Multi-Modal"",Knowledge graph reasoning is a fast-growing research direction.,""K. Liang, Lingyuan Meng, Meng Liu, Yue Liu, Wenxuan Tu, Siwei Wang, Sihang Zhou, Xinwang Liu, Fu Sun"",ArXiv,,,10.48550/arXiv.2212.05767,,2022,3,https://doi.org/10.48550/arXiv.2212.05767,https://semanticscholar.org/paper/3cf49f9962183823dcdab4c799e292b6ea9faede,""—Knowledge graph reasoning (KGR), aiming to deduce new facts from existing facts based on mined logic rules underlying knowledge graphs (KGs), has become a fast-growing research direction. It has been proven to signi?cantly bene?t the usage of KGs in many AI applications, such as question answering and recommendation systems, etc. According to the graph types, the existing KGR models can be roughly divided into three categories, i.e., static models, temporal models, and multi-modal models. The early works in this domain mainly focus on static KGR and tend to directly apply general knowledge graph embedding models to the reasoning task. However, these models are not suitable for more complex but practical tasks, such as inductive static KGR, temporal KGR, and multi-modal KGR. To this end, multiple works have been developed recently, but no survey papers and open-source repositories comprehensively summarize and discuss models in this important direction. To ?ll the gap, we conduct a survey for knowledge graph reasoning tracing from static to temporal and then to multi-modal KGs. Concretely, the preliminaries, summaries of KGR models, and typical datasets are introduced and discussed consequently. Moreover, we discuss the challenges and potential opportunities. The corresponding open-source repository is shared on GitHub: https://github.com/LIANGKE23/Awesome-Knowledge-Graph-Reasoning."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"InterHT: Knowledge Graph Embeddings by Interaction between Head and Tail Entities,Distance-based methods show promising performance on link prediction task.,""Baoxin Wang, Qingye Meng, Ziyue Wang, Dayong Wu, Wanxiang Che, Shijin Wang, Zhigang Chen, Cong Liu"",ArXiv,,,,,2022,7,,https://semanticscholar.org/paper/39acaf86de56a9054ccab9af1594395e2991c9ac,""Knowledge graph embedding (KGE) models learn the representation of entities and relations in knowledge graphs. Distance-based methods show promising performance on link prediction task, which predicts the result by the distance between two entity representations. However, most of these methods represent the head entity and tail entity separately, which limits the model capacity. We propose two novel distance-based methods named InterHT and InterHT+ that allow the head and tail entities to interact better and get better entity representation. Experimental results show that our proposed method achieves the best results on ogbl-wikikg2 dataset."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Multimodal Analogical Reasoning over Knowledge Graphs,Analogical reasoning is fundamental to human cognition and holds an important place in various fields.,""Ningyu Zhang, Lei Li, Xiang Chen, Xiaozhuan Liang, Shumin Deng, Huajun Chen"",ArXiv,,,10.48550/arXiv.2210.00312,,2022,2,https://doi.org/10.48550/arXiv.2210.00312,https://semanticscholar.org/paper/68adb238b0212dde289a02a524c6e33f8ad51497,""Analogical reasoning is fundamental to human cognition and holds an important place in various ?elds. However, previous studies mainly focus on single-modal analogical reasoning and ignore taking advantage of structure knowledge. No-tably, the research in cognitive psychology has demonstrated that information from multimodal sources always brings more powerful cognitive transfer than single modality sources. To this end, we introduce the new task of multimodal analogical reasoning over knowledge graphs, which requires multimodal reasoning ability with the help of background knowledge. Speci?cally, we construct a M ultimodal A nalogical R easoning data S et ( MARS ) and a multimodal knowledge graph MarKG . We evaluate with multimodal knowledge graph embedding and pre-trained Transformer baselines, illustrating the potential challenges of the proposed task. We further propose a novel model-agnostic M ultimodal a nalogical r easoning framework with T ransformer ( MarT ) motivated by the structure mapping theory, which can obtain better performance. We hope our work can deliver bene?ts and inspire future research 1 ."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"CAKE: A Scalable Commonsense-Aware Framework For Multi-View Knowledge Graph Completion,The proposed commonsense-aware negative sampling module is superior to other NS techniques.,""Guanglin Niu, Bo Li, Yongfei Zhang, Shi Pu"",Annual Meeting of the Association for Computational Linguistics,,,10.18653/v1/2022.acl-long.205,https://aclanthology.org/2022.acl-long.205.pdf,2022,8,https://doi.org/10.18653/v1/2022.acl-long.205,https://semanticscholar.org/paper/009263dec4026507d5809b14881f833c80b74cbc,""Knowledge graphs store a large number of factual triples while they are still incomplete, inevitably. The previous knowledge graph completion (KGC) models predict missing links between entities merely relying on fact-view data, ignoring the valuable commonsense knowledge. The previous knowledge graph embedding (KGE) techniques suffer from invalid negative sampling and the uncertainty of fact-view link prediction, limiting KGC’s performance. To address the above challenges, we propose a novel and scalable Commonsense-Aware Knowledge Embedding (CAKE) framework to automatically extract commonsense from factual triples with entity concepts. The generated commonsense augments effective self-supervision to facilitate both high-quality negative sampling (NS) and joint commonsense and fact-view link prediction. Experimental results on the KGC task demonstrate that assembling our framework could enhance the performance of the original KGE models, and the proposed commonsense-aware NS module is superior to other NS techniques. Besides, our proposed framework could be easily adaptive to various KGE models and explain the predicted results."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Towards Loosely-Coupling Knowledge Graph Embeddings and Ontology-based Reasoning,The prediction accuracy of knowledge graph embeddings is enhanced by domain knowledge that may not be included in the input knowledge graph.,""Zoi Kaoudi, Abelardo Carlos Mart??nez Lorenzo, V. Markl"",ArXiv,,,,,2022,2,,https://semanticscholar.org/paper/8ef2e6b11b519b609bfaa7ed056f621cee15d552,""Knowledge graph completion (a.k.a. link prediction), i.e., the task of inferring missing information from knowledge graphs, is a widely used task in many applications, such as product recommendation and question answering. The state-of-the-art approaches of knowledge graph embeddings and/or rule mining and reasoning are data-driven and, thus, solely based on the information the input knowledge graph contains. This leads to unsatisfactory prediction results which make such solutions inapplicable to crucial domains such as healthcare. To further enhance the accuracy of knowledge graph completion we propose to loosely-couple the data-driven power of knowledge graph embeddings with domain-specific reasoning stem-ming from experts or entailment regimes (e.g., OWL2). In this way, we not only enhance the prediction accuracy with domain knowledge that may not be included in the input knowledge graph but also allow users to plugin their own knowledge graph embedding and reasoning method. Our initial results show that we enhance the MRR accuracy of vanilla knowledge graph embeddings by up to 3x and outperform hybrid solutions that combine knowledge graph embeddings with rule mining and reasoning up to 3.5x MRR."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"InterHT: Knowledge Graph Embeddings by Interaction between Head and Tail Entities,Distance-based methods show promising performance on link prediction task.,""Baoxin Wang, Qingye Meng, Ziyue Wang, Dayong Wu, Wanxiang Che, Shijin Wang, Zhigang Chen, Cong Liu"",ArXiv,,,,,2022,3,,https://semanticscholar.org/paper/d0ec391c56b4d1593f8e305d49f5a409a94b1d4a,""Knowledge graph embedding (KGE) models learn the representation of entities and relations in knowledge graphs. Distance-based methods show promising performance on link prediction task, which predicts the result by the distance between two entity representations. However, most of these methods represent the head entity and tail entity separately, which limits the model capacity. We propose a novel distance-based method named InterHT that allows the head and tail entities to interact better and get better entity representation. Experimental results show that our proposed method achieves the best results on ogblwikikg2 dataset."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"KG-CRuSE: Recurrent Walks over Knowledge Graph for Explainable Conversation Reasoning using Semantic Embeddings,""A simple, yet effective LSTM-based decoder generates paths for effective conversation explanation."",""Rajdeep Sarkar, Mihael Arcan, John P. McCrae"",NLP4CONVAI,,,10.18653/v1/2022.nlp4convai-1.9,,2022,1,https://doi.org/10.18653/v1/2022.nlp4convai-1.9,https://semanticscholar.org/paper/124735e09b7c6ab3e5d953cfa4b328f0cdc50cd1,""Knowledge-grounded dialogue systems utilise external knowledge such as knowledge graphs to generate informative and appropriate responses. A crucial challenge of such systems is to select facts from a knowledge graph pertinent to the dialogue context for response generation. This fact selection can be formulated as path traversal over a knowledge graph conditioned on the dialogue context. Such paths can originate from facts mentioned in the dialogue history and terminate at the facts to be mentioned in the response. These walks, in turn, provide an explanation of the flow of the conversation. This work proposes KG-CRuSE, a simple, yet effective LSTM based decoder that utilises the semantic information in the dialogue history and the knowledge graph elements to generate such paths for effective conversation explanation. Extensive evaluations showed that our model outperforms the state-of-the-art models on the OpenDialKG dataset on multiple metrics."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"An Open Challenge for Inductive Link Prediction on Knowledge Graphs,The ILPC 2022 challenge on knowledge graph inductive link prediction is a novel open challenge on knowledge graphs.,""Mikhail Galkin, M. Berrendorf, Charles Tapley Hoyt"",ArXiv,,,10.48550/arXiv.2203.01520,,2022,4,https://doi.org/10.48550/arXiv.2203.01520,https://semanticscholar.org/paper/afbb1e7a2583c2d009845cbc112f4028f7ec92a3,""An emerging trend in representation learning over knowledge graphs (KGs) moves beyond transductive link prediction tasks over a fixed set of known entities in favor of inductive tasks that imply training on one graph and performing inference over a new graph with unseen entities. In inductive setups, node features are often not available and training shallow entity embedding matrices is meaningless as they cannot be used at inference time with unseen entities. Despite the growing interest, there are not enough benchmarks for evaluating inductive representation learning methods. In this work, we introduce ILPC 2022 , a novel open challenge on KG inductive link prediction. To this end, we constructed two new datasets based on Wikidata with various sizes of training and inference graphs that are much larger than existing inductive benchmarks. We also provide two strong baselines leveraging recently proposed inductive methods. We hope this challenge helps to streamline community efforts in the inductive graph representation learning area. ILPC 2022 follows best practices on evaluation fairness and reproducibility, and is available at https://github.com/pykeen/ilpc2022."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Modeling Precursors for Temporal Knowledge Graph Reasoning via Auto-encoder Structure,A novel auto-encoder architecture accommodates inference over the TKG.,""Yifu Gao, Linhui Feng, Zhigang Kan, Yi Han, Linbo Qiao, Dongsheng Li"",International Joint Conference on Artificial Intelligence,,,10.24963/ijcai.2022/284,https://www.ijcai.org/proceedings/2022/0284.pdf,2022,1,https://doi.org/10.24963/ijcai.2022/284,https://semanticscholar.org/paper/68107a3de4d5a9c76fa482111cfa547d2e07d32f,""Temporal knowledge graph (TKG) reasoning that infers missing facts in the future is an essential and challenging task. When predicting a future event, there must be a narrative evolutionary process composed of closely related historical facts to support the event's occurrence, namely fact precursors. However, most existing models employ a sequential reasoning process in an auto-regressive manner, which cannot capture precursor information. This paper proposes a novel auto-encoder architecture that introduces a relation-aware graph attention layer into transformer (rGalT) to accommodate inference over the TKG. Specifically, we first calculate the correlation between historical and predicted facts through multiple attention mechanisms along intra-graph and inter-graph dimensions, then constitute these mutually related facts into diverse fact segments. Next, we borrow the translation generation idea to decode in parallel the precursor information associated with the given query, which enables our model to infer future unknown facts by progressively generating graph structures. Experimental results on four benchmark datasets demonstrate that our model outperforms other state-of-the-art methods, and precursor identi?cation provides supporting evidence for prediction."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Explainable Knowledge Graph Embedding: Inference Reconciliation for Knowledge Inferences Supporting Robot Actions,A proposed inference reconciliation framework enables non-experts to correct erratic robot behaviors due to nonsensical beliefs within the black-box model.,""A. Daruna, Devleena Das, S. Chernova"",IEEE/RJS International Conference on Intelligent RObots and Systems,,,10.1109/IROS47612.2022.9982104,http://arxiv.org/pdf/2205.01836,2022,2,https://doi.org/10.1109/IROS47612.2022.9982104,https://semanticscholar.org/paper/25edfb99d3b8377a11433cf7be2bcd9f8bfbdb87,""Learned knowledge graph representations supporting robots contain a wealth of domain knowledge that drives robot behavior. However, there does not exist an inference reconciliation framework that expresses how a knowledge graph representation affects a robot's sequential decision making. We use a pedagogical approach to explain the inferences of a learned, black-box knowledge graph representation, a knowledge graph embedding. Our interpretable model uses a decision tree classifier to locally approximate the predictions of the black-box model and provides natural language explanations interpretable by non-experts. Results from our algorithmic evaluation affirm our model design choices, and the results of our user studies with non-experts support the need for the proposed inference reconciliation framework. Critically, results from our simulated robot evaluation indicate that our explanations enable non-experts to correct erratic robot behaviors due to nonsensical beliefs within the black-box."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Knowledge graph embedding for data mining vs. knowledge graph embedding for link prediction - two sides of the same coin?,Knowledge graph embeddings have been proposed for two purposes: providing an encoding for data mining tasks and predicting links in a knowledge graph.,""Jan Portisch, Nicolas Heist, H. Paulheim"",Semantic Web,,1.242 (2878),10.3233/sw-212892,https://content.iospress.com:443/download/semantic-web/sw212892?id=semantic-web%2Fsw212892,2022,9,https://doi.org/10.3233/sw-212892,https://semanticscholar.org/paper/9f7731d72e2aa251d2994eb1729c22aa78d0f718,""Knowledge Graph Embeddings, i.e., projections of entities and relations to lower dimensional spaces, have been proposed for two purposes: (1) providing an encoding for data mining tasks, and (2) predicting links in a knowledge graph. Both lines of research have been pursued rather in isolation from each other so far, each with their own benchmarks and evaluation methodologies. In this paper, we argue that both tasks are actually related, and we show that the first family of approaches can also be used for the second task and vice versa. In two series of experiments, we provide a comparison of both families of approaches on both tasks, which, to the best of our knowledge, has not been done so far. Furthermore, we discuss the differences in the similarity functions evoked by the different embedding approaches."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Augmenting Knowledge Graphs for Better Link Prediction,A knowledge graph augmentation method incorporates literals in an embedding model without modifying its loss function.,""Jiang Wang, Filip Ilievski, Pedro A. Szekely, Ke-Thia Yao"",International Joint Conference on Artificial Intelligence,,,10.48550/arXiv.2203.13965,,2022,2,https://doi.org/10.48550/arXiv.2203.13965,https://semanticscholar.org/paper/387a916fa4927a5998cbef2e0b7e1f5e6a2e9c3e,""Embedding methods have demonstrated robust performance on the task of link prediction in knowledge graphs, by mostly encoding entity relationships. Recent methods propose to enhance the loss function with a literal-aware term. In this paper, we propose KGA: a knowledge graph augmentation method that incorporates literals in an embedding model without modifying its loss function. KGA discretizes quantity and year values into bins, and chains these bins both horizontally, modeling neighboring values, and vertically, modeling multiple levels of granularity. KGA is scalable and can be used as a pre-processing step for any existing knowledge graph embedding model. Experiments on legacy benchmarks and a new large benchmark, DWD, show that augmenting the knowledge graph with quantities and years is beneficial for predicting both entities and numbers, as KGA outperforms the vanilla models and other relevant baselines. Our ablation studies confirm that both quantities and years contribute to KGA's performance, and that its performance depends on the discretization and binning settings. We make the code, models, and the DWD benchmark publicly available to facilitate reproducibility and future research."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Query Embedding on Hyper-relational Knowledge Graphs,""Existing algorithms operate only on classical, triple-based graphs."",""Dimitrios Alivanistos, M. Berrendorf, Michael Cochez, Mikhail Galkin"",ICLR,,,,,2022,1,,https://semanticscholar.org/paper/fedbff3683daf4317f3c9521f190ffc410f91458,""Multi-hop logical reasoning is an established problem in the field of representation learning on knowledge graphs (KGs). It subsumes both one-hop link prediction as well as other more complex types of logical queries. Existing algorithms operate only on classical, triple-based graphs, whereas modern KGs often employ a hyperrelational modeling paradigm. In this paradigm, typed edges may have several key-value pairs known as qualifiers that provide fine-grained context for facts. In queries, this context modifies the meaning of relations, and usually reduces the answer set. Hyper-relational queries are often observed in real-world KG applications, and existing approaches for approximate query answering cannot make use of qualifier pairs. In this work, we bridge this gap and extend the multi-hop reasoning problem to hyper-relational KGs allowing to tackle this new type of complex queries. Building upon recent advancements in Graph Neural Networks and query embedding techniques, we study how to embed and answer hyper-relational conjunctive queries. Besides that, we propose a method to answer such queries and demonstrate in our experiments that qualifiers improve query answering on a diverse set of query patterns."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Joint Language Semantic and Structure Embedding for Knowledge Graph Completion,The semantics in the natural language description of the knowledge triplets with their structure information play an important role in knowledge graph completion.,""Jianhao Shen, Chenguang Wang, Linyuan Gong, Dawn Song"",International Conference on Computational Linguistics,,,10.48550/arXiv.2209.08721,,2022,4,https://doi.org/10.48550/arXiv.2209.08721,https://semanticscholar.org/paper/933cb8bf1cd50d6d5833a627683327b15db28836,""The task of completing knowledge triplets has broad downstream applications. Both structural and semantic information plays an important role in knowledge graph completion. Unlike previous approaches that rely on either the structures or semantics of the knowledge graphs, we propose to jointly embed the semantics in the natural language description of the knowledge triplets with their structure information. Our method embeds knowledge graphs for the completion task via fine-tuning pre-trained language models with respect to a probabilistic structured loss, where the forward pass of the language models captures semantics and the loss reconstructs structures. Our extensive experiments on a variety of knowledge graph benchmarks have demonstrated the state-of-the-art performance of our method. We also show that our method can significantly improve the performance in a low-resource regime, thanks to the better use of semantics. The code and datasets are available at https://github.com/pkusjh/LASS."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Knowledge Graph Completion by Jointly Learning Structural Features and Soft Logical Rules,A novel knowledge graph embedding model can learn more expressive embedding of entities and relations.,""Weidong Li, Rong Peng, Zhi Li"",IEEE Transactions on Knowledge and Data Engineering,,2.431 (883),10.1109/TKDE.2021.3108224,,2023,3,https://doi.org/10.1109/TKDE.2021.3108224,https://semanticscholar.org/paper/2acfa599b8f6d6a25d650fc3030f87004c9f7d99,""With the rapid development and widespread application of Knowledge graphs (KGs) in many artificial intelligence tasks, a large number of efforts have been made to refine them and increase their quality. Knowedge graph embedding (KGE) has become one of the main refinement tasks, which aims to predict missing facts based on existing ones in KGs. However, there are still mainly two difficult unresolved challenges: (i) how to leverage the local structural features of entities and the potential soft logical rules to learn more expressive embedding of entites and relations; and (ii) how to combine these two learning processes into one unified model. To conquer these problems, we propose a novel KGE model named JSSKGE, which can Jointly learn the local Structural features of entities and Soft logical rules. First, we employ graph attention networks which are specially designed for graph-structured data to aggregate the local structural information of nodes. Then, we utilize soft logical rules implicated in KGs as an expert to further rectify the embeddings of entities and relations. By jointly learning, we can obtain more informative embeddings to predict new facts. With experiments on four commonly used datasets, the JSSKGE obtains better performance than state-of-the-art approaches."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"A Knowledge Graph Recommendation Model via High-order Feature Interaction and Intent Decomposition,Existing knowledge graph-based neural network models are coarse-grained.,""Ruoyi Zhang, Huifang Ma, Qingfeng Li, Zhixin Li, Yike Wang"",IEEE International Joint Conference on Neural Network,,,10.1109/IJCNN55064.2022.9892593,,2022,1,https://doi.org/10.1109/IJCNN55064.2022.9892593,https://semanticscholar.org/paper/5e956579cd2f5f085ead1a325d3ba60d5b9732e6,""Knowledge Graph(KG) contains structured attribute information which has been widely utilized for recommendations, as well as can effectively tackle the sparsity and cold start problems of collaborative filtering. In recent years, Graph Neural Networks (GNNs) serve as a novel deep learning technique that can significantly enhance recommendation performance. Unfortunately, existing KG-based GNN models are coarse-grained ignoring i)effective high-order feature interaction and fusion mechanism and ii)interpretable user latent intent decomposition. In this paper, we propose a new method named Knowledge Graph recommendation model via high-order feature Interaction and intent Decomposition(KGID), which explicitly models the fine-grained feature interaction and intent factors in KG-based GNN recommendation. Initially, high-order feature interactions are captured via the two-granularity convolutional neural networks on the item side. Next, the implicit intent factor behind the user decisions is modeled by two-level attention mechanisms. Ultimately, user representations and item representations are augmented simultaneously. We conduct experiments on three benchmark datasets to elucidate the superiority of the KGID to state-of-the-art baselines."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Inductive Logical Query Answering in Knowledge Graphs,Inductive models are able to perform logical reasoning at inference time over unseen nodes generalizing to graphs up to 500% larger than training ones.,""Mikhail Galkin, Zhaocheng Zhu, Hongyu Ren, Jian Tang"",ArXiv,,,10.48550/arXiv.2210.08008,,2022,3,https://doi.org/10.48550/arXiv.2210.08008,https://semanticscholar.org/paper/d2c177f6386e7b88b406e2f741ed5387e4ced3b0,""Formulating and answering logical queries is a standard communication interface for knowledge graphs (KGs). Alleviating the notorious incompleteness of real-world KGs, neural methods achieved impressive results in link prediction and complex query answering tasks by learning representations of entities, relations, and queries. Still, most existing query answering methods rely on transductive entity embeddings and cannot generalize to KGs containing new entities without retraining the entity embeddings. In this work, we study the inductive query answering task where inference is performed on a graph containing new entities with queries over both seen and unseen entities. To this end, we devise two mechanisms lever-aging inductive node and relational structure representations powered by graph neural networks (GNNs). Experimentally, we show that inductive models are able to perform logical reasoning at inference time over unseen nodes generalizing to graphs up to 500% larger than training ones. Exploring the ef?ciency–effectiveness trade-off, we ?nd the inductive relational structure representation method generally achieves higher performance, while the inductive node representation method is able to answer complex queries in the inference-only regime without any training on queries and scales to graphs of millions of nodes. Code is available at https://github.com/DeepGraphLearning/InductiveQE ."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"BertNet: Harvesting Knowledge Graphs from Pretrained Language Models,""The knowledge harvested with our approach shows competitive quality, diversity, and novelty."",""Shibo Hao, Bowen Tan, Kaiwen Tang, Hengzhe Zhang, E. Xing, Zhiting Hu"",ArXiv,,,10.48550/arXiv.2206.14268,,2022,9,https://doi.org/10.48550/arXiv.2206.14268,https://semanticscholar.org/paper/a11fa157d6d80b57016f548dbdf5ca94a3cd5a36,""Symbolic knowledge graphs (KGs) have been constructed either by expensive human crowdsourcing or with complex text mining pipelines. The emerging large pretrained language models (LMs), such as B ERT , have shown to implicitly encode massive knowledge which can be queried with properly designed prompts. However, compared to the explicit KGs, the implict knowledge in the black-box LMs is often dif?cult to access or edit and lacks explainability. In this work, we aim at harvesting symbolic KGs from the LMs, and propose a new framework for automatic KG construction empowered by the neural LMs’ ?exibility and scalability. Compared to prior works that often rely on large human annotated data or existing massive KGs, our approach requires only the minimal de?nition of relations as inputs, and hence is suitable for extracting knowledge of rich new relations that are instantly assigned and not available before. The framework automatically generates diverse prompts, and performs ef?cient knowledge search within a given LM for consistent outputs. The knowledge harvested with our approach shows competitive quality, diversity, and novelty. As a result, we derive from diverse LMs a family of new KGs (e.g., B ERT N ET and R O BERT A N ET ) that contain a richer set of relations, including some complex ones (e.g., """"A is capable of but not good at B"""" ) that cannot be extracted with previous methods. Besides, the resulting KGs also serve as a vehicle to interpret the respective source LMs, leading to new insigh",ts into the varying knowledge,capability,of d,ifferen,t LM,"s.""",",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Language Model Guided Knowledge Graph Embeddings,Pre-trained language models improve the accuracy of knowledge graph embedding models.,""Mirza Mohtashim Alam, M. Rony, M. Nayyeri, Karishma Mohiuddin, Mst. Mahfuja Akter, S. Vahdati, Jens Lehmann"",IEEE Access,,0.927 (4581),10.1109/access.2022.3191666,https://ieeexplore.ieee.org/ielx7/6287639/6514899/09831788.pdf,2022,1,https://doi.org/10.1109/access.2022.3191666,https://semanticscholar.org/paper/653d4dee4d18f6ce2bf84245f78a3512e7b2570a,""Knowledge graph embedding models have become a popular approach for knowledge graph completion through predicting the plausibility of (potential) triples. This is performed by transforming the entities and relations of the knowledge graph into an embedding space. However, knowledge graphs often include further textual information stored in literal, which is ignored by such embedding models. As a consequence, the learning process stays limited to the structure and the connections between the entities, which has the potential to negatively influence the performance. We bridge this gap by leveraging the capabilities of pre-trained language models to include textual knowledge in the learning process of embedding models. This is achieved by introducing a new loss function that guides embedding models in measuring the likelihood of triples by taking such complementary knowledge into consideration. The proposed solution is a model-independent loss function that can be plugged into any knowledge graph embedding model. In this paper, Sentence-BERT and fastText are used as pre-trained language models from which the embeddings of the textual knowledge are obtained and injected into the loss function. The loss function contains a trainable slack variable that determines the degree to which the language models influence the plausibility of triples. Our experimental evaluation on six benchmarks, namely Nations, UMLS, W","ordNet, and three versions of",CodEx confi,rms,the adv,anta,ge,of u,si,"ng pre-trained language models for boosting the accuracy of knowledge graph embedding models. We showcase this by performing evaluations on top of the five well-known knowledge graph embedding models such as TransE, RotatE, ComplEx, DistMult, and QuatE. The results show an improvement in accuracy up to 9% on UMLS dataset for the Distmult model and 4.2% on the Nations dataset for the ComplEx model when they are guided by pre-trained language models. We additionally studied the effect of multiple factors such as the structure of the knowledge graphs and training steps and presented them as ablation studies."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"A Comprehensive Survey of Graph Neural Networks for Knowledge Graphs,Graph neural network-based technologies for solving four different knowledge graph tasks are hot research topics in recent years.,""Zi Ye, Y. J. Kumar, G. O. Sing, Fengyan Song, Junsong Wang"",IEEE Access,,0.927 (4581),10.1109/access.2022.3191784,https://ieeexplore.ieee.org/ielx7/6287639/6514899/09831453.pdf,2022,2,https://doi.org/10.1109/access.2022.3191784,https://semanticscholar.org/paper/60a6b17f28e88f17e58f60923d98674358dbd0e4,""The Knowledge graph, a multi-relational graph that represents rich factual information among entities of diverse classifications, has gradually become one of the critical tools for knowledge management. However, the existing knowledge graph still has some problems which form hot research topics in recent years. Numerous methods have been proposed based on various representation techniques. Graph Neural Network, a framework that uses deep learning to process graph-structured data directly, has significantly advanced the state-of-the-art in the past few years. This study firstly is aimed at providing a broad, complete as well as comprehensive overview of GNN-based technologies for solving four different KG tasks, including link prediction, knowledge graph alignment, knowledge graph reasoning, and node classification. Further, we also investigated the related artificial intelligence applications of knowledge graphs based on advanced GNN methods, such as recommender systems, question answering, and drug-drug interaction. This review will provide new insights for further study of KG and GNN."",,Review",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Mask and Reason: Pre-Training Knowledge Graph Transformers for Complex Logical Queries,Knowledge graph transformers can consistently outperform both knowledge graph embedding-based baselines and advanced encoders on nine in-domain and out-domain reasoning tasks.,""Xiao Liu, Shiyu Zhao, Kai Su, Yukuo Cen, J. Qiu, Mengdi Zhang, Wei Wu, Yuxiao Dong, Jie Tang"",Knowledge Discovery and Data Mining,,,10.1145/3534678.3539472,https://dl.acm.org/doi/pdf/10.1145/3534678.3539472,2022,3,https://doi.org/10.1145/3534678.3539472,https://semanticscholar.org/paper/334f4d63c8974c685389ffee8d8ea907c8b583f3,""Knowledge graph (KG) embeddings have been a mainstream approach for reasoning over incomplete KGs. However, limited by their inherently shallow and static architectures, they can hardly deal with the rising focus on complex logical queries, which comprise logical operators, imputed edges, multiple source entities, and unknown intermediate entities. In this work, we present the Knowledge Graph Transformer (kgTransformer) with masked pre-training and fine-tuning strategies. We design a KG triple transformation method to enable Transformer to handle KGs, which is further strengthened by the Mixture-of-Experts (MoE) sparse activation. We then formulate the complex logical queries as masked prediction and introduce a two-stage masked pre-training strategy to improve transferability and generalizability.Extensive experiments on two benchmarks demonstrate that kgTransformer can consistently outperform both KG embedding-based baselines and advanced encoders on nine in-domain and out-of-domain reasoning tasks. Additionally, kgTransformer can reason with explainability via providing the full reasoning paths to interpret given answers."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Geometry Interaction Knowledge Graph Embeddings,Knowledge graph embeddings can capture a richer set of relational information.,""Zongsheng Cao, Qianqian Xu, Zhiyong Yang, Xiaochun Cao, Qingming Huang"",AAAI,,,10.48550/arXiv.2206.12418,,2022,3,https://doi.org/10.48550/arXiv.2206.12418,https://semanticscholar.org/paper/3f6861639551b33da7276b6e27a9933c467e9d3b,""Knowledge graph (KG) embeddings have shown great power in learning representations of entities and relations for link prediction tasks. Previous work usually embeds KGs into a single geometric space such as Euclidean space (zero curved), hyperbolic space (negatively curved) or hyperspherical space (positively curved) to maintain their specific geometric structures (e.g., chain, hierarchy and ring structures). However, the topological structure of KGs appears to be complicated, since it may contain multiple types of geometric structures simultaneously. Therefore, embedding KGs in a single space, no matter the Euclidean space, hyperbolic space or hyperspheric space, cannot capture the complex structures of KGs accurately. To overcome this challenge, we propose Geometry Interaction knowledge graph Embeddings (GIE), which learns spatial structures interactively between the Euclidean, hyperbolic and hyperspherical spaces. Theoretically, our proposed GIE can capture a richer set of relational information, model key inference patterns, and enable expressive semantic matching across entities. Experimental results on three well-established knowledge graph completion benchmarks show that our GIE achieves the state-of-the-art performance with fewer parameters."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Eureka: Neural Insight Learning for Knowledge Graph Reasoning,A neural insight learning framework named Eureka bridges the seen-to-unseen gap.,""Alex Zhang, Xun Liang, Bo Wu, Xiangping Zheng, Sensen Zhang, Yuhui Guo, Jun Wang, Xin-Yang Liu"",International Conference on Computational Linguistics,,,,,2022,,,https://semanticscholar.org/paper/35ca0a9d530cd848e89ff9c206fcb1ae541cff1c,""The human recognition system has presented the remarkable ability to effortlessly learn novel knowledge from only a few trigger events based on prior knowledge, which is called insight learning. Mimicking such behavior on Knowledge Graph Reasoning (KGR) is an interesting and challenging research problem with many practical applications. Simultaneously, existing works, such as knowledge embedding and few-shot learning models, have been limited to conducting KGR in either “seen-to-seen” or “unseen-to-unseen” scenarios. To this end, we propose a neural insight learning framework named Eureka to bridge the “seen” to “unseen” gap. Eureka is empowered to learn the seen relations with sufficient training triples while providing the flexibility of learning unseen relations given only one trigger without sacrificing its performance on seen relations. Eureka meets our expectation of the model to acquire seen and unseen relations at no extra cost, and eliminate the need to retrain when encountering emerging unseen relations. Experimental results on two real-world datasets demonstrate that the proposed framework also outperforms various state-of-the-art baselines on datasets of both seen and unseen relations."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Meta-Learning Based Knowledge Extrapolation for Knowledge Graphs in the Federated Setting,A model trained on an existing knowledge graph needs to embed an emerging knowledge graph with unseen entities and relations.,""Mingyang Chen, Wen Zhang, Zhen Yao, Xian-gan Chen, Mengxiao Ding, Fei Huang, Huajun Chen"",International Joint Conference on Artificial Intelligence,,,10.48550/arXiv.2205.04692,,2022,5,https://doi.org/10.48550/arXiv.2205.04692,https://semanticscholar.org/paper/c943efc1e766a08f67b1364c13292092b17592b1,""We study the knowledge extrapolation problem to embed new components (i.e., entities and relations) that come with emerging knowledge graphs (KGs) in the federated setting. In this problem, a model trained on an existing KG needs to embed an emerging KG with unseen entities and relations. To solve this problem, we introduce the meta-learning setting, where a set of tasks are sampled on the existing KG to mimic the link prediction task on the emerging KG. Based on sampled tasks, we meta-train a graph neural network framework that can construct features for unseen components based on structural information and output embeddings for them. Experimental results show that our proposed method can effectively embed unseen components and outperforms models that consider inductive settings for KGs and baselines that directly use conventional KG embedding methods."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Knowledge-graph-based explainable AI: A systematic review,Knowledge graphs have been mainly used in pre-model XAI for feature and relation extraction.,""Enayat Rajabi, Kobra Etminani"",Journal of information science,,0.761 (6154),10.1177/01655515221112844,,2022,1,https://doi.org/10.1177/01655515221112844,https://semanticscholar.org/paper/755a1b6fc68826c161cacefc75e6582c75a0f6d2,""In recent years, knowledge graphs (KGs) have been widely applied in various domains for different purposes. The semantic model of KGs can represent knowledge through a hierarchical structure based on classes of entities, their properties, and their relationships. The construction of large KGs can enable the integration of heterogeneous information sources and help Artificial Intelligence (AI) systems be more explainable and interpretable. This systematic review examines a selection of recent publications to understand how KGs are currently being used in eXplainable AI systems. To achieve this goal, we design a framework and divide the use of KGs into four categories: extracting features, extracting relationships, constructing KGs, and KG reasoning. We also identify where KGs are mostly used in eXplainable AI systems (pre-model, in-model, and post-model) according to the aforementioned categories. Based on our analysis, KGs have been mainly used in pre-model XAI for feature and relation extraction. They were also utilised for inference and reasoning in post-model XAI. We found several studies that leveraged KGs to explain the XAI models in the healthcare domain."",,Systematic Review",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Language Models as Knowledge Embeddings,Structure-based methods leverage textual information and language models.,""Xintao Wang, Qi He, Jiaqing Liang, Yanghua Xiao"",International Joint Conference on Artificial Intelligence,,,10.48550/arXiv.2206.12617,,2022,3,https://doi.org/10.48550/arXiv.2206.12617,https://semanticscholar.org/paper/008caa0a964c9df6b10d2cc3b699981029f83124,""Knowledge embeddings (KE) represent a knowledge graph (KG) by embedding entities and relations into continuous vector spaces. Existing methods are mainly structure-based or description-based. Structure-based methods learn representations that preserve the inherent structure of KGs. They cannot well represent abundant long-tail entities in real-world KGs with limited structural information. Description-based methods leverage textual information and language models. Prior approaches in this direction barely outperform structure-based ones, and suffer from problems like expensive negative sampling and restrictive description demand. In this paper, we propose LMKE, which adopts Language Models to derive Knowledge Embeddings, aiming at both enriching representations of long-tail entities and solving problems of prior description-based methods. We formulate description-based KE learning with a contrastive learning framework to improve efficiency in training and evaluation. Experimental results show that LMKE achieves state-of-the-art performance on KE benchmarks of link prediction and triple classification, especially for long-tail entities."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Future Event Prediction Based on Temporal Knowledge Graph Embedding,A novel historical and concurrent events attention-aware mechanism by modeling the event knowledge graph sequence recurrently is proposed.,""Zhipeng Li, Shanshan Feng, Jun Shi, Yang Zhou, Yong Liao, Yangzhao Yang, Yangyang Li, Nenghai Yu, Xun Shao"",Computer systems science and engineering,,0.316 (14303),10.32604/csse.2023.026823,https://file.techscience.com/ueditor/files/csse/TSP_CSSE-44-3/TSP_CSSE_26823/TSP_CSSE_26823.pdf,2022,1,https://doi.org/10.32604/csse.2023.026823,https://semanticscholar.org/paper/c620d157f5f999d698f0da86fb91d267ad8ded5c,""Accurate prediction of future events brings great benefits and reduces losses for society in many domains, such as civil unrest, pandemics, and crimes. Knowledge graph is a general language for describing and modeling complex systems. Different types of events continually occur, which are often related to historical and concurrent events. In this paper, we formalize the future event prediction as a temporal knowledge graph reasoning problem. Most existing studies either conduct reasoning on static knowledge graphs or assume knowledges graphs of all timestamps are available during the training process. As a result, they cannot effectively reason over temporal knowledge graphs and predict events happening in the future. To address this problem, some recent works learn to infer future events based on historical event-based temporal knowledge graphs. However, these methods do not comprehensively consider the latent patterns and influences behind historical events and concurrent events simultaneously. This paper proposes a new graph representation learning model, namely Recurrent Event Graph ATtention Network (RE-GAT), based on a novel historical and concurrent events attention-aware mechanism by modeling the event knowledge graph sequence recurrently. More specifically, our RE-GAT",uses an attention-based histor,ical events,emb,edding,modu,le,to e,nc,"ode past events, and employs an attentionbased concurrent events embedding module to model the associations of events at the same timestamp. A translation-based decoder module and a learning objective are developed to optimize the embeddings of entities and relations. We evaluate our proposed method on four benchmark datasets. Extensive experimental results demonstrate the superiority of our RE-GAT model comparing to various baselines, which proves that our method can more accurately predict what events are going to happen."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Knowledge Graph Embedding Methods for Entity Alignment: An Experimental Review,Embedding methods have been used for entity alignment tasks.,""N. Fanourakis, Vasilis Efthymiou, D. Kotzinos, V. Christophides"",ArXiv,,,10.48550/arXiv.2203.09280,,2022,,https://doi.org/10.48550/arXiv.2203.09280,https://semanticscholar.org/paper/9f827aeea7fe134afa9fe4b36a68b0dd668bd142,""In recent years, we have witnessed the proliferation of knowledge graphs (KG) in various domains, aiming to support applications like question answering, recommendations, etc. A frequent task when integrating knowledge from different KGs is to find which subgraphs refer to the same real-world entity. Recently, embedding methods have been used for entity alignment tasks, that learn a vector-space representation of entities which preserves their similarity in the original KGs. A wide variety of supervised, unsupervised, and semi-supervised methods have been proposed that exploit both factual (attribute based) and structural information (relation based) of entities in the KGs. Still, a quantitative assessment of their strengths and weaknesses in real-world KGs according to different performance metrics and KG characteristics is missing from the literature. In this work, we conduct the first meta-level analysis of popular embedding methods for entity alignment, based on a statistically sound methodology. Our analysis reveals statistically significant correlations of different embedding methods with various meta-features extracted by KGs and rank them in a statistically significant way according to their effectiveness across all real-world KGs of our testbed. Finally, we study interesting trade-offs in terms of methods’ effectiveness and efficiency."",,Review",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"The DLCC Node Classification Benchmark for Analyzing Knowledge Graph Embeddings,Knowledge graph embeddings have gained a lot of uptake and have been heavily used in link prediction and other downstream prediction tasks.,""Jan Portisch, H. Paulheim"",International Workshop on the Semantic Web,,,10.48550/arXiv.2207.06014,,2022,1,https://doi.org/10.48550/arXiv.2207.06014,https://semanticscholar.org/paper/634cfec43844c73363e7d83e76335aa606cc9358,"". Knowledge graph embedding is a representation learning technique that projects entities and relations in a knowledge graph to continuous vector spaces. Embeddings have gained a lot of uptake and have been heavily used in link prediction and other downstream prediction tasks. Most approaches are evaluated on a single task or a single group of tasks to determine their overall performance. The evaluation is then assessed in terms of how well the embedding approach performs on the task at hand. Still, it is hardly evaluated (and often not even deeply under-stood) what information the embedding approaches are actually learning to represent. To?llthis gap, we present the DLCC (Description Logic Class Constructors) benchmark, a resource to analyze embedding approaches in terms of which kinds of classes they can represent. Two gold standards are presented, one based on the real-world knowledge graph DBpedia and one synthetic gold standard. In addition, an evaluation framework is provided that implements an experiment protocol so that researchers can directly use the gold standard. To demonstrate the use of DLCC, we compare multiple embedding approaches using the gold standards. We ?nd that many DL constructors on DBpedia are actually learned by recognizing di?erent correlated patterns rather than those de?ned in the gold standard; we further ?nd that speci?c DL constructors, such as cardinality constraints, are particularly hard to be learned for most em","bedding approaches."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Reinforcement Recommendation Reasoning through Knowledge Graphs for Explanation Path Quality,Existing explainable recommendation approaches based on KG merely optimize the selected reasoning paths for product relevance.,""Giacomo Balloccu, Ludovico Boratto, G. Fenu, M. Marras"",Knowledge-Based Systems,,2.192 (1076),10.48550/arXiv.2209.04954,,2022,1,https://doi.org/10.48550/arXiv.2209.04954,https://semanticscholar.org/paper/bd14740c229ce4cea669186b97f4a468fa0bef3e,""Numerous Knowledge Graphs (KGs) are being created to make Recommender Systems (RSs) not only intelligent but also knowl-edgeable. Integrating a KG in the recommendation process allows the underlying model to extract reasoning paths between recommended products and already experienced products from the KG. These paths can be leveraged to generate textual explanations to be provided to the user for a given recommendation. However, the existing explainable recommendation approaches based on KG merely optimize the selected reasoning paths for product relevance, without considering any user-level property of the paths for explanation. In this paper, we propose a series of quantitative properties that monitor the quality of the reasoning paths from an explanation perspective, based on recency, popularity, and diversity. We then combine in- and post-processing approaches to optimize for both recommendation quality and reasoning path quality. Experiments on three public data sets show that our approaches sig-ni?cantly increase reasoning path quality according to the proposed properties, while preserving recommendation quality. Source code, data sets, and KGs are available at https://tinyurl.com/bdbfzr4n ."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Attention-Based Relational Graph Convolutional Network for Knowledge Graph Reasoning,The attention-based relational graph convolutional network outperforms the R-GCN in entity classification and link prediction tasks.,""Junhua Duan, Yucheng Huang, Zhu Yi-an, Dong Zhong"",International Symposium on Communications and Information Technologies,,,10.1109/ISCIT55906.2022.9931190,,2022,,https://doi.org/10.1109/ISCIT55906.2022.9931190,https://semanticscholar.org/paper/0dc146a3044991231c9f48b22170811fcb4c412c,""In recent years, with the rapid growth of knowledge graphs, knowledge reasoning technology is in great demand for research. The knowledge graph is a heterogeneous network with a graph structure. Graph Convolutional Network (GCN) is an extension of traditional Convolutional Neural Network (CNN) in non-Euclidean space, very suitable for processing complex graph data. In this paper, a attention-based relational graph convolutional network (AR-GCN) is proposed. When aggregating neighbor information, the weight of neighbor nodes is adaptively assigned through the attention mechanism, so that nodes can focus on different neighbor information and enhance the accuracy of feature representation. According to the topological characteristics of different knowledge graphs, two attention mechanisms are proposed. The experimental results show that AR-GCN outperforms R-GCN in entity classification and link prediction tasks, further showing that it has stronger characterization ability."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"KGGen: A Generative Approach for Incipient Knowledge Graph Population,A generative model KGGen can generate triplets regardless of entity pair co-occurrence in the text corpus.,""Hao Chen, Chenwei Zhang, Jun Li, Philip S. Yu, N. Jing"",IEEE Transactions on Knowledge and Data Engineering,,2.431 (883),10.1109/tkde.2020.3014166,,2022,3,https://doi.org/10.1109/tkde.2020.3014166,https://semanticscholar.org/paper/addaceff526337211d202e41fb6dd326d831decf,""Knowledge graph is becoming an indispensable resource that offers structured information for numerous AI applications. However, the knowledge graph often suffers from its incompleteness. Building a complete, high-quality knowledge graph is time-consuming and requires significant human annotation efforts. In this paper, we study the Knowledge Graph Population task, which aims at extending the scale of structured knowledge, with a special focus on reducing data preparation and annotation efforts. Previous works mainly based on discriminative methods build classifiers and verify candidate triplets that are extracted from texts, which heavily rely on the quality of data collection and co-occurrance of entities in the text. However, such methods fail to generalize on entity pairs that are not highly co-occurred, and fail to discover entity pairs that are not co-occurred at all in the given text corpus. We introduce a generative perspective to approach this task and define each relationship by learning the data distribution that embodies the core common properties for relational reasoning. A generative model KGGen is proposed, which samples from the learned data distribution for each relation and can generate triplets regardless of entity pair co-occurrence in the text corpus. To further improve the generation quality while alleviate human annotation efforts, adversarial learning is adopted to not only encourage generating high quality triplets, bu",t also give model the ability,to automati,call,y asses,s th,e g,ener,at,"ion quality. Quantitative and qualitative experimental results conducted on two real-world generic knowledge graphs show that the proposed model KGGen generates novel and meaningful triplets with improved efficiency and less human annotation comparing with the state-of-the-art approaches."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Using Graph Embedding Techniques in Process-Oriented Case-Based Reasoning,The approach has promise for use in a retrieval scenario.,""Maximilian Hoffmann, R. Bergmann"",Algorithms,,0.515 (9712),10.3390/a15020027,,2022,2,https://doi.org/10.3390/a15020027,https://semanticscholar.org/paper/92500bd480ed894203948b2acdc5278d2d733106,""Similarity-based retrieval of semantic graphs is a core task of Process-Oriented Case-Based Reasoning (POCBR) with applications in real-world scenarios, e.g., in smart manufacturing. The involved similarity computation is usually complex and time-consuming, as it requires some kind of inexact graph matching. To tackle these problems, we present an approach to modeling similarity measures based on embedding semantic graphs via Graph Neural Networks (GNNs). Therefore, we first examine how arbitrary semantic graphs, including node and edge types and their knowledge-rich semantic annotations, can be encoded in a numeric format that is usable by GNNs. Given this, the architecture of two generic graph embedding models from the literature is adapted to enable their usage as a similarity measure for similarity-based retrieval. Thereby, one of the two models is more optimized towards fast similarity prediction, while the other model is optimized towards knowledge-intensive, more expressive predictions. The evaluation examines the quality and performance of these models in preselecting retrieval candidates and in approximating the ground-truth similarities of a graph-matching-based similarity measure for two semantic graph domains. The results show the great potential of the approach for use in a retrieval scenario, either as a preselection model or as an approximation of a graph similarity measure."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Graph Intention Neural Network for Knowledge Graph Reasoning,The external-intention matrix is used to learn different embeddings adapting to the different scenarios.,""Weihao Jiang, Yao Fu, Hong Zhao, Junhong Wan, Shi Pu"",IEEE International Joint Conference on Neural Network,,,10.1109/IJCNN55064.2022.9892730,,2022,,https://doi.org/10.1109/IJCNN55064.2022.9892730,https://semanticscholar.org/paper/fbd32c616c0d74aecea410594c88fdfb723e085b,""Reasoning over knowledge graph explores valuable information for amounts of tasks. However, most methods adopt the coarse-grained and single representation of each entity for reasoning, ignoring simultaneously processing various semantics contained in internal information and external information. On the one hand, the surrounding nodes and relations existing in the graph structure express the internal information of the entity, which contains abundant graph context information, but the extracted internal features are still limited. On the other hand, different scenarios as the external information focus on different aspects of the certain entity, meanwhile the external information should have message interaction with the internal information to learn the adaptive embedding, both of which are seldom considered by the existing methods. In this paper, we propose a Graph Intention Neural Network (GINN) for knowledge graph reasoning to explore fine-grained entity representations, which use external-intention and internal-intention simultaneously. For external-intention, a novel constructed matrix is used to calculate the triple-attention that determines the aggregated information to learn different embeddings adapting to the different scenarios. Furthermore, a communication bridge is leveraged to have message interaction between the external information and the internal information. For the internal-intention, the surrounding nodes and relations are integrat",ed to update the entity embedd,ing with th,e co,nsidera,tion,of,the,i,"nteraction features between the external and internal information. The triple-attention can capture relevancy among the reasoning hops, which contributes to figuring out reasonable paths. We evaluate our approach on real-world datasets, achieving better performance compared to the state-of-the-art methods and showing plausible interpretability for the results."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"KR-GCN: Knowledge-aware Reasoning with Graph Convolution Network for Explainable Recommendation,A path-level self-attention mechanism improves the relevance of the final explanation.,""Ting Ma, Longtao Huang, Qian-Ying Lu, Songlin Hu"",ACM Transactions on Information Systems,,1.585 (1912),10.1145/3511019,https://dl.acm.org/doi/pdf/10.1145/3511019,2022,1,https://doi.org/10.1145/3511019,https://semanticscholar.org/paper/e2213a6de565a97bf4820450666bd26ecb970adb,""Incorporating knowledge graphs (KGs) into recommender systems to provide explainable recommendation has attracted much attention recently. The multi-hop paths in KGs can provide auxiliary facts for improving recommendation performance as well as explainability. However, existing studies may suffer from two major challenges: error propagation and weak explainability. Considering all paths between every user-item pair might involve irrelevant ones, which leads to error propagation of user preferences. Defining meta-paths might alleviate the error propagation, but the recommendation performance would heavily depend on the pre-defined meta-paths. Some recent methods based on graph convolution network (GCN) achieve better recommendation performance, but fail to provide explainability. To tackle the above problems, we propose a novel method named Knowledge-aware Reasoning with Graph Convolution Network (KR-GCN). Specifically, to alleviate the effect of error propagation, we design a transition-based method to determine the triple-level scores and utilize nucleus sampling to select triples within the paths between every user-item pair adaptively. To improve the recommendation performance and guarantee the diversity of explanations, user-item interactions and knowledge graphs are integrated into a heterogeneous graph, which is performed with the graph convolution network. A path-level self-attention mechanism is adopted to discriminate the",contributions of different se,lected path,s an,d predi,ct t,he,inte,ra,"ction probability, which improves the relevance of the final explanation. Extensive experiments conducted on three real-world datasets show that KR-GCN consistently outperforms several state-of-the-art baselines. And human evaluation proves the superiority of KR-GCN on explainability."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Multi-level Recommendation Reasoning over Knowledge Graphs with Reinforcement Learning,A multi-level reasoning path extraction method is proposed.,""Xiting Wang, Kunpeng Liu, Dongjie Wang, Le Wu, Yanjie Fu, Xing Xie"",WWW,,,10.1145/3485447.3512083,,2022,13,https://doi.org/10.1145/3485447.3512083,https://semanticscholar.org/paper/55ffe44c1dcec3f88136d2d0c81d961da8e0e3ad,""Knowledge graphs (KGs) have been widely used to improve recommendation accuracy. The multi-hop paths on KGs also enable recommendation reasoning, which is considered a crystal type of explainability. In this paper, we propose a reinforcement learning framework for multi-level recommendation reasoning over KGs, which leverages both ontology-view and instance-view KGs to model multi-level user interests. This framework ensures convergence to a more satisfying solution by effectively transferring high-level knowledge to lower levels. Based on the framework, we propose a multi-level reasoning path extraction method, which automatically selects between high-level concepts and low-level ones to form reasoning paths that better reveal user interests. Experiments on three datasets demonstrate the effectiveness of our method."",,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Building Semantic Knowledge Graphs from (Semi-)Structured Data: A Review,Knowledge graph creation from structured and semi-structured data sources using semantic web technologies is a hot topic in public and private domains.,""Vetle Ryen, A. Soylu, D. Roman"",Future Internet,,0.793 (5815),10.3390/fi14050129,https://www.mdpi.com/1999-5903/14/5/129/pdf?version=1650782411,2022,10,https://doi.org/10.3390/fi14050129,https://semanticscholar.org/paper/39345530afee65b6b945af5f837359b41a6584a9,""Knowledge graphs have, for the past decade, been a hot topic both in public and private domains, typically used for large-scale integration and analysis of data using graph-based data models. One of the central concepts in this area is the Semantic Web, with the vision of providing a well-defined meaning to information and services on the Web through a set of standards. Particularly, linked data and ontologies have been quite essential for data sharing, discovery, integration, and reuse. In this paper, we provide a systematic literature review on knowledge graph creation from structured and semi-structured data sources using Semantic Web technologies. The review takes into account four prominent publication venues, namely, Extended Semantic Web Conference, International Semantic Web Conference, Journal of Web Semantics, and Semantic Web Journal. The review highlights the tools, methods, types of data sources, ontologies, and publication methods, together with the challenges, limitations, and lessons learned in the knowledge graph creation processes."",,Review",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Multi-Modal Knowledge Graph Construction and Application: A Survey,Multi-modal knowledge graphs are an inevitable key step towards the realization of human-level machine intelligence.,""Xiangru Zhu, Zhixu Li, Xiaodan Wang, Xueyao Jiang, Penglei Sun, Xuwu Wang, Yanghua Xiao, N. Yuan"",ArXiv,,,,,2022,4,,https://semanticscholar.org/paper/c885288bf6dbd4448ffb0317af63cee63ce6eb62,""Recent years have witnessed the resurgence of knowledge engineering which is featured by the fast growth of knowledge graphs. However, most of existing knowledge graphs are represented with pure symbols, which hurts the machine’s capability to understand the real world. The multi-modalization of knowledge graphs is an inevitable key step towards the realization of human-level machine intelligence. The results of this endeavor are Multi-modal Knowledge Graphs (MMKGs). In this survey on MMKGs constructed by texts and images, we first give definitions of MMKGs, followed with the preliminaries on multi-modal tasks and techniques. We then systematically review the challenges, progresses and opportunities on the construction and application of MMKGs respectively, with detailed analyses of the strength and weakness of different solutions. We finalize this survey with open research problems relevant to"",,Review",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Multi-Modal Knowledge Graph Construction and Application: A Survey,Multi-modal knowledge graphs are an inevitable key step towards the realization of human-level machine intelligence.,""Xiangru Zhu, Zhixu Li, Xiaodan Wang, Xueyao Jiang, Penglei Sun, Xuwu Wang, Yanghua Xiao, N. Yuan"",IEEE Transactions on Knowledge and Data Engineering,,2.431 (883),10.1109/TKDE.2022.3224228,http://arxiv.org/pdf/2202.05786,2022,14,https://doi.org/10.1109/TKDE.2022.3224228,https://semanticscholar.org/paper/fa350b1089db1f8ab97bb72287b37ed4748c89cf,""—Recent years have witnessed the resurgence of knowledge engineering which is featured by the fast growth of knowledge graphs. However, most of existing knowledge graphs are represented with pure symbols, which hurts the machine’s capability to understand the real world. The multi-modalization of knowledge graphs is an inevitable key step towards the realization of human-level machine intelligence. The results of this endeavor are Multi-modal Knowledge Graphs (MMKGs). In this survey on MMKGs constructed by texts and images, we ?rst give de?nitions of MMKGs, followed with the preliminaries on multi-modal tasks and techniques. We then systematically review the challenges, progresses and opportunities on the construction and application of MMKGs respectively, with detailed analyses of the strengths and weaknesses of different solutions. We ?nalize this survey with open research problems relevant to MMKGs."",,Review",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
